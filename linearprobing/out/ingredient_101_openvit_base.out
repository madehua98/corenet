nohup: ignoring input
2024-07-31 04:08:49 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-07-31 04:08:49 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.mode' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-31 04:08:49 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.norm_layer' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-31 04:08:49 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.use_flash_attention' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
101
2024-07-31 04:08:51 - [32m[1mINFO   [0m - Freezing module: neural_augmentor
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing module: model
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.brightness._low
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.brightness._high
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.contrast._low
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.contrast._high
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.noise._low
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.noise._high
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.class_embedding
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.patch_embedding.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.position_embedding.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.pre_layrnorm.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.pre_layrnorm.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.k_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.k_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.v_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.v_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.q_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.q_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.out_proj.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.out_proj.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc1.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc1.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm2.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm2.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.post_layernorm.weight
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Freezing parameter: model.post_layernorm.bias
2024-07-31 04:08:52 - [32m[1mINFO   [0m - Trainable parameters: ['classifier.weight', 'classifier.bias']
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - [36mModel[0m
OpenClipViT(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (position_embedding): Embedding(197, 768)
    )
    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-11): 12 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=101, bias=True)
)
[31m=================================================================[0m
                        OpenClipViT Summary
[31m=================================================================[0m
Total parameters     =   85.877 M
Total trainable parameters =    0.078 M

2024-07-31 04:08:52 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                 | #parameters or shape   | #flops    |
|:---------------------------------------|:-----------------------|:----------|
| model                                  | 85.877M                | 17.582G   |
|  neural_augmentor                      |  6                     |           |
|   neural_augmentor.brightness          |   2                    |           |
|    neural_augmentor.brightness._low    |    ()                  |           |
|    neural_augmentor.brightness._high   |    ()                  |           |
|   neural_augmentor.contrast            |   2                    |           |
|    neural_augmentor.contrast._low      |    ()                  |           |
|    neural_augmentor.contrast._high     |    ()                  |           |
|   neural_augmentor.noise               |   2                    |           |
|    neural_augmentor.noise._low         |    ()                  |           |
|    neural_augmentor.noise._high        |    ()                  |           |
|  model                                 |  85.799M               |  17.582G  |
|   model.embeddings                     |   0.742M               |   0.116G  |
|    model.embeddings.class_embedding    |    (768,)              |           |
|    model.embeddings.patch_embedding    |    0.59M               |    0.116G |
|    model.embeddings.position_embedding |    0.151M              |    0      |
|   model.pre_layrnorm                   |   1.536K               |   0.756M  |
|    model.pre_layrnorm.weight           |    (768,)              |           |
|    model.pre_layrnorm.bias             |    (768,)              |           |
|   model.encoder.layers                 |   85.054M              |   17.466G |
|    model.encoder.layers.0              |    7.088M              |    1.455G |
|    model.encoder.layers.1              |    7.088M              |    1.455G |
|    model.encoder.layers.2              |    7.088M              |    1.455G |
|    model.encoder.layers.3              |    7.088M              |    1.455G |
|    model.encoder.layers.4              |    7.088M              |    1.455G |
|    model.encoder.layers.5              |    7.088M              |    1.455G |
|    model.encoder.layers.6              |    7.088M              |    1.455G |
|    model.encoder.layers.7              |    7.088M              |    1.455G |
|    model.encoder.layers.8              |    7.088M              |    1.455G |
|    model.encoder.layers.9              |    7.088M              |    1.455G |
|    model.encoder.layers.10             |    7.088M              |    1.455G |
|    model.encoder.layers.11             |    7.088M              |    1.455G |
|   model.post_layernorm                 |   1.536K               |           |
|    model.post_layernorm.weight         |    (768,)              |           |
|    model.post_layernorm.bias           |    (768,)              |           |
|  classifier                            |  77.669K               |  77.568K  |
|   classifier.weight                    |   (101, 768)           |           |
|   classifier.bias                      |   (101,)               |           |
2024-07-31 04:08:52 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-31 04:08:52 - [33m[1mWARNING[0m - Uncalled Modules:
{'neural_augmentor.noise.min_fn', 'neural_augmentor.contrast.min_fn', 'neural_augmentor.noise.max_fn', 'neural_augmentor.contrast', 'neural_augmentor', 'model.post_layernorm', 'neural_augmentor.contrast.max_fn', 'neural_augmentor.brightness.max_fn', 'neural_augmentor.noise', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.brightness'}
2024-07-31 04:08:52 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::embedding': 1, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-31 04:08:52 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train
2024-07-31 04:08:56 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:30001
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Total number of samples: 75750
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/train_images 
	is_training=True 
	num_samples=75750
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Total number of samples: 25250
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/test_images 
	is_training=False 
	num_samples=25250
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=128
	 scales=[(224, 224, 128)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-31 04:08:59 - [34m[1mLOGS   [0m - Number of data workers: 64
101
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing module: neural_augmentor
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing module: model
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.brightness._low
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.brightness._high
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.contrast._low
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.contrast._high
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.noise._low
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: neural_augmentor.noise._high
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.class_embedding
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.patch_embedding.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.embeddings.position_embedding.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.pre_layrnorm.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.pre_layrnorm.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.0.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.1.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.2.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.3.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.4.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.5.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.6.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.7.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.8.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.9.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.10.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.k_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.k_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.v_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.v_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.q_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.q_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.out_proj.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.self_attn.out_proj.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc1.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc1.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.mlp.fc2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm2.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.encoder.layers.11.layer_norm2.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.post_layernorm.weight
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Freezing parameter: model.post_layernorm.bias
2024-07-31 04:09:03 - [32m[1mINFO   [0m - Trainable parameters: ['classifier.weight', 'classifier.bias']
2024-07-31 04:09:03 - [34m[1mLOGS   [0m - [36mModel[0m
OpenClipViT(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (position_embedding): Embedding(197, 768)
    )
    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-11): 12 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=101, bias=True)
)
[31m=================================================================[0m
                        OpenClipViT Summary
[31m=================================================================[0m
Total parameters     =   85.877 M
Total trainable parameters =    0.078 M

2024-07-31 04:09:03 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-31 04:09:03 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                 | #parameters or shape   | #flops    |
|:---------------------------------------|:-----------------------|:----------|
| model                                  | 85.877M                | 17.582G   |
|  neural_augmentor                      |  6                     |           |
|   neural_augmentor.brightness          |   2                    |           |
|    neural_augmentor.brightness._low    |    ()                  |           |
|    neural_augmentor.brightness._high   |    ()                  |           |
|   neural_augmentor.contrast            |   2                    |           |
|    neural_augmentor.contrast._low      |    ()                  |           |
|    neural_augmentor.contrast._high     |    ()                  |           |
|   neural_augmentor.noise               |   2                    |           |
|    neural_augmentor.noise._low         |    ()                  |           |
|    neural_augmentor.noise._high        |    ()                  |           |
|  model                                 |  85.799M               |  17.582G  |
|   model.embeddings                     |   0.742M               |   0.116G  |
|    model.embeddings.class_embedding    |    (768,)              |           |
|    model.embeddings.patch_embedding    |    0.59M               |    0.116G |
|    model.embeddings.position_embedding |    0.151M              |    0      |
|   model.pre_layrnorm                   |   1.536K               |   0.756M  |
|    model.pre_layrnorm.weight           |    (768,)              |           |
|    model.pre_layrnorm.bias             |    (768,)              |           |
|   model.encoder.layers                 |   85.054M              |   17.466G |
|    model.encoder.layers.0              |    7.088M              |    1.455G |
|    model.encoder.layers.1              |    7.088M              |    1.455G |
|    model.encoder.layers.2              |    7.088M              |    1.455G |
|    model.encoder.layers.3              |    7.088M              |    1.455G |
|    model.encoder.layers.4              |    7.088M              |    1.455G |
|    model.encoder.layers.5              |    7.088M              |    1.455G |
|    model.encoder.layers.6              |    7.088M              |    1.455G |
|    model.encoder.layers.7              |    7.088M              |    1.455G |
|    model.encoder.layers.8              |    7.088M              |    1.455G |
|    model.encoder.layers.9              |    7.088M              |    1.455G |
|    model.encoder.layers.10             |    7.088M              |    1.455G |
|    model.encoder.layers.11             |    7.088M              |    1.455G |
|   model.post_layernorm                 |   1.536K               |           |
|    model.post_layernorm.weight         |    (768,)              |           |
|    model.post_layernorm.bias           |    (768,)              |           |
|  classifier                            |  77.669K               |  77.568K  |
|   classifier.weight                    |   (101, 768)           |           |
|   classifier.bias                      |   (101,)               |           |
2024-07-31 04:09:04 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-31 04:09:04 - [33m[1mWARNING[0m - Uncalled Modules:
{'neural_augmentor.noise.min_fn', 'neural_augmentor.noise', 'model.post_layernorm', 'neural_augmentor.contrast.max_fn', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.contrast.min_fn', 'neural_augmentor.brightness', 'neural_augmentor.brightness.max_fn', 'neural_augmentor.noise.max_fn', 'neural_augmentor.contrast', 'neural_augmentor'}
2024-07-31 04:09:04 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::embedding': 1, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - Max. epochs for training: 30
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=5e-05
 	 max_lr=0.0005
 	 period=30
 	 warmup_init_lr=1e-05
 	 warmup_iters=500
 )
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - Loaded checkpoint from /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:09:04 - [34m[1mLOGS   [0m - Resuming training for epoch 19
2024-07-31 04:09:04 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-31 04:09:06 - [32m[1mINFO   [0m - Training epoch 19
2024-07-31 04:08:56 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:30001
101
2024-07-31 04:08:56 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:30001
101
2024-07-31 04:08:56 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:30001
101
[rank2]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2024-07-31 04:12:00 - [34m[1mLOGS   [0m - Epoch:  19 [    2814/10000000], loss: {'classification': 3.099, 'neural_augmentation': 10.0197, 'total_loss': 13.1187}, LR: [0.000183, 0.000183], Avg. batch load time: 171.566, Elapsed time: 173.79
2024-07-31 04:12:13 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 3.1359, 'neural_augmentation': 10.3562, 'total_loss': 13.4921}
2024-07-31 04:15:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 0.7348, 'neural_augmentation': 0.0, 'total_loss': 0.7348} || top1={'logits': 85.3672} || top5={'logits': 97.5156}
2024-07-31 04:15:05 - [34m[1mLOGS   [0m - Best checkpoint with score 85.37 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:15:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_84.9375.pt
2024-07-31 04:15:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.0312.pt', 'checkpoint_score_85.0898.pt', 'checkpoint_score_85.2188.pt', 'checkpoint_score_85.2539.pt', 'checkpoint_score_85.3672.pt']
2024-07-31 04:15:13 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:15:13 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:15:13 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:15:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 2961 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_19_iter_2961.pt
2024-07-31 04:15:14 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 2961 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_19_iter_2961.pt
[31m===========================================================================[0m
2024-07-31 04:15:16 - [32m[1mINFO   [0m - Training epoch 20
2024-07-31 04:15:19 - [34m[1mLOGS   [0m - Epoch:  20 [    2962/10000000], loss: {'classification': 2.9884, 'neural_augmentation': 9.8849, 'total_loss': 12.8732}, LR: [0.000162, 0.000162], Avg. batch load time: 2.765, Elapsed time:  2.95
2024-07-31 04:15:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 3.1211, 'neural_augmentation': 10.2739, 'total_loss': 13.395}
2024-07-31 04:15:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 0.7301, 'neural_augmentation': 0.0, 'total_loss': 0.7301} || top1={'logits': 85.2422} || top5={'logits': 97.5}
2024-07-31 04:15:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:15:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:15:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 3109 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_20_iter_3109.pt
2024-07-31 04:15:42 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 3109 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_20_iter_3109.pt
[31m===========================================================================[0m
2024-07-31 04:15:44 - [32m[1mINFO   [0m - Training epoch 21
2024-07-31 04:15:49 - [34m[1mLOGS   [0m - Epoch:  21 [    3110/10000000], loss: {'classification': 3.016, 'neural_augmentation': 9.7507, 'total_loss': 12.7668}, LR: [0.000143, 0.000143], Avg. batch load time: 5.517, Elapsed time:  5.60
2024-07-31 04:16:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 3.1239, 'neural_augmentation': 10.2983, 'total_loss': 13.4221}
2024-07-31 04:16:11 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 0.7246, 'neural_augmentation': 0.0, 'total_loss': 0.7246} || top1={'logits': 85.4414} || top5={'logits': 97.4961}
2024-07-31 04:16:11 - [34m[1mLOGS   [0m - Best checkpoint with score 85.44 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:16:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.0312.pt
2024-07-31 04:16:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.0898.pt', 'checkpoint_score_85.2188.pt', 'checkpoint_score_85.2539.pt', 'checkpoint_score_85.3672.pt', 'checkpoint_score_85.4414.pt']
2024-07-31 04:16:15 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:16:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:16:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:16:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 3257 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_21_iter_3257.pt
2024-07-31 04:16:18 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 3257 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_21_iter_3257.pt
[31m===========================================================================[0m
2024-07-31 04:16:20 - [32m[1mINFO   [0m - Training epoch 22
2024-07-31 04:16:22 - [34m[1mLOGS   [0m - Epoch:  22 [    3258/10000000], loss: {'classification': 3.2587, 'neural_augmentation': 11.4316, 'total_loss': 14.6903}, LR: [0.000124, 0.000124], Avg. batch load time: 1.805, Elapsed time:  1.99
2024-07-31 04:16:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 3.1252, 'neural_augmentation': 10.304, 'total_loss': 13.4292}
2024-07-31 04:16:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 0.7212, 'neural_augmentation': 0.0, 'total_loss': 0.7212} || top1={'logits': 85.4688} || top5={'logits': 97.5312}
2024-07-31 04:16:44 - [34m[1mLOGS   [0m - Best checkpoint with score 85.47 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:16:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.0898.pt
2024-07-31 04:16:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.2188.pt', 'checkpoint_score_85.2539.pt', 'checkpoint_score_85.3672.pt', 'checkpoint_score_85.4414.pt', 'checkpoint_score_85.4688.pt']
2024-07-31 04:16:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:16:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:16:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:16:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 3405 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_22_iter_3405.pt
2024-07-31 04:16:50 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 3405 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_22_iter_3405.pt
[31m===========================================================================[0m
2024-07-31 04:16:52 - [32m[1mINFO   [0m - Training epoch 23
2024-07-31 04:16:55 - [34m[1mLOGS   [0m - Epoch:  23 [    3406/10000000], loss: {'classification': 3.2331, 'neural_augmentation': 11.2576, 'total_loss': 14.4907}, LR: [0.000108, 0.000108], Avg. batch load time: 2.688, Elapsed time:  2.87
2024-07-31 04:17:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 3.1074, 'neural_augmentation': 10.164, 'total_loss': 13.2715}
2024-07-31 04:17:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 0.7181, 'neural_augmentation': 0.0, 'total_loss': 0.7181} || top1={'logits': 85.5234} || top5={'logits': 97.5117}
2024-07-31 04:17:16 - [34m[1mLOGS   [0m - Best checkpoint with score 85.52 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:17:16 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.2188.pt
2024-07-31 04:17:16 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.2539.pt', 'checkpoint_score_85.3672.pt', 'checkpoint_score_85.4414.pt', 'checkpoint_score_85.4688.pt', 'checkpoint_score_85.5234.pt']
2024-07-31 04:17:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:17:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:17:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:17:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 3553 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_23_iter_3553.pt
2024-07-31 04:17:23 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 3553 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_23_iter_3553.pt
[31m===========================================================================[0m
2024-07-31 04:17:25 - [32m[1mINFO   [0m - Training epoch 24
2024-07-31 04:17:28 - [34m[1mLOGS   [0m - Epoch:  24 [    3554/10000000], loss: {'classification': 3.2036, 'neural_augmentation': 11.4261, 'total_loss': 14.6296}, LR: [9.3e-05, 9.3e-05], Avg. batch load time: 2.806, Elapsed time:  2.94
2024-07-31 04:17:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 3.1048, 'neural_augmentation': 10.1673, 'total_loss': 13.2722}
2024-07-31 04:17:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 0.7153, 'neural_augmentation': 0.0, 'total_loss': 0.7153} || top1={'logits': 85.5664} || top5={'logits': 97.5195}
2024-07-31 04:17:49 - [34m[1mLOGS   [0m - Best checkpoint with score 85.57 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:17:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.2539.pt
2024-07-31 04:17:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.3672.pt', 'checkpoint_score_85.4414.pt', 'checkpoint_score_85.4688.pt', 'checkpoint_score_85.5234.pt', 'checkpoint_score_85.5664.pt']
2024-07-31 04:17:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:17:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:17:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:17:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 3701 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_24_iter_3701.pt
2024-07-31 04:17:55 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 3701 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_24_iter_3701.pt
[31m===========================================================================[0m
2024-07-31 04:17:57 - [32m[1mINFO   [0m - Training epoch 25
2024-07-31 04:18:00 - [34m[1mLOGS   [0m - Epoch:  25 [    3702/10000000], loss: {'classification': 3.2539, 'neural_augmentation': 11.3243, 'total_loss': 14.5782}, LR: [8e-05, 8e-05], Avg. batch load time: 2.043, Elapsed time:  2.13
2024-07-31 04:18:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 3.121, 'neural_augmentation': 10.2729, 'total_loss': 13.3939}
2024-07-31 04:18:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 0.7128, 'neural_augmentation': 0.0, 'total_loss': 0.7128} || top1={'logits': 85.5938} || top5={'logits': 97.5508}
2024-07-31 04:18:21 - [34m[1mLOGS   [0m - Best checkpoint with score 85.59 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:18:21 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.3672.pt
2024-07-31 04:18:21 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.4414.pt', 'checkpoint_score_85.4688.pt', 'checkpoint_score_85.5234.pt', 'checkpoint_score_85.5664.pt', 'checkpoint_score_85.5938.pt']
2024-07-31 04:18:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:18:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:18:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:18:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 3849 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_25_iter_3849.pt
2024-07-31 04:18:27 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 3849 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_25_iter_3849.pt
[31m===========================================================================[0m
2024-07-31 04:18:29 - [32m[1mINFO   [0m - Training epoch 26
2024-07-31 04:18:32 - [34m[1mLOGS   [0m - Epoch:  26 [    3850/10000000], loss: {'classification': 3.0234, 'neural_augmentation': 9.252, 'total_loss': 12.2754}, LR: [6.9e-05, 6.9e-05], Avg. batch load time: 2.334, Elapsed time:  2.42
2024-07-31 04:18:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 3.1103, 'neural_augmentation': 10.1723, 'total_loss': 13.2826}
2024-07-31 04:18:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 0.711, 'neural_augmentation': 0.0, 'total_loss': 0.711} || top1={'logits': 85.6367} || top5={'logits': 97.5391}
2024-07-31 04:18:53 - [34m[1mLOGS   [0m - Best checkpoint with score 85.64 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:18:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.4414.pt
2024-07-31 04:18:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.4688.pt', 'checkpoint_score_85.5234.pt', 'checkpoint_score_85.5664.pt', 'checkpoint_score_85.5938.pt', 'checkpoint_score_85.6367.pt']
2024-07-31 04:18:56 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:18:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:18:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:18:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 3997 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_26_iter_3997.pt
2024-07-31 04:19:00 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 3997 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_26_iter_3997.pt
[31m===========================================================================[0m
2024-07-31 04:19:02 - [32m[1mINFO   [0m - Training epoch 27
2024-07-31 04:19:05 - [34m[1mLOGS   [0m - Epoch:  27 [    3998/10000000], loss: {'classification': 3.1415, 'neural_augmentation': 10.3953, 'total_loss': 13.5368}, LR: [6.1e-05, 6.1e-05], Avg. batch load time: 2.853, Elapsed time:  2.94
2024-07-31 04:19:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 3.1145, 'neural_augmentation': 10.2591, 'total_loss': 13.3736}
2024-07-31 04:19:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 0.7096, 'neural_augmentation': 0.0, 'total_loss': 0.7096} || top1={'logits': 85.6133} || top5={'logits': 97.5273}
2024-07-31 04:19:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:19:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:19:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 4145 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_27_iter_4145.pt
2024-07-31 04:19:26 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 4145 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_27_iter_4145.pt
[31m===========================================================================[0m
2024-07-31 04:19:28 - [32m[1mINFO   [0m - Training epoch 28
2024-07-31 04:19:34 - [34m[1mLOGS   [0m - Epoch:  28 [    4146/10000000], loss: {'classification': 3.0108, 'neural_augmentation': 9.0831, 'total_loss': 12.0939}, LR: [5.5e-05, 5.5e-05], Avg. batch load time: 5.725, Elapsed time:  5.81
2024-07-31 04:19:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 3.1097, 'neural_augmentation': 10.1761, 'total_loss': 13.2858}
2024-07-31 04:19:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 0.708, 'neural_augmentation': 0.0, 'total_loss': 0.708} || top1={'logits': 85.7227} || top5={'logits': 97.5469}
2024-07-31 04:19:55 - [34m[1mLOGS   [0m - Best checkpoint with score 85.72 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_best.pt
2024-07-31 04:19:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_score_85.4688.pt
2024-07-31 04:19:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_85.5234.pt', 'checkpoint_score_85.5664.pt', 'checkpoint_score_85.5938.pt', 'checkpoint_score_85.6367.pt', 'checkpoint_score_85.7227.pt']
2024-07-31 04:20:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_avg.pt
2024-07-31 04:20:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:20:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:20:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 4293 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_28_iter_4293.pt
2024-07-31 04:20:03 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 4293 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_28_iter_4293.pt
[31m===========================================================================[0m
2024-07-31 04:20:05 - [32m[1mINFO   [0m - Training epoch 29
2024-07-31 04:20:07 - [34m[1mLOGS   [0m - Epoch:  29 [    4294/10000000], loss: {'classification': 3.1258, 'neural_augmentation': 9.0912, 'total_loss': 12.217}, LR: [5.1e-05, 5.1e-05], Avg. batch load time: 2.080, Elapsed time:  2.16
2024-07-31 04:20:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 3.1084, 'neural_augmentation': 10.1758, 'total_loss': 13.2842}
2024-07-31 04:20:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 0.7069, 'neural_augmentation': 0.0, 'total_loss': 0.7069} || top1={'logits': 85.6719} || top5={'logits': 97.543}
2024-07-31 04:20:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_last.pt
2024-07-31 04:20:31 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_last.pt
2024-07-31 04:20:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 4441 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/training_checkpoint_epoch_29_iter_4441.pt
2024-07-31 04:20:31 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 4441 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient101_lp/train/checkpoint_epoch_29_iter_4441.pt
2024-07-31 04:20:31 - [34m[1mLOGS   [0m - Training took 00:11:26.73
