nohup: ignoring input
2024-08-08 12:44:44 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-08-08 12:44:45 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_19_iter_162435.pt
2024-08-08 12:44:45 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-08 12:44:45 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=172, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =  102.564 M
Total trainable parameters =  102.564 M

2024-08-08 12:44:45 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-08 12:44:45 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.103G                 | 13.398G    |
|  pos_embed                           |  (1, 1, 512)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  3.653M                |  5.52G     |
|   patch_embed.backbone.stem          |   0.151M               |   1.901G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    43.352M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    8.028M  |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    1.85G   |
|   patch_embed.backbone.stages        |   2.321M               |   3.387G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.478G  |
|    patch_embed.backbone.stages.1     |    2.047M              |    1.909G  |
|   patch_embed.backbone.pool          |   1.181M               |   0.232G   |
|    patch_embed.backbone.pool.proj    |    1.18M               |    0.231G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.004M  |
|  blocks                              |  18.404M               |  3.607G    |
|   blocks.0                           |   2.629M               |   0.515G   |
|    blocks.0.norm1                    |    1.024K              |    0.502M  |
|    blocks.0.attn                     |    1.051M              |    0.206G  |
|    blocks.0.norm2                    |    1.024K              |    0.502M  |
|    blocks.0.mlp                      |    1.576M              |    0.309G  |
|   blocks.1                           |   2.629M               |   0.515G   |
|    blocks.1.norm1                    |    1.024K              |    0.502M  |
|    blocks.1.attn                     |    1.051M              |    0.206G  |
|    blocks.1.norm2                    |    1.024K              |    0.502M  |
|    blocks.1.mlp                      |    1.576M              |    0.309G  |
|   blocks.2                           |   2.629M               |   0.515G   |
|    blocks.2.norm1                    |    1.024K              |    0.502M  |
|    blocks.2.attn                     |    1.051M              |    0.206G  |
|    blocks.2.norm2                    |    1.024K              |    0.502M  |
|    blocks.2.mlp                      |    1.576M              |    0.309G  |
|   blocks.3                           |   2.629M               |   0.515G   |
|    blocks.3.norm1                    |    1.024K              |    0.502M  |
|    blocks.3.attn                     |    1.051M              |    0.206G  |
|    blocks.3.norm2                    |    1.024K              |    0.502M  |
|    blocks.3.mlp                      |    1.576M              |    0.309G  |
|   blocks.4                           |   2.629M               |   0.515G   |
|    blocks.4.norm1                    |    1.024K              |    0.502M  |
|    blocks.4.attn                     |    1.051M              |    0.206G  |
|    blocks.4.norm2                    |    1.024K              |    0.502M  |
|    blocks.4.mlp                      |    1.576M              |    0.309G  |
|   blocks.5                           |   2.629M               |   0.515G   |
|    blocks.5.norm1                    |    1.024K              |    0.502M  |
|    blocks.5.attn                     |    1.051M              |    0.206G  |
|    blocks.5.norm2                    |    1.024K              |    0.502M  |
|    blocks.5.mlp                      |    1.576M              |    0.309G  |
|   blocks.6                           |   2.629M               |   0.515G   |
|    blocks.6.norm1                    |    1.024K              |    0.502M  |
|    blocks.6.attn                     |    1.051M              |    0.206G  |
|    blocks.6.norm2                    |    1.024K              |    0.502M  |
|    blocks.6.mlp                      |    1.576M              |    0.309G  |
|  pool                                |  4.721M                |  0.463G    |
|   pool.proj                          |   4.72M                |   0.462G   |
|    pool.proj.weight                  |    (1024, 512, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.024K               |   1.004M   |
|    pool.norm.weight                  |    (512,)              |            |
|    pool.norm.bias                    |    (512,)              |            |
|  blocks1                             |  73.508M               |  3.602G    |
|   blocks1.0                          |   10.501M              |   0.515G   |
|    blocks1.0.norm1                   |    2.048K              |    0.251M  |
|    blocks1.0.attn                    |    4.198M              |    0.206G  |
|    blocks1.0.norm2                   |    2.048K              |    0.251M  |
|    blocks1.0.mlp                     |    6.299M              |    0.309G  |
|   blocks1.1                          |   10.501M              |   0.515G   |
|    blocks1.1.norm1                   |    2.048K              |    0.251M  |
|    blocks1.1.attn                    |    4.198M              |    0.206G  |
|    blocks1.1.norm2                   |    2.048K              |    0.251M  |
|    blocks1.1.mlp                     |    6.299M              |    0.309G  |
|   blocks1.2                          |   10.501M              |   0.515G   |
|    blocks1.2.norm1                   |    2.048K              |    0.251M  |
|    blocks1.2.attn                    |    4.198M              |    0.206G  |
|    blocks1.2.norm2                   |    2.048K              |    0.251M  |
|    blocks1.2.mlp                     |    6.299M              |    0.309G  |
|   blocks1.3                          |   10.501M              |   0.515G   |
|    blocks1.3.norm1                   |    2.048K              |    0.251M  |
|    blocks1.3.attn                    |    4.198M              |    0.206G  |
|    blocks1.3.norm2                   |    2.048K              |    0.251M  |
|    blocks1.3.mlp                     |    6.299M              |    0.309G  |
|   blocks1.4                          |   10.501M              |   0.515G   |
|    blocks1.4.norm1                   |    2.048K              |    0.251M  |
|    blocks1.4.attn                    |    4.198M              |    0.206G  |
|    blocks1.4.norm2                   |    2.048K              |    0.251M  |
|    blocks1.4.mlp                     |    6.299M              |    0.309G  |
|   blocks1.5                          |   10.501M              |   0.515G   |
|    blocks1.5.norm1                   |    2.048K              |    0.251M  |
|    blocks1.5.attn                    |    4.198M              |    0.206G  |
|    blocks1.5.norm2                   |    2.048K              |    0.251M  |
|    blocks1.5.mlp                     |    6.299M              |    0.309G  |
|   blocks1.6                          |   10.501M              |   0.515G   |
|    blocks1.6.norm1                   |    2.048K              |    0.251M  |
|    blocks1.6.attn                    |    4.198M              |    0.206G  |
|    blocks1.6.norm2                   |    2.048K              |    0.251M  |
|    blocks1.6.mlp                     |    6.299M              |    0.309G  |
|  mlp                                 |  2.099M                |  0.206G    |
|   mlp.0                              |   1.05M                |   0.103G   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   0.103G   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  0.176M                |  0.176M    |
|   classifier.weight                  |   (172, 1024)          |            |
|   classifier.bias                    |   (172,)               |            |
2024-08-08 12:44:46 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-08 12:44:46 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.5.attn.k_norm', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stem.norm1.drop', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks1.0.attn.k_norm', 'patch_embed.backbone.stages.0.0.down', 'neural_augmentor.contrast', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks1.1.ls1', 'blocks1.2.drop_path1', 'blocks1.6.attn.q_norm', 'blocks1.2.drop_path2', 'blocks1.6.ls1', 'blocks1.5.attn.q_norm', 'blocks.6.attn.k_norm', 'blocks.4.attn.q_norm', 'blocks1.5.drop_path2', 'blocks1.4.attn.k_norm', 'blocks.3.attn.k_norm', 'blocks.4.ls2', 'blocks1.4.attn.attn_drop', 'blocks1.4.drop_path1', 'blocks.0.ls2', 'blocks1.0.attn.attn_drop', 'blocks.1.attn.attn_drop', 'blocks.3.ls2', 'blocks.6.ls1', 'blocks.5.attn.q_norm', 'blocks1.0.attn.q_norm', 'blocks.3.attn.attn_drop', 'blocks.3.drop_path2', 'blocks1.3.ls1', 'blocks.4.drop_path1', 'blocks1.5.attn.attn_drop', 'blocks.1.drop_path2', 'blocks.1.ls1', 'blocks.2.drop_path1', 'blocks.0.attn.k_norm', 'blocks.2.ls2', 'blocks1.2.ls1', 'patch_embed.backbone.stages.1.2.drop_path', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.0.drop_path1', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.1.drop_path', 'patch_embed.backbone.stages.0.1.shortcut', 'patch_embed.backbone.stages.1.3.down', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'neural_augmentor', 'neural_augmentor.brightness.min_fn', 'norm_pre', 'blocks.2.attn.q_norm', 'blocks1.2.attn.q_norm', 'blocks1.1.drop_path1', 'blocks1.3.attn.k_norm', 'patch_embed.backbone.stages.1.1.down', 'patch_drop', 'patch_embed.backbone.stages.0.1.down', 'blocks1.3.drop_path2', 'blocks1.0.ls2', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks1.1.attn.q_norm', 'blocks.1.attn.k_norm', 'blocks1.1.attn.k_norm', 'blocks.3.attn.q_norm', 'blocks.5.ls2', 'neural_augmentor.noise', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.6.attn.q_norm', 'blocks.5.drop_path1', 'blocks1.3.attn.q_norm', 'blocks1.6.drop_path1', 'blocks1.0.drop_path1', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks1.6.attn.attn_drop', 'blocks.6.drop_path1', 'patch_embed.backbone.stages.1.2.down', 'blocks1.1.attn.attn_drop', 'blocks1.5.drop_path1', 'blocks.4.attn.attn_drop', 'patch_embed.proj', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks1.5.attn.k_norm', 'blocks.4.ls1', 'blocks1.6.attn.k_norm', 'blocks1.4.ls1', 'blocks.3.ls1', 'patch_embed.backbone.stages.1.1.shortcut', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks1.5.ls1', 'blocks.4.drop_path2', 'blocks1.2.attn.attn_drop', 'neural_augmentor.contrast.max_fn', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.1.0.drop_path', 'neural_augmentor.brightness', 'blocks1.1.drop_path2', 'blocks1.3.ls2', 'blocks.5.attn.attn_drop', 'blocks.6.ls2', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks1.2.attn.k_norm', 'blocks1.3.attn.attn_drop', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks1.6.drop_path2', 'blocks.0.drop_path2', 'blocks.1.attn.q_norm', 'blocks1.4.ls2', 'blocks1.3.drop_path1', 'blocks.2.attn.k_norm', 'blocks.2.ls1', 'blocks.5.ls1', 'blocks1.0.drop_path2', 'neural_augmentor.noise.max_fn', 'blocks1.0.ls1', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.0.ls1', 'blocks.0.attn.q_norm', 'blocks.6.attn.attn_drop', 'blocks.1.drop_path1', 'blocks.4.attn.k_norm', 'blocks.6.drop_path2', 'patch_embed.backbone.stages.1.0.down', 'blocks.5.drop_path2', 'blocks.3.drop_path1', 'blocks.2.drop_path2', 'blocks1.5.ls2', 'blocks1.1.ls2', 'blocks.1.ls2', 'neural_augmentor.brightness.max_fn', 'neural_augmentor.contrast.min_fn', 'blocks1.2.ls2', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.6.ls2', 'blocks.0.attn.attn_drop', 'blocks1.4.attn.q_norm', 'norm'}
2024-08-08 12:44:46 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::add_': 14, 'aten::avg_pool2d': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-08-08 12:44:46 - [34m[1mLOGS   [0m - Directory created at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train
2024-08-08 12:44:50 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40000
base
dci
2024-08-08 12:44:50 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40000
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Number of categories: 172
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Total number of samples: 66071
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food172/food_172/train_images 
	is_training=True 
	num_samples=66071
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=172
)
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Number of categories: 172
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Total number of samples: 44170
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food172/food_172/test_images 
	is_training=False 
	num_samples=44170
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=172
)
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=64
	 scales=[(128, 128, 196), (160, 160, 125), (192, 192, 87), (224, 224, 64), (256, 256, 49), (288, 288, 38), (320, 320, 31)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-08-08 12:44:53 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-08-08 12:44:57 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_19_iter_162435.pt
2024-08-08 12:44:57 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-08 12:44:57 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=172, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =  102.564 M
Total trainable parameters =  102.564 M

2024-08-08 12:44:57 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-08 12:44:57 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.103G                 | 13.398G    |
|  pos_embed                           |  (1, 1, 512)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  3.653M                |  5.52G     |
|   patch_embed.backbone.stem          |   0.151M               |   1.901G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    43.352M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    8.028M  |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    1.85G   |
|   patch_embed.backbone.stages        |   2.321M               |   3.387G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.478G  |
|    patch_embed.backbone.stages.1     |    2.047M              |    1.909G  |
|   patch_embed.backbone.pool          |   1.181M               |   0.232G   |
|    patch_embed.backbone.pool.proj    |    1.18M               |    0.231G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.004M  |
|  blocks                              |  18.404M               |  3.607G    |
|   blocks.0                           |   2.629M               |   0.515G   |
|    blocks.0.norm1                    |    1.024K              |    0.502M  |
|    blocks.0.attn                     |    1.051M              |    0.206G  |
|    blocks.0.norm2                    |    1.024K              |    0.502M  |
|    blocks.0.mlp                      |    1.576M              |    0.309G  |
|   blocks.1                           |   2.629M               |   0.515G   |
|    blocks.1.norm1                    |    1.024K              |    0.502M  |
|    blocks.1.attn                     |    1.051M              |    0.206G  |
|    blocks.1.norm2                    |    1.024K              |    0.502M  |
|    blocks.1.mlp                      |    1.576M              |    0.309G  |
|   blocks.2                           |   2.629M               |   0.515G   |
|    blocks.2.norm1                    |    1.024K              |    0.502M  |
|    blocks.2.attn                     |    1.051M              |    0.206G  |
|    blocks.2.norm2                    |    1.024K              |    0.502M  |
|    blocks.2.mlp                      |    1.576M              |    0.309G  |
|   blocks.3                           |   2.629M               |   0.515G   |
|    blocks.3.norm1                    |    1.024K              |    0.502M  |
|    blocks.3.attn                     |    1.051M              |    0.206G  |
|    blocks.3.norm2                    |    1.024K              |    0.502M  |
|    blocks.3.mlp                      |    1.576M              |    0.309G  |
|   blocks.4                           |   2.629M               |   0.515G   |
|    blocks.4.norm1                    |    1.024K              |    0.502M  |
|    blocks.4.attn                     |    1.051M              |    0.206G  |
|    blocks.4.norm2                    |    1.024K              |    0.502M  |
|    blocks.4.mlp                      |    1.576M              |    0.309G  |
|   blocks.5                           |   2.629M               |   0.515G   |
|    blocks.5.norm1                    |    1.024K              |    0.502M  |
|    blocks.5.attn                     |    1.051M              |    0.206G  |
|    blocks.5.norm2                    |    1.024K              |    0.502M  |
|    blocks.5.mlp                      |    1.576M              |    0.309G  |
|   blocks.6                           |   2.629M               |   0.515G   |
|    blocks.6.norm1                    |    1.024K              |    0.502M  |
|    blocks.6.attn                     |    1.051M              |    0.206G  |
|    blocks.6.norm2                    |    1.024K              |    0.502M  |
|    blocks.6.mlp                      |    1.576M              |    0.309G  |
|  pool                                |  4.721M                |  0.463G    |
|   pool.proj                          |   4.72M                |   0.462G   |
|    pool.proj.weight                  |    (1024, 512, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.024K               |   1.004M   |
|    pool.norm.weight                  |    (512,)              |            |
|    pool.norm.bias                    |    (512,)              |            |
|  blocks1                             |  73.508M               |  3.602G    |
|   blocks1.0                          |   10.501M              |   0.515G   |
|    blocks1.0.norm1                   |    2.048K              |    0.251M  |
|    blocks1.0.attn                    |    4.198M              |    0.206G  |
|    blocks1.0.norm2                   |    2.048K              |    0.251M  |
|    blocks1.0.mlp                     |    6.299M              |    0.309G  |
|   blocks1.1                          |   10.501M              |   0.515G   |
|    blocks1.1.norm1                   |    2.048K              |    0.251M  |
|    blocks1.1.attn                    |    4.198M              |    0.206G  |
|    blocks1.1.norm2                   |    2.048K              |    0.251M  |
|    blocks1.1.mlp                     |    6.299M              |    0.309G  |
|   blocks1.2                          |   10.501M              |   0.515G   |
|    blocks1.2.norm1                   |    2.048K              |    0.251M  |
|    blocks1.2.attn                    |    4.198M              |    0.206G  |
|    blocks1.2.norm2                   |    2.048K              |    0.251M  |
|    blocks1.2.mlp                     |    6.299M              |    0.309G  |
|   blocks1.3                          |   10.501M              |   0.515G   |
|    blocks1.3.norm1                   |    2.048K              |    0.251M  |
|    blocks1.3.attn                    |    4.198M              |    0.206G  |
|    blocks1.3.norm2                   |    2.048K              |    0.251M  |
|    blocks1.3.mlp                     |    6.299M              |    0.309G  |
|   blocks1.4                          |   10.501M              |   0.515G   |
|    blocks1.4.norm1                   |    2.048K              |    0.251M  |
|    blocks1.4.attn                    |    4.198M              |    0.206G  |
|    blocks1.4.norm2                   |    2.048K              |    0.251M  |
|    blocks1.4.mlp                     |    6.299M              |    0.309G  |
|   blocks1.5                          |   10.501M              |   0.515G   |
|    blocks1.5.norm1                   |    2.048K              |    0.251M  |
|    blocks1.5.attn                    |    4.198M              |    0.206G  |
|    blocks1.5.norm2                   |    2.048K              |    0.251M  |
|    blocks1.5.mlp                     |    6.299M              |    0.309G  |
|   blocks1.6                          |   10.501M              |   0.515G   |
|    blocks1.6.norm1                   |    2.048K              |    0.251M  |
|    blocks1.6.attn                    |    4.198M              |    0.206G  |
|    blocks1.6.norm2                   |    2.048K              |    0.251M  |
|    blocks1.6.mlp                     |    6.299M              |    0.309G  |
|  mlp                                 |  2.099M                |  0.206G    |
|   mlp.0                              |   1.05M                |   0.103G   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   0.103G   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  0.176M                |  0.176M    |
|   classifier.weight                  |   (172, 1024)          |            |
|   classifier.bias                    |   (172,)               |            |
2024-08-08 12:44:58 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-08 12:44:58 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.0.ls2', 'blocks1.3.drop_path1', 'blocks1.2.drop_path2', 'blocks.4.drop_path2', 'blocks.3.drop_path2', 'blocks1.1.ls1', 'blocks.1.drop_path2', 'blocks1.5.ls2', 'blocks.2.ls2', 'patch_embed.backbone.stages.0.0.down', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks.0.attn.attn_drop', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'neural_augmentor.contrast.min_fn', 'blocks1.3.ls2', 'patch_embed.backbone.stages.1.2.down', 'blocks.6.attn.k_norm', 'blocks1.1.attn.k_norm', 'blocks.4.ls2', 'blocks.1.ls1', 'blocks.4.attn.k_norm', 'blocks1.6.attn.attn_drop', 'neural_augmentor.brightness.max_fn', 'blocks.0.drop_path1', 'blocks1.6.attn.k_norm', 'blocks1.1.drop_path1', 'blocks1.1.drop_path2', 'blocks.6.ls1', 'patch_embed.backbone.stages.1.1.drop_path', 'neural_augmentor.brightness', 'blocks1.0.ls1', 'patch_embed.backbone.stages.1.3.down', 'blocks.5.attn.k_norm', 'patch_embed.backbone.stages.1.0.drop_path', 'patch_embed.backbone.stem.norm1.drop', 'blocks.1.attn.q_norm', 'blocks1.0.attn.k_norm', 'blocks1.6.ls2', 'blocks.3.drop_path1', 'blocks.1.attn.attn_drop', 'blocks1.4.ls1', 'blocks.6.drop_path1', 'blocks.5.ls1', 'blocks.4.attn.q_norm', 'patch_embed.backbone.stages.1.2.drop_path', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.5.ls2', 'neural_augmentor.contrast', 'blocks.3.attn.k_norm', 'blocks1.2.drop_path1', 'blocks.3.attn.q_norm', 'blocks1.4.ls2', 'neural_augmentor.noise.min_fn', 'blocks1.2.attn.k_norm', 'blocks.6.attn.attn_drop', 'blocks.1.ls2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.2.drop_path1', 'blocks1.3.attn.k_norm', 'neural_augmentor.brightness.min_fn', 'patch_embed.backbone.stages.1.0.down', 'blocks1.6.ls1', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.3.drop_path2', 'blocks.0.attn.k_norm', 'blocks1.1.attn.attn_drop', 'blocks.6.drop_path2', 'blocks1.5.attn.k_norm', 'norm', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'neural_augmentor.noise.max_fn', 'blocks1.2.ls2', 'blocks1.4.drop_path1', 'blocks.2.ls1', 'blocks1.6.drop_path1', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks1.4.attn.q_norm', 'blocks.3.ls2', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks1.4.attn.k_norm', 'norm_pre', 'blocks.2.attn.q_norm', 'patch_embed.proj', 'blocks1.0.attn.q_norm', 'blocks.0.drop_path2', 'blocks1.1.ls2', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks1.2.attn.attn_drop', 'blocks1.5.ls1', 'blocks1.6.drop_path2', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.3.ls1', 'blocks.5.attn.attn_drop', 'blocks.3.ls1', 'blocks1.5.attn.attn_drop', 'blocks1.2.attn.q_norm', 'blocks.1.attn.k_norm', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'neural_augmentor', 'blocks.2.attn.k_norm', 'blocks1.2.ls1', 'neural_augmentor.noise', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks.5.attn.q_norm', 'blocks1.6.attn.q_norm', 'blocks1.0.ls2', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.4.attn.attn_drop', 'blocks1.3.attn.attn_drop', 'blocks.0.ls1', 'blocks.0.attn.q_norm', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.0.1.down', 'blocks.5.drop_path2', 'blocks.2.attn.attn_drop', 'blocks1.0.attn.attn_drop', 'blocks.2.drop_path2', 'blocks1.4.attn.attn_drop', 'blocks.4.drop_path1', 'blocks1.5.drop_path1', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'patch_embed.backbone.stages.1.1.down', 'blocks1.3.attn.q_norm', 'blocks1.5.drop_path2', 'blocks.6.ls2', 'blocks1.1.attn.q_norm', 'blocks.1.drop_path1', 'neural_augmentor.contrast.max_fn', 'blocks.3.attn.attn_drop', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'patch_embed.backbone.stages.0.1.shortcut', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks1.0.drop_path1', 'blocks.4.ls1', 'blocks.5.drop_path1', 'blocks1.0.drop_path2', 'patch_drop'}
2024-08-08 12:44:58 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::add_': 14, 'aten::avg_pool2d': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - Max. epochs for training: 30
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=30
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-08-08 12:44:58 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt'
2024-08-08 12:44:58 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-08 12:45:00 - [32m[1mINFO   [0m - Training epoch 0
2024-08-08 12:44:50 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40000
base
dci
2024-08-08 12:44:50 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40000
base
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-08-08 12:47:38 - [34m[1mLOGS   [0m - Epoch:   0 [       0/10000000], loss: {'classification': 6.9451, 'neural_augmentation': 0.3697, 'total_loss': 7.3148}, LR: [1e-06, 1e-06], Avg. batch load time: 156.156, Elapsed time: 157.94
2024-08-08 12:48:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 6.0258, 'neural_augmentation': 0.3578, 'total_loss': 6.3835}
2024-08-08 12:51:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 4.6541, 'neural_augmentation': 0.0, 'total_loss': 4.6541} || top1={'logits': 10.5631} || top5={'logits': 23.527}
2024-08-08 12:51:04 - [34m[1mLOGS   [0m - Best checkpoint with score 10.56 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:51:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:51:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:51:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 95 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_0_iter_95.pt
2024-08-08 12:51:08 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 95 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_0_iter_95.pt
[31m===========================================================================[0m
2024-08-08 12:51:10 - [32m[1mINFO   [0m - Training epoch 1
2024-08-08 12:51:11 - [34m[1mLOGS   [0m - Epoch:   1 [      95/10000000], loss: {'classification': 4.7585, 'neural_augmentation': 0.32, 'total_loss': 5.0785}, LR: [7e-06, 7e-06], Avg. batch load time: 0.301, Elapsed time:  0.46
2024-08-08 12:51:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 2.8816, 'neural_augmentation': 0.359, 'total_loss': 3.2405}
2024-08-08 12:51:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 0.7432, 'neural_augmentation': 0.0, 'total_loss': 0.7432} || top1={'logits': 83.0901} || top5={'logits': 95.6802}
2024-08-08 12:51:57 - [34m[1mLOGS   [0m - Best checkpoint with score 83.09 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:51:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:51:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:52:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 191 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_1_iter_191.pt
2024-08-08 12:52:01 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 191 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_1_iter_191.pt
[31m===========================================================================[0m
2024-08-08 12:52:03 - [32m[1mINFO   [0m - Training epoch 2
2024-08-08 12:52:04 - [34m[1mLOGS   [0m - Epoch:   2 [     191/10000000], loss: {'classification': 1.7439, 'neural_augmentation': 0.3561, 'total_loss': 2.1}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 1.021, Elapsed time:  1.18
2024-08-08 12:52:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 1.5518, 'neural_augmentation': 0.3538, 'total_loss': 1.9057}
2024-08-08 12:52:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 0.4972, 'neural_augmentation': 0.0, 'total_loss': 0.4972} || top1={'logits': 89.3221} || top5={'logits': 98.1982}
2024-08-08 12:52:55 - [34m[1mLOGS   [0m - Best checkpoint with score 89.32 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:52:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:52:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:52:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 298 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_2_iter_298.pt
2024-08-08 12:52:59 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 298 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_2_iter_298.pt
[31m===========================================================================[0m
2024-08-08 12:53:01 - [32m[1mINFO   [0m - Training epoch 3
2024-08-08 12:53:01 - [34m[1mLOGS   [0m - Epoch:   3 [     298/10000000], loss: {'classification': 1.3072, 'neural_augmentation': 0.3566, 'total_loss': 1.6639}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 0.237, Elapsed time:  0.41
2024-08-08 12:53:35 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 1.3689, 'neural_augmentation': 0.3483, 'total_loss': 1.7172}
2024-08-08 12:53:49 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 0.4412, 'neural_augmentation': 0.0, 'total_loss': 0.4412} || top1={'logits': 90.8041} || top5={'logits': 98.6396}
2024-08-08 12:53:50 - [34m[1mLOGS   [0m - Best checkpoint with score 90.80 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:53:51 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:53:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:53:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 399 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_3_iter_399.pt
2024-08-08 12:53:54 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 399 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_3_iter_399.pt
[31m===========================================================================[0m
2024-08-08 12:53:56 - [32m[1mINFO   [0m - Training epoch 4
2024-08-08 12:54:00 - [34m[1mLOGS   [0m - Epoch:   4 [     399/10000000], loss: {'classification': 1.3516, 'neural_augmentation': 0.336, 'total_loss': 1.6876}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 4.290, Elapsed time:  4.46
2024-08-08 12:54:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 1.2725, 'neural_augmentation': 0.3419, 'total_loss': 1.6144}
2024-08-08 12:54:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 0.4128, 'neural_augmentation': 0.0, 'total_loss': 0.4128} || top1={'logits': 91.9955} || top5={'logits': 98.9572}
2024-08-08 12:54:50 - [34m[1mLOGS   [0m - Best checkpoint with score 92.00 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:54:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:54:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:54:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 501 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_4_iter_501.pt
2024-08-08 12:54:54 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 501 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_4_iter_501.pt
[31m===========================================================================[0m
2024-08-08 12:54:56 - [32m[1mINFO   [0m - Training epoch 5
2024-08-08 12:54:57 - [34m[1mLOGS   [0m - Epoch:   5 [     501/10000000], loss: {'classification': 1.1746, 'neural_augmentation': 0.3787, 'total_loss': 1.5533}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 0.226, Elapsed time:  0.39
2024-08-08 12:55:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 1.2179, 'neural_augmentation': 0.3357, 'total_loss': 1.5537}
2024-08-08 12:55:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 0.3905, 'neural_augmentation': 0.0, 'total_loss': 0.3905} || top1={'logits': 92.5315} || top5={'logits': 99.0698}
2024-08-08 12:55:44 - [34m[1mLOGS   [0m - Best checkpoint with score 92.53 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:55:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_10.5631.pt
2024-08-08 12:55:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.0901.pt', 'checkpoint_score_89.3221.pt', 'checkpoint_score_90.8041.pt', 'checkpoint_score_91.9955.pt', 'checkpoint_score_92.5315.pt']
2024-08-08 12:55:49 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 12:55:50 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:55:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:55:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 597 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_5_iter_597.pt
2024-08-08 12:55:52 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 597 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_5_iter_597.pt
[31m===========================================================================[0m
2024-08-08 12:55:54 - [32m[1mINFO   [0m - Training epoch 6
2024-08-08 12:55:55 - [34m[1mLOGS   [0m - Epoch:   6 [     597/10000000], loss: {'classification': 1.1017, 'neural_augmentation': 0.288, 'total_loss': 1.3897}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.796, Elapsed time:  0.96
2024-08-08 12:56:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 1.1774, 'neural_augmentation': 0.3311, 'total_loss': 1.5085}
2024-08-08 12:56:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 0.3509, 'neural_augmentation': 0.0, 'total_loss': 0.3509} || top1={'logits': 92.8784} || top5={'logits': 99.1126}
2024-08-08 12:56:38 - [34m[1mLOGS   [0m - Best checkpoint with score 92.88 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:56:38 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_83.0901.pt
2024-08-08 12:56:38 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_89.3221.pt', 'checkpoint_score_90.8041.pt', 'checkpoint_score_91.9955.pt', 'checkpoint_score_92.5315.pt', 'checkpoint_score_92.8784.pt']
2024-08-08 12:56:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 12:56:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:56:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:56:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 685 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_6_iter_685.pt
2024-08-08 12:56:46 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 685 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_6_iter_685.pt
[31m===========================================================================[0m
2024-08-08 12:56:48 - [32m[1mINFO   [0m - Training epoch 7
2024-08-08 12:56:49 - [34m[1mLOGS   [0m - Epoch:   7 [     685/10000000], loss: {'classification': 1.1233, 'neural_augmentation': 0.32, 'total_loss': 1.4433}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.654, Elapsed time:  0.82
2024-08-08 12:57:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 1.1388, 'neural_augmentation': 0.3251, 'total_loss': 1.4639}
2024-08-08 12:57:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 0.3465, 'neural_augmentation': 0.0, 'total_loss': 0.3465} || top1={'logits': 93.2545} || top5={'logits': 99.1441}
2024-08-08 12:57:35 - [34m[1mLOGS   [0m - Best checkpoint with score 93.25 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:57:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_89.3221.pt
2024-08-08 12:57:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.8041.pt', 'checkpoint_score_91.9955.pt', 'checkpoint_score_92.5315.pt', 'checkpoint_score_92.8784.pt', 'checkpoint_score_93.2545.pt']
2024-08-08 12:57:41 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 12:57:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:57:42 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:57:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 780 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_7_iter_780.pt
2024-08-08 12:57:44 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 780 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_7_iter_780.pt
[31m===========================================================================[0m
2024-08-08 12:57:46 - [32m[1mINFO   [0m - Training epoch 8
2024-08-08 12:57:47 - [34m[1mLOGS   [0m - Epoch:   8 [     780/10000000], loss: {'classification': 1.1311, 'neural_augmentation': 0.3233, 'total_loss': 1.4544}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.136, Elapsed time:  1.30
2024-08-08 12:58:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 1.1151, 'neural_augmentation': 0.3233, 'total_loss': 1.4383}
2024-08-08 12:58:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 0.3444, 'neural_augmentation': 0.0, 'total_loss': 0.3444} || top1={'logits': 93.3311} || top5={'logits': 99.1149}
2024-08-08 12:58:36 - [34m[1mLOGS   [0m - Best checkpoint with score 93.33 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:58:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_90.8041.pt
2024-08-08 12:58:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.9955.pt', 'checkpoint_score_92.5315.pt', 'checkpoint_score_92.8784.pt', 'checkpoint_score_93.2545.pt', 'checkpoint_score_93.3311.pt']
2024-08-08 12:58:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 12:58:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:58:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:58:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 876 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_8_iter_876.pt
2024-08-08 12:58:46 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 876 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_8_iter_876.pt
[31m===========================================================================[0m
2024-08-08 12:58:48 - [32m[1mINFO   [0m - Training epoch 9
2024-08-08 12:58:50 - [34m[1mLOGS   [0m - Epoch:   9 [     876/10000000], loss: {'classification': 1.1097, 'neural_augmentation': 0.3149, 'total_loss': 1.4246}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 1.263, Elapsed time:  1.43
2024-08-08 12:59:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 1.0964, 'neural_augmentation': 0.3214, 'total_loss': 1.4178}
2024-08-08 12:59:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 0.3422, 'neural_augmentation': 0.0, 'total_loss': 0.3422} || top1={'logits': 93.455} || top5={'logits': 99.1959}
2024-08-08 12:59:37 - [34m[1mLOGS   [0m - Best checkpoint with score 93.45 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 12:59:38 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_91.9955.pt
2024-08-08 12:59:38 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.5315.pt', 'checkpoint_score_92.8784.pt', 'checkpoint_score_93.2545.pt', 'checkpoint_score_93.3311.pt', 'checkpoint_score_93.4550.pt']
2024-08-08 12:59:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 12:59:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 12:59:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 12:59:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 975 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_9_iter_975.pt
2024-08-08 12:59:50 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 975 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_9_iter_975.pt
[31m===========================================================================[0m
2024-08-08 12:59:52 - [32m[1mINFO   [0m - Training epoch 10
2024-08-08 12:59:56 - [34m[1mLOGS   [0m - Epoch:  10 [     975/10000000], loss: {'classification': 1.1408, 'neural_augmentation': 0.317, 'total_loss': 1.4577}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 3.170, Elapsed time:  3.33
2024-08-08 13:00:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 1.0782, 'neural_augmentation': 0.3234, 'total_loss': 1.4017}
2024-08-08 13:00:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 0.3404, 'neural_augmentation': 0.0, 'total_loss': 0.3404} || top1={'logits': 93.4685} || top5={'logits': 99.1532}
2024-08-08 13:00:44 - [34m[1mLOGS   [0m - Best checkpoint with score 93.47 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:00:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_92.5315.pt
2024-08-08 13:00:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.8784.pt', 'checkpoint_score_93.2545.pt', 'checkpoint_score_93.3311.pt', 'checkpoint_score_93.4550.pt', 'checkpoint_score_93.4685.pt']
2024-08-08 13:00:48 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:00:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:00:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:00:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 1073 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_10_iter_1073.pt
2024-08-08 13:00:51 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 1073 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_10_iter_1073.pt
[31m===========================================================================[0m
2024-08-08 13:00:53 - [32m[1mINFO   [0m - Training epoch 11
2024-08-08 13:00:54 - [34m[1mLOGS   [0m - Epoch:  11 [    1073/10000000], loss: {'classification': 0.9913, 'neural_augmentation': 0.3301, 'total_loss': 1.3214}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 1.134, Elapsed time:  1.30
2024-08-08 13:01:30 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 1.0563, 'neural_augmentation': 0.3271, 'total_loss': 1.3834}
2024-08-08 13:01:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 0.3386, 'neural_augmentation': 0.0, 'total_loss': 0.3386} || top1={'logits': 93.5811} || top5={'logits': 99.1644}
2024-08-08 13:01:45 - [34m[1mLOGS   [0m - Best checkpoint with score 93.58 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:01:46 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_92.8784.pt
2024-08-08 13:01:46 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.2545.pt', 'checkpoint_score_93.3311.pt', 'checkpoint_score_93.4550.pt', 'checkpoint_score_93.4685.pt', 'checkpoint_score_93.5811.pt']
2024-08-08 13:01:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:01:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:01:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:01:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 1177 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_11_iter_1177.pt
2024-08-08 13:01:55 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 1177 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_11_iter_1177.pt
[31m===========================================================================[0m
2024-08-08 13:01:57 - [32m[1mINFO   [0m - Training epoch 12
2024-08-08 13:01:57 - [34m[1mLOGS   [0m - Epoch:  12 [    1177/10000000], loss: {'classification': 1.016, 'neural_augmentation': 0.3599, 'total_loss': 1.3759}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 0.465, Elapsed time:  0.63
2024-08-08 13:02:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 1.045, 'neural_augmentation': 0.3362, 'total_loss': 1.3812}
2024-08-08 13:02:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 0.3398, 'neural_augmentation': 0.0, 'total_loss': 0.3398} || top1={'logits': 93.6892} || top5={'logits': 99.1847}
2024-08-08 13:02:51 - [34m[1mLOGS   [0m - Best checkpoint with score 93.69 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:02:51 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.2545.pt
2024-08-08 13:02:51 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.3311.pt', 'checkpoint_score_93.4550.pt', 'checkpoint_score_93.4685.pt', 'checkpoint_score_93.5811.pt', 'checkpoint_score_93.6892.pt']
2024-08-08 13:02:58 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:02:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:02:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:03:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 1281 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_12_iter_1281.pt
2024-08-08 13:03:01 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 1281 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_12_iter_1281.pt
[31m===========================================================================[0m
2024-08-08 13:03:03 - [32m[1mINFO   [0m - Training epoch 13
2024-08-08 13:03:04 - [34m[1mLOGS   [0m - Epoch:  13 [    1281/10000000], loss: {'classification': 1.1012, 'neural_augmentation': 0.3516, 'total_loss': 1.4528}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 0.879, Elapsed time:  1.04
2024-08-08 13:03:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 1.0315, 'neural_augmentation': 0.3459, 'total_loss': 1.3775}
2024-08-08 13:03:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 0.3352, 'neural_augmentation': 0.0, 'total_loss': 0.3352} || top1={'logits': 93.7005} || top5={'logits': 99.1599}
2024-08-08 13:03:52 - [34m[1mLOGS   [0m - Best checkpoint with score 93.70 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:03:52 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.3311.pt
2024-08-08 13:03:52 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.4550.pt', 'checkpoint_score_93.4685.pt', 'checkpoint_score_93.5811.pt', 'checkpoint_score_93.6892.pt', 'checkpoint_score_93.7005.pt']
2024-08-08 13:03:56 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:03:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:03:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:03:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 1381 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_13_iter_1381.pt
2024-08-08 13:03:59 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 1381 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_13_iter_1381.pt
[31m===========================================================================[0m
2024-08-08 13:04:01 - [32m[1mINFO   [0m - Training epoch 14
2024-08-08 13:04:05 - [34m[1mLOGS   [0m - Epoch:  14 [    1381/10000000], loss: {'classification': 1.0281, 'neural_augmentation': 0.3753, 'total_loss': 1.4034}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 3.227, Elapsed time:  3.40
2024-08-08 13:04:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 1.0232, 'neural_augmentation': 0.3616, 'total_loss': 1.3848}
2024-08-08 13:04:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 0.3327, 'neural_augmentation': 0.0, 'total_loss': 0.3327} || top1={'logits': 93.7027} || top5={'logits': 99.2005}
2024-08-08 13:04:54 - [34m[1mLOGS   [0m - Best checkpoint with score 93.70 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:04:55 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.4550.pt
2024-08-08 13:04:55 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.4685.pt', 'checkpoint_score_93.5811.pt', 'checkpoint_score_93.6892.pt', 'checkpoint_score_93.7005.pt', 'checkpoint_score_93.7027.pt']
2024-08-08 13:05:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:05:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:05:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:05:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 1480 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_14_iter_1480.pt
2024-08-08 13:05:06 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 1480 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_14_iter_1480.pt
[31m===========================================================================[0m
2024-08-08 13:05:08 - [32m[1mINFO   [0m - Training epoch 15
2024-08-08 13:05:09 - [34m[1mLOGS   [0m - Epoch:  15 [    1480/10000000], loss: {'classification': 1.0388, 'neural_augmentation': 0.3927, 'total_loss': 1.4315}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 1.354, Elapsed time:  1.51
2024-08-08 13:05:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 1.0145, 'neural_augmentation': 0.3802, 'total_loss': 1.3946}
2024-08-08 13:06:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 0.3256, 'neural_augmentation': 0.0, 'total_loss': 0.3256} || top1={'logits': 93.9212} || top5={'logits': 99.205}
2024-08-08 13:06:02 - [34m[1mLOGS   [0m - Best checkpoint with score 93.92 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:06:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.4685.pt
2024-08-08 13:06:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.5811.pt', 'checkpoint_score_93.6892.pt', 'checkpoint_score_93.7005.pt', 'checkpoint_score_93.7027.pt', 'checkpoint_score_93.9212.pt']
2024-08-08 13:06:09 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:06:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:06:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:06:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 1582 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_15_iter_1582.pt
2024-08-08 13:06:12 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 1582 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_15_iter_1582.pt
[31m===========================================================================[0m
2024-08-08 13:06:14 - [32m[1mINFO   [0m - Training epoch 16
2024-08-08 13:06:15 - [34m[1mLOGS   [0m - Epoch:  16 [    1582/10000000], loss: {'classification': 0.9714, 'neural_augmentation': 0.4351, 'total_loss': 1.4065}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 0.514, Elapsed time:  0.68
2024-08-08 13:06:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 1.003, 'neural_augmentation': 0.4001, 'total_loss': 1.403}
2024-08-08 13:07:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 0.335, 'neural_augmentation': 0.0, 'total_loss': 0.335} || top1={'logits': 93.8626} || top5={'logits': 99.1757}
2024-08-08 13:07:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:07:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:07:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 1684 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_16_iter_1684.pt
2024-08-08 13:07:07 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 1684 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_16_iter_1684.pt
[31m===========================================================================[0m
2024-08-08 13:07:09 - [32m[1mINFO   [0m - Training epoch 17
2024-08-08 13:07:10 - [34m[1mLOGS   [0m - Epoch:  17 [    1684/10000000], loss: {'classification': 0.9547, 'neural_augmentation': 0.4114, 'total_loss': 1.3661}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 1.229, Elapsed time:  1.40
2024-08-08 13:07:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 1.0012, 'neural_augmentation': 0.4242, 'total_loss': 1.4254}
2024-08-08 13:08:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 0.3301, 'neural_augmentation': 0.0, 'total_loss': 0.3301} || top1={'logits': 93.8986} || top5={'logits': 99.1779}
2024-08-08 13:08:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:08:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:08:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 1779 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_17_iter_1779.pt
2024-08-08 13:08:06 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 1779 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_17_iter_1779.pt
[31m===========================================================================[0m
2024-08-08 13:08:08 - [32m[1mINFO   [0m - Training epoch 18
2024-08-08 13:08:09 - [34m[1mLOGS   [0m - Epoch:  18 [    1779/10000000], loss: {'classification': 0.9402, 'neural_augmentation': 0.4309, 'total_loss': 1.371}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 0.934, Elapsed time:  1.10
2024-08-08 13:08:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 0.9935, 'neural_augmentation': 0.4493, 'total_loss': 1.4428}
2024-08-08 13:09:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 0.3316, 'neural_augmentation': 0.0, 'total_loss': 0.3316} || top1={'logits': 94.0225} || top5={'logits': 99.1554}
2024-08-08 13:09:06 - [34m[1mLOGS   [0m - Best checkpoint with score 94.02 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:09:08 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.5811.pt
2024-08-08 13:09:08 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.6892.pt', 'checkpoint_score_93.7005.pt', 'checkpoint_score_93.7027.pt', 'checkpoint_score_93.9212.pt', 'checkpoint_score_94.0225.pt']
2024-08-08 13:09:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:09:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:09:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:09:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 1875 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_18_iter_1875.pt
2024-08-08 13:09:20 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 1875 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_18_iter_1875.pt
[31m===========================================================================[0m
2024-08-08 13:09:22 - [32m[1mINFO   [0m - Training epoch 19
2024-08-08 13:09:23 - [34m[1mLOGS   [0m - Epoch:  19 [    1875/10000000], loss: {'classification': 0.9686, 'neural_augmentation': 0.4689, 'total_loss': 1.4375}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 0.811, Elapsed time:  0.98
2024-08-08 13:09:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 0.9861, 'neural_augmentation': 0.4772, 'total_loss': 1.4632}
2024-08-08 13:10:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 0.3372, 'neural_augmentation': 0.0, 'total_loss': 0.3372} || top1={'logits': 94.045} || top5={'logits': 99.1509}
2024-08-08 13:10:13 - [34m[1mLOGS   [0m - Best checkpoint with score 94.05 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:10:13 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.6892.pt
2024-08-08 13:10:13 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.7005.pt', 'checkpoint_score_93.7027.pt', 'checkpoint_score_93.9212.pt', 'checkpoint_score_94.0225.pt', 'checkpoint_score_94.0450.pt']
2024-08-08 13:10:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:10:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:10:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:10:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 1979 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_19_iter_1979.pt
2024-08-08 13:10:22 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 1979 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_19_iter_1979.pt
[31m===========================================================================[0m
2024-08-08 13:10:24 - [32m[1mINFO   [0m - Training epoch 20
2024-08-08 13:10:26 - [34m[1mLOGS   [0m - Epoch:  20 [    1979/10000000], loss: {'classification': 0.9536, 'neural_augmentation': 0.5147, 'total_loss': 1.4683}, LR: [1e-05, 1e-05], Avg. batch load time: 1.500, Elapsed time:  1.66
2024-08-08 13:10:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 0.9865, 'neural_augmentation': 0.5034, 'total_loss': 1.49}
2024-08-08 13:11:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 0.334, 'neural_augmentation': 0.0, 'total_loss': 0.334} || top1={'logits': 94.0405} || top5={'logits': 99.2207}
2024-08-08 13:11:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:11:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:11:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 2077 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_20_iter_2077.pt
2024-08-08 13:11:20 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 2077 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_20_iter_2077.pt
[31m===========================================================================[0m
2024-08-08 13:11:22 - [32m[1mINFO   [0m - Training epoch 21
2024-08-08 13:11:22 - [34m[1mLOGS   [0m - Epoch:  21 [    2077/10000000], loss: {'classification': 0.9418, 'neural_augmentation': 0.5252, 'total_loss': 1.467}, LR: [9e-06, 9e-06], Avg. batch load time: 0.290, Elapsed time:  0.46
2024-08-08 13:11:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 0.9807, 'neural_augmentation': 0.535, 'total_loss': 1.5157}
2024-08-08 13:12:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 0.3276, 'neural_augmentation': 0.0, 'total_loss': 0.3276} || top1={'logits': 94.0833} || top5={'logits': 99.2095}
2024-08-08 13:12:13 - [34m[1mLOGS   [0m - Best checkpoint with score 94.08 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:12:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.7005.pt
2024-08-08 13:12:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.7027.pt', 'checkpoint_score_93.9212.pt', 'checkpoint_score_94.0225.pt', 'checkpoint_score_94.0450.pt', 'checkpoint_score_94.0833.pt']
2024-08-08 13:12:24 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:12:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:12:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:12:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 2174 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_21_iter_2174.pt
2024-08-08 13:12:28 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 2174 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_21_iter_2174.pt
[31m===========================================================================[0m
2024-08-08 13:12:30 - [32m[1mINFO   [0m - Training epoch 22
2024-08-08 13:12:32 - [34m[1mLOGS   [0m - Epoch:  22 [    2174/10000000], loss: {'classification': 0.9898, 'neural_augmentation': 0.5673, 'total_loss': 1.5571}, LR: [7e-06, 7e-06], Avg. batch load time: 1.802, Elapsed time:  1.97
2024-08-08 13:13:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 0.9723, 'neural_augmentation': 0.5612, 'total_loss': 1.5335}
2024-08-08 13:13:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 0.33, 'neural_augmentation': 0.0, 'total_loss': 0.33} || top1={'logits': 94.1284} || top5={'logits': 99.2185}
2024-08-08 13:13:19 - [34m[1mLOGS   [0m - Best checkpoint with score 94.13 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:13:20 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.7027.pt
2024-08-08 13:13:20 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.9212.pt', 'checkpoint_score_94.0225.pt', 'checkpoint_score_94.0450.pt', 'checkpoint_score_94.0833.pt', 'checkpoint_score_94.1284.pt']
2024-08-08 13:13:24 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:13:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:13:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:13:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 2273 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_22_iter_2273.pt
2024-08-08 13:13:27 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 2273 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_22_iter_2273.pt
[31m===========================================================================[0m
2024-08-08 13:13:29 - [32m[1mINFO   [0m - Training epoch 23
2024-08-08 13:13:29 - [34m[1mLOGS   [0m - Epoch:  23 [    2273/10000000], loss: {'classification': 0.9413, 'neural_augmentation': 0.5874, 'total_loss': 1.5287}, LR: [6e-06, 6e-06], Avg. batch load time: 0.357, Elapsed time:  0.52
2024-08-08 13:14:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 0.9734, 'neural_augmentation': 0.5902, 'total_loss': 1.5636}
2024-08-08 13:14:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 0.3319, 'neural_augmentation': 0.0, 'total_loss': 0.3319} || top1={'logits': 94.0158} || top5={'logits': 99.1351}
2024-08-08 13:14:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:14:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:14:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 2371 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_23_iter_2371.pt
2024-08-08 13:14:25 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 2371 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_23_iter_2371.pt
[31m===========================================================================[0m
2024-08-08 13:14:27 - [32m[1mINFO   [0m - Training epoch 24
2024-08-08 13:14:28 - [34m[1mLOGS   [0m - Epoch:  24 [    2371/10000000], loss: {'classification': 0.9231, 'neural_augmentation': 0.6032, 'total_loss': 1.5263}, LR: [6e-06, 6e-06], Avg. batch load time: 0.981, Elapsed time:  1.14
2024-08-08 13:15:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 0.9675, 'neural_augmentation': 0.6148, 'total_loss': 1.5822}
2024-08-08 13:15:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 0.3309, 'neural_augmentation': 0.0, 'total_loss': 0.3309} || top1={'logits': 94.0631} || top5={'logits': 99.1914}
2024-08-08 13:15:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:15:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:15:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 2473 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_24_iter_2473.pt
2024-08-08 13:15:25 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 2473 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_24_iter_2473.pt
[31m===========================================================================[0m
2024-08-08 13:15:27 - [32m[1mINFO   [0m - Training epoch 25
2024-08-08 13:15:28 - [34m[1mLOGS   [0m - Epoch:  25 [    2473/10000000], loss: {'classification': 0.9368, 'neural_augmentation': 0.6267, 'total_loss': 1.5634}, LR: [5e-06, 5e-06], Avg. batch load time: 0.331, Elapsed time:  0.50
2024-08-08 13:16:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 0.9679, 'neural_augmentation': 0.6387, 'total_loss': 1.6066}
2024-08-08 13:16:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 0.3338, 'neural_augmentation': 0.0, 'total_loss': 0.3338} || top1={'logits': 94.0946} || top5={'logits': 99.1847}
2024-08-08 13:16:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:16:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:16:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 2571 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_25_iter_2571.pt
2024-08-08 13:16:20 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 2571 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_25_iter_2571.pt
[31m===========================================================================[0m
2024-08-08 13:16:22 - [32m[1mINFO   [0m - Training epoch 26
2024-08-08 13:16:23 - [34m[1mLOGS   [0m - Epoch:  26 [    2571/10000000], loss: {'classification': 0.8892, 'neural_augmentation': 0.651, 'total_loss': 1.5402}, LR: [4e-06, 4e-06], Avg. batch load time: 0.363, Elapsed time:  0.53
2024-08-08 13:16:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 0.9617, 'neural_augmentation': 0.6577, 'total_loss': 1.6194}
2024-08-08 13:17:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 0.3316, 'neural_augmentation': 0.0, 'total_loss': 0.3316} || top1={'logits': 94.1441} || top5={'logits': 99.1667}
2024-08-08 13:17:14 - [34m[1mLOGS   [0m - Best checkpoint with score 94.14 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_best.pt
2024-08-08 13:17:15 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_score_93.9212.pt
2024-08-08 13:17:15 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_94.0225.pt', 'checkpoint_score_94.0450.pt', 'checkpoint_score_94.0833.pt', 'checkpoint_score_94.1284.pt', 'checkpoint_score_94.1441.pt']
2024-08-08 13:17:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_avg.pt
2024-08-08 13:17:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:17:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:17:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 2677 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_26_iter_2677.pt
2024-08-08 13:17:23 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 2677 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_26_iter_2677.pt
[31m===========================================================================[0m
2024-08-08 13:17:25 - [32m[1mINFO   [0m - Training epoch 27
2024-08-08 13:17:27 - [34m[1mLOGS   [0m - Epoch:  27 [    2677/10000000], loss: {'classification': 0.9556, 'neural_augmentation': 0.6879, 'total_loss': 1.6436}, LR: [4e-06, 4e-06], Avg. batch load time: 1.921, Elapsed time:  2.09
2024-08-08 13:18:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 0.9628, 'neural_augmentation': 0.6774, 'total_loss': 1.6402}
2024-08-08 13:18:17 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 0.3311, 'neural_augmentation': 0.0, 'total_loss': 0.3311} || top1={'logits': 94.1329} || top5={'logits': 99.1486}
2024-08-08 13:18:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:18:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:18:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 2774 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_27_iter_2774.pt
2024-08-08 13:18:22 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 2774 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_27_iter_2774.pt
[31m===========================================================================[0m
2024-08-08 13:18:24 - [32m[1mINFO   [0m - Training epoch 28
2024-08-08 13:18:25 - [34m[1mLOGS   [0m - Epoch:  28 [    2774/10000000], loss: {'classification': 0.9271, 'neural_augmentation': 0.5966, 'total_loss': 1.5237}, LR: [3e-06, 3e-06], Avg. batch load time: 0.270, Elapsed time:  0.44
2024-08-08 13:19:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 0.9585, 'neural_augmentation': 0.6918, 'total_loss': 1.6503}
2024-08-08 13:19:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 0.3289, 'neural_augmentation': 0.0, 'total_loss': 0.3289} || top1={'logits': 94.1306} || top5={'logits': 99.1869}
2024-08-08 13:19:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:19:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:19:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 2879 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_28_iter_2879.pt
2024-08-08 13:19:20 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 2879 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_28_iter_2879.pt
[31m===========================================================================[0m
2024-08-08 13:19:22 - [32m[1mINFO   [0m - Training epoch 29
2024-08-08 13:19:25 - [34m[1mLOGS   [0m - Epoch:  29 [    2879/10000000], loss: {'classification': 0.9039, 'neural_augmentation': 0.7127, 'total_loss': 1.6167}, LR: [3e-06, 3e-06], Avg. batch load time: 2.331, Elapsed time:  2.50
2024-08-08 13:20:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 0.9615, 'neural_augmentation': 0.7011, 'total_loss': 1.6626}
2024-08-08 13:20:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 0.3308, 'neural_augmentation': 0.0, 'total_loss': 0.3308} || top1={'logits': 94.1396} || top5={'logits': 99.1689}
2024-08-08 13:20:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_last.pt
2024-08-08 13:20:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_last.pt
2024-08-08 13:20:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 2985 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/training_checkpoint_epoch_29_iter_2985.pt
2024-08-08 13:20:22 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 2985 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_food172/train/checkpoint_epoch_29_iter_2985.pt
2024-08-08 13:20:22 - [34m[1mLOGS   [0m - Training took 00:35:24.08
