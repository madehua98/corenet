nohup: ignoring input
2024-07-20 11:24:43 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
small
dci
2024-07-20 11:24:43 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results500_accum_dci/train/checkpoint_last.pt
2024-07-20 11:24:43 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-20 11:24:43 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   25.707 M
Total trainable parameters =   25.707 M

2024-07-20 11:24:43 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-20 11:24:43 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.707M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  51.813K               |  51.712K   |
|   classifier.weight                  |   (101, 512)           |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-20 11:24:44 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-20 11:24:44 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.1.ls2', 'blocks.2.attn.k_norm', 'blocks.5.attn.q_norm', 'blocks1.2.drop_path1', 'blocks1.2.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.4.drop_path2', 'blocks.4.attn.attn_drop', 'blocks.1.attn.attn_drop', 'patch_embed.backbone.stem.norm1.drop', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks.3.attn.attn_drop', 'blocks.4.ls2', 'blocks.1.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.6.drop_path1', 'blocks1.5.attn.q_norm', 'blocks1.2.drop_path2', 'blocks.1.drop_path2', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.6.drop_path1', 'blocks.6.ls1', 'blocks.3.ls1', 'blocks.1.drop_path1', 'blocks.4.ls1', 'blocks1.3.drop_path2', 'blocks1.4.attn.q_norm', 'blocks1.6.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks.5.attn.k_norm', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.1.0.down', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.6.attn.k_norm', 'patch_embed.proj', 'blocks.3.drop_path1', 'blocks1.4.ls1', 'blocks.2.attn.q_norm', 'norm', 'blocks1.5.drop_path1', 'blocks1.5.attn.attn_drop', 'blocks1.4.ls2', 'blocks.0.drop_path1', 'blocks1.1.drop_path2', 'neural_augmentor.brightness', 'neural_augmentor.contrast', 'blocks1.2.attn.k_norm', 'blocks1.0.ls2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.0.attn.q_norm', 'blocks1.1.attn.attn_drop', 'blocks.5.ls1', 'blocks.1.attn.q_norm', 'norm_pre', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks1.6.attn.attn_drop', 'blocks1.0.attn.k_norm', 'blocks1.5.ls1', 'blocks.0.attn.k_norm', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks1.3.attn.q_norm', 'blocks.2.ls2', 'blocks1.5.ls2', 'blocks.6.ls2', 'blocks.4.attn.q_norm', 'blocks.4.attn.k_norm', 'blocks.0.ls2', 'patch_embed.backbone.stages.0.0.drop_path', 'patch_embed.backbone.stages.1.1.shortcut', 'patch_embed.backbone.stages.1.3.down', 'blocks1.0.drop_path1', 'blocks1.4.drop_path1', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks1.1.attn.q_norm', 'blocks1.0.attn.attn_drop', 'blocks1.6.ls2', 'blocks1.0.ls1', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'neural_augmentor', 'patch_embed.backbone.stages.1.1.down', 'blocks.6.drop_path2', 'blocks1.1.ls2', 'blocks1.1.drop_path1', 'blocks.0.attn.attn_drop', 'blocks1.3.attn.k_norm', 'blocks.3.attn.q_norm', 'neural_augmentor.noise.max_fn', 'blocks.2.drop_path1', 'blocks1.6.attn.q_norm', 'blocks.0.ls1', 'blocks.1.ls1', 'blocks.6.attn.attn_drop', 'neural_augmentor.contrast.min_fn', 'blocks1.0.attn.q_norm', 'neural_augmentor.noise', 'blocks1.6.ls1', 'patch_embed.backbone.stages.0.0.down', 'patch_embed.backbone.stages.1.2.down', 'blocks1.4.attn.attn_drop', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks1.6.drop_path2', 'blocks.5.drop_path1', 'blocks.2.drop_path2', 'patch_drop', 'blocks1.2.attn.q_norm', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.0.drop_path2', 'blocks.3.attn.k_norm', 'blocks.2.ls1', 'blocks.5.attn.attn_drop', 'blocks1.2.ls2', 'blocks1.3.ls2', 'neural_augmentor.brightness.max_fn', 'blocks1.1.ls1', 'blocks1.0.drop_path2', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stages.0.1.down', 'blocks.4.drop_path2', 'blocks1.3.ls1', 'blocks1.5.attn.k_norm', 'blocks.3.ls2', 'blocks1.2.attn.attn_drop', 'blocks1.5.drop_path2', 'blocks1.3.drop_path1', 'blocks.5.ls2', 'neural_augmentor.brightness.min_fn', 'blocks.5.drop_path2', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.4.drop_path1', 'patch_embed.backbone.stages.1.0.drop_path', 'neural_augmentor.contrast.max_fn', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.3.attn.attn_drop', 'blocks.3.drop_path2', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.0.0.shortcut.expand'}
2024-07-20 11:24:44 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - Available GPUs: 8
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-20 11:24:44 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 7): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 6): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 4): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:48 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:48 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://di-20240206174114-98czq:30786
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Total number of samples: 75750
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/train_images 
	is_training=True 
	num_samples=75750
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Total number of samples: 25250
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/test_images 
	is_training=False 
	num_samples=25250
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=128
	 scales=[(128, 128, 392), (160, 160, 250), (192, 192, 174), (224, 224, 128), (256, 256, 98), (288, 288, 77), (320, 320, 62)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-20 11:24:51 - [34m[1mLOGS   [0m - Number of data workers: 64
small
dci
2024-07-20 11:24:56 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results500_accum_dci/train/checkpoint_last.pt
2024-07-20 11:24:56 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-20 11:24:56 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   25.707 M
Total trainable parameters =   25.707 M

2024-07-20 11:24:56 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-20 11:24:56 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.707M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  51.813K               |  51.712K   |
|   classifier.weight                  |   (101, 512)           |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-20 11:24:57 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-20 11:24:57 - [33m[1mWARNING[0m - Uncalled Modules:
{'neural_augmentor.brightness.min_fn', 'blocks.4.attn.k_norm', 'blocks.1.attn.k_norm', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'norm_pre', 'patch_embed.backbone.stages.0.1.down', 'blocks1.5.ls1', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks.4.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'neural_augmentor.noise.max_fn', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.2.drop_path1', 'blocks1.1.ls2', 'blocks.3.attn.k_norm', 'patch_embed.backbone.stem.norm1.drop', 'blocks.3.attn.attn_drop', 'blocks.1.attn.q_norm', 'blocks1.1.attn.q_norm', 'blocks.0.ls2', 'blocks.6.ls1', 'blocks.4.attn.attn_drop', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.0.attn.q_norm', 'blocks1.6.ls1', 'patch_embed.backbone.stages.1.1.down', 'blocks.0.attn.k_norm', 'blocks.1.drop_path2', 'blocks1.6.ls2', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.1.attn.attn_drop', 'neural_augmentor.brightness.max_fn', 'blocks1.4.ls1', 'blocks.3.attn.q_norm', 'blocks.1.ls1', 'patch_drop', 'patch_embed.backbone.stages.1.0.down', 'blocks.6.attn.attn_drop', 'patch_embed.proj', 'patch_embed.backbone.stages.0.0.down', 'blocks1.1.drop_path2', 'blocks1.5.attn.q_norm', 'blocks.6.ls2', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks.5.drop_path2', 'blocks1.2.attn.k_norm', 'blocks.1.ls2', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.5.drop_path1', 'blocks.5.drop_path1', 'blocks.3.ls1', 'blocks.0.ls1', 'blocks1.5.ls2', 'neural_augmentor', 'blocks.5.ls1', 'blocks1.0.attn.k_norm', 'blocks.3.ls2', 'blocks.6.drop_path2', 'neural_augmentor.brightness', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks1.3.attn.attn_drop', 'blocks1.0.attn.attn_drop', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'norm', 'blocks.6.drop_path1', 'blocks1.5.attn.attn_drop', 'blocks1.2.drop_path1', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.6.attn.attn_drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.0.ls1', 'blocks1.4.drop_path1', 'blocks1.2.ls1', 'blocks.2.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks1.0.ls2', 'blocks1.2.attn.q_norm', 'blocks1.4.attn.k_norm', 'blocks.5.attn.q_norm', 'blocks.5.attn.attn_drop', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.3.drop_path2', 'blocks1.3.attn.k_norm', 'blocks.0.attn.attn_drop', 'neural_augmentor.contrast', 'blocks1.0.drop_path1', 'blocks.1.drop_path1', 'blocks1.3.ls2', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks.2.ls1', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks.5.ls2', 'blocks1.4.attn.attn_drop', 'blocks.3.drop_path2', 'blocks1.5.drop_path2', 'neural_augmentor.contrast.max_fn', 'blocks1.0.drop_path2', 'blocks.2.ls2', 'blocks.0.drop_path1', 'blocks1.4.attn.q_norm', 'blocks1.6.attn.k_norm', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.6.attn.k_norm', 'blocks1.3.attn.q_norm', 'blocks1.1.drop_path1', 'blocks.4.attn.q_norm', 'blocks.6.attn.q_norm', 'blocks1.0.attn.q_norm', 'patch_embed.backbone.stages.1.2.shortcut', 'patch_embed.backbone.stages.1.2.down', 'blocks.4.drop_path2', 'blocks.0.drop_path2', 'blocks.2.drop_path2', 'blocks1.6.drop_path2', 'blocks1.6.drop_path1', 'blocks1.1.attn.attn_drop', 'blocks1.2.drop_path2', 'blocks1.3.ls1', 'blocks1.3.drop_path1', 'patch_embed.backbone.stages.1.1.drop_path', 'neural_augmentor.noise', 'blocks.2.attn.q_norm', 'blocks1.2.ls2', 'blocks1.4.ls2', 'blocks1.6.attn.q_norm', 'blocks.5.attn.k_norm', 'blocks1.1.ls1', 'blocks.4.ls2', 'blocks1.2.attn.attn_drop', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.1.3.down', 'blocks.4.drop_path1', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks1.5.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'neural_augmentor.contrast.min_fn'}
2024-07-20 11:24:57 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - Max. epochs for training: 120
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=120
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-20 11:24:57 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt'
2024-07-20 11:24:57 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-20 11:24:59 - [32m[1mINFO   [0m - Training epoch 0
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://di-20240206174114-98czq:30786
small
dci
2024-07-20 11:24:47 - [32m[1mINFO   [0m - distributed init (rank 5): tcp://di-20240206174114-98czq:30786
small
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-20 11:28:03 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'classification': 5.6033, 'neural_augmentation': 11.2353, 'total_loss': 16.8386}, LR: [1e-06, 1e-06], Avg. batch load time: 173.776, Elapsed time: 184.11
2024-07-20 11:28:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 5.3328, 'neural_augmentation': 10.3463, 'total_loss': 15.6792}
2024-07-20 11:31:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 4.8795, 'neural_augmentation': 0.0, 'total_loss': 4.8795} || top1={'logits': 1.5703} || top5={'logits': 7.4844}
2024-07-20 11:31:02 - [34m[1mLOGS   [0m - Best checkpoint with score 1.57 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:31:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:31:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:31:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 60 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_0_iter_60.pt
2024-07-20 11:31:03 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 60 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_0_iter_60.pt
[31m===========================================================================[0m
2024-07-20 11:31:05 - [32m[1mINFO   [0m - Training epoch 1
2024-07-20 11:31:09 - [34m[1mLOGS   [0m - Epoch:   1 [      61/10000000], loss: {'classification': 4.8797, 'neural_augmentation': 11.3078, 'total_loss': 16.1875}, LR: [4e-06, 4e-06], Avg. batch load time: 3.776, Elapsed time:  3.94
2024-07-20 11:31:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 4.6189, 'neural_augmentation': 10.2464, 'total_loss': 14.8653}
2024-07-20 11:31:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 4.3196, 'neural_augmentation': 0.0, 'total_loss': 4.3196} || top1={'logits': 5.8164} || top5={'logits': 18.4258}
2024-07-20 11:31:25 - [34m[1mLOGS   [0m - Best checkpoint with score 5.82 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:31:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:31:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:31:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 119 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_1_iter_119.pt
2024-07-20 11:31:26 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 119 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_1_iter_119.pt
[31m===========================================================================[0m
2024-07-20 11:31:28 - [32m[1mINFO   [0m - Training epoch 2
2024-07-20 11:31:31 - [34m[1mLOGS   [0m - Epoch:   2 [     120/10000000], loss: {'classification': 4.421, 'neural_augmentation': 9.4947, 'total_loss': 13.9157}, LR: [8e-06, 8e-06], Avg. batch load time: 2.471, Elapsed time:  2.64
2024-07-20 11:31:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 4.3058, 'neural_augmentation': 10.2554, 'total_loss': 14.5613}
2024-07-20 11:31:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 3.8958, 'neural_augmentation': 0.0, 'total_loss': 3.8958} || top1={'logits': 12.2812} || top5={'logits': 32.8398}
2024-07-20 11:31:47 - [34m[1mLOGS   [0m - Best checkpoint with score 12.28 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:31:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:31:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:31:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 177 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_2_iter_177.pt
2024-07-20 11:31:48 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 177 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_2_iter_177.pt
[31m===========================================================================[0m
2024-07-20 11:31:50 - [32m[1mINFO   [0m - Training epoch 3
2024-07-20 11:31:53 - [34m[1mLOGS   [0m - Epoch:   3 [     178/10000000], loss: {'classification': 4.1944, 'neural_augmentation': 11.7536, 'total_loss': 15.948}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 2.836, Elapsed time:  3.01
2024-07-20 11:32:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 4.0921, 'neural_augmentation': 10.2701, 'total_loss': 14.3622}
2024-07-20 11:32:11 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 3.5378, 'neural_augmentation': 0.0, 'total_loss': 3.5378} || top1={'logits': 18.5117} || top5={'logits': 43.0312}
2024-07-20 11:32:11 - [34m[1mLOGS   [0m - Best checkpoint with score 18.51 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:32:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:32:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:32:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 241 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_3_iter_241.pt
2024-07-20 11:32:12 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 241 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_3_iter_241.pt
[31m===========================================================================[0m
2024-07-20 11:32:14 - [32m[1mINFO   [0m - Training epoch 4
2024-07-20 11:32:16 - [34m[1mLOGS   [0m - Epoch:   4 [     242/10000000], loss: {'classification': 4.011, 'neural_augmentation': 11.242, 'total_loss': 15.2529}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 1.885, Elapsed time:  2.05
2024-07-20 11:32:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 3.9772, 'neural_augmentation': 10.2145, 'total_loss': 14.1917}
2024-07-20 11:32:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 3.3514, 'neural_augmentation': 0.0, 'total_loss': 3.3514} || top1={'logits': 21.7734} || top5={'logits': 48.668}
2024-07-20 11:32:32 - [34m[1mLOGS   [0m - Best checkpoint with score 21.77 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:32:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:32:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:32:33 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 289 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_4_iter_289.pt
2024-07-20 11:32:33 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 289 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_4_iter_289.pt
[31m===========================================================================[0m
2024-07-20 11:32:35 - [32m[1mINFO   [0m - Training epoch 5
2024-07-20 11:32:39 - [34m[1mLOGS   [0m - Epoch:   5 [     290/10000000], loss: {'classification': 3.9956, 'neural_augmentation': 10.9117, 'total_loss': 14.9073}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 4.160, Elapsed time:  4.34
2024-07-20 11:32:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 3.8801, 'neural_augmentation': 10.546, 'total_loss': 14.4261}
2024-07-20 11:32:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 3.1947, 'neural_augmentation': 0.0, 'total_loss': 3.1947} || top1={'logits': 24.793} || top5={'logits': 52.5}
2024-07-20 11:32:54 - [34m[1mLOGS   [0m - Best checkpoint with score 24.79 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:32:54 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_1.5703.pt
2024-07-20 11:32:54 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_5.8164.pt', 'checkpoint_score_12.2812.pt', 'checkpoint_score_18.5117.pt', 'checkpoint_score_21.7734.pt', 'checkpoint_score_24.7930.pt']
2024-07-20 11:33:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:33:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:33:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:33:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 347 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_5_iter_347.pt
2024-07-20 11:33:02 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 347 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_5_iter_347.pt
[31m===========================================================================[0m
2024-07-20 11:33:04 - [32m[1mINFO   [0m - Training epoch 6
2024-07-20 11:33:07 - [34m[1mLOGS   [0m - Epoch:   6 [     348/10000000], loss: {'classification': 3.927, 'neural_augmentation': 9.7322, 'total_loss': 13.6592}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 2.107, Elapsed time:  2.27
2024-07-20 11:33:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 3.8235, 'neural_augmentation': 10.1901, 'total_loss': 14.0136}
2024-07-20 11:33:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 3.0781, 'neural_augmentation': 0.0, 'total_loss': 3.0781} || top1={'logits': 26.8555} || top5={'logits': 55.4414}
2024-07-20 11:33:22 - [34m[1mLOGS   [0m - Best checkpoint with score 26.86 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:33:22 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_5.8164.pt
2024-07-20 11:33:22 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_12.2812.pt', 'checkpoint_score_18.5117.pt', 'checkpoint_score_21.7734.pt', 'checkpoint_score_24.7930.pt', 'checkpoint_score_26.8555.pt']
2024-07-20 11:33:24 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:33:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:33:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:33:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 403 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_6_iter_403.pt
2024-07-20 11:33:27 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 403 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_6_iter_403.pt
[31m===========================================================================[0m
2024-07-20 11:33:29 - [32m[1mINFO   [0m - Training epoch 7
2024-07-20 11:33:31 - [34m[1mLOGS   [0m - Epoch:   7 [     404/10000000], loss: {'classification': 3.8522, 'neural_augmentation': 10.5501, 'total_loss': 14.4023}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.300, Elapsed time:  2.52
2024-07-20 11:33:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 3.7603, 'neural_augmentation': 10.2775, 'total_loss': 14.0378}
2024-07-20 11:33:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 2.9926, 'neural_augmentation': 0.0, 'total_loss': 2.9926} || top1={'logits': 28.2539} || top5={'logits': 56.8633}
2024-07-20 11:33:47 - [34m[1mLOGS   [0m - Best checkpoint with score 28.25 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:33:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_12.2812.pt
2024-07-20 11:33:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_18.5117.pt', 'checkpoint_score_21.7734.pt', 'checkpoint_score_24.7930.pt', 'checkpoint_score_26.8555.pt', 'checkpoint_score_28.2539.pt']
2024-07-20 11:33:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:33:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:33:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:33:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_7_iter_465.pt
2024-07-20 11:33:54 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_7_iter_465.pt
[31m===========================================================================[0m
2024-07-20 11:33:56 - [32m[1mINFO   [0m - Training epoch 8
2024-07-20 11:33:57 - [34m[1mLOGS   [0m - Epoch:   8 [     466/10000000], loss: {'classification': 3.5612, 'neural_augmentation': 11.0279, 'total_loss': 14.5891}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.013, Elapsed time:  1.20
2024-07-20 11:34:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 3.7512, 'neural_augmentation': 10.4058, 'total_loss': 14.157}
2024-07-20 11:34:11 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 2.9222, 'neural_augmentation': 0.0, 'total_loss': 2.9222} || top1={'logits': 29.8555} || top5={'logits': 59.4922}
2024-07-20 11:34:12 - [34m[1mLOGS   [0m - Best checkpoint with score 29.86 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:34:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_18.5117.pt
2024-07-20 11:34:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_21.7734.pt', 'checkpoint_score_24.7930.pt', 'checkpoint_score_26.8555.pt', 'checkpoint_score_28.2539.pt', 'checkpoint_score_29.8555.pt']
2024-07-20 11:34:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:34:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:34:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:34:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 518 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_8_iter_518.pt
2024-07-20 11:34:16 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 518 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_8_iter_518.pt
[31m===========================================================================[0m
2024-07-20 11:34:18 - [32m[1mINFO   [0m - Training epoch 9
2024-07-20 11:34:20 - [34m[1mLOGS   [0m - Epoch:   9 [     519/10000000], loss: {'classification': 3.6938, 'neural_augmentation': 10.5528, 'total_loss': 14.2467}, LR: [3e-05, 3e-05], Avg. batch load time: 1.144, Elapsed time:  1.31
2024-07-20 11:34:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 3.6959, 'neural_augmentation': 10.357, 'total_loss': 14.0529}
2024-07-20 11:34:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 2.8822, 'neural_augmentation': 0.0, 'total_loss': 2.8822} || top1={'logits': 30.6055} || top5={'logits': 59.8047}
2024-07-20 11:34:35 - [34m[1mLOGS   [0m - Best checkpoint with score 30.61 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:34:35 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_21.7734.pt
2024-07-20 11:34:35 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_24.7930.pt', 'checkpoint_score_26.8555.pt', 'checkpoint_score_28.2539.pt', 'checkpoint_score_29.8555.pt', 'checkpoint_score_30.6055.pt']
2024-07-20 11:34:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:34:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:34:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:34:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 573 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_9_iter_573.pt
2024-07-20 11:34:39 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 573 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_9_iter_573.pt
[31m===========================================================================[0m
2024-07-20 11:34:41 - [32m[1mINFO   [0m - Training epoch 10
2024-07-20 11:34:42 - [34m[1mLOGS   [0m - Epoch:  10 [     574/10000000], loss: {'classification': 3.5718, 'neural_augmentation': 9.7953, 'total_loss': 13.367}, LR: [3e-05, 3e-05], Avg. batch load time: 1.252, Elapsed time:  1.41
2024-07-20 11:34:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 3.6777, 'neural_augmentation': 10.2944, 'total_loss': 13.9721}
2024-07-20 11:34:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 2.8178, 'neural_augmentation': 0.0, 'total_loss': 2.8178} || top1={'logits': 31.4023} || top5={'logits': 61.1992}
2024-07-20 11:34:57 - [34m[1mLOGS   [0m - Best checkpoint with score 31.40 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:34:57 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_24.7930.pt
2024-07-20 11:34:57 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_26.8555.pt', 'checkpoint_score_28.2539.pt', 'checkpoint_score_29.8555.pt', 'checkpoint_score_30.6055.pt', 'checkpoint_score_31.4023.pt']
2024-07-20 11:34:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:35:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:35:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:35:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 624 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_10_iter_624.pt
2024-07-20 11:35:01 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 624 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_10_iter_624.pt
[31m===========================================================================[0m
2024-07-20 11:35:03 - [32m[1mINFO   [0m - Training epoch 11
2024-07-20 11:35:04 - [34m[1mLOGS   [0m - Epoch:  11 [     625/10000000], loss: {'classification': 3.4598, 'neural_augmentation': 11.0078, 'total_loss': 14.4676}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.790, Elapsed time:  0.95
2024-07-20 11:35:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 3.6562, 'neural_augmentation': 10.2283, 'total_loss': 13.8846}
2024-07-20 11:35:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 2.8148, 'neural_augmentation': 0.0, 'total_loss': 2.8148} || top1={'logits': 32.0352} || top5={'logits': 61.1797}
2024-07-20 11:35:19 - [34m[1mLOGS   [0m - Best checkpoint with score 32.04 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:35:19 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_26.8555.pt
2024-07-20 11:35:19 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_28.2539.pt', 'checkpoint_score_29.8555.pt', 'checkpoint_score_30.6055.pt', 'checkpoint_score_31.4023.pt', 'checkpoint_score_32.0352.pt']
2024-07-20 11:35:21 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:35:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:35:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:35:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 673 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_11_iter_673.pt
2024-07-20 11:35:24 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 673 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_11_iter_673.pt
[31m===========================================================================[0m
2024-07-20 11:35:26 - [32m[1mINFO   [0m - Training epoch 12
2024-07-20 11:35:27 - [34m[1mLOGS   [0m - Epoch:  12 [     674/10000000], loss: {'classification': 3.5027, 'neural_augmentation': 9.3296, 'total_loss': 12.8323}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.817, Elapsed time:  0.98
2024-07-20 11:35:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 3.6227, 'neural_augmentation': 10.2218, 'total_loss': 13.8446}
2024-07-20 11:35:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 2.733, 'neural_augmentation': 0.0, 'total_loss': 2.733} || top1={'logits': 33.2617} || top5={'logits': 63.5391}
2024-07-20 11:35:42 - [34m[1mLOGS   [0m - Best checkpoint with score 33.26 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:35:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_28.2539.pt
2024-07-20 11:35:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_29.8555.pt', 'checkpoint_score_30.6055.pt', 'checkpoint_score_31.4023.pt', 'checkpoint_score_32.0352.pt', 'checkpoint_score_33.2617.pt']
2024-07-20 11:35:44 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:35:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:35:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:35:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 727 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_12_iter_727.pt
2024-07-20 11:35:46 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 727 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_12_iter_727.pt
[31m===========================================================================[0m
2024-07-20 11:35:48 - [32m[1mINFO   [0m - Training epoch 13
2024-07-20 11:35:49 - [34m[1mLOGS   [0m - Epoch:  13 [     728/10000000], loss: {'classification': 3.4958, 'neural_augmentation': 9.935, 'total_loss': 13.4308}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.426, Elapsed time:  1.58
2024-07-20 11:35:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 3.6117, 'neural_augmentation': 10.2537, 'total_loss': 13.8654}
2024-07-20 11:36:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 2.7057, 'neural_augmentation': 0.0, 'total_loss': 2.7057} || top1={'logits': 34.207} || top5={'logits': 63.7734}
2024-07-20 11:36:04 - [34m[1mLOGS   [0m - Best checkpoint with score 34.21 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:36:04 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_29.8555.pt
2024-07-20 11:36:04 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_30.6055.pt', 'checkpoint_score_31.4023.pt', 'checkpoint_score_32.0352.pt', 'checkpoint_score_33.2617.pt', 'checkpoint_score_34.2070.pt']
2024-07-20 11:36:07 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:36:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:36:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:36:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 779 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_13_iter_779.pt
2024-07-20 11:36:10 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 779 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_13_iter_779.pt
[31m===========================================================================[0m
2024-07-20 11:36:12 - [32m[1mINFO   [0m - Training epoch 14
2024-07-20 11:36:14 - [34m[1mLOGS   [0m - Epoch:  14 [     780/10000000], loss: {'classification': 3.5662, 'neural_augmentation': 11.029, 'total_loss': 14.5952}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.718, Elapsed time:  1.88
2024-07-20 11:36:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 3.5945, 'neural_augmentation': 10.2288, 'total_loss': 13.8233}
2024-07-20 11:36:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 2.696, 'neural_augmentation': 0.0, 'total_loss': 2.696} || top1={'logits': 34.2695} || top5={'logits': 64.082}
2024-07-20 11:36:29 - [34m[1mLOGS   [0m - Best checkpoint with score 34.27 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:36:29 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_30.6055.pt
2024-07-20 11:36:29 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_31.4023.pt', 'checkpoint_score_32.0352.pt', 'checkpoint_score_33.2617.pt', 'checkpoint_score_34.2070.pt', 'checkpoint_score_34.2695.pt']
2024-07-20 11:36:31 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:36:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:36:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:36:33 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 833 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_14_iter_833.pt
2024-07-20 11:36:33 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 833 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_14_iter_833.pt
[31m===========================================================================[0m
2024-07-20 11:36:35 - [32m[1mINFO   [0m - Training epoch 15
2024-07-20 11:36:36 - [34m[1mLOGS   [0m - Epoch:  15 [     834/10000000], loss: {'classification': 3.3276, 'neural_augmentation': 9.1476, 'total_loss': 12.4753}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.857, Elapsed time:  1.02
2024-07-20 11:36:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 3.5569, 'neural_augmentation': 10.3386, 'total_loss': 13.8954}
2024-07-20 11:36:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 2.6657, 'neural_augmentation': 0.0, 'total_loss': 2.6657} || top1={'logits': 34.7148} || top5={'logits': 64.9219}
2024-07-20 11:36:53 - [34m[1mLOGS   [0m - Best checkpoint with score 34.71 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:36:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_31.4023.pt
2024-07-20 11:36:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_32.0352.pt', 'checkpoint_score_33.2617.pt', 'checkpoint_score_34.2070.pt', 'checkpoint_score_34.2695.pt', 'checkpoint_score_34.7148.pt']
2024-07-20 11:36:55 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:36:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:36:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:36:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 893 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_15_iter_893.pt
2024-07-20 11:36:58 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 893 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_15_iter_893.pt
[31m===========================================================================[0m
2024-07-20 11:37:00 - [32m[1mINFO   [0m - Training epoch 16
2024-07-20 11:37:02 - [34m[1mLOGS   [0m - Epoch:  16 [     894/10000000], loss: {'classification': 3.5704, 'neural_augmentation': 9.4474, 'total_loss': 13.0177}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.853, Elapsed time:  2.01
2024-07-20 11:37:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 3.551, 'neural_augmentation': 10.4019, 'total_loss': 13.9529}
2024-07-20 11:37:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 2.5954, 'neural_augmentation': 0.0, 'total_loss': 2.5954} || top1={'logits': 36.6797} || top5={'logits': 66.7656}
2024-07-20 11:37:17 - [34m[1mLOGS   [0m - Best checkpoint with score 36.68 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:37:17 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_32.0352.pt
2024-07-20 11:37:17 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_33.2617.pt', 'checkpoint_score_34.2070.pt', 'checkpoint_score_34.2695.pt', 'checkpoint_score_34.7148.pt', 'checkpoint_score_36.6797.pt']
2024-07-20 11:37:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:37:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:37:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:37:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 948 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_16_iter_948.pt
2024-07-20 11:37:21 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 948 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_16_iter_948.pt
[31m===========================================================================[0m
2024-07-20 11:37:23 - [32m[1mINFO   [0m - Training epoch 17
2024-07-20 11:37:24 - [34m[1mLOGS   [0m - Epoch:  17 [     949/10000000], loss: {'classification': 3.3638, 'neural_augmentation': 10.1384, 'total_loss': 13.5022}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.912, Elapsed time:  1.07
2024-07-20 11:37:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 3.5218, 'neural_augmentation': 10.2906, 'total_loss': 13.8124}
2024-07-20 11:37:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 2.5999, 'neural_augmentation': 0.0, 'total_loss': 2.5999} || top1={'logits': 37.0156} || top5={'logits': 67.043}
2024-07-20 11:37:41 - [34m[1mLOGS   [0m - Best checkpoint with score 37.02 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:37:41 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_33.2617.pt
2024-07-20 11:37:41 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_34.2070.pt', 'checkpoint_score_34.2695.pt', 'checkpoint_score_34.7148.pt', 'checkpoint_score_36.6797.pt', 'checkpoint_score_37.0156.pt']
2024-07-20 11:37:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:37:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:37:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:37:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 1009 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_17_iter_1009.pt
2024-07-20 11:37:45 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 1009 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_17_iter_1009.pt
[31m===========================================================================[0m
2024-07-20 11:37:47 - [32m[1mINFO   [0m - Training epoch 18
2024-07-20 11:37:49 - [34m[1mLOGS   [0m - Epoch:  18 [    1010/10000000], loss: {'classification': 3.4909, 'neural_augmentation': 9.735, 'total_loss': 13.2259}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.725, Elapsed time:  1.89
2024-07-20 11:37:57 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 3.5289, 'neural_augmentation': 10.3242, 'total_loss': 13.8531}
2024-07-20 11:38:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 2.5676, 'neural_augmentation': 0.0, 'total_loss': 2.5676} || top1={'logits': 36.9492} || top5={'logits': 67.1641}
2024-07-20 11:38:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:38:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:38:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 1064 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_18_iter_1064.pt
2024-07-20 11:38:05 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 1064 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_18_iter_1064.pt
[31m===========================================================================[0m
2024-07-20 11:38:07 - [32m[1mINFO   [0m - Training epoch 19
2024-07-20 11:38:09 - [34m[1mLOGS   [0m - Epoch:  19 [    1065/10000000], loss: {'classification': 3.3474, 'neural_augmentation': 9.5241, 'total_loss': 12.8716}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.472, Elapsed time:  2.64
2024-07-20 11:38:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 3.5073, 'neural_augmentation': 10.4322, 'total_loss': 13.9395}
2024-07-20 11:38:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 2.5396, 'neural_augmentation': 0.0, 'total_loss': 2.5396} || top1={'logits': 37.6602} || top5={'logits': 67.7617}
2024-07-20 11:38:25 - [34m[1mLOGS   [0m - Best checkpoint with score 37.66 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:38:26 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_34.2070.pt
2024-07-20 11:38:26 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_34.2695.pt', 'checkpoint_score_34.7148.pt', 'checkpoint_score_36.6797.pt', 'checkpoint_score_37.0156.pt', 'checkpoint_score_37.6602.pt']
2024-07-20 11:38:28 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:38:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:38:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:38:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 1118 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_19_iter_1118.pt
2024-07-20 11:38:31 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 1118 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_19_iter_1118.pt
[31m===========================================================================[0m
2024-07-20 11:38:33 - [32m[1mINFO   [0m - Training epoch 20
2024-07-20 11:38:34 - [34m[1mLOGS   [0m - Epoch:  20 [    1119/10000000], loss: {'classification': 3.3552, 'neural_augmentation': 10.4225, 'total_loss': 13.7778}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.300, Elapsed time:  1.46
2024-07-20 11:38:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 3.4797, 'neural_augmentation': 10.2298, 'total_loss': 13.7095}
2024-07-20 11:38:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 2.5094, 'neural_augmentation': 0.0, 'total_loss': 2.5094} || top1={'logits': 38.1133} || top5={'logits': 68.3555}
2024-07-20 11:38:51 - [34m[1mLOGS   [0m - Best checkpoint with score 38.11 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:38:51 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_34.2695.pt
2024-07-20 11:38:51 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_34.7148.pt', 'checkpoint_score_36.6797.pt', 'checkpoint_score_37.0156.pt', 'checkpoint_score_37.6602.pt', 'checkpoint_score_38.1133.pt']
2024-07-20 11:38:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:38:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:38:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:38:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 1179 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_20_iter_1179.pt
2024-07-20 11:38:54 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 1179 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_20_iter_1179.pt
[31m===========================================================================[0m
2024-07-20 11:38:56 - [32m[1mINFO   [0m - Training epoch 21
2024-07-20 11:38:58 - [34m[1mLOGS   [0m - Epoch:  21 [    1180/10000000], loss: {'classification': 3.4317, 'neural_augmentation': 9.6495, 'total_loss': 13.0812}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.681, Elapsed time:  1.84
2024-07-20 11:39:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 3.4785, 'neural_augmentation': 10.1781, 'total_loss': 13.6566}
2024-07-20 11:39:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 2.492, 'neural_augmentation': 0.0, 'total_loss': 2.492} || top1={'logits': 38.6328} || top5={'logits': 68.7031}
2024-07-20 11:39:12 - [34m[1mLOGS   [0m - Best checkpoint with score 38.63 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:39:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_34.7148.pt
2024-07-20 11:39:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_36.6797.pt', 'checkpoint_score_37.0156.pt', 'checkpoint_score_37.6602.pt', 'checkpoint_score_38.1133.pt', 'checkpoint_score_38.6328.pt']
2024-07-20 11:39:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:39:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:39:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:39:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 1229 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_21_iter_1229.pt
2024-07-20 11:39:15 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 1229 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_21_iter_1229.pt
[31m===========================================================================[0m
2024-07-20 11:39:17 - [32m[1mINFO   [0m - Training epoch 22
2024-07-20 11:39:20 - [34m[1mLOGS   [0m - Epoch:  22 [    1230/10000000], loss: {'classification': 3.3816, 'neural_augmentation': 11.0842, 'total_loss': 14.4658}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.740, Elapsed time:  2.90
2024-07-20 11:39:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 3.4632, 'neural_augmentation': 10.2264, 'total_loss': 13.6896}
2024-07-20 11:39:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 2.4823, 'neural_augmentation': 0.0, 'total_loss': 2.4823} || top1={'logits': 38.9102} || top5={'logits': 68.832}
2024-07-20 11:39:36 - [34m[1mLOGS   [0m - Best checkpoint with score 38.91 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:39:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_36.6797.pt
2024-07-20 11:39:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_37.0156.pt', 'checkpoint_score_37.6602.pt', 'checkpoint_score_38.1133.pt', 'checkpoint_score_38.6328.pt', 'checkpoint_score_38.9102.pt']
2024-07-20 11:39:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:39:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:39:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:39:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 1290 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_22_iter_1290.pt
2024-07-20 11:39:39 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 1290 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_22_iter_1290.pt
[31m===========================================================================[0m
2024-07-20 11:39:41 - [32m[1mINFO   [0m - Training epoch 23
2024-07-20 11:39:43 - [34m[1mLOGS   [0m - Epoch:  23 [    1291/10000000], loss: {'classification': 3.3083, 'neural_augmentation': 10.3359, 'total_loss': 13.6442}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.648, Elapsed time:  1.81
2024-07-20 11:39:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 3.447, 'neural_augmentation': 10.1686, 'total_loss': 13.6155}
2024-07-20 11:39:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 2.4516, 'neural_augmentation': 0.0, 'total_loss': 2.4516} || top1={'logits': 39.6797} || top5={'logits': 69.7539}
2024-07-20 11:39:59 - [34m[1mLOGS   [0m - Best checkpoint with score 39.68 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:39:59 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_37.0156.pt
2024-07-20 11:39:59 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_37.6602.pt', 'checkpoint_score_38.1133.pt', 'checkpoint_score_38.6328.pt', 'checkpoint_score_38.9102.pt', 'checkpoint_score_39.6797.pt']
2024-07-20 11:40:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:40:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:40:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:40:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 1350 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_23_iter_1350.pt
2024-07-20 11:40:02 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 1350 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_23_iter_1350.pt
[31m===========================================================================[0m
2024-07-20 11:40:04 - [32m[1mINFO   [0m - Training epoch 24
2024-07-20 11:40:06 - [34m[1mLOGS   [0m - Epoch:  24 [    1351/10000000], loss: {'classification': 3.222, 'neural_augmentation': 11.0931, 'total_loss': 14.3151}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.407, Elapsed time:  1.57
2024-07-20 11:40:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 3.4621, 'neural_augmentation': 10.3796, 'total_loss': 13.8417}
2024-07-20 11:40:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 2.4363, 'neural_augmentation': 0.0, 'total_loss': 2.4363} || top1={'logits': 39.9258} || top5={'logits': 69.8086}
2024-07-20 11:40:21 - [34m[1mLOGS   [0m - Best checkpoint with score 39.93 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:40:21 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_37.6602.pt
2024-07-20 11:40:21 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.1133.pt', 'checkpoint_score_38.6328.pt', 'checkpoint_score_38.9102.pt', 'checkpoint_score_39.6797.pt', 'checkpoint_score_39.9258.pt']
2024-07-20 11:40:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:40:23 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:40:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:40:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 1403 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_24_iter_1403.pt
2024-07-20 11:40:25 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 1403 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_24_iter_1403.pt
[31m===========================================================================[0m
2024-07-20 11:40:27 - [32m[1mINFO   [0m - Training epoch 25
2024-07-20 11:40:28 - [34m[1mLOGS   [0m - Epoch:  25 [    1404/10000000], loss: {'classification': 3.3469, 'neural_augmentation': 11.3201, 'total_loss': 14.667}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.046, Elapsed time:  1.20
2024-07-20 11:40:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 3.4218, 'neural_augmentation': 10.2817, 'total_loss': 13.7035}
2024-07-20 11:40:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 2.4243, 'neural_augmentation': 0.0, 'total_loss': 2.4243} || top1={'logits': 40.6953} || top5={'logits': 70.2852}
2024-07-20 11:40:44 - [34m[1mLOGS   [0m - Best checkpoint with score 40.70 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:40:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_38.1133.pt
2024-07-20 11:40:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.6328.pt', 'checkpoint_score_38.9102.pt', 'checkpoint_score_39.6797.pt', 'checkpoint_score_39.9258.pt', 'checkpoint_score_40.6953.pt']
2024-07-20 11:40:46 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:40:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:40:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:40:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 1462 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_25_iter_1462.pt
2024-07-20 11:40:47 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 1462 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_25_iter_1462.pt
[31m===========================================================================[0m
2024-07-20 11:40:49 - [32m[1mINFO   [0m - Training epoch 26
2024-07-20 11:40:51 - [34m[1mLOGS   [0m - Epoch:  26 [    1463/10000000], loss: {'classification': 3.281, 'neural_augmentation': 9.614, 'total_loss': 12.895}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 2.151, Elapsed time:  2.31
2024-07-20 11:41:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 3.4101, 'neural_augmentation': 10.0618, 'total_loss': 13.4719}
2024-07-20 11:41:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 2.3974, 'neural_augmentation': 0.0, 'total_loss': 2.3974} || top1={'logits': 40.8672} || top5={'logits': 70.2188}
2024-07-20 11:41:07 - [34m[1mLOGS   [0m - Best checkpoint with score 40.87 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:41:07 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_38.6328.pt
2024-07-20 11:41:07 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.9102.pt', 'checkpoint_score_39.6797.pt', 'checkpoint_score_39.9258.pt', 'checkpoint_score_40.6953.pt', 'checkpoint_score_40.8672.pt']
2024-07-20 11:41:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:41:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:41:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:41:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 1518 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_26_iter_1518.pt
2024-07-20 11:41:11 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 1518 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_26_iter_1518.pt
[31m===========================================================================[0m
2024-07-20 11:41:13 - [32m[1mINFO   [0m - Training epoch 27
2024-07-20 11:41:15 - [34m[1mLOGS   [0m - Epoch:  27 [    1519/10000000], loss: {'classification': 3.2917, 'neural_augmentation': 10.1451, 'total_loss': 13.4369}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.878, Elapsed time:  2.11
2024-07-20 11:41:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 3.3733, 'neural_augmentation': 10.1692, 'total_loss': 13.5425}
2024-07-20 11:41:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 2.3909, 'neural_augmentation': 0.0, 'total_loss': 2.3909} || top1={'logits': 41.207} || top5={'logits': 70.3672}
2024-07-20 11:41:32 - [34m[1mLOGS   [0m - Best checkpoint with score 41.21 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:41:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_38.9102.pt
2024-07-20 11:41:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.6797.pt', 'checkpoint_score_39.9258.pt', 'checkpoint_score_40.6953.pt', 'checkpoint_score_40.8672.pt', 'checkpoint_score_41.2070.pt']
2024-07-20 11:41:33 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:41:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:41:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:41:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 1585 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_27_iter_1585.pt
2024-07-20 11:41:35 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 1585 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_27_iter_1585.pt
[31m===========================================================================[0m
2024-07-20 11:41:37 - [32m[1mINFO   [0m - Training epoch 28
2024-07-20 11:41:40 - [34m[1mLOGS   [0m - Epoch:  28 [    1586/10000000], loss: {'classification': 3.5244, 'neural_augmentation': 10.5982, 'total_loss': 14.1226}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 2.394, Elapsed time:  2.56
2024-07-20 11:41:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 3.4022, 'neural_augmentation': 10.0799, 'total_loss': 13.4821}
2024-07-20 11:41:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 2.3972, 'neural_augmentation': 0.0, 'total_loss': 2.3972} || top1={'logits': 40.5664} || top5={'logits': 70.3789}
2024-07-20 11:41:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:41:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:41:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 1639 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_28_iter_1639.pt
2024-07-20 11:41:55 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 1639 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_28_iter_1639.pt
[31m===========================================================================[0m
2024-07-20 11:41:57 - [32m[1mINFO   [0m - Training epoch 29
2024-07-20 11:41:59 - [34m[1mLOGS   [0m - Epoch:  29 [    1640/10000000], loss: {'classification': 3.2735, 'neural_augmentation': 9.4913, 'total_loss': 12.7649}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.862, Elapsed time:  2.03
2024-07-20 11:42:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 3.389, 'neural_augmentation': 10.2557, 'total_loss': 13.6447}
2024-07-20 11:42:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 2.3837, 'neural_augmentation': 0.0, 'total_loss': 2.3837} || top1={'logits': 41.6055} || top5={'logits': 70.543}
2024-07-20 11:42:17 - [34m[1mLOGS   [0m - Best checkpoint with score 41.61 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:42:17 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_39.6797.pt
2024-07-20 11:42:17 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.9258.pt', 'checkpoint_score_40.6953.pt', 'checkpoint_score_40.8672.pt', 'checkpoint_score_41.2070.pt', 'checkpoint_score_41.6055.pt']
2024-07-20 11:42:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:42:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:42:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:42:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 1695 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_29_iter_1695.pt
2024-07-20 11:42:19 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 1695 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_29_iter_1695.pt
[31m===========================================================================[0m
2024-07-20 11:42:21 - [32m[1mINFO   [0m - Training epoch 30
2024-07-20 11:42:24 - [34m[1mLOGS   [0m - Epoch:  30 [    1696/10000000], loss: {'classification': 3.3997, 'neural_augmentation': 10.4491, 'total_loss': 13.8488}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 2.697, Elapsed time:  2.85
2024-07-20 11:42:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'classification': 3.3939, 'neural_augmentation': 10.1867, 'total_loss': 13.5806}
2024-07-20 11:42:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'classification': 2.3625, 'neural_augmentation': 0.0, 'total_loss': 2.3625} || top1={'logits': 41.3789} || top5={'logits': 70.7227}
2024-07-20 11:42:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:42:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:42:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 1746 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_30_iter_1746.pt
2024-07-20 11:42:39 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 1746 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_30_iter_1746.pt
[31m===========================================================================[0m
2024-07-20 11:42:41 - [32m[1mINFO   [0m - Training epoch 31
2024-07-20 11:42:43 - [34m[1mLOGS   [0m - Epoch:  31 [    1747/10000000], loss: {'classification': 3.1697, 'neural_augmentation': 9.7191, 'total_loss': 12.8888}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 2.066, Elapsed time:  2.23
2024-07-20 11:42:52 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'classification': 3.4053, 'neural_augmentation': 10.1551, 'total_loss': 13.5603}
2024-07-20 11:42:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'classification': 2.3414, 'neural_augmentation': 0.0, 'total_loss': 2.3414} || top1={'logits': 42.2656} || top5={'logits': 71.4102}
2024-07-20 11:42:58 - [34m[1mLOGS   [0m - Best checkpoint with score 42.27 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:42:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_39.9258.pt
2024-07-20 11:42:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_40.6953.pt', 'checkpoint_score_40.8672.pt', 'checkpoint_score_41.2070.pt', 'checkpoint_score_41.6055.pt', 'checkpoint_score_42.2656.pt']
2024-07-20 11:43:00 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:43:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:43:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:43:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 1790 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_31_iter_1790.pt
2024-07-20 11:43:02 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 1790 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_31_iter_1790.pt
[31m===========================================================================[0m
2024-07-20 11:43:04 - [32m[1mINFO   [0m - Training epoch 32
2024-07-20 11:43:06 - [34m[1mLOGS   [0m - Epoch:  32 [    1791/10000000], loss: {'classification': 3.356, 'neural_augmentation': 9.3802, 'total_loss': 12.7362}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 2.045, Elapsed time:  2.20
2024-07-20 11:43:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'classification': 3.3431, 'neural_augmentation': 10.0982, 'total_loss': 13.4413}
2024-07-20 11:43:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'classification': 2.3253, 'neural_augmentation': 0.0, 'total_loss': 2.3253} || top1={'logits': 42.668} || top5={'logits': 71.9375}
2024-07-20 11:43:21 - [34m[1mLOGS   [0m - Best checkpoint with score 42.67 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:43:21 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_40.6953.pt
2024-07-20 11:43:21 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_40.8672.pt', 'checkpoint_score_41.2070.pt', 'checkpoint_score_41.6055.pt', 'checkpoint_score_42.2656.pt', 'checkpoint_score_42.6680.pt']
2024-07-20 11:43:22 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:43:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:43:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:43:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 1845 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_32_iter_1845.pt
2024-07-20 11:43:24 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 1845 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_32_iter_1845.pt
[31m===========================================================================[0m
2024-07-20 11:43:26 - [32m[1mINFO   [0m - Training epoch 33
2024-07-20 11:43:28 - [34m[1mLOGS   [0m - Epoch:  33 [    1846/10000000], loss: {'classification': 3.3132, 'neural_augmentation': 9.8124, 'total_loss': 13.1256}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 2.312, Elapsed time:  2.47
2024-07-20 11:43:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'classification': 3.3577, 'neural_augmentation': 10.1397, 'total_loss': 13.4974}
2024-07-20 11:43:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'classification': 2.3384, 'neural_augmentation': 0.0, 'total_loss': 2.3384} || top1={'logits': 41.7305} || top5={'logits': 71.4141}
2024-07-20 11:43:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:43:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:43:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 1897 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_33_iter_1897.pt
2024-07-20 11:43:43 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 1897 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_33_iter_1897.pt
[31m===========================================================================[0m
2024-07-20 11:43:45 - [32m[1mINFO   [0m - Training epoch 34
2024-07-20 11:43:49 - [34m[1mLOGS   [0m - Epoch:  34 [    1898/10000000], loss: {'classification': 3.2779, 'neural_augmentation': 10.9394, 'total_loss': 14.2173}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 3.934, Elapsed time:  4.10
2024-07-20 11:43:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'classification': 3.3316, 'neural_augmentation': 10.1794, 'total_loss': 13.511}
2024-07-20 11:44:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'classification': 2.3183, 'neural_augmentation': 0.0, 'total_loss': 2.3183} || top1={'logits': 42.8125} || top5={'logits': 71.7852}
2024-07-20 11:44:05 - [34m[1mLOGS   [0m - Best checkpoint with score 42.81 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:44:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_40.8672.pt
2024-07-20 11:44:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_41.2070.pt', 'checkpoint_score_41.6055.pt', 'checkpoint_score_42.2656.pt', 'checkpoint_score_42.6680.pt', 'checkpoint_score_42.8125.pt']
2024-07-20 11:44:06 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:44:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:44:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:44:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 1955 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_34_iter_1955.pt
2024-07-20 11:44:08 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 1955 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_34_iter_1955.pt
[31m===========================================================================[0m
2024-07-20 11:44:10 - [32m[1mINFO   [0m - Training epoch 35
2024-07-20 11:44:13 - [34m[1mLOGS   [0m - Epoch:  35 [    1956/10000000], loss: {'classification': 3.429, 'neural_augmentation': 9.5723, 'total_loss': 13.0013}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 2.404, Elapsed time:  2.56
2024-07-20 11:44:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'classification': 3.333, 'neural_augmentation': 10.2186, 'total_loss': 13.5516}
2024-07-20 11:44:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'classification': 2.3054, 'neural_augmentation': 0.0, 'total_loss': 2.3054} || top1={'logits': 42.9102} || top5={'logits': 72.0508}
2024-07-20 11:44:28 - [34m[1mLOGS   [0m - Best checkpoint with score 42.91 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:44:28 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_41.2070.pt
2024-07-20 11:44:28 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_41.6055.pt', 'checkpoint_score_42.2656.pt', 'checkpoint_score_42.6680.pt', 'checkpoint_score_42.8125.pt', 'checkpoint_score_42.9102.pt']
2024-07-20 11:44:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:44:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:44:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:44:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 2010 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_35_iter_2010.pt
2024-07-20 11:44:30 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 2010 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_35_iter_2010.pt
[31m===========================================================================[0m
2024-07-20 11:44:32 - [32m[1mINFO   [0m - Training epoch 36
2024-07-20 11:44:34 - [34m[1mLOGS   [0m - Epoch:  36 [    2011/10000000], loss: {'classification': 3.2579, 'neural_augmentation': 11.0043, 'total_loss': 14.2622}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.026, Elapsed time:  2.19
2024-07-20 11:44:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'classification': 3.3455, 'neural_augmentation': 10.1959, 'total_loss': 13.5414}
2024-07-20 11:44:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'classification': 2.289, 'neural_augmentation': 0.0, 'total_loss': 2.289} || top1={'logits': 43.418} || top5={'logits': 72.6797}
2024-07-20 11:44:49 - [34m[1mLOGS   [0m - Best checkpoint with score 43.42 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:44:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_41.6055.pt
2024-07-20 11:44:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_42.2656.pt', 'checkpoint_score_42.6680.pt', 'checkpoint_score_42.8125.pt', 'checkpoint_score_42.9102.pt', 'checkpoint_score_43.4180.pt']
2024-07-20 11:44:50 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:44:51 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:44:51 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:44:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 2061 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_36_iter_2061.pt
2024-07-20 11:44:52 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 2061 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_36_iter_2061.pt
[31m===========================================================================[0m
2024-07-20 11:44:54 - [32m[1mINFO   [0m - Training epoch 37
2024-07-20 11:44:56 - [34m[1mLOGS   [0m - Epoch:  37 [    2062/10000000], loss: {'classification': 3.2951, 'neural_augmentation': 10.3622, 'total_loss': 13.6574}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.373, Elapsed time:  2.53
2024-07-20 11:45:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'classification': 3.3175, 'neural_augmentation': 10.0942, 'total_loss': 13.4117}
2024-07-20 11:45:11 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'classification': 2.2512, 'neural_augmentation': 0.0, 'total_loss': 2.2512} || top1={'logits': 44.0586} || top5={'logits': 73.2578}
2024-07-20 11:45:11 - [34m[1mLOGS   [0m - Best checkpoint with score 44.06 saved at /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_best.pt
2024-07-20 11:45:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_score_42.2656.pt
2024-07-20 11:45:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_42.6680.pt', 'checkpoint_score_42.8125.pt', 'checkpoint_score_42.9102.pt', 'checkpoint_score_43.4180.pt', 'checkpoint_score_44.0586.pt']
2024-07-20 11:45:13 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_avg.pt
2024-07-20 11:45:13 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_last.pt
2024-07-20 11:45:13 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_last.pt
2024-07-20 11:45:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 2117 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/training_checkpoint_epoch_37_iter_2117.pt
2024-07-20 11:45:15 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 2117 is saved at: /ML-A100/team/mm/models/catlip_data/single_foodv_small_dci/train/checkpoint_epoch_37_iter_2117.pt
[31m===========================================================================[0m
2024-07-20 11:45:17 - [32m[1mINFO   [0m - Training epoch 38
2024-07-20 11:45:20 - [34m[1mLOGS   [0m - Epoch:  38 [    2118/10000000], loss: {'classification': 3.4256, 'neural_augmentation': 11.0135, 'total_loss': 14.439}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.712, Elapsed time:  2.87
Process SpawnProcess-1:
Terminated
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/process.py", line 317, in _bootstrap
    util._exit_function()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/util.py", line 353, in _exit_function
    p._popen.terminate()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/popen_fork.py", line 57, in terminate
    self._send_signal(signal.SIGTERM)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/popen_fork.py", line 49, in _send_signal
    os.kill(self.pid, sig)
KeyboardInterrupt
2024-07-20 11:45:23 - [34m[1mLOGS   [0m - Keyboard interruption. Exiting from early training
2024-07-20 11:45:23 - [34m[1mLOGS   [0m - Training took 00:20:25.83
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
