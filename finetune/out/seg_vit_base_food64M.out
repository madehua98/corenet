nohup: ignoring input
2024-08-01 11:01:25 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_vit_base/train/checkpoint_epoch_9_iter_79045.pt
2024-08-01 11:01:27 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-08-01 11:01:27 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-01 11:01:27 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_emb.0.block.conv.weight', 'encoder.patch_emb.0.block.norm.weight', 'encoder.patch_emb.0.block.norm.bias', 'encoder.patch_emb.1.block.conv.weight', 'encoder.patch_emb.1.block.norm.weight', 'encoder.patch_emb.1.block.norm.bias', 'encoder.patch_emb.2.block.conv.weight', 'encoder.patch_emb.2.block.conv.bias', 'encoder.post_transformer_norm.weight', 'encoder.post_transformer_norm.bias', 'encoder.transformer.0.pre_norm_mha.0.weight', 'encoder.transformer.0.pre_norm_mha.0.bias', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.0.pre_norm_ffn.0.weight', 'encoder.transformer.0.pre_norm_ffn.0.bias', 'encoder.transformer.0.pre_norm_ffn.1.weight', 'encoder.transformer.0.pre_norm_ffn.1.bias', 'encoder.transformer.0.pre_norm_ffn.4.weight', 'encoder.transformer.0.pre_norm_ffn.4.bias', 'encoder.transformer.1.pre_norm_mha.0.weight', 'encoder.transformer.1.pre_norm_mha.0.bias', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.1.pre_norm_ffn.0.weight', 'encoder.transformer.1.pre_norm_ffn.0.bias', 'encoder.transformer.1.pre_norm_ffn.1.weight', 'encoder.transformer.1.pre_norm_ffn.1.bias', 'encoder.transformer.1.pre_norm_ffn.4.weight', 'encoder.transformer.1.pre_norm_ffn.4.bias', 'encoder.transformer.2.pre_norm_mha.0.weight', 'encoder.transformer.2.pre_norm_mha.0.bias', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.2.pre_norm_ffn.0.weight', 'encoder.transformer.2.pre_norm_ffn.0.bias', 'encoder.transformer.2.pre_norm_ffn.1.weight', 'encoder.transformer.2.pre_norm_ffn.1.bias', 'encoder.transformer.2.pre_norm_ffn.4.weight', 'encoder.transformer.2.pre_norm_ffn.4.bias', 'encoder.transformer.3.pre_norm_mha.0.weight', 'encoder.transformer.3.pre_norm_mha.0.bias', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.3.pre_norm_ffn.0.weight', 'encoder.transformer.3.pre_norm_ffn.0.bias', 'encoder.transformer.3.pre_norm_ffn.1.weight', 'encoder.transformer.3.pre_norm_ffn.1.bias', 'encoder.transformer.3.pre_norm_ffn.4.weight', 'encoder.transformer.3.pre_norm_ffn.4.bias', 'encoder.transformer.4.pre_norm_mha.0.weight', 'encoder.transformer.4.pre_norm_mha.0.bias', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.4.pre_norm_ffn.0.weight', 'encoder.transformer.4.pre_norm_ffn.0.bias', 'encoder.transformer.4.pre_norm_ffn.1.weight', 'encoder.transformer.4.pre_norm_ffn.1.bias', 'encoder.transformer.4.pre_norm_ffn.4.weight', 'encoder.transformer.4.pre_norm_ffn.4.bias', 'encoder.transformer.5.pre_norm_mha.0.weight', 'encoder.transformer.5.pre_norm_mha.0.bias', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.5.pre_norm_ffn.0.weight', 'encoder.transformer.5.pre_norm_ffn.0.bias', 'encoder.transformer.5.pre_norm_ffn.1.weight', 'encoder.transformer.5.pre_norm_ffn.1.bias', 'encoder.transformer.5.pre_norm_ffn.4.weight', 'encoder.transformer.5.pre_norm_ffn.4.bias', 'encoder.transformer.6.pre_norm_mha.0.weight', 'encoder.transformer.6.pre_norm_mha.0.bias', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.6.pre_norm_ffn.0.weight', 'encoder.transformer.6.pre_norm_ffn.0.bias', 'encoder.transformer.6.pre_norm_ffn.1.weight', 'encoder.transformer.6.pre_norm_ffn.1.bias', 'encoder.transformer.6.pre_norm_ffn.4.weight', 'encoder.transformer.6.pre_norm_ffn.4.bias', 'encoder.transformer.7.pre_norm_mha.0.weight', 'encoder.transformer.7.pre_norm_mha.0.bias', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.7.pre_norm_ffn.0.weight', 'encoder.transformer.7.pre_norm_ffn.0.bias', 'encoder.transformer.7.pre_norm_ffn.1.weight', 'encoder.transformer.7.pre_norm_ffn.1.bias', 'encoder.transformer.7.pre_norm_ffn.4.weight', 'encoder.transformer.7.pre_norm_ffn.4.bias', 'encoder.transformer.8.pre_norm_mha.0.weight', 'encoder.transformer.8.pre_norm_mha.0.bias', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.8.pre_norm_ffn.0.weight', 'encoder.transformer.8.pre_norm_ffn.0.bias', 'encoder.transformer.8.pre_norm_ffn.1.weight', 'encoder.transformer.8.pre_norm_ffn.1.bias', 'encoder.transformer.8.pre_norm_ffn.4.weight', 'encoder.transformer.8.pre_norm_ffn.4.bias', 'encoder.transformer.9.pre_norm_mha.0.weight', 'encoder.transformer.9.pre_norm_mha.0.bias', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.9.pre_norm_ffn.0.weight', 'encoder.transformer.9.pre_norm_ffn.0.bias', 'encoder.transformer.9.pre_norm_ffn.1.weight', 'encoder.transformer.9.pre_norm_ffn.1.bias', 'encoder.transformer.9.pre_norm_ffn.4.weight', 'encoder.transformer.9.pre_norm_ffn.4.bias', 'encoder.transformer.10.pre_norm_mha.0.weight', 'encoder.transformer.10.pre_norm_mha.0.bias', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.10.pre_norm_ffn.0.weight', 'encoder.transformer.10.pre_norm_ffn.0.bias', 'encoder.transformer.10.pre_norm_ffn.1.weight', 'encoder.transformer.10.pre_norm_ffn.1.bias', 'encoder.transformer.10.pre_norm_ffn.4.weight', 'encoder.transformer.10.pre_norm_ffn.4.bias', 'encoder.transformer.11.pre_norm_mha.0.weight', 'encoder.transformer.11.pre_norm_mha.0.bias', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.11.pre_norm_ffn.0.weight', 'encoder.transformer.11.pre_norm_ffn.0.bias', 'encoder.transformer.11.pre_norm_ffn.1.weight', 'encoder.transformer.11.pre_norm_ffn.1.bias', 'encoder.transformer.11.pre_norm_ffn.4.weight', 'encoder.transformer.11.pre_norm_ffn.4.bias', 'encoder.pos_embed.pos_embed.pos_embed', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): VisionTransformer(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_emb): Sequential(
      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
      (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
      (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
    )
    (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
    (transformer): Sequential(
      (0): FlashTransformerEncoder
      (1): FlashTransformerEncoder
      (2): FlashTransformerEncoder
      (3): FlashTransformerEncoder
      (4): FlashTransformerEncoder
      (5): FlashTransformerEncoder
      (6): FlashTransformerEncoder
      (7): FlashTransformerEncoder
      (8): FlashTransformerEncoder
      (9): FlashTransformerEncoder
      (10): FlashTransformerEncoder
      (11): FlashTransformerEncoder
    )
    (classifier): None
    (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
    (emb_dropout): Dropout(p=0.0, inplace=False)
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=16.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   91.220 M
Total trainable parameters =   91.220 M

2024-08-01 11:01:27 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 91.22M                 | 17.947G    |
|  encoder                                  |  85.955M               |  16.928G   |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_emb                       |   0.748M               |   0.262G   |
|    encoder.patch_emb.0.block              |    9.6K                |    30.106M |
|    encoder.patch_emb.1.block              |    0.148M              |    0.116G  |
|    encoder.patch_emb.2.block.conv         |    0.591M              |    0.116G  |
|   encoder.post_transformer_norm           |   1.536K               |   0.753M   |
|    encoder.post_transformer_norm.weight   |    (768,)              |            |
|    encoder.post_transformer_norm.bias     |    (768,)              |            |
|   encoder.transformer                     |   85.054M              |   16.665G  |
|    encoder.transformer.0                  |    7.088M              |    1.389G  |
|    encoder.transformer.1                  |    7.088M              |    1.389G  |
|    encoder.transformer.2                  |    7.088M              |    1.389G  |
|    encoder.transformer.3                  |    7.088M              |    1.389G  |
|    encoder.transformer.4                  |    7.088M              |    1.389G  |
|    encoder.transformer.5                  |    7.088M              |    1.389G  |
|    encoder.transformer.6                  |    7.088M              |    1.389G  |
|    encoder.transformer.7                  |    7.088M              |    1.389G  |
|    encoder.transformer.8                  |    7.088M              |    1.389G  |
|    encoder.transformer.9                  |    7.088M              |    1.389G  |
|    encoder.transformer.10                 |    7.088M              |    1.389G  |
|    encoder.transformer.11                 |    7.088M              |    1.389G  |
|   encoder.pos_embed.pos_embed             |   0.151M               |   0        |
|    encoder.pos_embed.pos_embed.pos_embed  |    (1, 1, 196, 768)    |            |
|  seg_head                                 |  5.266M                |  1.02G     |
|   seg_head.aspp.aspp_layer                |   5.242M               |   0.994G   |
|    seg_head.aspp.aspp_layer.convs         |    4.991M              |    0.945G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    49.26M  |
|   seg_head.classifier.block.conv          |   23.4K                |   4.566M   |
|    seg_head.classifier.block.conv.weight  |    (104, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (104,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.873M  |
2024-08-01 11:01:27 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-01 11:01:27 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.transformer.6.drop_path', 'encoder.neural_augmentor.contrast', 'encoder.transformer.3.drop_path', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.transformer.8.drop_path', 'encoder.neural_augmentor.noise.min_fn', 'encoder.neural_augmentor', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.transformer.10.drop_path', 'encoder.transformer.5.drop_path', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.transformer.2.drop_path', 'encoder.transformer.0.drop_path', 'encoder.transformer.9.drop_path', 'encoder.transformer.4.drop_path', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.transformer.7.drop_path', 'encoder.neural_augmentor.brightness', 'encoder.neural_augmentor.noise.max_fn', 'encoder.transformer.1.drop_path', 'encoder.transformer.11.drop_path', 'encoder.neural_augmentor.noise'}
2024-08-01 11:01:27 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 20, 'aten::scaled_dot_product_attention': 12, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-08-01 11:01:27 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-01 11:01:28 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-08-01 11:01:28 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train
2024-08-01 11:01:33 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40010
2024-08-01 11:01:32 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40010
2024-08-01 11:01:36 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=True 
	num_samples=4983
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=224, w=224), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-01 11:01:36 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=False 
	num_samples=2135
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-01 11:01:36 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-08-01 11:01:36 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-08-01 11:01:36 - [34m[1mLOGS   [0m - Number of data workers: 64
2024-08-01 11:01:38 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_vit_base/train/checkpoint_epoch_9_iter_79045.pt
2024-08-01 11:01:38 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-08-01 11:01:38 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-01 11:01:38 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_emb.0.block.conv.weight', 'encoder.patch_emb.0.block.norm.weight', 'encoder.patch_emb.0.block.norm.bias', 'encoder.patch_emb.1.block.conv.weight', 'encoder.patch_emb.1.block.norm.weight', 'encoder.patch_emb.1.block.norm.bias', 'encoder.patch_emb.2.block.conv.weight', 'encoder.patch_emb.2.block.conv.bias', 'encoder.post_transformer_norm.weight', 'encoder.post_transformer_norm.bias', 'encoder.transformer.0.pre_norm_mha.0.weight', 'encoder.transformer.0.pre_norm_mha.0.bias', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.0.pre_norm_ffn.0.weight', 'encoder.transformer.0.pre_norm_ffn.0.bias', 'encoder.transformer.0.pre_norm_ffn.1.weight', 'encoder.transformer.0.pre_norm_ffn.1.bias', 'encoder.transformer.0.pre_norm_ffn.4.weight', 'encoder.transformer.0.pre_norm_ffn.4.bias', 'encoder.transformer.1.pre_norm_mha.0.weight', 'encoder.transformer.1.pre_norm_mha.0.bias', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.1.pre_norm_ffn.0.weight', 'encoder.transformer.1.pre_norm_ffn.0.bias', 'encoder.transformer.1.pre_norm_ffn.1.weight', 'encoder.transformer.1.pre_norm_ffn.1.bias', 'encoder.transformer.1.pre_norm_ffn.4.weight', 'encoder.transformer.1.pre_norm_ffn.4.bias', 'encoder.transformer.2.pre_norm_mha.0.weight', 'encoder.transformer.2.pre_norm_mha.0.bias', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.2.pre_norm_ffn.0.weight', 'encoder.transformer.2.pre_norm_ffn.0.bias', 'encoder.transformer.2.pre_norm_ffn.1.weight', 'encoder.transformer.2.pre_norm_ffn.1.bias', 'encoder.transformer.2.pre_norm_ffn.4.weight', 'encoder.transformer.2.pre_norm_ffn.4.bias', 'encoder.transformer.3.pre_norm_mha.0.weight', 'encoder.transformer.3.pre_norm_mha.0.bias', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.3.pre_norm_ffn.0.weight', 'encoder.transformer.3.pre_norm_ffn.0.bias', 'encoder.transformer.3.pre_norm_ffn.1.weight', 'encoder.transformer.3.pre_norm_ffn.1.bias', 'encoder.transformer.3.pre_norm_ffn.4.weight', 'encoder.transformer.3.pre_norm_ffn.4.bias', 'encoder.transformer.4.pre_norm_mha.0.weight', 'encoder.transformer.4.pre_norm_mha.0.bias', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.4.pre_norm_ffn.0.weight', 'encoder.transformer.4.pre_norm_ffn.0.bias', 'encoder.transformer.4.pre_norm_ffn.1.weight', 'encoder.transformer.4.pre_norm_ffn.1.bias', 'encoder.transformer.4.pre_norm_ffn.4.weight', 'encoder.transformer.4.pre_norm_ffn.4.bias', 'encoder.transformer.5.pre_norm_mha.0.weight', 'encoder.transformer.5.pre_norm_mha.0.bias', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.5.pre_norm_ffn.0.weight', 'encoder.transformer.5.pre_norm_ffn.0.bias', 'encoder.transformer.5.pre_norm_ffn.1.weight', 'encoder.transformer.5.pre_norm_ffn.1.bias', 'encoder.transformer.5.pre_norm_ffn.4.weight', 'encoder.transformer.5.pre_norm_ffn.4.bias', 'encoder.transformer.6.pre_norm_mha.0.weight', 'encoder.transformer.6.pre_norm_mha.0.bias', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.6.pre_norm_ffn.0.weight', 'encoder.transformer.6.pre_norm_ffn.0.bias', 'encoder.transformer.6.pre_norm_ffn.1.weight', 'encoder.transformer.6.pre_norm_ffn.1.bias', 'encoder.transformer.6.pre_norm_ffn.4.weight', 'encoder.transformer.6.pre_norm_ffn.4.bias', 'encoder.transformer.7.pre_norm_mha.0.weight', 'encoder.transformer.7.pre_norm_mha.0.bias', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.7.pre_norm_ffn.0.weight', 'encoder.transformer.7.pre_norm_ffn.0.bias', 'encoder.transformer.7.pre_norm_ffn.1.weight', 'encoder.transformer.7.pre_norm_ffn.1.bias', 'encoder.transformer.7.pre_norm_ffn.4.weight', 'encoder.transformer.7.pre_norm_ffn.4.bias', 'encoder.transformer.8.pre_norm_mha.0.weight', 'encoder.transformer.8.pre_norm_mha.0.bias', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.8.pre_norm_ffn.0.weight', 'encoder.transformer.8.pre_norm_ffn.0.bias', 'encoder.transformer.8.pre_norm_ffn.1.weight', 'encoder.transformer.8.pre_norm_ffn.1.bias', 'encoder.transformer.8.pre_norm_ffn.4.weight', 'encoder.transformer.8.pre_norm_ffn.4.bias', 'encoder.transformer.9.pre_norm_mha.0.weight', 'encoder.transformer.9.pre_norm_mha.0.bias', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.9.pre_norm_ffn.0.weight', 'encoder.transformer.9.pre_norm_ffn.0.bias', 'encoder.transformer.9.pre_norm_ffn.1.weight', 'encoder.transformer.9.pre_norm_ffn.1.bias', 'encoder.transformer.9.pre_norm_ffn.4.weight', 'encoder.transformer.9.pre_norm_ffn.4.bias', 'encoder.transformer.10.pre_norm_mha.0.weight', 'encoder.transformer.10.pre_norm_mha.0.bias', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.10.pre_norm_ffn.0.weight', 'encoder.transformer.10.pre_norm_ffn.0.bias', 'encoder.transformer.10.pre_norm_ffn.1.weight', 'encoder.transformer.10.pre_norm_ffn.1.bias', 'encoder.transformer.10.pre_norm_ffn.4.weight', 'encoder.transformer.10.pre_norm_ffn.4.bias', 'encoder.transformer.11.pre_norm_mha.0.weight', 'encoder.transformer.11.pre_norm_mha.0.bias', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.11.pre_norm_ffn.0.weight', 'encoder.transformer.11.pre_norm_ffn.0.bias', 'encoder.transformer.11.pre_norm_ffn.1.weight', 'encoder.transformer.11.pre_norm_ffn.1.bias', 'encoder.transformer.11.pre_norm_ffn.4.weight', 'encoder.transformer.11.pre_norm_ffn.4.bias', 'encoder.pos_embed.pos_embed.pos_embed', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-01 11:01:38 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): VisionTransformer(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_emb): Sequential(
      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
      (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
      (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
    )
    (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
    (transformer): Sequential(
      (0): FlashTransformerEncoder
      (1): FlashTransformerEncoder
      (2): FlashTransformerEncoder
      (3): FlashTransformerEncoder
      (4): FlashTransformerEncoder
      (5): FlashTransformerEncoder
      (6): FlashTransformerEncoder
      (7): FlashTransformerEncoder
      (8): FlashTransformerEncoder
      (9): FlashTransformerEncoder
      (10): FlashTransformerEncoder
      (11): FlashTransformerEncoder
    )
    (classifier): None
    (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
    (emb_dropout): Dropout(p=0.0, inplace=False)
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=16.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   91.220 M
Total trainable parameters =   91.220 M

2024-08-01 11:01:39 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 91.22M                 | 17.947G    |
|  encoder                                  |  85.955M               |  16.928G   |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_emb                       |   0.748M               |   0.262G   |
|    encoder.patch_emb.0.block              |    9.6K                |    30.106M |
|    encoder.patch_emb.1.block              |    0.148M              |    0.116G  |
|    encoder.patch_emb.2.block.conv         |    0.591M              |    0.116G  |
|   encoder.post_transformer_norm           |   1.536K               |   0.753M   |
|    encoder.post_transformer_norm.weight   |    (768,)              |            |
|    encoder.post_transformer_norm.bias     |    (768,)              |            |
|   encoder.transformer                     |   85.054M              |   16.665G  |
|    encoder.transformer.0                  |    7.088M              |    1.389G  |
|    encoder.transformer.1                  |    7.088M              |    1.389G  |
|    encoder.transformer.2                  |    7.088M              |    1.389G  |
|    encoder.transformer.3                  |    7.088M              |    1.389G  |
|    encoder.transformer.4                  |    7.088M              |    1.389G  |
|    encoder.transformer.5                  |    7.088M              |    1.389G  |
|    encoder.transformer.6                  |    7.088M              |    1.389G  |
|    encoder.transformer.7                  |    7.088M              |    1.389G  |
|    encoder.transformer.8                  |    7.088M              |    1.389G  |
|    encoder.transformer.9                  |    7.088M              |    1.389G  |
|    encoder.transformer.10                 |    7.088M              |    1.389G  |
|    encoder.transformer.11                 |    7.088M              |    1.389G  |
|   encoder.pos_embed.pos_embed             |   0.151M               |   0        |
|    encoder.pos_embed.pos_embed.pos_embed  |    (1, 1, 196, 768)    |            |
|  seg_head                                 |  5.266M                |  1.02G     |
|   seg_head.aspp.aspp_layer                |   5.242M               |   0.994G   |
|    seg_head.aspp.aspp_layer.convs         |    4.991M              |    0.945G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    49.26M  |
|   seg_head.classifier.block.conv          |   23.4K                |   4.566M   |
|    seg_head.classifier.block.conv.weight  |    (104, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (104,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.873M  |
2024-08-01 11:01:39 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-01 11:01:39 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.transformer.7.drop_path', 'encoder.transformer.3.drop_path', 'encoder.transformer.4.drop_path', 'encoder.neural_augmentor.noise.max_fn', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.neural_augmentor.noise', 'encoder.neural_augmentor', 'encoder.transformer.11.drop_path', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.transformer.1.drop_path', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.transformer.10.drop_path', 'encoder.neural_augmentor.contrast', 'encoder.transformer.8.drop_path', 'encoder.neural_augmentor.brightness', 'encoder.transformer.9.drop_path', 'encoder.transformer.0.drop_path', 'encoder.transformer.5.drop_path', 'encoder.transformer.2.drop_path', 'encoder.transformer.6.drop_path', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.neural_augmentor.noise.min_fn'}
2024-08-01 11:01:39 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 20, 'aten::scaled_dot_product_attention': 12, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - Max. epochs for training: 50
2024-08-01 11:01:39 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=50
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-08-01 11:01:41 - [34m[1mLOGS   [0m - Loaded checkpoint from /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:01:41 - [34m[1mLOGS   [0m - Resuming training for epoch 30
2024-08-01 11:01:41 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-01 11:01:43 - [32m[1mINFO   [0m - Training epoch 30
2024-08-01 11:01:33 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40010
2024-08-01 11:01:33 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40010
2024-08-01 11:04:42 - [34m[1mLOGS   [0m - Epoch:  30 [    4682/10000000], loss: {'segmentation': 0.303, 'neural_augmentation': 0.4492, 'total_loss': 0.7523}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 177.005, Elapsed time: 179.09
2024-08-01 11:04:49 - [34m[1mLOGS   [0m - Epoch:  30 [    4782/10000000], loss: {'segmentation': 0.3026, 'neural_augmentation': 0.4543, 'total_loss': 0.757}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 1.753, Elapsed time: 186.41
2024-08-01 11:04:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'segmentation': 0.3011, 'neural_augmentation': 0.4543, 'total_loss': 0.7554}
2024-08-01 11:07:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'segmentation': 1.0111, 'neural_augmentation': 0.0, 'total_loss': 1.0111} || iou=38.9426
2024-08-01 11:07:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:07:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:07:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 4837 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_30_iter_4837.pt
2024-08-01 11:07:56 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 4837 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_30_iter_4837.pt
[31m===========================================================================[0m
2024-08-01 11:07:58 - [32m[1mINFO   [0m - Training epoch 31
2024-08-01 11:07:59 - [34m[1mLOGS   [0m - Epoch:  31 [    4838/10000000], loss: {'segmentation': 0.3562, 'neural_augmentation': 0.521, 'total_loss': 0.8771}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.438, Elapsed time:  0.54
2024-08-01 11:08:06 - [34m[1mLOGS   [0m - Epoch:  31 [    4938/10000000], loss: {'segmentation': 0.2927, 'neural_augmentation': 0.4656, 'total_loss': 0.7583}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.005, Elapsed time:  7.84
2024-08-01 11:08:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'segmentation': 0.2913, 'neural_augmentation': 0.4661, 'total_loss': 0.7573}
2024-08-01 11:08:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'segmentation': 1.0301, 'neural_augmentation': 0.0, 'total_loss': 1.0301} || iou=38.9103
2024-08-01 11:08:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:08:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:08:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 4993 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_31_iter_4993.pt
2024-08-01 11:08:18 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 4993 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_31_iter_4993.pt
[31m===========================================================================[0m
2024-08-01 11:08:20 - [32m[1mINFO   [0m - Training epoch 32
2024-08-01 11:08:20 - [34m[1mLOGS   [0m - Epoch:  32 [    4994/10000000], loss: {'segmentation': 0.2904, 'neural_augmentation': 0.4713, 'total_loss': 0.7617}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.383, Elapsed time:  0.49
2024-08-01 11:08:28 - [34m[1mLOGS   [0m - Epoch:  32 [    5094/10000000], loss: {'segmentation': 0.2793, 'neural_augmentation': 0.4823, 'total_loss': 0.7616}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.004, Elapsed time:  7.90
2024-08-01 11:08:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'segmentation': 0.2804, 'neural_augmentation': 0.4842, 'total_loss': 0.7647}
2024-08-01 11:08:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'segmentation': 1.0117, 'neural_augmentation': 0.0, 'total_loss': 1.0117} || iou=39.3222
2024-08-01 11:08:36 - [34m[1mLOGS   [0m - Best checkpoint with score 39.32 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:08:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_38.4749.pt
2024-08-01 11:08:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.7421.pt', 'checkpoint_score_38.8282.pt', 'checkpoint_score_38.8409.pt', 'checkpoint_score_38.9590.pt', 'checkpoint_score_39.3222.pt']
2024-08-01 11:08:42 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:08:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:08:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:08:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 5149 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_32_iter_5149.pt
2024-08-01 11:08:45 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 5149 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_32_iter_5149.pt
[31m===========================================================================[0m
2024-08-01 11:08:47 - [32m[1mINFO   [0m - Training epoch 33
2024-08-01 11:08:48 - [34m[1mLOGS   [0m - Epoch:  33 [    5150/10000000], loss: {'segmentation': 0.2487, 'neural_augmentation': 0.5822, 'total_loss': 0.8309}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.248, Elapsed time:  0.35
2024-08-01 11:08:55 - [34m[1mLOGS   [0m - Epoch:  33 [    5250/10000000], loss: {'segmentation': 0.27, 'neural_augmentation': 0.5022, 'total_loss': 0.7722}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.004, Elapsed time:  7.80
2024-08-01 11:08:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'segmentation': 0.2701, 'neural_augmentation': 0.5038, 'total_loss': 0.7738}
2024-08-01 11:09:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'segmentation': 1.0113, 'neural_augmentation': 0.0, 'total_loss': 1.0113} || iou=39.4557
2024-08-01 11:09:03 - [34m[1mLOGS   [0m - Best checkpoint with score 39.46 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:09:04 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_38.7421.pt
2024-08-01 11:09:04 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.8282.pt', 'checkpoint_score_38.8409.pt', 'checkpoint_score_38.9590.pt', 'checkpoint_score_39.3222.pt', 'checkpoint_score_39.4557.pt']
2024-08-01 11:09:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:09:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:09:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:09:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 5305 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_33_iter_5305.pt
2024-08-01 11:09:13 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 5305 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_33_iter_5305.pt
[31m===========================================================================[0m
2024-08-01 11:09:15 - [32m[1mINFO   [0m - Training epoch 34
2024-08-01 11:09:15 - [34m[1mLOGS   [0m - Epoch:  34 [    5306/10000000], loss: {'segmentation': 0.2871, 'neural_augmentation': 0.4646, 'total_loss': 0.7517}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.236, Elapsed time:  0.35
2024-08-01 11:09:22 - [34m[1mLOGS   [0m - Epoch:  34 [    5406/10000000], loss: {'segmentation': 0.2645, 'neural_augmentation': 0.5277, 'total_loss': 0.7923}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.003, Elapsed time:  7.57
2024-08-01 11:09:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'segmentation': 0.2618, 'neural_augmentation': 0.5232, 'total_loss': 0.785}
2024-08-01 11:09:30 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'segmentation': 0.9917, 'neural_augmentation': 0.0, 'total_loss': 0.9917} || iou=39.4818
2024-08-01 11:09:31 - [34m[1mLOGS   [0m - Best checkpoint with score 39.48 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:09:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_38.8282.pt
2024-08-01 11:09:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.8409.pt', 'checkpoint_score_38.9590.pt', 'checkpoint_score_39.3222.pt', 'checkpoint_score_39.4557.pt', 'checkpoint_score_39.4818.pt']
2024-08-01 11:09:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:09:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:09:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:09:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 5461 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_34_iter_5461.pt
2024-08-01 11:09:42 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 5461 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_34_iter_5461.pt
[31m===========================================================================[0m
2024-08-01 11:09:44 - [32m[1mINFO   [0m - Training epoch 35
2024-08-01 11:09:45 - [34m[1mLOGS   [0m - Epoch:  35 [    5462/10000000], loss: {'segmentation': 0.2287, 'neural_augmentation': 0.5959, 'total_loss': 0.8247}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.537, Elapsed time:  0.63
2024-08-01 11:09:52 - [34m[1mLOGS   [0m - Epoch:  35 [    5562/10000000], loss: {'segmentation': 0.2547, 'neural_augmentation': 0.5427, 'total_loss': 0.7974}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.005, Elapsed time:  7.85
2024-08-01 11:09:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'segmentation': 0.2564, 'neural_augmentation': 0.5427, 'total_loss': 0.7991}
2024-08-01 11:09:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'segmentation': 1.0017, 'neural_augmentation': 0.0, 'total_loss': 1.0017} || iou=39.6255
2024-08-01 11:10:00 - [34m[1mLOGS   [0m - Best checkpoint with score 39.63 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:10:00 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_38.8409.pt
2024-08-01 11:10:00 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_38.9590.pt', 'checkpoint_score_39.3222.pt', 'checkpoint_score_39.4557.pt', 'checkpoint_score_39.4818.pt', 'checkpoint_score_39.6255.pt']
2024-08-01 11:10:04 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:10:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:10:05 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:10:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 5617 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_35_iter_5617.pt
2024-08-01 11:10:06 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 5617 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_35_iter_5617.pt
[31m===========================================================================[0m
2024-08-01 11:10:08 - [32m[1mINFO   [0m - Training epoch 36
2024-08-01 11:10:08 - [34m[1mLOGS   [0m - Epoch:  36 [    5618/10000000], loss: {'segmentation': 0.2262, 'neural_augmentation': 0.5807, 'total_loss': 0.8069}, LR: [8e-06, 8e-06, 8e-06, 8e-06], Avg. batch load time: 0.186, Elapsed time:  0.31
2024-08-01 11:10:16 - [34m[1mLOGS   [0m - Epoch:  36 [    5718/10000000], loss: {'segmentation': 0.2479, 'neural_augmentation': 0.5679, 'total_loss': 0.8158}, LR: [8e-06, 8e-06, 8e-06, 8e-06], Avg. batch load time: 0.004, Elapsed time:  7.91
2024-08-01 11:10:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'segmentation': 0.247, 'neural_augmentation': 0.5642, 'total_loss': 0.8111}
2024-08-01 11:10:23 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'segmentation': 1.0133, 'neural_augmentation': 0.0, 'total_loss': 1.0133} || iou=39.4843
2024-08-01 11:10:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:10:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:10:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 5773 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_36_iter_5773.pt
2024-08-01 11:10:28 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 5773 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_36_iter_5773.pt
[31m===========================================================================[0m
2024-08-01 11:10:30 - [32m[1mINFO   [0m - Training epoch 37
2024-08-01 11:10:30 - [34m[1mLOGS   [0m - Epoch:  37 [    5774/10000000], loss: {'segmentation': 0.2749, 'neural_augmentation': 0.5373, 'total_loss': 0.8122}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.318, Elapsed time:  0.44
2024-08-01 11:10:37 - [34m[1mLOGS   [0m - Epoch:  37 [    5874/10000000], loss: {'segmentation': 0.2419, 'neural_augmentation': 0.5786, 'total_loss': 0.8205}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.005, Elapsed time:  7.86
2024-08-01 11:10:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'segmentation': 0.2418, 'neural_augmentation': 0.5833, 'total_loss': 0.8252}
2024-08-01 11:10:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'segmentation': 1.0095, 'neural_augmentation': 0.0, 'total_loss': 1.0095} || iou=39.8543
2024-08-01 11:10:46 - [34m[1mLOGS   [0m - Best checkpoint with score 39.85 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:10:46 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_38.9590.pt
2024-08-01 11:10:46 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.3222.pt', 'checkpoint_score_39.4557.pt', 'checkpoint_score_39.4818.pt', 'checkpoint_score_39.6255.pt', 'checkpoint_score_39.8543.pt']
2024-08-01 11:10:50 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:10:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:10:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:10:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 5929 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_37_iter_5929.pt
2024-08-01 11:10:54 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 5929 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_37_iter_5929.pt
[31m===========================================================================[0m
2024-08-01 11:10:56 - [32m[1mINFO   [0m - Training epoch 38
2024-08-01 11:10:56 - [34m[1mLOGS   [0m - Epoch:  38 [    5930/10000000], loss: {'segmentation': 0.2401, 'neural_augmentation': 0.5719, 'total_loss': 0.812}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.207, Elapsed time:  0.33
2024-08-01 11:11:04 - [34m[1mLOGS   [0m - Epoch:  38 [    6030/10000000], loss: {'segmentation': 0.2404, 'neural_augmentation': 0.5962, 'total_loss': 0.8365}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.004, Elapsed time:  7.76
2024-08-01 11:11:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'segmentation': 0.2383, 'neural_augmentation': 0.5933, 'total_loss': 0.8316}
2024-08-01 11:11:11 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'segmentation': 1.0134, 'neural_augmentation': 0.0, 'total_loss': 1.0134} || iou=39.801
2024-08-01 11:11:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:11:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:11:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 6085 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_38_iter_6085.pt
2024-08-01 11:11:17 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 6085 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_38_iter_6085.pt
[31m===========================================================================[0m
2024-08-01 11:11:19 - [32m[1mINFO   [0m - Training epoch 39
2024-08-01 11:11:20 - [34m[1mLOGS   [0m - Epoch:  39 [    6086/10000000], loss: {'segmentation': 0.2102, 'neural_augmentation': 0.6775, 'total_loss': 0.8877}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.644, Elapsed time:  0.73
2024-08-01 11:11:28 - [34m[1mLOGS   [0m - Epoch:  39 [    6186/10000000], loss: {'segmentation': 0.2317, 'neural_augmentation': 0.6143, 'total_loss': 0.846}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.007, Elapsed time:  8.09
2024-08-01 11:11:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'segmentation': 0.2324, 'neural_augmentation': 0.6148, 'total_loss': 0.8473}
2024-08-01 11:11:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'segmentation': 1.0083, 'neural_augmentation': 0.0, 'total_loss': 1.0083} || iou=39.8156
2024-08-01 11:11:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:11:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:11:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 6241 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_39_iter_6241.pt
2024-08-01 11:11:44 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 6241 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_39_iter_6241.pt
[31m===========================================================================[0m
2024-08-01 11:11:46 - [32m[1mINFO   [0m - Training epoch 40
2024-08-01 11:11:46 - [34m[1mLOGS   [0m - Epoch:  40 [    6242/10000000], loss: {'segmentation': 0.2386, 'neural_augmentation': 0.6766, 'total_loss': 0.9152}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.298, Elapsed time:  0.42
2024-08-01 11:11:53 - [34m[1mLOGS   [0m - Epoch:  40 [    6342/10000000], loss: {'segmentation': 0.2267, 'neural_augmentation': 0.6348, 'total_loss': 0.8615}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.003, Elapsed time:  7.64
2024-08-01 11:11:57 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'segmentation': 0.2281, 'neural_augmentation': 0.6331, 'total_loss': 0.8612}
2024-08-01 11:12:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'segmentation': 1.0147, 'neural_augmentation': 0.0, 'total_loss': 1.0147} || iou=39.7947
2024-08-01 11:12:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:12:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:12:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 6397 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_40_iter_6397.pt
2024-08-01 11:12:05 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 6397 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_40_iter_6397.pt
[31m===========================================================================[0m
2024-08-01 11:12:07 - [32m[1mINFO   [0m - Training epoch 41
2024-08-01 11:12:07 - [34m[1mLOGS   [0m - Epoch:  41 [    6398/10000000], loss: {'segmentation': 0.2306, 'neural_augmentation': 0.5619, 'total_loss': 0.7925}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.215, Elapsed time:  0.35
2024-08-01 11:12:15 - [34m[1mLOGS   [0m - Epoch:  41 [    6498/10000000], loss: {'segmentation': 0.2241, 'neural_augmentation': 0.6357, 'total_loss': 0.8598}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.006, Elapsed time:  8.10
2024-08-01 11:12:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'segmentation': 0.2245, 'neural_augmentation': 0.6378, 'total_loss': 0.8623}
2024-08-01 11:12:22 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'segmentation': 1.0103, 'neural_augmentation': 0.0, 'total_loss': 1.0103} || iou=39.8057
2024-08-01 11:12:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:12:24 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:12:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 6553 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_41_iter_6553.pt
2024-08-01 11:12:26 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 6553 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_41_iter_6553.pt
[31m===========================================================================[0m
2024-08-01 11:12:28 - [32m[1mINFO   [0m - Training epoch 42
2024-08-01 11:12:29 - [34m[1mLOGS   [0m - Epoch:  42 [    6554/10000000], loss: {'segmentation': 0.1821, 'neural_augmentation': 0.6173, 'total_loss': 0.7994}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.476, Elapsed time:  0.57
2024-08-01 11:12:36 - [34m[1mLOGS   [0m - Epoch:  42 [    6654/10000000], loss: {'segmentation': 0.2211, 'neural_augmentation': 0.6607, 'total_loss': 0.8818}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.006, Elapsed time:  7.92
2024-08-01 11:12:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'segmentation': 0.2199, 'neural_augmentation': 0.6581, 'total_loss': 0.878}
2024-08-01 11:12:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'segmentation': 1.0116, 'neural_augmentation': 0.0, 'total_loss': 1.0116} || iou=39.8166
2024-08-01 11:12:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:12:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:12:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 6709 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_42_iter_6709.pt
2024-08-01 11:12:49 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 6709 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_42_iter_6709.pt
[31m===========================================================================[0m
2024-08-01 11:12:51 - [32m[1mINFO   [0m - Training epoch 43
2024-08-01 11:12:51 - [34m[1mLOGS   [0m - Epoch:  43 [    6710/10000000], loss: {'segmentation': 0.198, 'neural_augmentation': 0.7304, 'total_loss': 0.9284}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.628, Elapsed time:  0.72
2024-08-01 11:12:59 - [34m[1mLOGS   [0m - Epoch:  43 [    6810/10000000], loss: {'segmentation': 0.2161, 'neural_augmentation': 0.674, 'total_loss': 0.8901}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.006, Elapsed time:  7.85
2024-08-01 11:13:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'segmentation': 0.2172, 'neural_augmentation': 0.6718, 'total_loss': 0.889}
2024-08-01 11:13:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'segmentation': 1.0283, 'neural_augmentation': 0.0, 'total_loss': 1.0283} || iou=39.9422
2024-08-01 11:13:07 - [34m[1mLOGS   [0m - Best checkpoint with score 39.94 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:13:08 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_39.3222.pt
2024-08-01 11:13:08 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.4557.pt', 'checkpoint_score_39.4818.pt', 'checkpoint_score_39.6255.pt', 'checkpoint_score_39.8543.pt', 'checkpoint_score_39.9422.pt']
2024-08-01 11:13:12 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:13:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:13:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:13:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 6865 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_43_iter_6865.pt
2024-08-01 11:13:18 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 6865 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_43_iter_6865.pt
[31m===========================================================================[0m
2024-08-01 11:13:20 - [32m[1mINFO   [0m - Training epoch 44
2024-08-01 11:13:21 - [34m[1mLOGS   [0m - Epoch:  44 [    6866/10000000], loss: {'segmentation': 0.2167, 'neural_augmentation': 0.6614, 'total_loss': 0.8781}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.772, Elapsed time:  0.85
2024-08-01 11:13:28 - [34m[1mLOGS   [0m - Epoch:  44 [    6966/10000000], loss: {'segmentation': 0.2174, 'neural_augmentation': 0.6865, 'total_loss': 0.9039}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.008, Elapsed time:  7.99
2024-08-01 11:13:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'segmentation': 0.2145, 'neural_augmentation': 0.686, 'total_loss': 0.9005}
2024-08-01 11:13:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'segmentation': 1.0274, 'neural_augmentation': 0.0, 'total_loss': 1.0274} || iou=39.9609
2024-08-01 11:13:36 - [34m[1mLOGS   [0m - Best checkpoint with score 39.96 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:13:37 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_39.4557.pt
2024-08-01 11:13:37 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.4818.pt', 'checkpoint_score_39.6255.pt', 'checkpoint_score_39.8543.pt', 'checkpoint_score_39.9422.pt', 'checkpoint_score_39.9609.pt']
2024-08-01 11:13:41 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:13:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:13:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:13:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 7021 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_44_iter_7021.pt
2024-08-01 11:13:44 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 7021 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_44_iter_7021.pt
[31m===========================================================================[0m
2024-08-01 11:13:46 - [32m[1mINFO   [0m - Training epoch 45
2024-08-01 11:13:47 - [34m[1mLOGS   [0m - Epoch:  45 [    7022/10000000], loss: {'segmentation': 0.2047, 'neural_augmentation': 0.7892, 'total_loss': 0.9939}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.845, Elapsed time:  0.93
2024-08-01 11:13:55 - [34m[1mLOGS   [0m - Epoch:  45 [    7122/10000000], loss: {'segmentation': 0.2103, 'neural_augmentation': 0.6968, 'total_loss': 0.9071}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.009, Elapsed time:  8.14
2024-08-01 11:13:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'segmentation': 0.2122, 'neural_augmentation': 0.6922, 'total_loss': 0.9044}
2024-08-01 11:14:02 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'segmentation': 1.0297, 'neural_augmentation': 0.0, 'total_loss': 1.0297} || iou=39.9324
2024-08-01 11:14:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:14:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:14:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 7177 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_45_iter_7177.pt
2024-08-01 11:14:06 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 7177 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_45_iter_7177.pt
[31m===========================================================================[0m
2024-08-01 11:14:08 - [32m[1mINFO   [0m - Training epoch 46
2024-08-01 11:14:09 - [34m[1mLOGS   [0m - Epoch:  46 [    7178/10000000], loss: {'segmentation': 0.1839, 'neural_augmentation': 0.7121, 'total_loss': 0.896}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.121, Elapsed time:  0.25
2024-08-01 11:14:16 - [34m[1mLOGS   [0m - Epoch:  46 [    7278/10000000], loss: {'segmentation': 0.2128, 'neural_augmentation': 0.6918, 'total_loss': 0.9047}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.005, Elapsed time:  7.80
2024-08-01 11:14:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'segmentation': 0.2114, 'neural_augmentation': 0.6946, 'total_loss': 0.906}
2024-08-01 11:14:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'segmentation': 1.0336, 'neural_augmentation': 0.0, 'total_loss': 1.0336} || iou=39.9368
2024-08-01 11:14:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:14:27 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:14:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 7333 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_46_iter_7333.pt
2024-08-01 11:14:30 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 7333 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_46_iter_7333.pt
[31m===========================================================================[0m
2024-08-01 11:14:32 - [32m[1mINFO   [0m - Training epoch 47
2024-08-01 11:14:33 - [34m[1mLOGS   [0m - Epoch:  47 [    7334/10000000], loss: {'segmentation': 0.2433, 'neural_augmentation': 0.6309, 'total_loss': 0.8742}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.343, Elapsed time:  0.46
2024-08-01 11:14:40 - [34m[1mLOGS   [0m - Epoch:  47 [    7434/10000000], loss: {'segmentation': 0.2075, 'neural_augmentation': 0.7071, 'total_loss': 0.9146}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.004, Elapsed time:  7.93
2024-08-01 11:14:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'segmentation': 0.2083, 'neural_augmentation': 0.7066, 'total_loss': 0.9149}
2024-08-01 11:14:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'segmentation': 1.0308, 'neural_augmentation': 0.0, 'total_loss': 1.0308} || iou=40.0053
2024-08-01 11:14:48 - [34m[1mLOGS   [0m - Best checkpoint with score 40.01 saved at /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_best.pt
2024-08-01 11:14:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_score_39.4818.pt
2024-08-01 11:14:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_39.6255.pt', 'checkpoint_score_39.8543.pt', 'checkpoint_score_39.9422.pt', 'checkpoint_score_39.9609.pt', 'checkpoint_score_40.0053.pt']
2024-08-01 11:14:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_avg.pt
2024-08-01 11:14:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:14:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:14:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 7489 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_47_iter_7489.pt
2024-08-01 11:14:56 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 7489 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_47_iter_7489.pt
[31m===========================================================================[0m
2024-08-01 11:14:58 - [32m[1mINFO   [0m - Training epoch 48
2024-08-01 11:14:59 - [34m[1mLOGS   [0m - Epoch:  48 [    7490/10000000], loss: {'segmentation': 0.2091, 'neural_augmentation': 0.6856, 'total_loss': 0.8947}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.295, Elapsed time:  0.41
2024-08-01 11:15:06 - [34m[1mLOGS   [0m - Epoch:  48 [    7590/10000000], loss: {'segmentation': 0.2067, 'neural_augmentation': 0.7155, 'total_loss': 0.9222}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.004, Elapsed time:  7.79
2024-08-01 11:15:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'segmentation': 0.2062, 'neural_augmentation': 0.7134, 'total_loss': 0.9196}
2024-08-01 11:15:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'segmentation': 1.0367, 'neural_augmentation': 0.0, 'total_loss': 1.0367} || iou=39.8927
2024-08-01 11:15:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:15:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:15:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 7645 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_48_iter_7645.pt
2024-08-01 11:15:19 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 7645 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_48_iter_7645.pt
[31m===========================================================================[0m
2024-08-01 11:15:21 - [32m[1mINFO   [0m - Training epoch 49
2024-08-01 11:15:22 - [34m[1mLOGS   [0m - Epoch:  49 [    7646/10000000], loss: {'segmentation': 0.2111, 'neural_augmentation': 0.5971, 'total_loss': 0.8082}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.324, Elapsed time:  0.44
2024-08-01 11:15:29 - [34m[1mLOGS   [0m - Epoch:  49 [    7746/10000000], loss: {'segmentation': 0.205, 'neural_augmentation': 0.7163, 'total_loss': 0.9213}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.006, Elapsed time:  7.88
2024-08-01 11:15:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'segmentation': 0.2046, 'neural_augmentation': 0.7135, 'total_loss': 0.9181}
2024-08-01 11:15:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'segmentation': 1.0347, 'neural_augmentation': 0.0, 'total_loss': 1.0347} || iou=39.7261
2024-08-01 11:15:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_last.pt
2024-08-01 11:15:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_last.pt
2024-08-01 11:15:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 7801 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/training_checkpoint_epoch_49_iter_7801.pt
2024-08-01 11:15:43 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 7801 is saved at: /ML-A100/team/mm/models/catlip_data/results_vit_base/seg/train/checkpoint_epoch_49_iter_7801.pt
2024-08-01 11:15:43 - [34m[1mLOGS   [0m - Training took 00:14:02.36
