nohup: ignoring input
2024-07-25 08:18:27 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-07-25 08:18:29 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-07-25 08:18:29 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-25 08:18:29 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-25 08:18:29 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-25 08:18:29 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): ViTamin(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=512, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(512, 102, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  118.961 M
Total trainable parameters =  118.961 M

2024-07-25 08:18:29 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-25 08:18:29 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.119G                 | 13.768G    |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  16.574M               |  0.808G    |
|   seg_head.aspp.aspp_layer                |   16.521M              |   0.784G   |
|    seg_head.aspp.aspp_layer.convs         |    15.209M             |    0.72G   |
|    seg_head.aspp.aspp_layer.project.block |    1.312M              |    64.275M |
|   seg_head.classifier.block.conv          |   52.326K              |   2.559M   |
|    seg_head.classifier.block.conv.weight  |    (102, 512, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (102,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.472M  |
2024-07-25 08:18:30 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-25 08:18:30 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.blocks1.0.ls2', 'encoder.blocks.5.attn.k_norm', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks1.2.ls1', 'encoder.blocks1.6.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.neural_augmentor.noise', 'encoder.blocks.6.attn.attn_drop', 'encoder.blocks.1.attn.q_norm', 'encoder.blocks.1.drop_path2', 'encoder.blocks.3.ls1', 'encoder.blocks.2.ls2', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.blocks1.2.drop_path1', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.neural_augmentor.contrast', 'encoder.blocks.0.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.blocks1.4.attn.k_norm', 'encoder.blocks1.2.drop_path2', 'encoder.blocks.4.drop_path2', 'encoder.blocks.5.ls2', 'encoder.blocks1.6.ls1', 'encoder.blocks1.3.attn.k_norm', 'encoder.mlp.0', 'encoder.blocks.4.ls1', 'encoder.blocks1.0.ls1', 'encoder.blocks.4.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.blocks.5.attn.attn_drop', 'encoder.blocks.0.drop_path1', 'encoder.blocks.0.attn.q_norm', 'encoder.blocks.3.drop_path2', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.blocks.1.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.blocks1.4.drop_path2', 'encoder.blocks.1.drop_path1', 'encoder.blocks.6.drop_path2', 'encoder.norm', 'encoder.blocks1.6.attn.attn_drop', 'encoder.neural_augmentor.noise.max_fn', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.blocks.6.attn.q_norm', 'encoder.blocks.2.attn.q_norm', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks.1.ls1', 'encoder.neural_augmentor.brightness', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.blocks1.5.ls1', 'encoder.blocks1.3.drop_path2', 'encoder.blocks.2.drop_path1', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.blocks1.5.attn.k_norm', 'encoder.blocks1.6.drop_path1', 'encoder.mlp', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.blocks.5.ls1', 'encoder.blocks1.5.attn.q_norm', 'encoder.blocks.3.ls2', 'encoder.blocks.4.attn.attn_drop', 'encoder.blocks.6.drop_path1', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.blocks1.3.ls2', 'encoder.blocks1.1.drop_path2', 'encoder.blocks1.1.attn.attn_drop', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.blocks.5.drop_path1', 'encoder.blocks1.1.ls1', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks.0.attn.k_norm', 'encoder.blocks.3.attn.k_norm', 'encoder.blocks1.6.ls2', 'encoder.blocks.5.drop_path2', 'encoder.blocks.2.ls1', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.patch_drop', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.patch_embed.proj', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.mlp.1', 'encoder.blocks1.3.attn.attn_drop', 'encoder.blocks.1.ls2', 'encoder.blocks.6.ls2', 'encoder.blocks1.1.drop_path1', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.blocks1.4.ls1', 'encoder.mlp.2', 'encoder.blocks1.0.drop_path1', 'encoder.norm_pre', 'encoder.blocks.2.drop_path2', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.blocks1.6.attn.q_norm', 'encoder.blocks1.3.attn.q_norm', 'encoder.blocks1.3.ls1', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.blocks1.5.drop_path2', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.blocks.2.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.blocks.3.drop_path1', 'encoder.classifier_drop', 'encoder.neural_augmentor.noise.min_fn', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.blocks1.2.ls2', 'encoder.blocks.2.attn.k_norm', 'encoder.blocks1.6.drop_path2', 'encoder.blocks.6.ls1', 'encoder.blocks1.1.attn.k_norm', 'encoder.blocks1.0.drop_path2', 'encoder.blocks1.2.attn.q_norm', 'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.blocks1.1.ls2', 'encoder.blocks1.0.attn.attn_drop', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks.3.attn.q_norm', 'encoder.blocks1.3.drop_path1', 'encoder.blocks.4.ls2', 'encoder.blocks.1.attn.k_norm', 'encoder.blocks.6.attn.k_norm', 'encoder.fc_norm', 'encoder.blocks1.4.attn.q_norm', 'encoder.blocks1.4.drop_path1', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.blocks.0.ls2', 'encoder.blocks.0.ls1', 'encoder.blocks.4.drop_path1', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.blocks.3.attn.attn_drop', 'encoder.blocks1.4.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.blocks.0.drop_path2', 'encoder.blocks1.4.ls2', 'encoder.blocks1.2.attn.k_norm', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.blocks.4.attn.k_norm', 'encoder.neural_augmentor', 'encoder.blocks1.5.ls2', 'encoder.blocks1.2.attn.attn_drop', 'encoder.blocks1.0.attn.k_norm', 'encoder.blocks1.5.drop_path1'}
2024-07-25 08:18:30 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-25 08:18:30 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train
2024-07-25 08:18:32 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40010
2024-07-25 08:18:41 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=True 
	num_samples=9000
	transforms=Compose(
			RandomShortSizeResize(short_side_min=256, short_side_max=768, interpolation=bicubic), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=512, w=512), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-25 08:18:41 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=False 
	num_samples=1000
	transforms=Compose(
			Resize(size=[512, 512], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-25 08:18:41 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=512, w=512)
	base_batch_size=8
)
2024-07-25 08:18:41 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=512, w=512)
	base_batch_size=4
)
2024-07-25 08:18:41 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-07-25 08:18:45 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-07-25 08:18:45 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-25 08:18:45 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-25 08:18:45 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-25 08:18:45 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): ViTamin(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=512, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(512, 102, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  118.961 M
Total trainable parameters =  118.961 M

2024-07-25 08:18:45 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-25 08:18:45 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.119G                 | 13.768G    |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  16.574M               |  0.808G    |
|   seg_head.aspp.aspp_layer                |   16.521M              |   0.784G   |
|    seg_head.aspp.aspp_layer.convs         |    15.209M             |    0.72G   |
|    seg_head.aspp.aspp_layer.project.block |    1.312M              |    64.275M |
|   seg_head.classifier.block.conv          |   52.326K              |   2.559M   |
|    seg_head.classifier.block.conv.weight  |    (102, 512, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (102,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.472M  |
2024-07-25 08:18:46 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-25 08:18:46 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.neural_augmentor.brightness', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.blocks1.3.drop_path1', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.blocks1.5.drop_path2', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.blocks.5.ls2', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.blocks1.2.ls2', 'encoder.blocks1.2.attn.k_norm', 'encoder.mlp.0', 'encoder.blocks1.6.ls2', 'encoder.blocks1.3.attn.k_norm', 'encoder.blocks1.4.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.blocks1.4.ls2', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.blocks1.0.ls1', 'encoder.blocks1.2.drop_path2', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.blocks.1.ls2', 'encoder.blocks1.5.drop_path1', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.neural_augmentor.noise', 'encoder.blocks1.4.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.blocks.3.ls1', 'encoder.blocks.0.drop_path2', 'encoder.norm_pre', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks.6.attn.q_norm', 'encoder.blocks.3.ls2', 'encoder.blocks1.1.ls1', 'encoder.patch_embed.proj', 'encoder.blocks.1.attn.q_norm', 'encoder.blocks.6.ls2', 'encoder.blocks1.4.ls1', 'encoder.blocks.5.ls1', 'encoder.blocks1.4.drop_path1', 'encoder.blocks.4.attn.attn_drop', 'encoder.blocks.4.ls1', 'encoder.blocks.4.drop_path2', 'encoder.blocks.6.drop_path2', 'encoder.blocks1.6.attn.attn_drop', 'encoder.blocks.5.drop_path2', 'encoder.blocks.3.drop_path2', 'encoder.blocks.5.attn.attn_drop', 'encoder.blocks.0.drop_path1', 'encoder.blocks1.3.ls1', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.blocks.1.drop_path1', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.blocks.2.drop_path1', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks.3.attn.attn_drop', 'encoder.patch_drop', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.mlp.1', 'encoder.blocks.6.attn.k_norm', 'encoder.blocks1.6.attn.k_norm', 'encoder.blocks.3.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.blocks.3.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.blocks1.2.attn.attn_drop', 'encoder.blocks1.0.attn.k_norm', 'encoder.blocks.0.ls1', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.blocks1.6.drop_path2', 'encoder.blocks1.2.drop_path1', 'encoder.blocks.4.attn.k_norm', 'encoder.blocks1.6.drop_path1', 'encoder.blocks.0.attn.k_norm', 'encoder.blocks1.3.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.blocks1.1.drop_path1', 'encoder.blocks.4.attn.q_norm', 'encoder.blocks1.6.attn.q_norm', 'encoder.blocks.0.ls2', 'encoder.neural_augmentor', 'encoder.blocks1.0.drop_path2', 'encoder.blocks.3.drop_path1', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.mlp.2', 'encoder.blocks1.1.attn.k_norm', 'encoder.blocks1.5.attn.q_norm', 'encoder.blocks1.4.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.blocks.4.ls2', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks1.0.attn.attn_drop', 'encoder.blocks.2.ls1', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks.2.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.blocks1.2.ls1', 'encoder.neural_augmentor.contrast', 'encoder.blocks1.3.ls2', 'encoder.classifier_drop', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.blocks.0.attn.attn_drop', 'encoder.blocks1.5.ls1', 'encoder.norm', 'encoder.blocks1.1.ls2', 'encoder.blocks.1.ls1', 'encoder.blocks.5.attn.k_norm', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.blocks.6.ls1', 'encoder.blocks1.1.drop_path2', 'encoder.blocks.2.attn.attn_drop', 'encoder.blocks.1.attn.attn_drop', 'encoder.blocks1.0.drop_path1', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.neural_augmentor.noise.min_fn', 'encoder.blocks.2.drop_path2', 'encoder.blocks1.5.attn.k_norm', 'encoder.blocks1.6.ls1', 'encoder.blocks.6.attn.attn_drop', 'encoder.blocks.5.drop_path1', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.blocks1.4.drop_path2', 'encoder.mlp', 'encoder.blocks1.2.attn.q_norm', 'encoder.fc_norm', 'encoder.blocks.4.drop_path1', 'encoder.blocks1.0.ls2', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.blocks.2.attn.q_norm', 'encoder.blocks.1.drop_path2', 'encoder.blocks.2.ls2', 'encoder.blocks1.5.ls2', 'encoder.blocks1.1.attn.attn_drop', 'encoder.blocks1.3.attn.q_norm', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.blocks.6.drop_path1', 'encoder.blocks1.3.drop_path2', 'encoder.blocks.1.attn.k_norm', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.blocks.0.attn.q_norm', 'encoder.neural_augmentor.noise.max_fn'}
2024-07-25 08:18:46 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - Max. epochs for training: 50
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=50
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-25 08:18:47 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt'
2024-07-25 08:18:47 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-25 08:18:49 - [32m[1mINFO   [0m - Training epoch 0
2024-07-25 08:18:39 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40010
base
dci
2024-07-25 08:18:37 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40010
base
dci
2024-07-25 08:18:35 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40010
base
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-25 08:21:36 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'segmentation': 4.5572, 'neural_augmentation': 0.2551, 'total_loss': 4.8122}, LR: [1e-06, 1e-06, 1e-06, 1e-06], Avg. batch load time: 162.983, Elapsed time: 167.88
2024-07-25 08:22:24 - [34m[1mLOGS   [0m - Epoch:   0 [     101/10000000], loss: {'segmentation': 4.033, 'neural_augmentation': 0.2302, 'total_loss': 4.2632}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 1.614, Elapsed time: 215.26
2024-07-25 08:23:10 - [34m[1mLOGS   [0m - Epoch:   0 [     201/10000000], loss: {'segmentation': 3.3624, 'neural_augmentation': 0.2255, 'total_loss': 3.5879}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.811, Elapsed time: 261.74
2024-07-25 08:23:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'segmentation': 2.9988, 'neural_augmentation': 0.2226, 'total_loss': 3.2214}
2024-07-25 08:26:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'segmentation': 1.7629, 'neural_augmentation': 0.0, 'total_loss': 1.7629} || iou=9.0536
2024-07-25 08:26:52 - [34m[1mLOGS   [0m - Best checkpoint with score 9.05 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:26:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:26:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:27:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_0_iter_282.pt
2024-07-25 08:27:00 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_0_iter_282.pt
[31m===========================================================================[0m
2024-07-25 08:27:02 - [32m[1mINFO   [0m - Training epoch 1
2024-07-25 08:27:04 - [34m[1mLOGS   [0m - Epoch:   1 [     283/10000000], loss: {'segmentation': 1.8998, 'neural_augmentation': 0.2733, 'total_loss': 2.1731}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.889, Elapsed time:  1.37
2024-07-25 08:27:50 - [34m[1mLOGS   [0m - Epoch:   1 [     383/10000000], loss: {'segmentation': 1.6114, 'neural_augmentation': 0.2176, 'total_loss': 1.829}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.009, Elapsed time: 47.83
2024-07-25 08:28:36 - [34m[1mLOGS   [0m - Epoch:   1 [     483/10000000], loss: {'segmentation': 1.413, 'neural_augmentation': 0.2151, 'total_loss': 1.6281}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.005, Elapsed time: 94.29
2024-07-25 08:29:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'segmentation': 1.2918, 'neural_augmentation': 0.2146, 'total_loss': 1.5065}
2024-07-25 08:29:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'segmentation': 0.8552, 'neural_augmentation': 0.0, 'total_loss': 0.8552} || iou=18.0812
2024-07-25 08:29:21 - [34m[1mLOGS   [0m - Best checkpoint with score 18.08 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:29:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:29:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:29:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_1_iter_564.pt
2024-07-25 08:29:32 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_1_iter_564.pt
[31m===========================================================================[0m
2024-07-25 08:29:34 - [32m[1mINFO   [0m - Training epoch 2
2024-07-25 08:29:36 - [34m[1mLOGS   [0m - Epoch:   2 [     565/10000000], loss: {'segmentation': 0.976, 'neural_augmentation': 0.2446, 'total_loss': 1.2206}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 1.539, Elapsed time:  2.01
2024-07-25 08:30:22 - [34m[1mLOGS   [0m - Epoch:   2 [     665/10000000], loss: {'segmentation': 0.8104, 'neural_augmentation': 0.2118, 'total_loss': 1.0223}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.016, Elapsed time: 48.54
2024-07-25 08:31:09 - [34m[1mLOGS   [0m - Epoch:   2 [     765/10000000], loss: {'segmentation': 0.7484, 'neural_augmentation': 0.212, 'total_loss': 0.9604}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.008, Elapsed time: 94.92
2024-07-25 08:31:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'segmentation': 0.7099, 'neural_augmentation': 0.2133, 'total_loss': 0.9232}
2024-07-25 08:31:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'segmentation': 0.582, 'neural_augmentation': 0.0, 'total_loss': 0.582} || iou=20.8087
2024-07-25 08:31:53 - [34m[1mLOGS   [0m - Best checkpoint with score 20.81 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:31:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:31:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:32:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_2_iter_846.pt
2024-07-25 08:32:02 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_2_iter_846.pt
[31m===========================================================================[0m
2024-07-25 08:32:04 - [32m[1mINFO   [0m - Training epoch 3
2024-07-25 08:32:04 - [34m[1mLOGS   [0m - Epoch:   3 [     847/10000000], loss: {'segmentation': 0.5799, 'neural_augmentation': 0.2227, 'total_loss': 0.8026}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.305, Elapsed time:  0.78
2024-07-25 08:32:51 - [34m[1mLOGS   [0m - Epoch:   3 [     947/10000000], loss: {'segmentation': 0.5289, 'neural_augmentation': 0.2177, 'total_loss': 0.7466}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.005, Elapsed time: 47.56
2024-07-25 08:33:38 - [34m[1mLOGS   [0m - Epoch:   3 [    1047/10000000], loss: {'segmentation': 0.5141, 'neural_augmentation': 0.2179, 'total_loss': 0.732}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.003, Elapsed time: 94.01
2024-07-25 08:34:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'segmentation': 0.5018, 'neural_augmentation': 0.2165, 'total_loss': 0.7183}
2024-07-25 08:34:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'segmentation': 0.4377, 'neural_augmentation': 0.0, 'total_loss': 0.4377} || iou=22.206
2024-07-25 08:34:22 - [34m[1mLOGS   [0m - Best checkpoint with score 22.21 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:34:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:34:27 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:34:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_3_iter_1128.pt
2024-07-25 08:34:31 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_3_iter_1128.pt
[31m===========================================================================[0m
2024-07-25 08:34:33 - [32m[1mINFO   [0m - Training epoch 4
2024-07-25 08:34:34 - [34m[1mLOGS   [0m - Epoch:   4 [    1129/10000000], loss: {'segmentation': 0.524, 'neural_augmentation': 0.2595, 'total_loss': 0.7834}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.354, Elapsed time:  0.83
2024-07-25 08:35:21 - [34m[1mLOGS   [0m - Epoch:   4 [    1229/10000000], loss: {'segmentation': 0.3984, 'neural_augmentation': 0.2051, 'total_loss': 0.6035}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.009, Elapsed time: 47.88
2024-07-25 08:36:07 - [34m[1mLOGS   [0m - Epoch:   4 [    1329/10000000], loss: {'segmentation': 0.3912, 'neural_augmentation': 0.2054, 'total_loss': 0.5966}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.005, Elapsed time: 94.36
2024-07-25 08:36:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'segmentation': 0.3849, 'neural_augmentation': 0.2054, 'total_loss': 0.5902}
2024-07-25 08:36:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'segmentation': 0.3856, 'neural_augmentation': 0.0, 'total_loss': 0.3856} || iou=22.2009
2024-07-25 08:36:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:36:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:36:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_4_iter_1410.pt
2024-07-25 08:36:59 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_4_iter_1410.pt
[31m===========================================================================[0m
2024-07-25 08:37:01 - [32m[1mINFO   [0m - Training epoch 5
2024-07-25 08:37:02 - [34m[1mLOGS   [0m - Epoch:   5 [    1411/10000000], loss: {'segmentation': 0.3734, 'neural_augmentation': 0.2213, 'total_loss': 0.5946}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 1.106, Elapsed time:  1.58
2024-07-25 08:37:49 - [34m[1mLOGS   [0m - Epoch:   5 [    1511/10000000], loss: {'segmentation': 0.3296, 'neural_augmentation': 0.2064, 'total_loss': 0.5361}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.011, Elapsed time: 48.22
2024-07-25 08:38:35 - [34m[1mLOGS   [0m - Epoch:   5 [    1611/10000000], loss: {'segmentation': 0.3219, 'neural_augmentation': 0.2039, 'total_loss': 0.5258}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.006, Elapsed time: 94.92
2024-07-25 08:39:13 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'segmentation': 0.3199, 'neural_augmentation': 0.2027, 'total_loss': 0.5226}
2024-07-25 08:39:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'segmentation': 0.3773, 'neural_augmentation': 0.0, 'total_loss': 0.3773} || iou=22.1416
2024-07-25 08:39:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:39:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:39:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_5_iter_1692.pt
2024-07-25 08:39:23 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_5_iter_1692.pt
[31m===========================================================================[0m
2024-07-25 08:39:25 - [32m[1mINFO   [0m - Training epoch 6
2024-07-25 08:39:26 - [34m[1mLOGS   [0m - Epoch:   6 [    1693/10000000], loss: {'segmentation': 0.2219, 'neural_augmentation': 0.1712, 'total_loss': 0.3931}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.663, Elapsed time:  1.14
2024-07-25 08:40:13 - [34m[1mLOGS   [0m - Epoch:   6 [    1793/10000000], loss: {'segmentation': 0.2893, 'neural_augmentation': 0.202, 'total_loss': 0.4914}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.007, Elapsed time: 47.64
2024-07-25 08:40:59 - [34m[1mLOGS   [0m - Epoch:   6 [    1893/10000000], loss: {'segmentation': 0.2838, 'neural_augmentation': 0.1987, 'total_loss': 0.4826}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.004, Elapsed time: 94.13
2024-07-25 08:41:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'segmentation': 0.2819, 'neural_augmentation': 0.1995, 'total_loss': 0.4815}
2024-07-25 08:41:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'segmentation': 0.3657, 'neural_augmentation': 0.0, 'total_loss': 0.3657} || iou=21.9043
2024-07-25 08:41:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:41:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:41:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_6_iter_1974.pt
2024-07-25 08:41:47 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_6_iter_1974.pt
[31m===========================================================================[0m
2024-07-25 08:41:49 - [32m[1mINFO   [0m - Training epoch 7
2024-07-25 08:41:51 - [34m[1mLOGS   [0m - Epoch:   7 [    1975/10000000], loss: {'segmentation': 0.2908, 'neural_augmentation': 0.1621, 'total_loss': 0.453}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.990, Elapsed time:  1.47
2024-07-25 08:42:37 - [34m[1mLOGS   [0m - Epoch:   7 [    2075/10000000], loss: {'segmentation': 0.251, 'neural_augmentation': 0.2004, 'total_loss': 0.4514}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.010, Elapsed time: 47.97
2024-07-25 08:43:24 - [34m[1mLOGS   [0m - Epoch:   7 [    2175/10000000], loss: {'segmentation': 0.2449, 'neural_augmentation': 0.2017, 'total_loss': 0.4466}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.005, Elapsed time: 94.44
2024-07-25 08:44:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'segmentation': 0.2448, 'neural_augmentation': 0.1994, 'total_loss': 0.4441}
2024-07-25 08:44:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'segmentation': 0.3714, 'neural_augmentation': 0.0, 'total_loss': 0.3714} || iou=21.8713
2024-07-25 08:44:08 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:44:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:44:11 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_7_iter_2256.pt
2024-07-25 08:44:12 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_7_iter_2256.pt
[31m===========================================================================[0m
2024-07-25 08:44:14 - [32m[1mINFO   [0m - Training epoch 8
2024-07-25 08:44:15 - [34m[1mLOGS   [0m - Epoch:   8 [    2257/10000000], loss: {'segmentation': 0.1781, 'neural_augmentation': 0.2496, 'total_loss': 0.4277}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 1.210, Elapsed time:  1.68
2024-07-25 08:45:02 - [34m[1mLOGS   [0m - Epoch:   8 [    2357/10000000], loss: {'segmentation': 0.2187, 'neural_augmentation': 0.2012, 'total_loss': 0.4199}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.012, Elapsed time: 48.20
2024-07-25 08:45:48 - [34m[1mLOGS   [0m - Epoch:   8 [    2457/10000000], loss: {'segmentation': 0.2171, 'neural_augmentation': 0.1985, 'total_loss': 0.4156}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.006, Elapsed time: 94.61
2024-07-25 08:46:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'segmentation': 0.2161, 'neural_augmentation': 0.1965, 'total_loss': 0.4126}
2024-07-25 08:46:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'segmentation': 0.345, 'neural_augmentation': 0.0, 'total_loss': 0.345} || iou=22.3694
2024-07-25 08:46:32 - [34m[1mLOGS   [0m - Best checkpoint with score 22.37 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:46:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:46:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:46:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_8_iter_2538.pt
2024-07-25 08:46:40 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_8_iter_2538.pt
[31m===========================================================================[0m
2024-07-25 08:46:42 - [32m[1mINFO   [0m - Training epoch 9
2024-07-25 08:46:43 - [34m[1mLOGS   [0m - Epoch:   9 [    2539/10000000], loss: {'segmentation': 0.1927, 'neural_augmentation': 0.2241, 'total_loss': 0.4168}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 1.076, Elapsed time:  1.55
2024-07-25 08:47:30 - [34m[1mLOGS   [0m - Epoch:   9 [    2639/10000000], loss: {'segmentation': 0.1928, 'neural_augmentation': 0.1958, 'total_loss': 0.3886}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.011, Elapsed time: 48.18
2024-07-25 08:48:16 - [34m[1mLOGS   [0m - Epoch:   9 [    2739/10000000], loss: {'segmentation': 0.1951, 'neural_augmentation': 0.1945, 'total_loss': 0.3896}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.006, Elapsed time: 94.57
2024-07-25 08:48:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'segmentation': 0.1956, 'neural_augmentation': 0.1935, 'total_loss': 0.389}
2024-07-25 08:48:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'segmentation': 0.3572, 'neural_augmentation': 0.0, 'total_loss': 0.3572} || iou=22.1219
2024-07-25 08:49:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:49:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:49:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_9_iter_2820.pt
2024-07-25 08:49:06 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_9_iter_2820.pt
[31m===========================================================================[0m
2024-07-25 08:49:08 - [32m[1mINFO   [0m - Training epoch 10
2024-07-25 08:49:10 - [34m[1mLOGS   [0m - Epoch:  10 [    2821/10000000], loss: {'segmentation': 0.1857, 'neural_augmentation': 0.1416, 'total_loss': 0.3273}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 1.095, Elapsed time:  1.56
2024-07-25 08:49:57 - [34m[1mLOGS   [0m - Epoch:  10 [    2921/10000000], loss: {'segmentation': 0.1829, 'neural_augmentation': 0.1922, 'total_loss': 0.3751}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.012, Elapsed time: 48.32
2024-07-25 08:50:43 - [34m[1mLOGS   [0m - Epoch:  10 [    3021/10000000], loss: {'segmentation': 0.1849, 'neural_augmentation': 0.1935, 'total_loss': 0.3784}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.006, Elapsed time: 94.74
2024-07-25 08:51:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'segmentation': 0.1852, 'neural_augmentation': 0.1917, 'total_loss': 0.3769}
2024-07-25 08:51:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'segmentation': 0.3597, 'neural_augmentation': 0.0, 'total_loss': 0.3597} || iou=22.0367
2024-07-25 08:51:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:51:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:51:33 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_10_iter_3102.pt
2024-07-25 08:51:34 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_10_iter_3102.pt
[31m===========================================================================[0m
2024-07-25 08:51:36 - [32m[1mINFO   [0m - Training epoch 11
2024-07-25 08:51:37 - [34m[1mLOGS   [0m - Epoch:  11 [    3103/10000000], loss: {'segmentation': 0.1983, 'neural_augmentation': 0.1891, 'total_loss': 0.3874}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.689, Elapsed time:  1.16
2024-07-25 08:52:23 - [34m[1mLOGS   [0m - Epoch:  11 [    3203/10000000], loss: {'segmentation': 0.1721, 'neural_augmentation': 0.1875, 'total_loss': 0.3596}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.007, Elapsed time: 47.85
2024-07-25 08:53:10 - [34m[1mLOGS   [0m - Epoch:  11 [    3303/10000000], loss: {'segmentation': 0.1672, 'neural_augmentation': 0.1918, 'total_loss': 0.3589}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.004, Elapsed time: 94.28
2024-07-25 08:53:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'segmentation': 0.1656, 'neural_augmentation': 0.1927, 'total_loss': 0.3583}
2024-07-25 08:53:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'segmentation': 0.3443, 'neural_augmentation': 0.0, 'total_loss': 0.3443} || iou=22.2804
2024-07-25 08:53:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:53:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:53:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_11_iter_3384.pt
2024-07-25 08:54:00 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_11_iter_3384.pt
[31m===========================================================================[0m
2024-07-25 08:54:02 - [32m[1mINFO   [0m - Training epoch 12
2024-07-25 08:54:04 - [34m[1mLOGS   [0m - Epoch:  12 [    3385/10000000], loss: {'segmentation': 0.1944, 'neural_augmentation': 0.1915, 'total_loss': 0.3859}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 1.235, Elapsed time:  1.70
2024-07-25 08:54:50 - [34m[1mLOGS   [0m - Epoch:  12 [    3485/10000000], loss: {'segmentation': 0.1544, 'neural_augmentation': 0.1894, 'total_loss': 0.3439}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.013, Elapsed time: 48.25
2024-07-25 08:55:37 - [34m[1mLOGS   [0m - Epoch:  12 [    3585/10000000], loss: {'segmentation': 0.1625, 'neural_augmentation': 0.1902, 'total_loss': 0.3527}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.006, Elapsed time: 94.83
2024-07-25 08:56:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'segmentation': 0.161, 'neural_augmentation': 0.1901, 'total_loss': 0.3511}
2024-07-25 08:56:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'segmentation': 0.3525, 'neural_augmentation': 0.0, 'total_loss': 0.3525} || iou=22.2217
2024-07-25 08:56:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:56:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:56:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_12_iter_3666.pt
2024-07-25 08:56:27 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_12_iter_3666.pt
[31m===========================================================================[0m
2024-07-25 08:56:29 - [32m[1mINFO   [0m - Training epoch 13
2024-07-25 08:56:31 - [34m[1mLOGS   [0m - Epoch:  13 [    3667/10000000], loss: {'segmentation': 0.1753, 'neural_augmentation': 0.1889, 'total_loss': 0.3643}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 1.050, Elapsed time:  1.51
2024-07-25 08:57:17 - [34m[1mLOGS   [0m - Epoch:  13 [    3767/10000000], loss: {'segmentation': 0.1506, 'neural_augmentation': 0.1949, 'total_loss': 0.3455}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.011, Elapsed time: 48.05
2024-07-25 08:58:04 - [34m[1mLOGS   [0m - Epoch:  13 [    3867/10000000], loss: {'segmentation': 0.1497, 'neural_augmentation': 0.194, 'total_loss': 0.3437}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.005, Elapsed time: 94.68
2024-07-25 08:58:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'segmentation': 0.1472, 'neural_augmentation': 0.1953, 'total_loss': 0.3425}
2024-07-25 08:58:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'segmentation': 0.3486, 'neural_augmentation': 0.0, 'total_loss': 0.3486} || iou=22.3883
2024-07-25 08:58:48 - [34m[1mLOGS   [0m - Best checkpoint with score 22.39 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 08:58:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_score_9.0536.pt
2024-07-25 08:58:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_18.0812.pt', 'checkpoint_score_20.8087.pt', 'checkpoint_score_22.2060.pt', 'checkpoint_score_22.3694.pt', 'checkpoint_score_22.3883.pt']
2024-07-25 08:58:55 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_avg.pt
2024-07-25 08:58:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 08:58:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 08:59:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_13_iter_3948.pt
2024-07-25 08:59:01 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_13_iter_3948.pt
[31m===========================================================================[0m
2024-07-25 08:59:03 - [32m[1mINFO   [0m - Training epoch 14
2024-07-25 08:59:05 - [34m[1mLOGS   [0m - Epoch:  14 [    3949/10000000], loss: {'segmentation': 0.1066, 'neural_augmentation': 0.2191, 'total_loss': 0.3257}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 1.308, Elapsed time:  1.78
2024-07-25 08:59:51 - [34m[1mLOGS   [0m - Epoch:  14 [    4049/10000000], loss: {'segmentation': 0.1387, 'neural_augmentation': 0.1946, 'total_loss': 0.3333}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.013, Elapsed time: 48.30
2024-07-25 09:00:38 - [34m[1mLOGS   [0m - Epoch:  14 [    4149/10000000], loss: {'segmentation': 0.1407, 'neural_augmentation': 0.197, 'total_loss': 0.3377}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.007, Elapsed time: 94.89
2024-07-25 09:01:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'segmentation': 0.1435, 'neural_augmentation': 0.1979, 'total_loss': 0.3414}
2024-07-25 09:01:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'segmentation': 0.3307, 'neural_augmentation': 0.0, 'total_loss': 0.3307} || iou=22.2152
2024-07-25 09:01:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:01:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:01:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_14_iter_4230.pt
2024-07-25 09:01:28 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_14_iter_4230.pt
[31m===========================================================================[0m
2024-07-25 09:01:30 - [32m[1mINFO   [0m - Training epoch 15
2024-07-25 09:01:32 - [34m[1mLOGS   [0m - Epoch:  15 [    4231/10000000], loss: {'segmentation': 0.1275, 'neural_augmentation': 0.2212, 'total_loss': 0.3487}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 1.102, Elapsed time:  1.58
2024-07-25 09:02:18 - [34m[1mLOGS   [0m - Epoch:  15 [    4331/10000000], loss: {'segmentation': 0.1373, 'neural_augmentation': 0.2003, 'total_loss': 0.3375}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.011, Elapsed time: 48.10
2024-07-25 09:03:05 - [34m[1mLOGS   [0m - Epoch:  15 [    4431/10000000], loss: {'segmentation': 0.1395, 'neural_augmentation': 0.2043, 'total_loss': 0.3438}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.006, Elapsed time: 94.71
2024-07-25 09:03:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'segmentation': 0.1367, 'neural_augmentation': 0.2065, 'total_loss': 0.3431}
2024-07-25 09:03:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'segmentation': 0.3829, 'neural_augmentation': 0.0, 'total_loss': 0.3829} || iou=21.9227
2024-07-25 09:03:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:03:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:03:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_15_iter_4512.pt
2024-07-25 09:03:55 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_15_iter_4512.pt
[31m===========================================================================[0m
2024-07-25 09:03:57 - [32m[1mINFO   [0m - Training epoch 16
2024-07-25 09:03:59 - [34m[1mLOGS   [0m - Epoch:  16 [    4513/10000000], loss: {'segmentation': 0.1178, 'neural_augmentation': 0.1977, 'total_loss': 0.3154}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.888, Elapsed time:  1.36
2024-07-25 09:04:45 - [34m[1mLOGS   [0m - Epoch:  16 [    4613/10000000], loss: {'segmentation': 0.1264, 'neural_augmentation': 0.2142, 'total_loss': 0.3406}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.009, Elapsed time: 47.86
2024-07-25 09:05:32 - [34m[1mLOGS   [0m - Epoch:  16 [    4713/10000000], loss: {'segmentation': 0.128, 'neural_augmentation': 0.2124, 'total_loss': 0.3404}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.005, Elapsed time: 94.47
2024-07-25 09:06:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'segmentation': 0.1267, 'neural_augmentation': 0.2124, 'total_loss': 0.3391}
2024-07-25 09:06:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'segmentation': 0.348, 'neural_augmentation': 0.0, 'total_loss': 0.348} || iou=22.3453
2024-07-25 09:06:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:06:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:06:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_16_iter_4794.pt
2024-07-25 09:06:22 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_16_iter_4794.pt
[31m===========================================================================[0m
2024-07-25 09:06:24 - [32m[1mINFO   [0m - Training epoch 17
2024-07-25 09:06:26 - [34m[1mLOGS   [0m - Epoch:  17 [    4795/10000000], loss: {'segmentation': 0.1682, 'neural_augmentation': 0.1886, 'total_loss': 0.3569}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 1.168, Elapsed time:  1.64
2024-07-25 09:07:12 - [34m[1mLOGS   [0m - Epoch:  17 [    4895/10000000], loss: {'segmentation': 0.1192, 'neural_augmentation': 0.2177, 'total_loss': 0.3369}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.012, Elapsed time: 48.12
2024-07-25 09:07:59 - [34m[1mLOGS   [0m - Epoch:  17 [    4995/10000000], loss: {'segmentation': 0.1251, 'neural_augmentation': 0.2193, 'total_loss': 0.3443}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.006, Elapsed time: 94.71
2024-07-25 09:08:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'segmentation': 0.1243, 'neural_augmentation': 0.22, 'total_loss': 0.3444}
2024-07-25 09:08:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'segmentation': 0.3582, 'neural_augmentation': 0.0, 'total_loss': 0.3582} || iou=22.3022
2024-07-25 09:08:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:08:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:08:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_17_iter_5076.pt
2024-07-25 09:08:48 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_17_iter_5076.pt
[31m===========================================================================[0m
2024-07-25 09:08:50 - [32m[1mINFO   [0m - Training epoch 18
2024-07-25 09:08:52 - [34m[1mLOGS   [0m - Epoch:  18 [    5077/10000000], loss: {'segmentation': 0.1208, 'neural_augmentation': 0.2144, 'total_loss': 0.3353}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.993, Elapsed time:  1.47
2024-07-25 09:09:38 - [34m[1mLOGS   [0m - Epoch:  18 [    5177/10000000], loss: {'segmentation': 0.1151, 'neural_augmentation': 0.2317, 'total_loss': 0.3468}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.010, Elapsed time: 47.95
2024-07-25 09:10:25 - [34m[1mLOGS   [0m - Epoch:  18 [    5277/10000000], loss: {'segmentation': 0.1148, 'neural_augmentation': 0.2331, 'total_loss': 0.3479}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.005, Elapsed time: 94.40
2024-07-25 09:11:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'segmentation': 0.1159, 'neural_augmentation': 0.2332, 'total_loss': 0.3491}
2024-07-25 09:11:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'segmentation': 0.3346, 'neural_augmentation': 0.0, 'total_loss': 0.3346} || iou=22.6397
2024-07-25 09:11:09 - [34m[1mLOGS   [0m - Best checkpoint with score 22.64 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_best.pt
2024-07-25 09:11:09 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_score_18.0812.pt
2024-07-25 09:11:09 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_20.8087.pt', 'checkpoint_score_22.2060.pt', 'checkpoint_score_22.3694.pt', 'checkpoint_score_22.3883.pt', 'checkpoint_score_22.6397.pt']
2024-07-25 09:11:16 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_avg.pt
2024-07-25 09:11:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:11:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:11:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_18_iter_5358.pt
2024-07-25 09:11:21 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_18_iter_5358.pt
[31m===========================================================================[0m
2024-07-25 09:11:23 - [32m[1mINFO   [0m - Training epoch 19
2024-07-25 09:11:26 - [34m[1mLOGS   [0m - Epoch:  19 [    5359/10000000], loss: {'segmentation': 0.1002, 'neural_augmentation': 0.2164, 'total_loss': 0.3166}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 1.662, Elapsed time:  2.13
2024-07-25 09:12:12 - [34m[1mLOGS   [0m - Epoch:  19 [    5459/10000000], loss: {'segmentation': 0.1135, 'neural_augmentation': 0.2413, 'total_loss': 0.3548}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.017, Elapsed time: 48.62
2024-07-25 09:12:59 - [34m[1mLOGS   [0m - Epoch:  19 [    5559/10000000], loss: {'segmentation': 0.1153, 'neural_augmentation': 0.2433, 'total_loss': 0.3585}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.009, Elapsed time: 95.06
2024-07-25 09:13:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'segmentation': 0.1163, 'neural_augmentation': 0.2446, 'total_loss': 0.3609}
2024-07-25 09:13:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'segmentation': 0.3512, 'neural_augmentation': 0.0, 'total_loss': 0.3512} || iou=22.2807
2024-07-25 09:13:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:13:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:13:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_19_iter_5640.pt
2024-07-25 09:13:48 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_19_iter_5640.pt
[31m===========================================================================[0m
2024-07-25 09:13:50 - [32m[1mINFO   [0m - Training epoch 20
2024-07-25 09:13:52 - [34m[1mLOGS   [0m - Epoch:  20 [    5641/10000000], loss: {'segmentation': 0.0915, 'neural_augmentation': 0.2417, 'total_loss': 0.3333}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 1.400, Elapsed time:  1.87
2024-07-25 09:14:39 - [34m[1mLOGS   [0m - Epoch:  20 [    5741/10000000], loss: {'segmentation': 0.1156, 'neural_augmentation': 0.2615, 'total_loss': 0.3771}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.014, Elapsed time: 48.35
2024-07-25 09:15:25 - [34m[1mLOGS   [0m - Epoch:  20 [    5841/10000000], loss: {'segmentation': 0.1176, 'neural_augmentation': 0.2594, 'total_loss': 0.377}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.007, Elapsed time: 94.79
2024-07-25 09:16:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'segmentation': 0.1174, 'neural_augmentation': 0.2589, 'total_loss': 0.3763}
2024-07-25 09:16:08 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'segmentation': 0.3518, 'neural_augmentation': 0.0, 'total_loss': 0.3518} || iou=22.2937
2024-07-25 09:16:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:16:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:16:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_20_iter_5922.pt
2024-07-25 09:16:13 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_20_iter_5922.pt
[31m===========================================================================[0m
2024-07-25 09:16:15 - [32m[1mINFO   [0m - Training epoch 21
2024-07-25 09:16:16 - [34m[1mLOGS   [0m - Epoch:  21 [    5923/10000000], loss: {'segmentation': 0.1266, 'neural_augmentation': 0.272, 'total_loss': 0.3986}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.819, Elapsed time:  1.28
2024-07-25 09:17:03 - [34m[1mLOGS   [0m - Epoch:  21 [    6023/10000000], loss: {'segmentation': 0.1081, 'neural_augmentation': 0.2726, 'total_loss': 0.3807}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.008, Elapsed time: 47.76
2024-07-25 09:17:49 - [34m[1mLOGS   [0m - Epoch:  21 [    6123/10000000], loss: {'segmentation': 0.1093, 'neural_augmentation': 0.2732, 'total_loss': 0.3825}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.004, Elapsed time: 94.21
2024-07-25 09:18:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'segmentation': 0.1085, 'neural_augmentation': 0.2739, 'total_loss': 0.3825}
2024-07-25 09:18:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'segmentation': 0.3408, 'neural_augmentation': 0.0, 'total_loss': 0.3408} || iou=22.5647
2024-07-25 09:18:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:18:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:18:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_21_iter_6204.pt
2024-07-25 09:18:37 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_21_iter_6204.pt
[31m===========================================================================[0m
2024-07-25 09:18:39 - [32m[1mINFO   [0m - Training epoch 22
2024-07-25 09:18:41 - [34m[1mLOGS   [0m - Epoch:  22 [    6205/10000000], loss: {'segmentation': 0.0891, 'neural_augmentation': 0.3512, 'total_loss': 0.4403}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 1.682, Elapsed time:  2.15
2024-07-25 09:19:27 - [34m[1mLOGS   [0m - Epoch:  22 [    6305/10000000], loss: {'segmentation': 0.1087, 'neural_augmentation': 0.2924, 'total_loss': 0.4012}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.017, Elapsed time: 48.63
2024-07-25 09:20:14 - [34m[1mLOGS   [0m - Epoch:  22 [    6405/10000000], loss: {'segmentation': 0.106, 'neural_augmentation': 0.2898, 'total_loss': 0.3958}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.009, Elapsed time: 95.11
2024-07-25 09:20:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'segmentation': 0.1069, 'neural_augmentation': 0.2899, 'total_loss': 0.3968}
2024-07-25 09:20:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'segmentation': 0.3711, 'neural_augmentation': 0.0, 'total_loss': 0.3711} || iou=22.1178
2024-07-25 09:20:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_last.pt
2024-07-25 09:20:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_last.pt
2024-07-25 09:21:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/training_checkpoint_epoch_22_iter_6486.pt
2024-07-25 09:21:02 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec/train/checkpoint_epoch_22_iter_6486.pt
[31m===========================================================================[0m
2024-07-25 09:21:04 - [32m[1mINFO   [0m - Training epoch 23
2024-07-25 09:21:04 - [34m[1mLOGS   [0m - Epoch:  23 [    6487/10000000], loss: {'segmentation': 0.0899, 'neural_augmentation': 0.2881, 'total_loss': 0.378}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.350, Elapsed time:  0.83
2024-07-25 09:21:52 - [34m[1mLOGS   [0m - Epoch:  23 [    6587/10000000], loss: {'segmentation': 0.1063, 'neural_augmentation': 0.311, 'total_loss': 0.4173}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.008, Elapsed time: 47.96
2024-07-25 09:22:38 - [34m[1mLOGS   [0m - Epoch:  23 [    6687/10000000], loss: {'segmentation': 0.1039, 'neural_augmentation': 0.31, 'total_loss': 0.4139}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.004, Elapsed time: 94.44
Terminated
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1608 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
