nohup: ignoring input
2024-07-22 06:14:01 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
small
dci
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results500_accum_dci/train/checkpoint_epoch_9_iter_79046.pt
2024-07-22 06:14:02 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   25.707 M
Total trainable parameters =   25.707 M

2024-07-22 06:14:02 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.707M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  51.813K               |  51.712K   |
|   classifier.weight                  |   (101, 512)           |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-22 06:14:02 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-22 06:14:02 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.1.attn.attn_drop', 'blocks1.6.drop_path2', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.4.ls2', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.5.drop_path2', 'blocks1.2.ls1', 'blocks1.1.drop_path1', 'blocks1.2.ls2', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.2.ls2', 'blocks1.5.ls1', 'patch_drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.1.ls2', 'blocks.1.attn.k_norm', 'blocks1.3.attn.k_norm', 'blocks.4.drop_path2', 'patch_embed.backbone.stages.1.2.down', 'blocks.2.drop_path2', 'blocks.2.ls1', 'patch_embed.backbone.stages.0.1.down', 'blocks.6.attn.k_norm', 'blocks1.6.ls1', 'blocks.5.drop_path1', 'patch_embed.backbone.stages.1.0.down', 'blocks.3.attn.q_norm', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.3.drop_path2', 'blocks1.2.attn.attn_drop', 'blocks1.2.drop_path1', 'blocks1.1.attn.attn_drop', 'blocks1.2.drop_path2', 'blocks.5.attn.k_norm', 'blocks1.6.attn.attn_drop', 'blocks1.3.ls1', 'neural_augmentor.contrast', 'blocks1.5.drop_path1', 'blocks1.4.attn.k_norm', 'blocks.6.drop_path2', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks1.5.attn.k_norm', 'blocks.5.ls1', 'neural_augmentor.brightness.max_fn', 'blocks.3.attn.k_norm', 'neural_augmentor.brightness.min_fn', 'blocks1.3.attn.q_norm', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks.2.attn.q_norm', 'patch_embed.backbone.stem.norm1.drop', 'blocks.5.ls2', 'blocks1.4.attn.attn_drop', 'blocks.0.attn.attn_drop', 'blocks1.6.drop_path1', 'blocks1.2.attn.q_norm', 'blocks.6.ls2', 'blocks.0.ls2', 'blocks.1.ls1', 'blocks1.0.drop_path1', 'blocks1.6.ls2', 'patch_embed.backbone.stages.1.3.down', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.0.ls1', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.0.ls1', 'blocks1.4.drop_path2', 'patch_embed.proj', 'blocks1.3.drop_path1', 'blocks.4.ls1', 'blocks.1.drop_path1', 'blocks.0.drop_path1', 'blocks.0.drop_path2', 'blocks.6.attn.q_norm', 'blocks.6.drop_path1', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'norm_pre', 'blocks1.5.ls2', 'blocks.1.ls2', 'blocks1.0.drop_path2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks1.2.attn.k_norm', 'blocks.0.attn.q_norm', 'blocks1.0.ls2', 'patch_embed.backbone.stages.1.1.down', 'blocks1.5.drop_path2', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.4.drop_path1', 'patch_embed.backbone.stages.0.0.down', 'blocks.1.attn.q_norm', 'blocks.6.attn.attn_drop', 'blocks.5.attn.attn_drop', 'blocks1.3.ls2', 'blocks1.0.attn.q_norm', 'blocks1.4.ls2', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.3.ls2', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.0.0.drop_path', 'neural_augmentor.contrast.min_fn', 'blocks1.0.attn.attn_drop', 'blocks1.0.attn.k_norm', 'blocks.0.attn.k_norm', 'blocks1.1.ls1', 'blocks1.3.drop_path2', 'blocks1.5.attn.q_norm', 'neural_augmentor', 'neural_augmentor.contrast.max_fn', 'patch_embed.backbone.stages.0.1.shortcut', 'neural_augmentor.brightness', 'neural_augmentor.noise.max_fn', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks1.4.attn.q_norm', 'blocks1.5.attn.attn_drop', 'blocks.2.drop_path1', 'neural_augmentor.noise', 'blocks.3.ls1', 'blocks1.6.attn.k_norm', 'neural_augmentor.noise.min_fn', 'blocks.1.drop_path2', 'blocks.4.attn.attn_drop', 'blocks.2.attn.k_norm', 'blocks1.1.attn.q_norm', 'blocks.4.attn.q_norm', 'blocks.4.attn.k_norm', 'blocks1.3.attn.attn_drop', 'blocks1.1.drop_path2', 'blocks.3.attn.attn_drop', 'blocks1.1.attn.k_norm', 'norm', 'blocks.5.attn.q_norm', 'blocks1.4.drop_path1', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.4.ls1', 'blocks1.6.attn.q_norm', 'blocks.6.ls1', 'patch_embed.backbone.stages.1.3.pre_norm.drop'}
2024-07-22 06:14:02 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-22 06:14:02 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train
2024-07-22 06:14:05 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40003
small
dci
2024-07-22 06:14:09 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40003
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Total number of samples: 75750
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/train_images 
	is_training=True 
	num_samples=75750
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Total number of samples: 25250
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-22 06:14:11 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/test_images 
	is_training=False 
	num_samples=25250
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-22 06:14:12 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=128
	 scales=[(128, 128, 392), (160, 160, 250), (192, 192, 174), (224, 224, 128), (256, 256, 98), (288, 288, 77), (320, 320, 62)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-22 06:14:12 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-22 06:14:12 - [34m[1mLOGS   [0m - Number of data workers: 64
small
dci
2024-07-22 06:14:15 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results500_accum_dci/train/checkpoint_epoch_9_iter_79046.pt
2024-07-22 06:14:15 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-22 06:14:15 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   25.707 M
Total trainable parameters =   25.707 M

2024-07-22 06:14:15 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-22 06:14:15 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.707M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  51.813K               |  51.712K   |
|   classifier.weight                  |   (101, 512)           |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-22 06:14:17 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-22 06:14:17 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks1.4.drop_path1', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks1.3.ls1', 'blocks.4.attn.attn_drop', 'blocks.2.attn.k_norm', 'blocks.0.ls2', 'blocks1.5.ls1', 'blocks.1.drop_path1', 'blocks1.4.attn.attn_drop', 'blocks1.3.attn.attn_drop', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.0.drop_path2', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.3.attn.q_norm', 'blocks.3.ls1', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.3.attn.k_norm', 'blocks1.4.attn.q_norm', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks1.6.attn.attn_drop', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.1.1.down', 'blocks.4.drop_path2', 'blocks.0.drop_path2', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'patch_embed.backbone.stages.0.0.down', 'blocks1.3.drop_path1', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks.2.drop_path1', 'neural_augmentor.contrast.min_fn', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.4.ls2', 'blocks.0.attn.q_norm', 'blocks.0.attn.attn_drop', 'blocks.6.ls1', 'patch_embed.backbone.stages.1.1.drop_path', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks.3.ls2', 'neural_augmentor.contrast', 'blocks1.5.attn.attn_drop', 'blocks1.1.drop_path2', 'blocks1.0.ls2', 'blocks.6.drop_path2', 'patch_embed.backbone.stages.1.2.shortcut', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks1.5.attn.k_norm', 'blocks.2.ls2', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks1.6.ls2', 'blocks1.0.attn.k_norm', 'blocks.5.drop_path1', 'blocks.3.attn.attn_drop', 'blocks.6.attn.k_norm', 'blocks1.0.attn.attn_drop', 'norm_pre', 'neural_augmentor', 'blocks1.3.attn.q_norm', 'neural_augmentor.brightness.max_fn', 'blocks.6.attn.attn_drop', 'blocks.4.ls1', 'blocks.5.attn.attn_drop', 'blocks1.2.drop_path2', 'blocks.2.attn.attn_drop', 'patch_drop', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks1.2.ls2', 'blocks1.2.ls1', 'patch_embed.backbone.stem.norm1.drop', 'blocks1.4.drop_path2', 'blocks.1.drop_path2', 'blocks1.1.ls1', 'blocks.1.ls2', 'blocks1.1.ls2', 'blocks1.1.drop_path1', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks1.4.ls1', 'patch_embed.backbone.stages.1.0.down', 'patch_embed.backbone.stages.1.2.down', 'blocks1.4.ls2', 'blocks1.5.drop_path2', 'neural_augmentor.noise.max_fn', 'neural_augmentor.contrast.max_fn', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.2.attn.q_norm', 'blocks.0.ls1', 'blocks1.0.attn.q_norm', 'patch_embed.backbone.stages.1.3.down', 'blocks.1.attn.k_norm', 'blocks.2.attn.q_norm', 'blocks.5.attn.q_norm', 'blocks1.5.ls2', 'blocks.4.drop_path1', 'blocks.5.attn.k_norm', 'blocks.4.attn.k_norm', 'blocks.2.drop_path2', 'blocks1.2.drop_path1', 'blocks.5.ls1', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks1.1.attn.q_norm', 'blocks.6.attn.q_norm', 'blocks1.0.drop_path1', 'patch_embed.proj', 'blocks.1.attn.q_norm', 'blocks1.0.ls1', 'neural_augmentor.brightness', 'blocks.6.drop_path1', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.1.attn.attn_drop', 'neural_augmentor.brightness.min_fn', 'blocks.0.drop_path1', 'blocks.3.drop_path2', 'blocks.2.ls1', 'blocks1.3.drop_path2', 'blocks1.5.drop_path1', 'blocks1.3.ls2', 'blocks1.2.attn.attn_drop', 'blocks1.6.drop_path1', 'blocks.0.attn.k_norm', 'blocks.1.attn.attn_drop', 'blocks1.3.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks1.6.ls1', 'blocks.4.attn.q_norm', 'norm', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.0.0.drop_path', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks1.6.attn.q_norm', 'blocks1.2.attn.k_norm', 'blocks.5.ls2', 'blocks1.6.attn.k_norm', 'blocks.1.ls1', 'blocks1.6.drop_path2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.0.1.down', 'blocks.6.ls2', 'neural_augmentor.noise.min_fn', 'blocks.5.drop_path2', 'neural_augmentor.noise'}
2024-07-22 06:14:17 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - Max. epochs for training: 120
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=120
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-22 06:14:17 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt'
2024-07-22 06:14:17 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-22 06:14:19 - [32m[1mINFO   [0m - Training epoch 0
2024-07-22 06:14:09 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40003
small
dci
2024-07-22 06:14:05 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40003
small
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-22 06:17:18 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'classification': 8.3299, 'neural_augmentation': 0.3188, 'total_loss': 8.6487}, LR: [1e-06, 1e-06], Avg. batch load time: 176.695, Elapsed time: 179.18
2024-07-22 06:17:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 6.1978, 'neural_augmentation': 0.3189, 'total_loss': 6.5166}
2024-07-22 06:20:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 3.6225, 'neural_augmentation': 0.0, 'total_loss': 3.6225} || top1={'logits': 20.3164} || top5={'logits': 42.4531}
2024-07-22 06:20:30 - [34m[1mLOGS   [0m - Best checkpoint with score 20.32 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:20:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:20:31 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:20:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 115 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_0_iter_115.pt
2024-07-22 06:20:31 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 115 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_0_iter_115.pt
[31m===========================================================================[0m
2024-07-22 06:20:33 - [32m[1mINFO   [0m - Training epoch 1
2024-07-22 06:20:36 - [34m[1mLOGS   [0m - Epoch:   1 [     116/10000000], loss: {'classification': 3.9375, 'neural_augmentation': 0.3171, 'total_loss': 4.2546}, LR: [8e-06, 8e-06], Avg. batch load time: 3.063, Elapsed time:  3.23
2024-07-22 06:20:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 2.3077, 'neural_augmentation': 0.3212, 'total_loss': 2.6289}
2024-07-22 06:21:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 0.5501, 'neural_augmentation': 0.0, 'total_loss': 0.5501} || top1={'logits': 88.9336} || top5={'logits': 97.3945}
2024-07-22 06:21:04 - [34m[1mLOGS   [0m - Best checkpoint with score 88.93 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:21:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:21:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:21:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 234 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_1_iter_234.pt
2024-07-22 06:21:05 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 234 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_1_iter_234.pt
[31m===========================================================================[0m
2024-07-22 06:21:07 - [32m[1mINFO   [0m - Training epoch 2
2024-07-22 06:21:09 - [34m[1mLOGS   [0m - Epoch:   2 [     235/10000000], loss: {'classification': 1.589, 'neural_augmentation': 0.2912, 'total_loss': 1.8802}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 1.681, Elapsed time:  1.86
2024-07-22 06:21:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 1.539, 'neural_augmentation': 0.3193, 'total_loss': 1.8583}
2024-07-22 06:21:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 0.4126, 'neural_augmentation': 0.0, 'total_loss': 0.4126} || top1={'logits': 92.25} || top5={'logits': 98.457}
2024-07-22 06:21:38 - [34m[1mLOGS   [0m - Best checkpoint with score 92.25 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:21:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:21:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:21:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 354 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_2_iter_354.pt
2024-07-22 06:21:39 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 354 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_2_iter_354.pt
[31m===========================================================================[0m
2024-07-22 06:21:41 - [32m[1mINFO   [0m - Training epoch 3
2024-07-22 06:21:43 - [34m[1mLOGS   [0m - Epoch:   3 [     355/10000000], loss: {'classification': 1.2618, 'neural_augmentation': 0.297, 'total_loss': 1.5588}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 2.011, Elapsed time:  2.18
2024-07-22 06:22:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 1.4266, 'neural_augmentation': 0.3194, 'total_loss': 1.746}
2024-07-22 06:22:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 0.3572, 'neural_augmentation': 0.0, 'total_loss': 0.3572} || top1={'logits': 93.207} || top5={'logits': 98.7734}
2024-07-22 06:22:11 - [34m[1mLOGS   [0m - Best checkpoint with score 93.21 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:22:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:22:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:22:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_3_iter_465.pt
2024-07-22 06:22:12 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_3_iter_465.pt
[31m===========================================================================[0m
2024-07-22 06:22:14 - [32m[1mINFO   [0m - Training epoch 4
2024-07-22 06:22:16 - [34m[1mLOGS   [0m - Epoch:   4 [     466/10000000], loss: {'classification': 1.494, 'neural_augmentation': 0.3487, 'total_loss': 1.8427}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.514, Elapsed time:  1.68
2024-07-22 06:22:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 1.3778, 'neural_augmentation': 0.3159, 'total_loss': 1.6937}
2024-07-22 06:22:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 0.3508, 'neural_augmentation': 0.0, 'total_loss': 0.3508} || top1={'logits': 93.3359} || top5={'logits': 98.9375}
2024-07-22 06:22:43 - [34m[1mLOGS   [0m - Best checkpoint with score 93.34 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:22:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:22:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:22:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 568 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_4_iter_568.pt
2024-07-22 06:22:44 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 568 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_4_iter_568.pt
[31m===========================================================================[0m
2024-07-22 06:22:46 - [32m[1mINFO   [0m - Training epoch 5
2024-07-22 06:22:51 - [34m[1mLOGS   [0m - Epoch:   5 [     569/10000000], loss: {'classification': 1.3664, 'neural_augmentation': 0.3171, 'total_loss': 1.6835}, LR: [3e-05, 3e-05], Avg. batch load time: 4.513, Elapsed time:  4.68
2024-07-22 06:23:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 1.3132, 'neural_augmentation': 0.3148, 'total_loss': 1.628}
2024-07-22 06:23:17 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 0.3367, 'neural_augmentation': 0.0, 'total_loss': 0.3367} || top1={'logits': 93.8086} || top5={'logits': 98.9336}
2024-07-22 06:23:17 - [34m[1mLOGS   [0m - Best checkpoint with score 93.81 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:23:18 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_20.3164.pt
2024-07-22 06:23:18 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_88.9336.pt', 'checkpoint_score_92.2500.pt', 'checkpoint_score_93.2070.pt', 'checkpoint_score_93.3359.pt', 'checkpoint_score_93.8086.pt']
2024-07-22 06:23:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:23:23 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:23:24 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:23:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 684 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_5_iter_684.pt
2024-07-22 06:23:24 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 684 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_5_iter_684.pt
[31m===========================================================================[0m
2024-07-22 06:23:26 - [32m[1mINFO   [0m - Training epoch 6
2024-07-22 06:23:30 - [34m[1mLOGS   [0m - Epoch:   6 [     685/10000000], loss: {'classification': 1.3294, 'neural_augmentation': 0.3078, 'total_loss': 1.6373}, LR: [3e-05, 3e-05], Avg. batch load time: 3.695, Elapsed time:  3.91
2024-07-22 06:23:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 1.2821, 'neural_augmentation': 0.3118, 'total_loss': 1.5939}
2024-07-22 06:23:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 0.3309, 'neural_augmentation': 0.0, 'total_loss': 0.3309} || top1={'logits': 93.9922} || top5={'logits': 99.1055}
2024-07-22 06:23:56 - [34m[1mLOGS   [0m - Best checkpoint with score 93.99 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:23:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_88.9336.pt
2024-07-22 06:23:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.2500.pt', 'checkpoint_score_93.2070.pt', 'checkpoint_score_93.3359.pt', 'checkpoint_score_93.8086.pt', 'checkpoint_score_93.9922.pt']
2024-07-22 06:23:58 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:23:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:23:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:24:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 798 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_6_iter_798.pt
2024-07-22 06:24:01 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 798 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_6_iter_798.pt
[31m===========================================================================[0m
2024-07-22 06:24:03 - [32m[1mINFO   [0m - Training epoch 7
2024-07-22 06:24:07 - [34m[1mLOGS   [0m - Epoch:   7 [     799/10000000], loss: {'classification': 1.3432, 'neural_augmentation': 0.3106, 'total_loss': 1.6538}, LR: [3e-05, 3e-05], Avg. batch load time: 3.908, Elapsed time:  4.17
2024-07-22 06:24:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 1.2484, 'neural_augmentation': 0.3103, 'total_loss': 1.5586}
2024-07-22 06:24:33 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 0.3235, 'neural_augmentation': 0.0, 'total_loss': 0.3235} || top1={'logits': 93.9258} || top5={'logits': 99.0586}
2024-07-22 06:24:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:24:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:24:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 919 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_7_iter_919.pt
2024-07-22 06:24:35 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 919 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_7_iter_919.pt
[31m===========================================================================[0m
2024-07-22 06:24:37 - [32m[1mINFO   [0m - Training epoch 8
2024-07-22 06:24:39 - [34m[1mLOGS   [0m - Epoch:   8 [     920/10000000], loss: {'classification': 1.1836, 'neural_augmentation': 0.284, 'total_loss': 1.4676}, LR: [3e-05, 3e-05], Avg. batch load time: 1.805, Elapsed time:  1.97
2024-07-22 06:24:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 1.2362, 'neural_augmentation': 0.3094, 'total_loss': 1.5456}
2024-07-22 06:25:05 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 0.322, 'neural_augmentation': 0.0, 'total_loss': 0.322} || top1={'logits': 94.1367} || top5={'logits': 99.1758}
2024-07-22 06:25:06 - [34m[1mLOGS   [0m - Best checkpoint with score 94.14 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:25:06 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_92.2500.pt
2024-07-22 06:25:06 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.2070.pt', 'checkpoint_score_93.3359.pt', 'checkpoint_score_93.8086.pt', 'checkpoint_score_93.9922.pt', 'checkpoint_score_94.1367.pt']
2024-07-22 06:25:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:25:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:25:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:25:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 1028 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_8_iter_1028.pt
2024-07-22 06:25:11 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 1028 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_8_iter_1028.pt
[31m===========================================================================[0m
2024-07-22 06:25:13 - [32m[1mINFO   [0m - Training epoch 9
2024-07-22 06:25:14 - [34m[1mLOGS   [0m - Epoch:   9 [    1029/10000000], loss: {'classification': 1.0642, 'neural_augmentation': 0.3139, 'total_loss': 1.3782}, LR: [3e-05, 3e-05], Avg. batch load time: 1.649, Elapsed time:  1.81
2024-07-22 06:25:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 1.2074, 'neural_augmentation': 0.3071, 'total_loss': 1.5145}
2024-07-22 06:25:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 0.3232, 'neural_augmentation': 0.0, 'total_loss': 0.3232} || top1={'logits': 94.2383} || top5={'logits': 99.1562}
2024-07-22 06:25:40 - [34m[1mLOGS   [0m - Best checkpoint with score 94.24 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:25:40 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/tra/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 600 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
 06:25:42 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:25:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:25:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:25:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 1140 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_9_iter_1140.pt
2024-07-22 06:25:45 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 1140 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_9_iter_1140.pt
[31m===========================================================================[0m
2024-07-22 06:25:47 - [32m[1mINFO   [0m - Training epoch 10
2024-07-22 06:25:49 - [34m[1mLOGS   [0m - Epoch:  10 [    1141/10000000], loss: {'classification': 1.1116, 'neural_augmentation': 0.3272, 'total_loss': 1.4388}, LR: [3e-05, 3e-05], Avg. batch load time: 1.664, Elapsed time:  1.82
2024-07-22 06:26:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 1.1924, 'neural_augmentation': 0.3071, 'total_loss': 1.4995}
2024-07-22 06:26:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 0.3085, 'neural_augmentation': 0.0, 'total_loss': 0.3085} || top1={'logits': 94.3359} || top5={'logits': 99.1367}
2024-07-22 06:26:16 - [34m[1mLOGS   [0m - Best checkpoint with score 94.34 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:26:16 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_93.3359.pt
2024-07-22 06:26:16 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.8086.pt', 'checkpoint_score_93.9922.pt', 'checkpoint_score_94.1367.pt', 'checkpoint_score_94.2383.pt', 'checkpoint_score_94.3359.pt']
2024-07-22 06:26:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:26:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:26:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:26:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 1254 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_10_iter_1254.pt
2024-07-22 06:26:21 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 1254 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_10_iter_1254.pt
[31m===========================================================================[0m
2024-07-22 06:26:23 - [32m[1mINFO   [0m - Training epoch 11
2024-07-22 06:26:24 - [34m[1mLOGS   [0m - Epoch:  11 [    1255/10000000], loss: {'classification': 1.122, 'neural_augmentation': 0.2732, 'total_loss': 1.3952}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.103, Elapsed time:  1.26
2024-07-22 06:26:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 1.1864, 'neural_augmentation': 0.3028, 'total_loss': 1.4892}
2024-07-22 06:26:49 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 0.3086, 'neural_augmentation': 0.0, 'total_loss': 0.3086} || top1={'logits': 94.4609} || top5={'logits': 99.1523}
2024-07-22 06:26:50 - [34m[1mLOGS   [0m - Best checkpoint with score 94.46 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:26:50 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_93.8086.pt
2024-07-22 06:26:50 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_93.9922.pt', 'checkpoint_score_94.1367.pt', 'checkpoint_score_94.2383.pt', 'checkpoint_score_94.3359.pt', 'checkpoint_score_94.4609.pt']
2024-07-22 06:26:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:26:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:26:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:26:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 1357 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_11_iter_1357.pt
2024-07-22 06:26:55 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 1357 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_11_iter_1357.pt
[31m===========================================================================[0m
2024-07-22 06:26:57 - [32m[1mINFO   [0m - Training epoch 12
2024-07-22 06:26:58 - [34m[1mLOGS   [0m - Epoch:  12 [    1358/10000000], loss: {'classification': 1.1279, 'neural_augmentation': 0.3024, 'total_loss': 1.4303}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.106, Elapsed time:  1.26
2024-07-22 06:27:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 1.1592, 'neural_augmentation': 0.2999, 'total_loss': 1.4591}
2024-07-22 06:27:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 0.2976, 'neural_augmentation': 0.0, 'total_loss': 0.2976} || top1={'logits': 94.4258} || top5={'logits': 99.1562}
2024-07-22 06:27:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:27:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:27:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 1473 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_12_iter_1473.pt
2024-07-22 06:27:26 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 1473 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_12_iter_1473.pt
[31m===========================================================================[0m
2024-07-22 06:27:28 - [32m[1mINFO   [0m - Training epoch 13
2024-07-22 06:27:30 - [34m[1mLOGS   [0m - Epoch:  13 [    1474/10000000], loss: {'classification': 1.0722, 'neural_augmentation': 0.3191, 'total_loss': 1.3914}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.982, Elapsed time:  2.15
2024-07-22 06:27:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 1.1508, 'neural_augmentation': 0.2989, 'total_loss': 1.4497}
2024-07-22 06:27:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 0.3022, 'neural_augmentation': 0.0, 'total_loss': 0.3022} || top1={'logits': 94.3242} || top5={'logits': 99.1523}
2024-07-22 06:27:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:27:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:27:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 1579 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_13_iter_1579.pt
2024-07-22 06:27:58 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 1579 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_13_iter_1579.pt
[31m===========================================================================[0m
2024-07-22 06:28:00 - [32m[1mINFO   [0m - Training epoch 14
2024-07-22 06:28:04 - [34m[1mLOGS   [0m - Epoch:  14 [    1580/10000000], loss: {'classification': 1.1814, 'neural_augmentation': 0.314, 'total_loss': 1.4954}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 4.009, Elapsed time:  4.17
2024-07-22 06:28:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 1.1407, 'neural_augmentation': 0.2979, 'total_loss': 1.4386}
2024-07-22 06:28:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 0.3021, 'neural_augmentation': 0.0, 'total_loss': 0.3021} || top1={'logits': 94.4648} || top5={'logits': 99.1797}
2024-07-22 06:28:29 - [34m[1mLOGS   [0m - Best checkpoint with score 94.46 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:28:29 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_93.9922.pt
2024-07-22 06:28:29 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_94.1367.pt', 'checkpoint_score_94.2383.pt', 'checkpoint_score_94.3359.pt', 'checkpoint_score_94.4609.pt', 'checkpoint_score_94.4648.pt']
2024-07-22 06:28:31 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:28:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:28:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:28:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_14_iter_1692.pt
2024-07-22 06:28:34 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_14_iter_1692.pt
[31m===========================================================================[0m
2024-07-22 06:28:36 - [32m[1mINFO   [0m - Training epoch 15
2024-07-22 06:28:37 - [34m[1mLOGS   [0m - Epoch:  15 [    1693/10000000], loss: {'classification': 1.0372, 'neural_augmentation': 0.2945, 'total_loss': 1.3317}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.160, Elapsed time:  1.32
2024-07-22 06:28:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 1.1337, 'neural_augmentation': 0.2965, 'total_loss': 1.4302}
2024-07-22 06:29:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 0.3041, 'neural_augmentation': 0.0, 'total_loss': 0.3041} || top1={'logits': 94.4766} || top5={'logits': 99.1719}
2024-07-22 06:29:04 - [34m[1mLOGS   [0m - Best checkpoint with score 94.48 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:29:04 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_94.1367.pt
2024-07-22 06:29:04 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_94.2383.pt', 'checkpoint_score_94.3359.pt', 'checkpoint_score_94.4609.pt', 'checkpoint_score_94.4648.pt', 'checkpoint_score_94.4766.pt']
2024-07-22 06:29:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:29:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:29:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:29:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 1803 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_15_iter_1803.pt
2024-07-22 06:29:08 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 1803 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_15_iter_1803.pt
[31m===========================================================================[0m
2024-07-22 06:29:10 - [32m[1mINFO   [0m - Training epoch 16
2024-07-22 06:29:14 - [34m[1mLOGS   [0m - Epoch:  16 [    1804/10000000], loss: {'classification': 1.056, 'neural_augmentation': 0.2932, 'total_loss': 1.3491}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 3.022, Elapsed time:  3.28
2024-07-22 06:29:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 1.1021, 'neural_augmentation': 0.2934, 'total_loss': 1.3955}
2024-07-22 06:29:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 0.2964, 'neural_augmentation': 0.0, 'total_loss': 0.2964} || top1={'logits': 94.4219} || top5={'logits': 99.207}
2024-07-22 06:29:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:29:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:29:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 1925 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_16_iter_1925.pt
2024-07-22 06:29:41 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 1925 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_16_iter_1925.pt
[31m===========================================================================[0m
2024-07-22 06:29:43 - [32m[1mINFO   [0m - Training epoch 17
2024-07-22 06:29:45 - [34m[1mLOGS   [0m - Epoch:  17 [    1926/10000000], loss: {'classification': 1.0721, 'neural_augmentation': 0.2564, 'total_loss': 1.3285}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.362, Elapsed time:  1.53
2024-07-22 06:30:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 1.1056, 'neural_augmentation': 0.2885, 'total_loss': 1.394}
2024-07-22 06:30:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 0.3075, 'neural_augmentation': 0.0, 'total_loss': 0.3075} || top1={'logits': 94.4375} || top5={'logits': 99.1914}
2024-07-22 06:30:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:30:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:30:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 2039 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_17_iter_2039.pt
2024-07-22 06:30:14 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 2039 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_17_iter_2039.pt
[31m===========================================================================[0m
2024-07-22 06:30:16 - [32m[1mINFO   [0m - Training epoch 18
2024-07-22 06:30:20 - [34m[1mLOGS   [0m - Epoch:  18 [    2040/10000000], loss: {'classification': 1.0958, 'neural_augmentation': 0.2851, 'total_loss': 1.3809}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 3.430, Elapsed time:  3.59
2024-07-22 06:30:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 1.097, 'neural_augmentation': 0.2888, 'total_loss': 1.3857}
2024-07-22 06:30:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 0.2994, 'neural_augmentation': 0.0, 'total_loss': 0.2994} || top1={'logits': 94.5} || top5={'logits': 99.1875}
2024-07-22 06:30:45 - [34m[1mLOGS   [0m - Best checkpoint with score 94.50 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:30:45 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_94.2383.pt
2024-07-22 06:30:45 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_94.3359.pt', 'checkpoint_score_94.4609.pt', 'checkpoint_score_94.4648.pt', 'checkpoint_score_94.4766.pt', 'checkpoint_score_94.5000.pt']
2024-07-22 06:30:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:30:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:30:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:30:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 2152 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_18_iter_2152.pt
2024-07-22 06:30:50 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 2152 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_18_iter_2152.pt
[31m===========================================================================[0m
2024-07-22 06:30:52 - [32m[1mINFO   [0m - Training epoch 19
2024-07-22 06:30:53 - [34m[1mLOGS   [0m - Epoch:  19 [    2153/10000000], loss: {'classification': 1.0454, 'neural_augmentation': 0.3029, 'total_loss': 1.3483}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.389, Elapsed time:  1.55
2024-07-22 06:31:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 1.0865, 'neural_augmentation': 0.2861, 'total_loss': 1.3726}
2024-07-22 06:31:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 0.3018, 'neural_augmentation': 0.0, 'total_loss': 0.3018} || top1={'logits': 94.4531} || top5={'logits': 99.1953}
2024-07-22 06:31:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:31:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:31:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 2262 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_19_iter_2262.pt
2024-07-22 06:31:21 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 2262 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_19_iter_2262.pt
[31m===========================================================================[0m
2024-07-22 06:31:23 - [32m[1mINFO   [0m - Training epoch 20
2024-07-22 06:31:26 - [34m[1mLOGS   [0m - Epoch:  20 [    2263/10000000], loss: {'classification': 0.9523, 'neural_augmentation': 0.263, 'total_loss': 1.2154}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.952, Elapsed time:  3.12
2024-07-22 06:31:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 1.0725, 'neural_augmentation': 0.2839, 'total_loss': 1.3564}
2024-07-22 06:31:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 0.3056, 'neural_augmentation': 0.0, 'total_loss': 0.3056} || top1={'logits': 94.4297} || top5={'logits': 99.2188}
2024-07-22 06:31:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:31:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:31:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 2381 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_20_iter_2381.pt
2024-07-22 06:31:54 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 2381 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_20_iter_2381.pt
[31m===========================================================================[0m
2024-07-22 06:31:56 - [32m[1mINFO   [0m - Training epoch 21
2024-07-22 06:31:59 - [34m[1mLOGS   [0m - Epoch:  21 [    2382/10000000], loss: {'classification': 1.0105, 'neural_augmentation': 0.2892, 'total_loss': 1.2996}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.865, Elapsed time:  3.03
2024-07-22 06:32:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 1.0706, 'neural_augmentation': 0.2822, 'total_loss': 1.3528}
2024-07-22 06:32:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 0.2984, 'neural_augmentation': 0.0, 'total_loss': 0.2984} || top1={'logits': 94.5} || top5={'logits': 99.2305}
2024-07-22 06:32:25 - [34m[1mLOGS   [0m - Best checkpoint with score 94.50 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:32:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:32:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:32:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 2490 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_21_iter_2490.pt
2024-07-22 06:32:26 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 2490 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_21_iter_2490.pt
[31m===========================================================================[0m
2024-07-22 06:32:28 - [32m[1mINFO   [0m - Training epoch 22
2024-07-22 06:32:31 - [34m[1mLOGS   [0m - Epoch:  22 [    2491/10000000], loss: {'classification': 1.0518, 'neural_augmentation': 0.2792, 'total_loss': 1.331}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 3.154, Elapsed time:  3.31
2024-07-22 06:32:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 1.0713, 'neural_augmentation': 0.2819, 'total_loss': 1.3532}
2024-07-22 06:32:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 0.3122, 'neural_augmentation': 0.0, 'total_loss': 0.3122} || top1={'logits': 94.375} || top5={'logits': 99.1484}
2024-07-22 06:32:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:32:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:32:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 2607 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_22_iter_2607.pt
2024-07-22 06:32:58 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 2607 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_22_iter_2607.pt
[31m===========================================================================[0m
2024-07-22 06:33:00 - [32m[1mINFO   [0m - Training epoch 23
2024-07-22 06:33:03 - [34m[1mLOGS   [0m - Epoch:  23 [    2608/10000000], loss: {'classification': 0.9932, 'neural_augmentation': 0.2875, 'total_loss': 1.2806}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.323, Elapsed time:  2.48
2024-07-22 06:33:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 1.0574, 'neural_augmentation': 0.2794, 'total_loss': 1.3367}
2024-07-22 06:33:30 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 0.2994, 'neural_augmentation': 0.0, 'total_loss': 0.2994} || top1={'logits': 94.457} || top5={'logits': 99.1836}
2024-07-22 06:33:30 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:33:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:33:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 2722 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_23_iter_2722.pt
2024-07-22 06:33:31 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 2722 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_23_iter_2722.pt
[31m===========================================================================[0m
2024-07-22 06:33:33 - [32m[1mINFO   [0m - Training epoch 24
2024-07-22 06:33:34 - [34m[1mLOGS   [0m - Epoch:  24 [    2723/10000000], loss: {'classification': 1.0713, 'neural_augmentation': 0.296, 'total_loss': 1.3673}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.202, Elapsed time:  1.37
2024-07-22 06:33:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 1.0606, 'neural_augmentation': 0.2776, 'total_loss': 1.3383}
2024-07-22 06:34:00 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 0.3101, 'neural_augmentation': 0.0, 'total_loss': 0.3101} || top1={'logits': 94.3672} || top5={'logits': 99.2188}
2024-07-22 06:34:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:34:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:34:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 2830 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_24_iter_2830.pt
2024-07-22 06:34:02 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 2830 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_24_iter_2830.pt
[31m===========================================================================[0m
2024-07-22 06:34:04 - [32m[1mINFO   [0m - Training epoch 25
2024-07-22 06:34:05 - [34m[1mLOGS   [0m - Epoch:  25 [    2831/10000000], loss: {'classification': 1.0369, 'neural_augmentation': 0.244, 'total_loss': 1.281}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.432, Elapsed time:  1.60
2024-07-22 06:34:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 1.0529, 'neural_augmentation': 0.2754, 'total_loss': 1.3283}
2024-07-22 06:34:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 0.2989, 'neural_augmentation': 0.0, 'total_loss': 0.2989} || top1={'logits': 94.6367} || top5={'logits': 99.2266}
2024-07-22 06:34:31 - [34m[1mLOGS   [0m - Best checkpoint with score 94.64 saved at /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_best.pt
2024-07-22 06:34:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_score_94.3359.pt
2024-07-22 06:34:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_94.4609.pt', 'checkpoint_score_94.4648.pt', 'checkpoint_score_94.4766.pt', 'checkpoint_score_94.5000.pt', 'checkpoint_score_94.6367.pt']
2024-07-22 06:34:33 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_avg.pt
2024-07-22 06:34:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:34:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:34:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 2936 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_25_iter_2936.pt
2024-07-22 06:34:36 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 2936 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_25_iter_2936.pt
[31m===========================================================================[0m
2024-07-22 06:34:38 - [32m[1mINFO   [0m - Training epoch 26
2024-07-22 06:34:40 - [34m[1mLOGS   [0m - Epoch:  26 [    2937/10000000], loss: {'classification': 0.966, 'neural_augmentation': 0.3017, 'total_loss': 1.2677}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.477, Elapsed time:  1.64
2024-07-22 06:34:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 1.0349, 'neural_augmentation': 0.275, 'total_loss': 1.3099}
2024-07-22 06:35:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 0.3058, 'neural_augmentation': 0.0, 'total_loss': 0.3058} || top1={'logits': 94.4297} || top5={'logits': 99.1719}
2024-07-22 06:35:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:35:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:35:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 3050 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_26_iter_3050.pt
2024-07-22 06:35:08 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 3050 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_26_iter_3050.pt
[31m===========================================================================[0m
2024-07-22 06:35:10 - [32m[1mINFO   [0m - Training epoch 27
2024-07-22 06:35:13 - [34m[1mLOGS   [0m - Epoch:  27 [    3051/10000000], loss: {'classification': 1.0274, 'neural_augmentation': 0.2723, 'total_loss': 1.2997}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 2.800, Elapsed time:  2.96
2024-07-22 06:35:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 1.0281, 'neural_augmentation': 0.2732, 'total_loss': 1.3013}
2024-07-22 06:35:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 0.3105, 'neural_augmentation': 0.0, 'total_loss': 0.3105} || top1={'logits': 94.3594} || top5={'logits': 99.1445}
2024-07-22 06:35:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:35:42 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:35:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 3176 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_27_iter_3176.pt
2024-07-22 06:35:42 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 3176 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_27_iter_3176.pt
[31m===========================================================================[0m
2024-07-22 06:35:44 - [32m[1mINFO   [0m - Training epoch 28
2024-07-22 06:35:48 - [34m[1mLOGS   [0m - Epoch:  28 [    3177/10000000], loss: {'classification': 1.0882, 'neural_augmentation': 0.2607, 'total_loss': 1.3489}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 4.123, Elapsed time:  4.28
2024-07-22 06:36:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 1.0393, 'neural_augmentation': 0.2732, 'total_loss': 1.3125}
2024-07-22 06:36:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 0.31, 'neural_augmentation': 0.0, 'total_loss': 0.31} || top1={'logits': 94.4219} || top5={'logits': 99.1484}
2024-07-22 06:36:13 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:36:13 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:36:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 3281 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_28_iter_3281.pt
2024-07-22 06:36:13 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 3281 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_28_iter_3281.pt
[31m===========================================================================[0m
2024-07-22 06:36:15 - [32m[1mINFO   [0m - Training epoch 29
2024-07-22 06:36:17 - [34m[1mLOGS   [0m - Epoch:  29 [    3282/10000000], loss: {'classification': 0.9551, 'neural_augmentation': 0.2595, 'total_loss': 1.2146}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.082, Elapsed time:  1.31
2024-07-22 06:36:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 1.0275, 'neural_augmentation': 0.2718, 'total_loss': 1.2993}
2024-07-22 06:36:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 0.3138, 'neural_augmentation': 0.0, 'total_loss': 0.3138} || top1={'logits': 94.3203} || top5={'logits': 99.0859}
2024-07-22 06:36:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:36:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:36:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 3387 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_29_iter_3387.pt
2024-07-22 06:36:44 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 3387 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_29_iter_3387.pt
[31m===========================================================================[0m
2024-07-22 06:36:46 - [32m[1mINFO   [0m - Training epoch 30
2024-07-22 06:36:50 - [34m[1mLOGS   [0m - Epoch:  30 [    3388/10000000], loss: {'classification': 0.9991, 'neural_augmentation': 0.2846, 'total_loss': 1.2837}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 3.787, Elapsed time:  3.95
2024-07-22 06:37:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'classification': 1.0269, 'neural_augmentation': 0.271, 'total_loss': 1.2978}
2024-07-22 06:37:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'classification': 0.3204, 'neural_augmentation': 0.0, 'total_loss': 0.3204} || top1={'logits': 94.4297} || top5={'logits': 99.0625}
2024-07-22 06:37:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:37:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:37:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 3500 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_30_iter_3500.pt
2024-07-22 06:37:16 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 3500 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_30_iter_3500.pt
[31m===========================================================================[0m
2024-07-22 06:37:18 - [32m[1mINFO   [0m - Training epoch 31
2024-07-22 06:37:20 - [34m[1mLOGS   [0m - Epoch:  31 [    3501/10000000], loss: {'classification': 1.0003, 'neural_augmentation': 0.2889, 'total_loss': 1.2892}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.951, Elapsed time:  2.11
2024-07-22 06:37:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'classification': 1.0221, 'neural_augmentation': 0.2693, 'total_loss': 1.2915}
2024-07-22 06:37:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'classification': 0.3126, 'neural_augmentation': 0.0, 'total_loss': 0.3126} || top1={'logits': 94.3008} || top5={'logits': 99.0625}
2024-07-22 06:37:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:37:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:37:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 3600 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_31_iter_3600.pt
2024-07-22 06:37:46 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 3600 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_31_iter_3600.pt
[31m===========================================================================[0m
2024-07-22 06:37:48 - [32m[1mINFO   [0m - Training epoch 32
2024-07-22 06:37:52 - [34m[1mLOGS   [0m - Epoch:  32 [    3601/10000000], loss: {'classification': 0.975, 'neural_augmentation': 0.2775, 'total_loss': 1.2525}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 3.759, Elapsed time:  3.91
2024-07-22 06:38:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'classification': 1.0169, 'neural_augmentation': 0.27, 'total_loss': 1.2869}
2024-07-22 06:38:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'classification': 0.314, 'neural_augmentation': 0.0, 'total_loss': 0.314} || top1={'logits': 94.4688} || top5={'logits': 99.1094}
2024-07-22 06:38:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:38:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:38:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 3707 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_32_iter_3707.pt
2024-07-22 06:38:18 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 3707 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_32_iter_3707.pt
[31m===========================================================================[0m
2024-07-22 06:38:20 - [32m[1mINFO   [0m - Training epoch 33
2024-07-22 06:38:23 - [34m[1mLOGS   [0m - Epoch:  33 [    3708/10000000], loss: {'classification': 1.002, 'neural_augmentation': 0.2714, 'total_loss': 1.2735}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 3.248, Elapsed time:  3.41
2024-07-22 06:38:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'classification': 1.0125, 'neural_augmentation': 0.2723, 'total_loss': 1.2849}
2024-07-22 06:38:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'classification': 0.3092, 'neural_augmentation': 0.0, 'total_loss': 0.3092} || top1={'logits': 94.6211} || top5={'logits': 99.1797}
2024-07-22 06:38:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:38:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:38:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 3808 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_33_iter_3808.pt
2024-07-22 06:38:48 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 3808 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_33_iter_3808.pt
[31m===========================================================================[0m
2024-07-22 06:38:50 - [32m[1mINFO   [0m - Training epoch 34
2024-07-22 06:38:53 - [34m[1mLOGS   [0m - Epoch:  34 [    3809/10000000], loss: {'classification': 0.9353, 'neural_augmentation': 0.2664, 'total_loss': 1.2017}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 3.185, Elapsed time:  3.35
2024-07-22 06:39:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'classification': 1.0104, 'neural_augmentation': 0.2699, 'total_loss': 1.2804}
2024-07-22 06:39:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'classification': 0.3155, 'neural_augmentation': 0.0, 'total_loss': 0.3155} || top1={'logits': 94.4453} || top5={'logits': 99.0977}
2024-07-22 06:39:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:39:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:39:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 3913 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_34_iter_3913.pt
2024-07-22 06:39:19 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 3913 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_34_iter_3913.pt
[31m===========================================================================[0m
2024-07-22 06:39:21 - [32m[1mINFO   [0m - Training epoch 35
2024-07-22 06:39:27 - [34m[1mLOGS   [0m - Epoch:  35 [    3914/10000000], loss: {'classification': 1.0657, 'neural_augmentation': 0.2639, 'total_loss': 1.3297}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 5.806, Elapsed time:  5.97
2024-07-22 06:39:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'classification': 0.9996, 'neural_augmentation': 0.27, 'total_loss': 1.2697}
2024-07-22 06:39:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'classification': 0.3161, 'neural_augmentation': 0.0, 'total_loss': 0.3161} || top1={'logits': 94.5} || top5={'logits': 99.0898}
2024-07-22 06:39:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:39:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:39:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 4025 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_35_iter_4025.pt
2024-07-22 06:39:55 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 4025 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_35_iter_4025.pt
[31m===========================================================================[0m
2024-07-22 06:39:57 - [32m[1mINFO   [0m - Training epoch 36
2024-07-22 06:40:00 - [34m[1mLOGS   [0m - Epoch:  36 [    4026/10000000], loss: {'classification': 0.9447, 'neural_augmentation': 0.2752, 'total_loss': 1.2199}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 3.081, Elapsed time:  3.25
2024-07-22 06:40:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'classification': 1.0054, 'neural_augmentation': 0.2708, 'total_loss': 1.2762}
2024-07-22 06:40:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'classification': 0.3113, 'neural_augmentation': 0.0, 'total_loss': 0.3113} || top1={'logits': 94.5664} || top5={'logits': 98.9883}
2024-07-22 06:40:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:40:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:40:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 4127 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_36_iter_4127.pt
2024-07-22 06:40:26 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 4127 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_36_iter_4127.pt
[31m===========================================================================[0m
2024-07-22 06:40:28 - [32m[1mINFO   [0m - Training epoch 37
2024-07-22 06:40:32 - [34m[1mLOGS   [0m - Epoch:  37 [    4128/10000000], loss: {'classification': 0.9817, 'neural_augmentation': 0.2671, 'total_loss': 1.2488}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 3.498, Elapsed time:  3.66
2024-07-22 06:40:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'classification': 0.9859, 'neural_augmentation': 0.2736, 'total_loss': 1.2596}
2024-07-22 06:41:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'classification': 0.3194, 'neural_augmentation': 0.0, 'total_loss': 0.3194} || top1={'logits': 94.3945} || top5={'logits': 99.0703}
2024-07-22 06:41:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:41:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:41:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 4247 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_37_iter_4247.pt
2024-07-22 06:41:02 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 4247 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_37_iter_4247.pt
[31m===========================================================================[0m
2024-07-22 06:41:04 - [32m[1mINFO   [0m - Training epoch 38
2024-07-22 06:41:10 - [34m[1mLOGS   [0m - Epoch:  38 [    4248/10000000], loss: {'classification': 1.0609, 'neural_augmentation': 0.2624, 'total_loss': 1.3234}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 5.183, Elapsed time:  5.34
2024-07-22 06:41:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'classification': 0.9885, 'neural_augmentation': 0.2728, 'total_loss': 1.2613}
2024-07-22 06:41:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'classification': 0.3167, 'neural_augmentation': 0.0, 'total_loss': 0.3167} || top1={'logits': 94.3633} || top5={'logits': 99.0391}
2024-07-22 06:41:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:41:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:41:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 4361 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_38_iter_4361.pt
2024-07-22 06:41:36 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 4361 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_38_iter_4361.pt
[31m===========================================================================[0m
2024-07-22 06:41:38 - [32m[1mINFO   [0m - Training epoch 39
2024-07-22 06:41:43 - [34m[1mLOGS   [0m - Epoch:  39 [    4362/10000000], loss: {'classification': 0.9623, 'neural_augmentation': 0.2767, 'total_loss': 1.239}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 4.179, Elapsed time:  4.36
2024-07-22 06:42:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'classification': 0.9886, 'neural_augmentation': 0.2745, 'total_loss': 1.2631}
2024-07-22 06:42:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'classification': 0.3164, 'neural_augmentation': 0.0, 'total_loss': 0.3164} || top1={'logits': 94.4375} || top5={'logits': 98.9961}
2024-07-22 06:42:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:42:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:42:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 4474 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_39_iter_4474.pt
2024-07-22 06:42:10 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 4474 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_39_iter_4474.pt
[31m===========================================================================[0m
2024-07-22 06:42:12 - [32m[1mINFO   [0m - Training epoch 40
2024-07-22 06:42:17 - [34m[1mLOGS   [0m - Epoch:  40 [    4475/10000000], loss: {'classification': 1.0352, 'neural_augmentation': 0.2723, 'total_loss': 1.3075}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 4.884, Elapsed time:  5.05
2024-07-22 06:42:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'classification': 0.9854, 'neural_augmentation': 0.2769, 'total_loss': 1.2623}
2024-07-22 06:42:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'classification': 0.3124, 'neural_augmentation': 0.0, 'total_loss': 0.3124} || top1={'logits': 94.3594} || top5={'logits': 99.0938}
2024-07-22 06:42:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:42:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:42:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 4585 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_40_iter_4585.pt
2024-07-22 06:42:43 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 4585 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_40_iter_4585.pt
[31m===========================================================================[0m
2024-07-22 06:42:45 - [32m[1mINFO   [0m - Training epoch 41
2024-07-22 06:42:50 - [34m[1mLOGS   [0m - Epoch:  41 [    4586/10000000], loss: {'classification': 0.9828, 'neural_augmentation': 0.2877, 'total_loss': 1.2705}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 4.663, Elapsed time:  4.82
2024-07-22 06:43:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'classification': 0.9919, 'neural_augmentation': 0.2783, 'total_loss': 1.2703}
2024-07-22 06:43:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'classification': 0.3209, 'neural_augmentation': 0.0, 'total_loss': 0.3209} || top1={'logits': 94.2812} || top5={'logits': 99.0312}
2024-07-22 06:43:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:43:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:43:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 4683 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_41_iter_4683.pt
2024-07-22 06:43:15 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 4683 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_41_iter_4683.pt
[31m===========================================================================[0m
2024-07-22 06:43:17 - [32m[1mINFO   [0m - Training epoch 42
2024-07-22 06:43:20 - [34m[1mLOGS   [0m - Epoch:  42 [    4684/10000000], loss: {'classification': 0.8716, 'neural_augmentation': 0.2725, 'total_loss': 1.1441}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 2.921, Elapsed time:  3.09
2024-07-22 06:43:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'classification': 0.9739, 'neural_augmentation': 0.2818, 'total_loss': 1.2557}
2024-07-22 06:43:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'classification': 0.32, 'neural_augmentation': 0.0, 'total_loss': 0.32} || top1={'logits': 94.1914} || top5={'logits': 98.9922}
2024-07-22 06:43:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:43:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:43:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 4801 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_42_iter_4801.pt
2024-07-22 06:43:49 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 4801 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_42_iter_4801.pt
[31m===========================================================================[0m
2024-07-22 06:43:51 - [32m[1mINFO   [0m - Training epoch 43
2024-07-22 06:43:57 - [34m[1mLOGS   [0m - Epoch:  43 [    4802/10000000], loss: {'classification': 1.0439, 'neural_augmentation': 0.2824, 'total_loss': 1.3263}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 5.812, Elapsed time:  6.05
2024-07-22 06:44:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'classification': 0.9748, 'neural_augmentation': 0.282, 'total_loss': 1.2568}
2024-07-22 06:44:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'classification': 0.3238, 'neural_augmentation': 0.0, 'total_loss': 0.3238} || top1={'logits': 94.2969} || top5={'logits': 98.9766}
2024-07-22 06:44:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:44:24 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:44:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 4921 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_43_iter_4921.pt
2024-07-22 06:44:25 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 4921 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_43_iter_4921.pt
[31m===========================================================================[0m
2024-07-22 06:44:27 - [32m[1mINFO   [0m - Training epoch 44
2024-07-22 06:44:31 - [34m[1mLOGS   [0m - Epoch:  44 [    4922/10000000], loss: {'classification': 0.9641, 'neural_augmentation': 0.2779, 'total_loss': 1.242}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 4.135, Elapsed time:  4.30
2024-07-22 06:44:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'classification': 0.9764, 'neural_augmentation': 0.2847, 'total_loss': 1.2611}
2024-07-22 06:44:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'classification': 0.3192, 'neural_augmentation': 0.0, 'total_loss': 0.3192} || top1={'logits': 94.1992} || top5={'logits': 99.0039}
2024-07-22 06:44:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:44:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:44:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 5032 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_44_iter_5032.pt
2024-07-22 06:44:58 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 5032 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_44_iter_5032.pt
[31m===========================================================================[0m
2024-07-22 06:45:00 - [32m[1mINFO   [0m - Training epoch 45
2024-07-22 06:45:03 - [34m[1mLOGS   [0m - Epoch:  45 [    5033/10000000], loss: {'classification': 0.97, 'neural_augmentation': 0.2781, 'total_loss': 1.2481}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 2.926, Elapsed time:  3.13
2024-07-22 06:45:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'classification': 0.9736, 'neural_augmentation': 0.2892, 'total_loss': 1.2628}
2024-07-22 06:45:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'classification': 0.3232, 'neural_augmentation': 0.0, 'total_loss': 0.3232} || top1={'logits': 94.3281} || top5={'logits': 98.9805}
2024-07-22 06:45:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:45:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:45:29 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 5136 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_45_iter_5136.pt
2024-07-22 06:45:29 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 5136 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_45_iter_5136.pt
[31m===========================================================================[0m
2024-07-22 06:45:31 - [32m[1mINFO   [0m - Training epoch 46
2024-07-22 06:45:34 - [34m[1mLOGS   [0m - Epoch:  46 [    5137/10000000], loss: {'classification': 0.9721, 'neural_augmentation': 0.2939, 'total_loss': 1.266}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 2.549, Elapsed time:  2.72
2024-07-22 06:45:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'classification': 0.9639, 'neural_augmentation': 0.2912, 'total_loss': 1.2551}
2024-07-22 06:46:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'classification': 0.3165, 'neural_augmentation': 0.0, 'total_loss': 0.3165} || top1={'logits': 94.4531} || top5={'logits': 99.043}
2024-07-22 06:46:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:46:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:46:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 5248 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_46_iter_5248.pt
2024-07-22 06:46:02 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 5248 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_46_iter_5248.pt
[31m===========================================================================[0m
2024-07-22 06:46:04 - [32m[1mINFO   [0m - Training epoch 47
2024-07-22 06:46:06 - [34m[1mLOGS   [0m - Epoch:  47 [    5249/10000000], loss: {'classification': 0.9176, 'neural_augmentation': 0.2923, 'total_loss': 1.2099}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 1.675, Elapsed time:  1.86
2024-07-22 06:46:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'classification': 0.9656, 'neural_augmentation': 0.296, 'total_loss': 1.2616}
2024-07-22 06:46:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'classification': 0.3244, 'neural_augmentation': 0.0, 'total_loss': 0.3244} || top1={'logits': 94.3867} || top5={'logits': 98.9688}
2024-07-22 06:46:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:46:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:46:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 5363 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_47_iter_5363.pt
2024-07-22 06:46:36 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 5363 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_47_iter_5363.pt
[31m===========================================================================[0m
2024-07-22 06:46:38 - [32m[1mINFO   [0m - Training epoch 48
2024-07-22 06:46:40 - [34m[1mLOGS   [0m - Epoch:  48 [    5364/10000000], loss: {'classification': 0.8891, 'neural_augmentation': 0.3124, 'total_loss': 1.2016}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 1.515, Elapsed time:  1.67
2024-07-22 06:47:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'classification': 0.9631, 'neural_augmentation': 0.3002, 'total_loss': 1.2634}
2024-07-22 06:47:08 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'classification': 0.3249, 'neural_augmentation': 0.0, 'total_loss': 0.3249} || top1={'logits': 94.3203} || top5={'logits': 98.9688}
2024-07-22 06:47:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:47:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:47:09 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 5476 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_48_iter_5476.pt
2024-07-22 06:47:09 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 5476 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_48_iter_5476.pt
[31m===========================================================================[0m
2024-07-22 06:47:11 - [32m[1mINFO   [0m - Training epoch 49
2024-07-22 06:47:15 - [34m[1mLOGS   [0m - Epoch:  49 [    5477/10000000], loss: {'classification': 0.9133, 'neural_augmentation': 0.3078, 'total_loss': 1.2211}, LR: [2e-05, 2e-05], Avg. batch load time: 3.230, Elapsed time:  3.43
2024-07-22 06:47:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'classification': 0.958, 'neural_augmentation': 0.3038, 'total_loss': 1.2619}
2024-07-22 06:47:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'classification': 0.328, 'neural_augmentation': 0.0, 'total_loss': 0.328} || top1={'logits': 94.1602} || top5={'logits': 98.9961}
2024-07-22 06:47:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:47:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:47:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 5595 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_49_iter_5595.pt
2024-07-22 06:47:45 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 5595 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_49_iter_5595.pt
[31m===========================================================================[0m
2024-07-22 06:47:47 - [32m[1mINFO   [0m - Training epoch 50
2024-07-22 06:47:49 - [34m[1mLOGS   [0m - Epoch:  50 [    5596/10000000], loss: {'classification': 0.8906, 'neural_augmentation': 0.3079, 'total_loss': 1.1985}, LR: [2e-05, 2e-05], Avg. batch load time: 2.224, Elapsed time:  2.40
2024-07-22 06:48:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 50
	 loss={'classification': 0.9587, 'neural_augmentation': 0.3073, 'total_loss': 1.266}
2024-07-22 06:48:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 50
	 loss={'classification': 0.3296, 'neural_augmentation': 0.0, 'total_loss': 0.3296} || top1={'logits': 94.3945} || top5={'logits': 98.9844}
2024-07-22 06:48:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:48:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:48:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 50/iteration 5709 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_50_iter_5709.pt
2024-07-22 06:48:21 - [34m[1mLOGS   [0m - Model state for epoch 50/iteration 5709 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_50_iter_5709.pt
[31m===========================================================================[0m
2024-07-22 06:48:23 - [32m[1mINFO   [0m - Training epoch 51
2024-07-22 06:48:28 - [34m[1mLOGS   [0m - Epoch:  51 [    5710/10000000], loss: {'classification': 0.9036, 'neural_augmentation': 0.3168, 'total_loss': 1.2204}, LR: [2e-05, 2e-05], Avg. batch load time: 4.720, Elapsed time:  4.89
2024-07-22 06:48:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 51
	 loss={'classification': 0.9532, 'neural_augmentation': 0.3132, 'total_loss': 1.2664}
2024-07-22 06:48:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 51
	 loss={'classification': 0.3317, 'neural_augmentation': 0.0, 'total_loss': 0.3317} || top1={'logits': 94.1992} || top5={'logits': 98.9844}
2024-07-22 06:48:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:49:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:49:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 51/iteration 5833 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_51_iter_5833.pt
2024-07-22 06:49:00 - [34m[1mLOGS   [0m - Model state for epoch 51/iteration 5833 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_51_iter_5833.pt
[31m===========================================================================[0m
2024-07-22 06:49:02 - [32m[1mINFO   [0m - Training epoch 52
2024-07-22 06:49:10 - [34m[1mLOGS   [0m - Epoch:  52 [    5834/10000000], loss: {'classification': 1.0211, 'neural_augmentation': 0.3129, 'total_loss': 1.334}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 7.033, Elapsed time:  7.20
2024-07-22 06:49:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 52
	 loss={'classification': 0.9553, 'neural_augmentation': 0.3175, 'total_loss': 1.2728}
2024-07-22 06:49:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 52
	 loss={'classification': 0.3335, 'neural_augmentation': 0.0, 'total_loss': 0.3335} || top1={'logits': 94.1953} || top5={'logits': 98.957}
2024-07-22 06:49:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:49:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:49:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 52/iteration 5954 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_52_iter_5954.pt
2024-07-22 06:49:38 - [34m[1mLOGS   [0m - Model state for epoch 52/iteration 5954 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_52_iter_5954.pt
[31m===========================================================================[0m
2024-07-22 06:49:40 - [32m[1mINFO   [0m - Training epoch 53
2024-07-22 06:49:44 - [34m[1mLOGS   [0m - Epoch:  53 [    5955/10000000], loss: {'classification': 0.9266, 'neural_augmentation': 0.3228, 'total_loss': 1.2493}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 4.363, Elapsed time:  4.52
2024-07-22 06:50:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 53
	 loss={'classification': 0.9457, 'neural_augmentation': 0.3243, 'total_loss': 1.27}
2024-07-22 06:50:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 53
	 loss={'classification': 0.3266, 'neural_augmentation': 0.0, 'total_loss': 0.3266} || top1={'logits': 94.0898} || top5={'logits': 98.9883}
2024-07-22 06:50:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:50:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:50:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 53/iteration 6082 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_53_iter_6082.pt
2024-07-22 06:50:15 - [34m[1mLOGS   [0m - Model state for epoch 53/iteration 6082 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_53_iter_6082.pt
[31m===========================================================================[0m
2024-07-22 06:50:17 - [32m[1mINFO   [0m - Training epoch 54
2024-07-22 06:50:20 - [34m[1mLOGS   [0m - Epoch:  54 [    6083/10000000], loss: {'classification': 0.969, 'neural_augmentation': 0.3226, 'total_loss': 1.2917}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 2.706, Elapsed time:  2.87
2024-07-22 06:50:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 54
	 loss={'classification': 0.9561, 'neural_augmentation': 0.329, 'total_loss': 1.2851}
2024-07-22 06:50:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 54
	 loss={'classification': 0.3308, 'neural_augmentation': 0.0, 'total_loss': 0.3308} || top1={'logits': 94.2344} || top5={'logits': 98.9336}
2024-07-22 06:50:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:50:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:50:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 54/iteration 6196 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_54_iter_6196.pt
2024-07-22 06:50:49 - [34m[1mLOGS   [0m - Model state for epoch 54/iteration 6196 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_54_iter_6196.pt
[31m===========================================================================[0m
2024-07-22 06:50:51 - [32m[1mINFO   [0m - Training epoch 55
2024-07-22 06:50:54 - [34m[1mLOGS   [0m - Epoch:  55 [    6197/10000000], loss: {'classification': 0.8929, 'neural_augmentation': 0.3308, 'total_loss': 1.2237}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 2.122, Elapsed time:  2.29
2024-07-22 06:51:13 - [34m[1mLOGS   [0m - *** Training summary for epoch 55
	 loss={'classification': 0.957, 'neural_augmentation': 0.3346, 'total_loss': 1.2917}
2024-07-22 06:51:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 55
	 loss={'classification': 0.3365, 'neural_augmentation': 0.0, 'total_loss': 0.3365} || top1={'logits': 94.2109} || top5={'logits': 98.918}
2024-07-22 06:51:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:51:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:51:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 55/iteration 6302 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_55_iter_6302.pt
2024-07-22 06:51:22 - [34m[1mLOGS   [0m - Model state for epoch 55/iteration 6302 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_55_iter_6302.pt
[31m===========================================================================[0m
2024-07-22 06:51:24 - [32m[1mINFO   [0m - Training epoch 56
2024-07-22 06:51:30 - [34m[1mLOGS   [0m - Epoch:  56 [    6303/10000000], loss: {'classification': 0.9688, 'neural_augmentation': 0.3327, 'total_loss': 1.3015}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 5.259, Elapsed time:  5.42
2024-07-22 06:51:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 56
	 loss={'classification': 0.9499, 'neural_augmentation': 0.341, 'total_loss': 1.2909}
2024-07-22 06:51:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 56
	 loss={'classification': 0.3251, 'neural_augmentation': 0.0, 'total_loss': 0.3251} || top1={'logits': 94.2422} || top5={'logits': 98.9297}
2024-07-22 06:51:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:51:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:51:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 56/iteration 6410 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_56_iter_6410.pt
2024-07-22 06:51:55 - [34m[1mLOGS   [0m - Model state for epoch 56/iteration 6410 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_56_iter_6410.pt
[31m===========================================================================[0m
2024-07-22 06:51:57 - [32m[1mINFO   [0m - Training epoch 57
2024-07-22 06:52:00 - [34m[1mLOGS   [0m - Epoch:  57 [    6411/10000000], loss: {'classification': 0.9811, 'neural_augmentation': 0.3378, 'total_loss': 1.3189}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 2.209, Elapsed time:  2.38
2024-07-22 06:52:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 57
	 loss={'classification': 0.955, 'neural_augmentation': 0.347, 'total_loss': 1.3019}
2024-07-22 06:52:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 57
	 loss={'classification': 0.3327, 'neural_augmentation': 0.0, 'total_loss': 0.3327} || top1={'logits': 94.1797} || top5={'logits': 98.9297}
2024-07-22 06:52:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:52:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:52:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 57/iteration 6509 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_57_iter_6509.pt
2024-07-22 06:52:27 - [34m[1mLOGS   [0m - Model state for epoch 57/iteration 6509 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_57_iter_6509.pt
[31m===========================================================================[0m
2024-07-22 06:52:29 - [32m[1mINFO   [0m - Training epoch 58
2024-07-22 06:52:34 - [34m[1mLOGS   [0m - Epoch:  58 [    6510/10000000], loss: {'classification': 0.9576, 'neural_augmentation': 0.3657, 'total_loss': 1.3233}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 4.812, Elapsed time:  4.97
2024-07-22 06:52:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 58
	 loss={'classification': 0.9488, 'neural_augmentation': 0.3518, 'total_loss': 1.3006}
2024-07-22 06:52:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 58
	 loss={'classification': 0.327, 'neural_augmentation': 0.0, 'total_loss': 0.327} || top1={'logits': 94.2305} || top5={'logits': 98.9102}
2024-07-22 06:53:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:53:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:53:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 58/iteration 6618 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_58_iter_6618.pt
2024-07-22 06:53:00 - [34m[1mLOGS   [0m - Model state for epoch 58/iteration 6618 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_58_iter_6618.pt
[31m===========================================================================[0m
2024-07-22 06:53:02 - [32m[1mINFO   [0m - Training epoch 59
2024-07-22 06:53:06 - [34m[1mLOGS   [0m - Epoch:  59 [    6619/10000000], loss: {'classification': 0.8548, 'neural_augmentation': 0.3507, 'total_loss': 1.2055}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 3.057, Elapsed time:  3.24
2024-07-22 06:53:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 59
	 loss={'classification': 0.9533, 'neural_augmentation': 0.3596, 'total_loss': 1.3129}
2024-07-22 06:53:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 59
	 loss={'classification': 0.3312, 'neural_augmentation': 0.0, 'total_loss': 0.3312} || top1={'logits': 94.3477} || top5={'logits': 98.8594}
2024-07-22 06:53:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:53:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:53:33 - [34m[1mLOGS   [0m - Training checkpoint for epoch 59/iteration 6727 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_59_iter_6727.pt
2024-07-22 06:53:33 - [34m[1mLOGS   [0m - Model state for epoch 59/iteration 6727 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_59_iter_6727.pt
[31m===========================================================================[0m
2024-07-22 06:53:35 - [32m[1mINFO   [0m - Training epoch 60
2024-07-22 06:53:40 - [34m[1mLOGS   [0m - Epoch:  60 [    6728/10000000], loss: {'classification': 0.9762, 'neural_augmentation': 0.3684, 'total_loss': 1.3446}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 4.999, Elapsed time:  5.16
2024-07-22 06:53:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 60
	 loss={'classification': 0.9428, 'neural_augmentation': 0.3673, 'total_loss': 1.3101}
2024-07-22 06:54:05 - [34m[1mLOGS   [0m - *** Validation summary for epoch 60
	 loss={'classification': 0.3313, 'neural_augmentation': 0.0, 'total_loss': 0.3313} || top1={'logits': 94.3203} || top5={'logits': 98.9453}
2024-07-22 06:54:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:54:05 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:54:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 60/iteration 6830 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_60_iter_6830.pt
2024-07-22 06:54:06 - [34m[1mLOGS   [0m - Model state for epoch 60/iteration 6830 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_60_iter_6830.pt
[31m===========================================================================[0m
2024-07-22 06:54:08 - [32m[1mINFO   [0m - Training epoch 61
2024-07-22 06:54:14 - [34m[1mLOGS   [0m - Epoch:  61 [    6831/10000000], loss: {'classification': 0.969, 'neural_augmentation': 0.3791, 'total_loss': 1.3481}, LR: [1.6e-05, 1.6e-05], Avg. batch load time: 5.893, Elapsed time:  6.05
2024-07-22 06:54:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 61
	 loss={'classification': 0.936, 'neural_augmentation': 0.3741, 'total_loss': 1.3101}
2024-07-22 06:54:39 - [34m[1mLOGS   [0m - *** Validation summary for epoch 61
	 loss={'classification': 0.3354, 'neural_augmentation': 0.0, 'total_loss': 0.3354} || top1={'logits': 94.2227} || top5={'logits': 98.9062}
2024-07-22 06:54:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:54:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:54:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 61/iteration 6941 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_61_iter_6941.pt
2024-07-22 06:54:41 - [34m[1mLOGS   [0m - Model state for epoch 61/iteration 6941 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_61_iter_6941.pt
[31m===========================================================================[0m
2024-07-22 06:54:43 - [32m[1mINFO   [0m - Training epoch 62
2024-07-22 06:54:46 - [34m[1mLOGS   [0m - Epoch:  62 [    6942/10000000], loss: {'classification': 0.8545, 'neural_augmentation': 0.3794, 'total_loss': 1.2339}, LR: [1.6e-05, 1.6e-05], Avg. batch load time: 3.418, Elapsed time:  3.59
2024-07-22 06:55:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 62
	 loss={'classification': 0.9331, 'neural_augmentation': 0.3818, 'total_loss': 1.3149}
2024-07-22 06:55:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 62
	 loss={'classification': 0.3292, 'neural_augmentation': 0.0, 'total_loss': 0.3292} || top1={'logits': 94.3086} || top5={'logits': 98.9141}
2024-07-22 06:55:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:55:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:55:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 62/iteration 7063 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_62_iter_7063.pt
2024-07-22 06:55:16 - [34m[1mLOGS   [0m - Model state for epoch 62/iteration 7063 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_62_iter_7063.pt
[31m===========================================================================[0m
2024-07-22 06:55:18 - [32m[1mINFO   [0m - Training epoch 63
2024-07-22 06:55:20 - [34m[1mLOGS   [0m - Epoch:  63 [    7064/10000000], loss: {'classification': 0.8629, 'neural_augmentation': 0.3906, 'total_loss': 1.2535}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 2.223, Elapsed time:  2.39
2024-07-22 06:55:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 63
	 loss={'classification': 0.9461, 'neural_augmentation': 0.3889, 'total_loss': 1.3349}
2024-07-22 06:55:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 63
	 loss={'classification': 0.3331, 'neural_augmentation': 0.0, 'total_loss': 0.3331} || top1={'logits': 94.2148} || top5={'logits': 98.875}
2024-07-22 06:55:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:55:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:55:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 63/iteration 7164 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_63_iter_7164.pt
2024-07-22 06:55:48 - [34m[1mLOGS   [0m - Model state for epoch 63/iteration 7164 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_63_iter_7164.pt
[31m===========================================================================[0m
2024-07-22 06:55:50 - [32m[1mINFO   [0m - Training epoch 64
2024-07-22 06:55:54 - [34m[1mLOGS   [0m - Epoch:  64 [    7165/10000000], loss: {'classification': 0.8807, 'neural_augmentation': 0.3857, 'total_loss': 1.2664}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 3.607, Elapsed time:  3.77
2024-07-22 06:56:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 64
	 loss={'classification': 0.9321, 'neural_augmentation': 0.396, 'total_loss': 1.3282}
2024-07-22 06:56:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 64
	 loss={'classification': 0.3281, 'neural_augmentation': 0.0, 'total_loss': 0.3281} || top1={'logits': 94.332} || top5={'logits': 98.8906}
2024-07-22 06:56:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:56:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:56:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 64/iteration 7279 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_64_iter_7279.pt
2024-07-22 06:56:21 - [34m[1mLOGS   [0m - Model state for epoch 64/iteration 7279 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_64_iter_7279.pt
[31m===========================================================================[0m
2024-07-22 06:56:23 - [32m[1mINFO   [0m - Training epoch 65
2024-07-22 06:56:27 - [34m[1mLOGS   [0m - Epoch:  65 [    7280/10000000], loss: {'classification': 0.8929, 'neural_augmentation': 0.4021, 'total_loss': 1.295}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 3.275, Elapsed time:  3.46
2024-07-22 06:56:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 65
	 loss={'classification': 0.9288, 'neural_augmentation': 0.4046, 'total_loss': 1.3333}
2024-07-22 06:56:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 65
	 loss={'classification': 0.3309, 'neural_augmentation': 0.0, 'total_loss': 0.3309} || top1={'logits': 94.2812} || top5={'logits': 98.9141}
2024-07-22 06:56:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:56:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:56:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 65/iteration 7398 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_65_iter_7398.pt
2024-07-22 06:56:55 - [34m[1mLOGS   [0m - Model state for epoch 65/iteration 7398 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_65_iter_7398.pt
[31m===========================================================================[0m
2024-07-22 06:56:57 - [32m[1mINFO   [0m - Training epoch 66
2024-07-22 06:57:01 - [34m[1mLOGS   [0m - Epoch:  66 [    7399/10000000], loss: {'classification': 0.8872, 'neural_augmentation': 0.4094, 'total_loss': 1.2966}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 3.506, Elapsed time:  3.67
2024-07-22 06:57:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 66
	 loss={'classification': 0.9333, 'neural_augmentation': 0.4121, 'total_loss': 1.3454}
2024-07-22 06:57:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 66
	 loss={'classification': 0.3319, 'neural_augmentation': 0.0, 'total_loss': 0.3319} || top1={'logits': 94.293} || top5={'logits': 98.918}
2024-07-22 06:57:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:57:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:57:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 66/iteration 7504 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_66_iter_7504.pt
2024-07-22 06:57:28 - [34m[1mLOGS   [0m - Model state for epoch 66/iteration 7504 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_66_iter_7504.pt
[31m===========================================================================[0m
2024-07-22 06:57:30 - [32m[1mINFO   [0m - Training epoch 67
2024-07-22 06:57:33 - [34m[1mLOGS   [0m - Epoch:  67 [    7505/10000000], loss: {'classification': 0.8683, 'neural_augmentation': 0.4123, 'total_loss': 1.2806}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 2.212, Elapsed time:  2.39
2024-07-22 06:57:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 67
	 loss={'classification': 0.9322, 'neural_augmentation': 0.4207, 'total_loss': 1.3529}
2024-07-22 06:58:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 67
	 loss={'classification': 0.3384, 'neural_augmentation': 0.0, 'total_loss': 0.3384} || top1={'logits': 94.1484} || top5={'logits': 98.8594}
2024-07-22 06:58:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:58:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:58:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 67/iteration 7618 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_67_iter_7618.pt
2024-07-22 06:58:03 - [34m[1mLOGS   [0m - Model state for epoch 67/iteration 7618 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_67_iter_7618.pt
[31m===========================================================================[0m
2024-07-22 06:58:05 - [32m[1mINFO   [0m - Training epoch 68
2024-07-22 06:58:07 - [34m[1mLOGS   [0m - Epoch:  68 [    7619/10000000], loss: {'classification': 0.9087, 'neural_augmentation': 0.4183, 'total_loss': 1.3269}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 1.893, Elapsed time:  2.06
2024-07-22 06:58:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 68
	 loss={'classification': 0.9347, 'neural_augmentation': 0.427, 'total_loss': 1.3617}
2024-07-22 06:58:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 68
	 loss={'classification': 0.3371, 'neural_augmentation': 0.0, 'total_loss': 0.3371} || top1={'logits': 94.125} || top5={'logits': 98.8516}
2024-07-22 06:58:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:58:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:58:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 68/iteration 7724 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_68_iter_7724.pt
2024-07-22 06:58:39 - [34m[1mLOGS   [0m - Model state for epoch 68/iteration 7724 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_68_iter_7724.pt
[31m===========================================================================[0m
2024-07-22 06:58:41 - [32m[1mINFO   [0m - Training epoch 69
2024-07-22 06:58:44 - [34m[1mLOGS   [0m - Epoch:  69 [    7725/10000000], loss: {'classification': 0.8689, 'neural_augmentation': 0.4318, 'total_loss': 1.3008}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 2.829, Elapsed time:  3.02
2024-07-22 06:59:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 69
	 loss={'classification': 0.9301, 'neural_augmentation': 0.4364, 'total_loss': 1.3665}
2024-07-22 06:59:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 69
	 loss={'classification': 0.3344, 'neural_augmentation': 0.0, 'total_loss': 0.3344} || top1={'logits': 94.2969} || top5={'logits': 98.832}
2024-07-22 06:59:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:59:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:59:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 69/iteration 7832 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_69_iter_7832.pt
2024-07-22 06:59:15 - [34m[1mLOGS   [0m - Model state for epoch 69/iteration 7832 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_69_iter_7832.pt
[31m===========================================================================[0m
2024-07-22 06:59:17 - [32m[1mINFO   [0m - Training epoch 70
2024-07-22 06:59:19 - [34m[1mLOGS   [0m - Epoch:  70 [    7833/10000000], loss: {'classification': 0.9275, 'neural_augmentation': 0.4378, 'total_loss': 1.3654}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 1.779, Elapsed time:  1.98
2024-07-22 06:59:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 70
	 loss={'classification': 0.9339, 'neural_augmentation': 0.4449, 'total_loss': 1.3788}
2024-07-22 06:59:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 70
	 loss={'classification': 0.3367, 'neural_augmentation': 0.0, 'total_loss': 0.3367} || top1={'logits': 94.1523} || top5={'logits': 98.7891}
2024-07-22 06:59:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 06:59:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 06:59:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 70/iteration 7934 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_70_iter_7934.pt
2024-07-22 06:59:50 - [34m[1mLOGS   [0m - Model state for epoch 70/iteration 7934 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_70_iter_7934.pt
[31m===========================================================================[0m
2024-07-22 06:59:52 - [32m[1mINFO   [0m - Training epoch 71
2024-07-22 06:59:55 - [34m[1mLOGS   [0m - Epoch:  71 [    7935/10000000], loss: {'classification': 0.9359, 'neural_augmentation': 0.4439, 'total_loss': 1.3798}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 3.632, Elapsed time:  3.83
2024-07-22 07:00:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 71
	 loss={'classification': 0.9257, 'neural_augmentation': 0.4532, 'total_loss': 1.3788}
2024-07-22 07:00:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 71
	 loss={'classification': 0.3377, 'neural_augmentation': 0.0, 'total_loss': 0.3377} || top1={'logits': 94.2773} || top5={'logits': 98.8633}
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
    with _resource_sharer.get_connection(self._id) as conn:
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 757, in answer_challenge
    answer_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 752, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    message = connection.recv_bytes(256)         # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    buf = self._recv(4)
    chunk = read(handle, remaining)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
ConnectionResetError: [Errno 104] Connection reset by peer
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
2024-07-22 07:00:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_last.pt
2024-07-22 07:00:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_last.pt
2024-07-22 07:00:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 71/iteration 8061 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/training_checkpoint_epoch_71_iter_8061.pt
2024-07-22 07:00:28 - [34m[1mLOGS   [0m - Model state for epoch 71/iteration 8061 is saved at: /ML-A100/team/mm/models/catlip_data/results500_accum_dci/9_food101/train/checkpoint_epoch_71_iter_8061.pt
2024-07-22 07:00:30 - [34m[1mLOGS   [0m - Keyboard interruption. Exiting from early training
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 8 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
