nohup: ignoring input
2024-07-26 04:02:47 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-07-26 04:02:48 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/vit_base.pt
2024-07-26 04:02:48 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-07-26 04:02:48 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-26 04:02:48 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_emb.0.block.conv.weight', 'encoder.patch_emb.0.block.norm.weight', 'encoder.patch_emb.0.block.norm.bias', 'encoder.patch_emb.1.block.conv.weight', 'encoder.patch_emb.1.block.norm.weight', 'encoder.patch_emb.1.block.norm.bias', 'encoder.patch_emb.2.block.conv.weight', 'encoder.patch_emb.2.block.conv.bias', 'encoder.post_transformer_norm.weight', 'encoder.post_transformer_norm.bias', 'encoder.transformer.0.pre_norm_mha.0.weight', 'encoder.transformer.0.pre_norm_mha.0.bias', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.0.pre_norm_ffn.0.weight', 'encoder.transformer.0.pre_norm_ffn.0.bias', 'encoder.transformer.0.pre_norm_ffn.1.weight', 'encoder.transformer.0.pre_norm_ffn.1.bias', 'encoder.transformer.0.pre_norm_ffn.4.weight', 'encoder.transformer.0.pre_norm_ffn.4.bias', 'encoder.transformer.1.pre_norm_mha.0.weight', 'encoder.transformer.1.pre_norm_mha.0.bias', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.1.pre_norm_ffn.0.weight', 'encoder.transformer.1.pre_norm_ffn.0.bias', 'encoder.transformer.1.pre_norm_ffn.1.weight', 'encoder.transformer.1.pre_norm_ffn.1.bias', 'encoder.transformer.1.pre_norm_ffn.4.weight', 'encoder.transformer.1.pre_norm_ffn.4.bias', 'encoder.transformer.2.pre_norm_mha.0.weight', 'encoder.transformer.2.pre_norm_mha.0.bias', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.2.pre_norm_ffn.0.weight', 'encoder.transformer.2.pre_norm_ffn.0.bias', 'encoder.transformer.2.pre_norm_ffn.1.weight', 'encoder.transformer.2.pre_norm_ffn.1.bias', 'encoder.transformer.2.pre_norm_ffn.4.weight', 'encoder.transformer.2.pre_norm_ffn.4.bias', 'encoder.transformer.3.pre_norm_mha.0.weight', 'encoder.transformer.3.pre_norm_mha.0.bias', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.3.pre_norm_ffn.0.weight', 'encoder.transformer.3.pre_norm_ffn.0.bias', 'encoder.transformer.3.pre_norm_ffn.1.weight', 'encoder.transformer.3.pre_norm_ffn.1.bias', 'encoder.transformer.3.pre_norm_ffn.4.weight', 'encoder.transformer.3.pre_norm_ffn.4.bias', 'encoder.transformer.4.pre_norm_mha.0.weight', 'encoder.transformer.4.pre_norm_mha.0.bias', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.4.pre_norm_ffn.0.weight', 'encoder.transformer.4.pre_norm_ffn.0.bias', 'encoder.transformer.4.pre_norm_ffn.1.weight', 'encoder.transformer.4.pre_norm_ffn.1.bias', 'encoder.transformer.4.pre_norm_ffn.4.weight', 'encoder.transformer.4.pre_norm_ffn.4.bias', 'encoder.transformer.5.pre_norm_mha.0.weight', 'encoder.transformer.5.pre_norm_mha.0.bias', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.5.pre_norm_ffn.0.weight', 'encoder.transformer.5.pre_norm_ffn.0.bias', 'encoder.transformer.5.pre_norm_ffn.1.weight', 'encoder.transformer.5.pre_norm_ffn.1.bias', 'encoder.transformer.5.pre_norm_ffn.4.weight', 'encoder.transformer.5.pre_norm_ffn.4.bias', 'encoder.transformer.6.pre_norm_mha.0.weight', 'encoder.transformer.6.pre_norm_mha.0.bias', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.6.pre_norm_ffn.0.weight', 'encoder.transformer.6.pre_norm_ffn.0.bias', 'encoder.transformer.6.pre_norm_ffn.1.weight', 'encoder.transformer.6.pre_norm_ffn.1.bias', 'encoder.transformer.6.pre_norm_ffn.4.weight', 'encoder.transformer.6.pre_norm_ffn.4.bias', 'encoder.transformer.7.pre_norm_mha.0.weight', 'encoder.transformer.7.pre_norm_mha.0.bias', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.7.pre_norm_ffn.0.weight', 'encoder.transformer.7.pre_norm_ffn.0.bias', 'encoder.transformer.7.pre_norm_ffn.1.weight', 'encoder.transformer.7.pre_norm_ffn.1.bias', 'encoder.transformer.7.pre_norm_ffn.4.weight', 'encoder.transformer.7.pre_norm_ffn.4.bias', 'encoder.transformer.8.pre_norm_mha.0.weight', 'encoder.transformer.8.pre_norm_mha.0.bias', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.8.pre_norm_ffn.0.weight', 'encoder.transformer.8.pre_norm_ffn.0.bias', 'encoder.transformer.8.pre_norm_ffn.1.weight', 'encoder.transformer.8.pre_norm_ffn.1.bias', 'encoder.transformer.8.pre_norm_ffn.4.weight', 'encoder.transformer.8.pre_norm_ffn.4.bias', 'encoder.transformer.9.pre_norm_mha.0.weight', 'encoder.transformer.9.pre_norm_mha.0.bias', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.9.pre_norm_ffn.0.weight', 'encoder.transformer.9.pre_norm_ffn.0.bias', 'encoder.transformer.9.pre_norm_ffn.1.weight', 'encoder.transformer.9.pre_norm_ffn.1.bias', 'encoder.transformer.9.pre_norm_ffn.4.weight', 'encoder.transformer.9.pre_norm_ffn.4.bias', 'encoder.transformer.10.pre_norm_mha.0.weight', 'encoder.transformer.10.pre_norm_mha.0.bias', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.10.pre_norm_ffn.0.weight', 'encoder.transformer.10.pre_norm_ffn.0.bias', 'encoder.transformer.10.pre_norm_ffn.1.weight', 'encoder.transformer.10.pre_norm_ffn.1.bias', 'encoder.transformer.10.pre_norm_ffn.4.weight', 'encoder.transformer.10.pre_norm_ffn.4.bias', 'encoder.transformer.11.pre_norm_mha.0.weight', 'encoder.transformer.11.pre_norm_mha.0.bias', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.11.pre_norm_ffn.0.weight', 'encoder.transformer.11.pre_norm_ffn.0.bias', 'encoder.transformer.11.pre_norm_ffn.1.weight', 'encoder.transformer.11.pre_norm_ffn.1.bias', 'encoder.transformer.11.pre_norm_ffn.4.weight', 'encoder.transformer.11.pre_norm_ffn.4.bias', 'encoder.pos_embed.pos_embed.pos_embed', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-26 04:02:48 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): VisionTransformer(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_emb): Sequential(
      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
      (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
      (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
    )
    (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
    (transformer): Sequential(
      (0): FlashTransformerEncoder
      (1): FlashTransformerEncoder
      (2): FlashTransformerEncoder
      (3): FlashTransformerEncoder
      (4): FlashTransformerEncoder
      (5): FlashTransformerEncoder
      (6): FlashTransformerEncoder
      (7): FlashTransformerEncoder
      (8): FlashTransformerEncoder
      (9): FlashTransformerEncoder
      (10): FlashTransformerEncoder
      (11): FlashTransformerEncoder
    )
    (classifier): None
    (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
    (emb_dropout): Dropout(p=0.0, inplace=False)
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=8.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=512, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(512, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   98.728 M
Total trainable parameters =   98.728 M

2024-07-26 04:02:48 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-26 04:02:48 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops    |
|:------------------------------------------|:-----------------------|:----------|
| model                                     | 98.728M                | 77.442G   |
|  encoder                                  |  85.955M               |  67.713G  |
|   encoder.neural_augmentor                |   6                    |           |
|    encoder.neural_augmentor.brightness    |    2                   |           |
|    encoder.neural_augmentor.contrast      |    2                   |           |
|    encoder.neural_augmentor.noise         |    2                   |           |
|   encoder.patch_emb                       |   0.748M               |   1.046G  |
|    encoder.patch_emb.0.block              |    9.6K                |    0.12G  |
|    encoder.patch_emb.1.block              |    0.148M              |    0.464G |
|    encoder.patch_emb.2.block.conv         |    0.591M              |    0.462G |
|   encoder.post_transformer_norm           |   1.536K               |   3.011M  |
|    encoder.post_transformer_norm.weight   |    (768,)              |           |
|    encoder.post_transformer_norm.bias     |    (768,)              |           |
|   encoder.transformer                     |   85.054M              |   66.661G |
|    encoder.transformer.0                  |    7.088M              |    5.555G |
|    encoder.transformer.1                  |    7.088M              |    5.555G |
|    encoder.transformer.2                  |    7.088M              |    5.555G |
|    encoder.transformer.3                  |    7.088M              |    5.555G |
|    encoder.transformer.4                  |    7.088M              |    5.555G |
|    encoder.transformer.5                  |    7.088M              |    5.555G |
|    encoder.transformer.6                  |    7.088M              |    5.555G |
|    encoder.transformer.7                  |    7.088M              |    5.555G |
|    encoder.transformer.8                  |    7.088M              |    5.555G |
|    encoder.transformer.9                  |    7.088M              |    5.555G |
|    encoder.transformer.10                 |    7.088M              |    5.555G |
|    encoder.transformer.11                 |    7.088M              |    5.555G |
|   encoder.pos_embed.pos_embed             |   0.151M               |   2.408M  |
|    encoder.pos_embed.pos_embed.pos_embed  |    (1, 1, 196, 768)    |           |
|  seg_head                                 |  12.773M               |  9.729G   |
|   seg_head.aspp.aspp_layer                |   12.72M               |   9.666G  |
|    seg_head.aspp.aspp_layer.convs         |    11.408M             |    8.638G |
|    seg_head.aspp.aspp_layer.project.block |    1.312M              |    1.028G |
|   seg_head.classifier.block.conv          |   53.352K              |   41.746M |
|    seg_head.classifier.block.conv.weight  |    (104, 512, 1, 1)    |           |
|    seg_head.classifier.block.conv.bias    |    (104,)              |           |
|   seg_head.upsample_seg_out               |                        |   20.873M |
2024-07-26 04:02:49 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-26 04:02:49 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.transformer.8.drop_path', 'encoder.neural_augmentor.noise.max_fn', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.neural_augmentor.noise.min_fn', 'encoder.neural_augmentor.brightness', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.transformer.10.drop_path', 'encoder.transformer.11.drop_path', 'encoder.transformer.5.drop_path', 'encoder.transformer.7.drop_path', 'encoder.transformer.1.drop_path', 'encoder.transformer.0.drop_path', 'encoder.transformer.9.drop_path', 'encoder.transformer.4.drop_path', 'encoder.transformer.3.drop_path', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.neural_augmentor', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.neural_augmentor.contrast', 'encoder.transformer.2.drop_path', 'encoder.transformer.6.drop_path', 'encoder.neural_augmentor.noise'}
2024-07-26 04:02:49 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 20, 'aten::scaled_dot_product_attention': 12, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-26 04:02:49 - [34m[1mLOGS   [0m - Directory created at: /ML-A100/team/mm/models/catlip_data/seg_vit_base/train
2024-07-26 04:02:52 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40010
2024-07-26 04:02:55 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=True 
	num_samples=4983
	transforms=Compose(
			RandomShortSizeResize(short_side_min=256, short_side_max=768, interpolation=bicubic), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=512, w=512), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-26 04:02:55 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=False 
	num_samples=2135
	transforms=Compose(
			Resize(size=[512, 512], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-26 04:02:55 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=512, w=512)
	base_batch_size=8
)
2024-07-26 04:02:55 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=512, w=512)
	base_batch_size=8
)
2024-07-26 04:02:55 - [34m[1mLOGS   [0m - Number of data workers: 64
2024-07-26 04:02:58 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/vit_base.pt
2024-07-26 04:02:58 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-07-26 04:02:58 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-26 04:02:58 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_emb.0.block.conv.weight', 'encoder.patch_emb.0.block.norm.weight', 'encoder.patch_emb.0.block.norm.bias', 'encoder.patch_emb.1.block.conv.weight', 'encoder.patch_emb.1.block.norm.weight', 'encoder.patch_emb.1.block.norm.bias', 'encoder.patch_emb.2.block.conv.weight', 'encoder.patch_emb.2.block.conv.bias', 'encoder.post_transformer_norm.weight', 'encoder.post_transformer_norm.bias', 'encoder.transformer.0.pre_norm_mha.0.weight', 'encoder.transformer.0.pre_norm_mha.0.bias', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.0.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.0.pre_norm_ffn.0.weight', 'encoder.transformer.0.pre_norm_ffn.0.bias', 'encoder.transformer.0.pre_norm_ffn.1.weight', 'encoder.transformer.0.pre_norm_ffn.1.bias', 'encoder.transformer.0.pre_norm_ffn.4.weight', 'encoder.transformer.0.pre_norm_ffn.4.bias', 'encoder.transformer.1.pre_norm_mha.0.weight', 'encoder.transformer.1.pre_norm_mha.0.bias', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.1.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.1.pre_norm_ffn.0.weight', 'encoder.transformer.1.pre_norm_ffn.0.bias', 'encoder.transformer.1.pre_norm_ffn.1.weight', 'encoder.transformer.1.pre_norm_ffn.1.bias', 'encoder.transformer.1.pre_norm_ffn.4.weight', 'encoder.transformer.1.pre_norm_ffn.4.bias', 'encoder.transformer.2.pre_norm_mha.0.weight', 'encoder.transformer.2.pre_norm_mha.0.bias', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.2.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.2.pre_norm_ffn.0.weight', 'encoder.transformer.2.pre_norm_ffn.0.bias', 'encoder.transformer.2.pre_norm_ffn.1.weight', 'encoder.transformer.2.pre_norm_ffn.1.bias', 'encoder.transformer.2.pre_norm_ffn.4.weight', 'encoder.transformer.2.pre_norm_ffn.4.bias', 'encoder.transformer.3.pre_norm_mha.0.weight', 'encoder.transformer.3.pre_norm_mha.0.bias', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.3.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.3.pre_norm_ffn.0.weight', 'encoder.transformer.3.pre_norm_ffn.0.bias', 'encoder.transformer.3.pre_norm_ffn.1.weight', 'encoder.transformer.3.pre_norm_ffn.1.bias', 'encoder.transformer.3.pre_norm_ffn.4.weight', 'encoder.transformer.3.pre_norm_ffn.4.bias', 'encoder.transformer.4.pre_norm_mha.0.weight', 'encoder.transformer.4.pre_norm_mha.0.bias', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.4.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.4.pre_norm_ffn.0.weight', 'encoder.transformer.4.pre_norm_ffn.0.bias', 'encoder.transformer.4.pre_norm_ffn.1.weight', 'encoder.transformer.4.pre_norm_ffn.1.bias', 'encoder.transformer.4.pre_norm_ffn.4.weight', 'encoder.transformer.4.pre_norm_ffn.4.bias', 'encoder.transformer.5.pre_norm_mha.0.weight', 'encoder.transformer.5.pre_norm_mha.0.bias', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.5.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.5.pre_norm_ffn.0.weight', 'encoder.transformer.5.pre_norm_ffn.0.bias', 'encoder.transformer.5.pre_norm_ffn.1.weight', 'encoder.transformer.5.pre_norm_ffn.1.bias', 'encoder.transformer.5.pre_norm_ffn.4.weight', 'encoder.transformer.5.pre_norm_ffn.4.bias', 'encoder.transformer.6.pre_norm_mha.0.weight', 'encoder.transformer.6.pre_norm_mha.0.bias', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.6.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.6.pre_norm_ffn.0.weight', 'encoder.transformer.6.pre_norm_ffn.0.bias', 'encoder.transformer.6.pre_norm_ffn.1.weight', 'encoder.transformer.6.pre_norm_ffn.1.bias', 'encoder.transformer.6.pre_norm_ffn.4.weight', 'encoder.transformer.6.pre_norm_ffn.4.bias', 'encoder.transformer.7.pre_norm_mha.0.weight', 'encoder.transformer.7.pre_norm_mha.0.bias', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.7.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.7.pre_norm_ffn.0.weight', 'encoder.transformer.7.pre_norm_ffn.0.bias', 'encoder.transformer.7.pre_norm_ffn.1.weight', 'encoder.transformer.7.pre_norm_ffn.1.bias', 'encoder.transformer.7.pre_norm_ffn.4.weight', 'encoder.transformer.7.pre_norm_ffn.4.bias', 'encoder.transformer.8.pre_norm_mha.0.weight', 'encoder.transformer.8.pre_norm_mha.0.bias', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.8.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.8.pre_norm_ffn.0.weight', 'encoder.transformer.8.pre_norm_ffn.0.bias', 'encoder.transformer.8.pre_norm_ffn.1.weight', 'encoder.transformer.8.pre_norm_ffn.1.bias', 'encoder.transformer.8.pre_norm_ffn.4.weight', 'encoder.transformer.8.pre_norm_ffn.4.bias', 'encoder.transformer.9.pre_norm_mha.0.weight', 'encoder.transformer.9.pre_norm_mha.0.bias', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.9.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.9.pre_norm_ffn.0.weight', 'encoder.transformer.9.pre_norm_ffn.0.bias', 'encoder.transformer.9.pre_norm_ffn.1.weight', 'encoder.transformer.9.pre_norm_ffn.1.bias', 'encoder.transformer.9.pre_norm_ffn.4.weight', 'encoder.transformer.9.pre_norm_ffn.4.bias', 'encoder.transformer.10.pre_norm_mha.0.weight', 'encoder.transformer.10.pre_norm_mha.0.bias', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.10.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.10.pre_norm_ffn.0.weight', 'encoder.transformer.10.pre_norm_ffn.0.bias', 'encoder.transformer.10.pre_norm_ffn.1.weight', 'encoder.transformer.10.pre_norm_ffn.1.bias', 'encoder.transformer.10.pre_norm_ffn.4.weight', 'encoder.transformer.10.pre_norm_ffn.4.bias', 'encoder.transformer.11.pre_norm_mha.0.weight', 'encoder.transformer.11.pre_norm_mha.0.bias', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.weight', 'encoder.transformer.11.pre_norm_mha.1.qkv_proj.bias', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'encoder.transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'encoder.transformer.11.pre_norm_ffn.0.weight', 'encoder.transformer.11.pre_norm_ffn.0.bias', 'encoder.transformer.11.pre_norm_ffn.1.weight', 'encoder.transformer.11.pre_norm_ffn.1.bias', 'encoder.transformer.11.pre_norm_ffn.4.weight', 'encoder.transformer.11.pre_norm_ffn.4.bias', 'encoder.pos_embed.pos_embed.pos_embed', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-26 04:02:58 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): VisionTransformer(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_emb): Sequential(
      (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
      (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
      (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
    )
    (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
    (transformer): Sequential(
      (0): FlashTransformerEncoder
      (1): FlashTransformerEncoder
      (2): FlashTransformerEncoder
      (3): FlashTransformerEncoder
      (4): FlashTransformerEncoder
      (5): FlashTransformerEncoder
      (6): FlashTransformerEncoder
      (7): FlashTransformerEncoder
      (8): FlashTransformerEncoder
      (9): FlashTransformerEncoder
      (10): FlashTransformerEncoder
      (11): FlashTransformerEncoder
    )
    (classifier): None
    (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
    (emb_dropout): Dropout(p=0.0, inplace=False)
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=8.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=512, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(512, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   98.728 M
Total trainable parameters =   98.728 M

2024-07-26 04:02:58 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-26 04:02:58 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops    |
|:------------------------------------------|:-----------------------|:----------|
| model                                     | 98.728M                | 77.442G   |
|  encoder                                  |  85.955M               |  67.713G  |
|   encoder.neural_augmentor                |   6                    |           |
|    encoder.neural_augmentor.brightness    |    2                   |           |
|    encoder.neural_augmentor.contrast      |    2                   |           |
|    encoder.neural_augmentor.noise         |    2                   |           |
|   encoder.patch_emb                       |   0.748M               |   1.046G  |
|    encoder.patch_emb.0.block              |    9.6K                |    0.12G  |
|    encoder.patch_emb.1.block              |    0.148M              |    0.464G |
|    encoder.patch_emb.2.block.conv         |    0.591M              |    0.462G |
|   encoder.post_transformer_norm           |   1.536K               |   3.011M  |
|    encoder.post_transformer_norm.weight   |    (768,)              |           |
|    encoder.post_transformer_norm.bias     |    (768,)              |           |
|   encoder.transformer                     |   85.054M              |   66.661G |
|    encoder.transformer.0                  |    7.088M              |    5.555G |
|    encoder.transformer.1                  |    7.088M              |    5.555G |
|    encoder.transformer.2                  |    7.088M              |    5.555G |
|    encoder.transformer.3                  |    7.088M              |    5.555G |
|    encoder.transformer.4                  |    7.088M              |    5.555G |
|    encoder.transformer.5                  |    7.088M              |    5.555G |
|    encoder.transformer.6                  |    7.088M              |    5.555G |
|    encoder.transformer.7                  |    7.088M              |    5.555G |
|    encoder.transformer.8                  |    7.088M              |    5.555G |
|    encoder.transformer.9                  |    7.088M              |    5.555G |
|    encoder.transformer.10                 |    7.088M              |    5.555G |
|    encoder.transformer.11                 |    7.088M              |    5.555G |
|   encoder.pos_embed.pos_embed             |   0.151M               |   2.408M  |
|    encoder.pos_embed.pos_embed.pos_embed  |    (1, 1, 196, 768)    |           |
|  seg_head                                 |  12.773M               |  9.729G   |
|   seg_head.aspp.aspp_layer                |   12.72M               |   9.666G  |
|    seg_head.aspp.aspp_layer.convs         |    11.408M             |    8.638G |
|    seg_head.aspp.aspp_layer.project.block |    1.312M              |    1.028G |
|   seg_head.classifier.block.conv          |   53.352K              |   41.746M |
|    seg_head.classifier.block.conv.weight  |    (104, 512, 1, 1)    |           |
|    seg_head.classifier.block.conv.bias    |    (104,)              |           |
|   seg_head.upsample_seg_out               |                        |   20.873M |
2024-07-26 04:02:59 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-26 04:02:59 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.transformer.2.drop_path', 'encoder.transformer.3.drop_path', 'encoder.transformer.4.drop_path', 'encoder.neural_augmentor.contrast', 'encoder.transformer.6.drop_path', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.transformer.11.drop_path', 'encoder.neural_augmentor.brightness', 'encoder.neural_augmentor', 'encoder.transformer.7.drop_path', 'encoder.transformer.1.drop_path', 'encoder.neural_augmentor.noise.min_fn', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.transformer.10.drop_path', 'encoder.transformer.0.drop_path', 'encoder.transformer.5.drop_path', 'encoder.transformer.8.drop_path', 'encoder.transformer.9.drop_path', 'encoder.neural_augmentor.noise.max_fn', 'encoder.neural_augmentor.noise', 'encoder.neural_augmentor.contrast.max_fn'}
2024-07-26 04:02:59 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 20, 'aten::scaled_dot_product_attention': 12, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - Max. epochs for training: 50
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=50
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-26 04:02:59 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/seg_vit_base/train/training_checkpoint_last.pt'
2024-07-26 04:02:59 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/seg_vit_base/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-26 04:03:01 - [32m[1mINFO   [0m - Training epoch 0
2024-07-26 04:02:52 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40010
2024-07-26 04:02:52 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40010
2024-07-26 04:02:52 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40010
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4c841d77f0>
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff792bd77f0>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0ce87db7f0>
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    self._shutdown_workers()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1462, in _shutdown_workers
    if w.is_alive():
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/process.py", line 165, in is_alive
    returncode = self._popen.poll()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    if w.is_alive():
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/process.py", line 165, in is_alive
    if w.is_alive():
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/process.py", line 165, in is_alive
    returncode = self._popen.poll()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    returncode = self._popen.poll()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
KeyboardInterrupt: 
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt: 
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fed6e3cb7f0>
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1438, in _shutdown_workers
    self._mark_worker_as_unavailable(worker_id, shutdown=True)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1380, in _mark_worker_as_unavailable
    assert self._workers_status[worker_id] or (self._persistent_workers and shutdown)
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
2024-07-26 04:03:45 - [34m[1mLOGS   [0m - Keyboard interruption. Exiting from early training
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/spawn.py", line 126, in _main
    self = reduction.pickle.load(from_parent)
_pickle.UnpicklingError: pickle data was truncated
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 8 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
