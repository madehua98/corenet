nohup: ignoring input
2024-08-04 06:34:15 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
../projects/catlip/image_classification/food200/foodv_small.yaml
{'taskname': '+ ViT-B/16 [FT-IN1k]', 'common': {'run_label': 'train', 'log_freq': 500, 'auto_resume': True, 'mixed_precision': True, 'mixed_precision_dtype': 'bfloat16', 'grad_clip': 1.0, 'save_all_checkpoints': True}, 'dataset': {'root_train': '/ML-A100/team/mm/models/food200/train_images', 'root_val': '/ML-A100/team/mm/models/food200/test_images', 'train_batch_size0': 128, 'val_batch_size0': 100, 'eval_batch_size0': 100, 'workers': 64, 'persistent_workers': True, 'pin_memory': True, 'name': 'imagenet', 'category': 'classification'}, 'image_augmentation': {'random_resized_crop': {'enable': True, 'interpolation': 'bilinear'}, 'random_horizontal_flip': {'enable': True}, 'resize': {'enable': True, 'size': 232, 'interpolation': 'bilinear'}, 'center_crop': {'enable': True, 'size': 224}}, 'sampler': {'name': 'variable_batch_sampler', 'vbs': {'crop_size_width': 224, 'crop_size_height': 224, 'max_n_scales': 25, 'min_crop_size_width': 128, 'max_crop_size_width': 320, 'min_crop_size_height': 128, 'max_crop_size_height': 320, 'check_scale': 32}}, 'loss': {'category': 'composite_loss', 'composite_loss': [{'loss_category': 'classification', 'loss_weight': 1.0, 'classification': {'name': 'cross_entropy', 'cross_entropy': {'label_smoothing': 0.1}}}, {'loss_category': 'neural_augmentation', 'loss_weight': 1.0, 'neural_augmentation': {'perceptual_metric': 'psnr', 'target_value': [40, 20], 'curriculum_method': 'cosine'}}]}, 'optim': {'name': 'adamw', 'weight_decay': 0.05, 'no_decay_bn_filter_bias': True, 'adamw': {'beta1': 0.9, 'beta2': 0.999}}, 'scheduler': {'name': 'cosine', 'max_epochs': 30, 'warmup_iterations': 500, 'warmup_init_lr': 1e-06, 'cosine': {'max_lr': 5e-05, 'min_lr': 5e-06}}, 'model': {'activation_checkpointing': True, 'resume_exclude_scopes': ['classifier'], 'ft': True, 'classification': {'name': 'foodv', 'n_classes': 200, 'pretrained': '/ML-A100/team/mm/models/catlip_data/results_small_dci/train/checkpoint_epoch_9_iter_79046.pt', 'foodv': {'mode': 'small', 'norm_layer': 'layer_norm_fp32', 'use_flash_attention': True, 'connector_type': 'dci'}}, 'learn_augmentation': {'brightness': True, 'contrast': True, 'noise': True, 'mode': 'distribution'}, 'activation': {'name': 'gelu'}, 'layer': {'conv_init': 'kaiming_normal', 'linear_init': 'trunc_normal', 'linear_init_std_dev': 0.02}}, 'ema': {'enable': False, 'momentum': 0.0005}, 'stats': {'train': ['loss'], 'val': ['loss', 'top1', 'top5'], 'checkpoint_metric': 'top1.logits', 'checkpoint_metric_max': True}}
small
dci
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_small_dci/train/checkpoint_epoch_9_iter_79046.pt
2024-08-04 06:34:16 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=200, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =   25.758 M
Total trainable parameters =   25.758 M

2024-08-04 06:34:16 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.758M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  0.103M                |  0.102M    |
|   classifier.weight                  |   (200, 512)           |            |
|   classifier.bias                    |   (200,)               |            |
2024-08-04 06:34:16 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-04 06:34:16 - [33m[1mWARNING[0m - Uncalled Modules:
{'patch_drop', 'blocks.3.drop_path1', 'blocks.5.attn.k_norm', 'blocks.5.attn.q_norm', 'blocks.0.ls2', 'patch_embed.backbone.stages.0.0.down', 'blocks1.2.ls2', 'blocks1.4.attn.q_norm', 'blocks.0.drop_path1', 'blocks.1.ls1', 'blocks.5.drop_path2', 'blocks1.0.attn.q_norm', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks1.3.attn.k_norm', 'blocks.0.attn.q_norm', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.6.ls1', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.2.ls2', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.0.drop_path1', 'blocks.6.ls2', 'blocks1.4.attn.k_norm', 'blocks1.3.attn.q_norm', 'blocks1.4.drop_path1', 'blocks1.6.attn.k_norm', 'blocks1.4.ls2', 'blocks1.0.attn.attn_drop', 'blocks.0.attn.k_norm', 'blocks1.0.ls2', 'blocks.2.ls1', 'patch_embed.backbone.stages.1.2.down', 'blocks.5.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks1.3.drop_path2', 'blocks1.1.attn.attn_drop', 'blocks.3.attn.q_norm', 'neural_augmentor.brightness', 'blocks1.5.attn.k_norm', 'patch_embed.backbone.stages.0.1.down', 'blocks.1.ls2', 'blocks.5.drop_path1', 'patch_embed.backbone.stem.norm1.drop', 'blocks1.6.drop_path1', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.4.attn.attn_drop', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'patch_embed.proj', 'blocks1.5.attn.attn_drop', 'blocks1.0.ls1', 'blocks.4.attn.attn_drop', 'blocks.3.drop_path2', 'blocks1.1.ls2', 'blocks1.5.ls2', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.2.attn.k_norm', 'neural_augmentor.noise.max_fn', 'blocks1.3.drop_path1', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.5.drop_path1', 'blocks1.3.attn.attn_drop', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.1.attn.k_norm', 'blocks.5.attn.attn_drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.2.attn.attn_drop', 'blocks.4.ls2', 'neural_augmentor.contrast', 'blocks1.6.ls2', 'patch_embed.backbone.stages.0.0.drop_path', 'neural_augmentor.brightness.min_fn', 'blocks1.3.ls2', 'blocks.1.attn.q_norm', 'blocks.3.attn.k_norm', 'blocks1.4.ls1', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks.1.drop_path2', 'blocks1.1.drop_path2', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'neural_augmentor.brightness.max_fn', 'blocks1.2.drop_path1', 'blocks.1.drop_path1', 'blocks.3.attn.attn_drop', 'norm_pre', 'blocks.4.drop_path1', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks.4.attn.k_norm', 'blocks1.2.ls1', 'blocks1.2.attn.k_norm', 'neural_augmentor', 'blocks1.2.attn.q_norm', 'blocks.4.ls1', 'neural_augmentor.noise.min_fn', 'blocks.6.attn.attn_drop', 'blocks.0.drop_path2', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.4.attn.q_norm', 'blocks1.3.ls1', 'blocks.1.attn.attn_drop', 'patch_embed.backbone.stages.1.3.down', 'blocks.0.attn.attn_drop', 'blocks.0.ls1', 'blocks1.2.drop_path2', 'neural_augmentor.noise', 'blocks1.1.drop_path1', 'blocks.2.drop_path1', 'blocks1.6.attn.q_norm', 'norm', 'blocks.2.attn.attn_drop', 'blocks1.6.drop_path2', 'blocks.5.ls2', 'blocks1.0.attn.k_norm', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.2.attn.q_norm', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.6.ls1', 'blocks1.1.ls1', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.1.0.down', 'blocks1.5.ls1', 'blocks.6.drop_path1', 'blocks.2.drop_path2', 'blocks.3.ls2', 'neural_augmentor.contrast.max_fn', 'patch_embed.backbone.stages.1.1.down', 'blocks1.0.drop_path2', 'blocks1.5.drop_path2', 'blocks.4.drop_path2', 'neural_augmentor.contrast.min_fn', 'blocks.6.attn.k_norm', 'blocks.6.drop_path2', 'blocks1.1.attn.q_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.3.ls1', 'blocks1.6.attn.attn_drop'}
2024-08-04 06:34:16 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::add_': 14, 'aten::avg_pool2d': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-08-04 06:34:16 - [34m[1mLOGS   [0m - Directory created at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train
2024-08-04 06:34:20 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:30003
small
dci
2024-08-04 06:34:20 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:30003
small
dci
2024-08-04 06:34:20 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:30003
small
dci
2024-08-04 06:34:20 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:30003
2024-08-04 06:34:23 - [34m[1mLOGS   [0m - Number of categories: 200
2024-08-04 06:34:23 - [34m[1mLOGS   [0m - Total number of samples: 118210
2024-08-04 06:34:23 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-08-04 06:34:23 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food200/train_images 
	is_training=True 
	num_samples=118210
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=200
)
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Number of categories: 200
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Total number of samples: 59287
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food200/test_images 
	is_training=False 
	num_samples=59287
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=200
)
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=128
	 scales=[(128, 128, 392), (160, 160, 250), (192, 192, 174), (224, 224, 128), (256, 256, 98), (288, 288, 77), (320, 320, 62)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-08-04 06:34:24 - [34m[1mLOGS   [0m - Number of data workers: 64
small
dci
2024-08-04 06:34:27 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_small_dci/train/checkpoint_epoch_9_iter_79046.pt
2024-08-04 06:34:27 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-04 06:34:27 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=256, out_features=512, bias=True)
        (w1): Linear(in_features=256, out_features=512, bias=True)
        (w2): Linear(in_features=512, out_features=256, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=200, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =   25.758 M
Total trainable parameters =   25.758 M

2024-08-04 06:34:27 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-04 06:34:27 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 25.758M                | 3.385G     |
|  pos_embed                           |  (1, 1, 256)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  0.93M                 |  1.411G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.488G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    21.676M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    4.014M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.462G  |
|   patch_embed.backbone.stages        |   0.595M               |   0.865G   |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.379G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.486G  |
|   patch_embed.backbone.pool          |   0.295M               |   58.305M  |
|    patch_embed.backbone.pool.proj    |    0.295M              |    57.803M |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.502M  |
|  blocks                              |  4.614M                |  0.904G    |
|   blocks.0                           |   0.659M               |   0.129G   |
|    blocks.0.norm1                    |    0.512K              |    0.251M  |
|    blocks.0.attn                     |    0.263M              |    51.38M  |
|    blocks.0.norm2                    |    0.512K              |    0.251M  |
|    blocks.0.mlp                      |    0.395M              |    77.321M |
|   blocks.1                           |   0.659M               |   0.129G   |
|    blocks.1.norm1                    |    0.512K              |    0.251M  |
|    blocks.1.attn                     |    0.263M              |    51.38M  |
|    blocks.1.norm2                    |    0.512K              |    0.251M  |
|    blocks.1.mlp                      |    0.395M              |    77.321M |
|   blocks.2                           |   0.659M               |   0.129G   |
|    blocks.2.norm1                    |    0.512K              |    0.251M  |
|    blocks.2.attn                     |    0.263M              |    51.38M  |
|    blocks.2.norm2                    |    0.512K              |    0.251M  |
|    blocks.2.mlp                      |    0.395M              |    77.321M |
|   blocks.3                           |   0.659M               |   0.129G   |
|    blocks.3.norm1                    |    0.512K              |    0.251M  |
|    blocks.3.attn                     |    0.263M              |    51.38M  |
|    blocks.3.norm2                    |    0.512K              |    0.251M  |
|    blocks.3.mlp                      |    0.395M              |    77.321M |
|   blocks.4                           |   0.659M               |   0.129G   |
|    blocks.4.norm1                    |    0.512K              |    0.251M  |
|    blocks.4.attn                     |    0.263M              |    51.38M  |
|    blocks.4.norm2                    |    0.512K              |    0.251M  |
|    blocks.4.mlp                      |    0.395M              |    77.321M |
|   blocks.5                           |   0.659M               |   0.129G   |
|    blocks.5.norm1                    |    0.512K              |    0.251M  |
|    blocks.5.attn                     |    0.263M              |    51.38M  |
|    blocks.5.norm2                    |    0.512K              |    0.251M  |
|    blocks.5.mlp                      |    0.395M              |    77.321M |
|   blocks.6                           |   0.659M               |   0.129G   |
|    blocks.6.norm1                    |    0.512K              |    0.251M  |
|    blocks.6.attn                     |    0.263M              |    51.38M  |
|    blocks.6.norm2                    |    0.512K              |    0.251M  |
|    blocks.6.mlp                      |    0.395M              |    77.321M |
|  pool                                |  1.181M                |  0.116G    |
|   pool.proj                          |   1.18M                |   0.116G   |
|    pool.proj.weight                  |    (512, 256, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.512K               |   0.502M   |
|    pool.norm.weight                  |    (256,)              |            |
|    pool.norm.bias                    |    (256,)              |            |
|  blocks1                             |  18.404M               |  0.902G    |
|   blocks1.0                          |   2.629M               |   0.129G   |
|    blocks1.0.norm1                   |    1.024K              |    0.125M  |
|    blocks1.0.attn                    |    1.051M              |    51.38M  |
|    blocks1.0.norm2                   |    1.024K              |    0.125M  |
|    blocks1.0.mlp                     |    1.576M              |    77.196M |
|   blocks1.1                          |   2.629M               |   0.129G   |
|    blocks1.1.norm1                   |    1.024K              |    0.125M  |
|    blocks1.1.attn                    |    1.051M              |    51.38M  |
|    blocks1.1.norm2                   |    1.024K              |    0.125M  |
|    blocks1.1.mlp                     |    1.576M              |    77.196M |
|   blocks1.2                          |   2.629M               |   0.129G   |
|    blocks1.2.norm1                   |    1.024K              |    0.125M  |
|    blocks1.2.attn                    |    1.051M              |    51.38M  |
|    blocks1.2.norm2                   |    1.024K              |    0.125M  |
|    blocks1.2.mlp                     |    1.576M              |    77.196M |
|   blocks1.3                          |   2.629M               |   0.129G   |
|    blocks1.3.norm1                   |    1.024K              |    0.125M  |
|    blocks1.3.attn                    |    1.051M              |    51.38M  |
|    blocks1.3.norm2                   |    1.024K              |    0.125M  |
|    blocks1.3.mlp                     |    1.576M              |    77.196M |
|   blocks1.4                          |   2.629M               |   0.129G   |
|    blocks1.4.norm1                   |    1.024K              |    0.125M  |
|    blocks1.4.attn                    |    1.051M              |    51.38M  |
|    blocks1.4.norm2                   |    1.024K              |    0.125M  |
|    blocks1.4.mlp                     |    1.576M              |    77.196M |
|   blocks1.5                          |   2.629M               |   0.129G   |
|    blocks1.5.norm1                   |    1.024K              |    0.125M  |
|    blocks1.5.attn                    |    1.051M              |    51.38M  |
|    blocks1.5.norm2                   |    1.024K              |    0.125M  |
|    blocks1.5.mlp                     |    1.576M              |    77.196M |
|   blocks1.6                          |   2.629M               |   0.129G   |
|    blocks1.6.norm1                   |    1.024K              |    0.125M  |
|    blocks1.6.attn                    |    1.051M              |    51.38M  |
|    blocks1.6.norm2                   |    1.024K              |    0.125M  |
|    blocks1.6.mlp                     |    1.576M              |    77.196M |
|  mlp                                 |  0.525M                |  51.38M    |
|   mlp.0                              |   0.263M               |   25.69M   |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   25.69M   |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  0.103M                |  0.102M    |
|   classifier.weight                  |   (200, 512)           |            |
|   classifier.bias                    |   (200,)               |            |
2024-08-04 06:34:28 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-04 06:34:28 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.3.drop_path2', 'neural_augmentor.noise.max_fn', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks1.2.attn.attn_drop', 'blocks1.2.attn.q_norm', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.0.down', 'blocks1.4.attn.q_norm', 'blocks.2.ls1', 'norm_pre', 'neural_augmentor', 'blocks1.4.drop_path1', 'norm', 'blocks.2.ls2', 'neural_augmentor.contrast.max_fn', 'blocks.0.ls1', 'blocks1.2.ls2', 'blocks.6.attn.q_norm', 'blocks1.3.drop_path2', 'blocks.3.attn.k_norm', 'neural_augmentor.contrast.min_fn', 'blocks1.4.attn.attn_drop', 'patch_embed.backbone.stages.1.1.down', 'blocks.1.attn.q_norm', 'blocks1.6.ls2', 'blocks.2.attn.k_norm', 'blocks1.1.ls2', 'blocks1.5.attn.k_norm', 'blocks1.6.drop_path2', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.0.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks.0.drop_path2', 'neural_augmentor.contrast', 'blocks1.3.attn.attn_drop', 'blocks1.0.ls2', 'blocks1.3.ls2', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks.1.drop_path2', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.4.attn.k_norm', 'patch_embed.backbone.stem.norm1.drop', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks.2.drop_path1', 'blocks1.6.attn.q_norm', 'patch_embed.backbone.stages.1.3.drop_path', 'neural_augmentor.brightness.min_fn', 'patch_embed.backbone.stages.0.1.down', 'blocks.6.attn.attn_drop', 'blocks.4.drop_path2', 'blocks1.6.attn.attn_drop', 'blocks1.6.ls1', 'blocks.3.attn.q_norm', 'patch_embed.backbone.stages.1.2.drop_path', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.6.ls2', 'patch_embed.backbone.stages.1.2.down', 'blocks1.3.ls1', 'blocks1.0.attn.q_norm', 'blocks1.5.drop_path2', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks.0.attn.k_norm', 'patch_embed.backbone.stages.1.0.drop_path', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.5.ls1', 'blocks1.5.attn.attn_drop', 'blocks1.6.attn.k_norm', 'blocks1.0.ls1', 'blocks1.1.attn.k_norm', 'neural_augmentor.noise', 'blocks.0.ls2', 'blocks.5.drop_path1', 'blocks1.2.drop_path1', 'blocks.2.drop_path2', 'blocks.0.drop_path1', 'patch_drop', 'blocks.1.ls2', 'blocks.1.ls1', 'blocks1.1.ls1', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.1.drop_path1', 'blocks.6.drop_path1', 'blocks.5.attn.q_norm', 'blocks.4.attn.q_norm', 'blocks1.4.ls2', 'blocks.1.drop_path1', 'blocks1.2.attn.k_norm', 'patch_embed.backbone.stages.0.0.drop_path', 'patch_embed.backbone.stages.1.3.down', 'blocks.5.attn.attn_drop', 'blocks1.2.drop_path2', 'blocks.6.ls1', 'blocks1.0.drop_path1', 'blocks.4.ls1', 'blocks.2.attn.q_norm', 'blocks1.3.attn.k_norm', 'blocks.6.attn.k_norm', 'blocks1.4.ls1', 'blocks.5.ls2', 'blocks.3.ls1', 'blocks1.1.drop_path2', 'blocks.4.drop_path1', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.1.attn.k_norm', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.6.drop_path2', 'blocks1.3.attn.q_norm', 'blocks.4.ls2', 'blocks1.0.drop_path2', 'patch_embed.proj', 'blocks.0.attn.q_norm', 'blocks.5.drop_path2', 'blocks1.5.drop_path1', 'blocks.4.attn.attn_drop', 'blocks1.5.ls2', 'blocks.3.ls2', 'blocks1.3.drop_path1', 'blocks1.1.attn.attn_drop', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks1.2.ls1', 'neural_augmentor.brightness.max_fn', 'blocks.0.attn.attn_drop', 'blocks1.6.drop_path1', 'blocks.5.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.3.attn.attn_drop', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.1.2.shortcut', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.1.attn.attn_drop', 'blocks1.0.attn.attn_drop', 'neural_augmentor.brightness', 'blocks1.5.attn.q_norm', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.0.0.down', 'blocks1.1.attn.q_norm', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.5.ls1'}
2024-08-04 06:34:28 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::add_': 14, 'aten::avg_pool2d': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - Max. epochs for training: 30
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=5e-06
 	 max_lr=5e-05
 	 period=30
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-08-04 06:34:28 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt'
2024-08-04 06:34:28 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-04 06:34:30 - [32m[1mINFO   [0m - Training epoch 0
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-08-04 06:37:22 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'classification': 8.6979, 'neural_augmentation': 0.3401, 'total_loss': 9.038}, LR: [1e-06, 1e-06], Avg. batch load time: 168.975, Elapsed time: 172.04
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:38:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 6.0256, 'neural_augmentation': 0.3614, 'total_loss': 6.387}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:41:00 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 4.25, 'neural_augmentation': 0.0, 'total_loss': 4.25} || top1={'logits': 14.2198} || top5={'logits': 33.3842}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:41:00 - [34m[1mLOGS   [0m - Best checkpoint with score 14.22 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:41:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:41:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:41:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 185 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_0_iter_185.pt
2024-08-04 06:41:02 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 185 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_0_iter_185.pt
[31m===========================================================================[0m
2024-08-04 06:41:04 - [32m[1mINFO   [0m - Training epoch 1
2024-08-04 06:41:15 - [34m[1mLOGS   [0m - Epoch:   1 [     186/10000000], loss: {'classification': 4.5706, 'neural_augmentation': 0.3569, 'total_loss': 4.9276}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 11.768, Elapsed time: 11.93
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:41:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 3.5922, 'neural_augmentation': 0.3609, 'total_loss': 3.9531}
2024-08-04 06:41:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 1.971, 'neural_augmentation': 0.0, 'total_loss': 1.971} || top1={'logits': 50.4195} || top5={'logits': 80.4245}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:41:58 - [34m[1mLOGS   [0m - Best checkpoint with score 50.42 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:41:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:41:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:41:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 351 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_1_iter_351.pt
2024-08-04 06:41:59 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 351 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_1_iter_351.pt
[31m===========================================================================[0m
2024-08-04 06:42:01 - [32m[1mINFO   [0m - Training epoch 2
2024-08-04 06:42:09 - [34m[1mLOGS   [0m - Epoch:   2 [     352/10000000], loss: {'classification': 2.8005, 'neural_augmentation': 0.3635, 'total_loss': 3.164}, LR: [3.5e-05, 3.5e-05], Avg. batch load time: 7.338, Elapsed time:  7.51
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:42:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 2.5841, 'neural_augmentation': 0.3566, 'total_loss': 2.9407}
2024-08-04 06:42:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 1.4404, 'neural_augmentation': 0.0, 'total_loss': 1.4404} || top1={'logits': 62.9178} || top5={'logits': 88.9312}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:43:00 - [34m[1mLOGS   [0m - Best checkpoint with score 62.92 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:43:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:43:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:43:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 519 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_2_iter_519.pt
2024-08-04 06:43:01 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 519 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_2_iter_519.pt
[31m===========================================================================[0m
2024-08-04 06:43:03 - [32m[1mINFO   [0m - Training epoch 3
2024-08-04 06:43:20 - [34m[1mLOGS   [0m - Epoch:   3 [     520/10000000], loss: {'classification': 2.3973, 'neural_augmentation': 0.3721, 'total_loss': 2.7694}, LR: [4.9e-05, 4.9e-05], Avg. batch load time: 16.948, Elapsed time: 17.26
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:43:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 2.2316, 'neural_augmentation': 0.3495, 'total_loss': 2.5811}
2024-08-04 06:44:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 1.2284, 'neural_augmentation': 0.0, 'total_loss': 1.2284} || top1={'logits': 67.1376} || top5={'logits': 91.4832}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:44:10 - [34m[1mLOGS   [0m - Best checkpoint with score 67.14 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:44:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:44:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:44:11 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 694 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_3_iter_694.pt
2024-08-04 06:44:11 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 694 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_3_iter_694.pt
[31m===========================================================================[0m
2024-08-04 06:44:13 - [32m[1mINFO   [0m - Training epoch 4
2024-08-04 06:44:32 - [34m[1mLOGS   [0m - Epoch:   4 [     695/10000000], loss: {'classification': 2.1703, 'neural_augmentation': 0.3406, 'total_loss': 2.5109}, LR: [4.8e-05, 4.8e-05], Avg. batch load time: 18.378, Elapsed time: 18.54
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
2024-08-04 06:45:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 2.0459, 'neural_augmentation': 0.3428, 'total_loss': 2.3888}
2024-08-04 06:45:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 1.1366, 'neural_augmentation': 0.0, 'total_loss': 1.1366} || top1={'logits': 69.5755} || top5={'logits': 92.8708}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:45:25 - [34m[1mLOGS   [0m - Best checkpoint with score 69.58 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:45:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:45:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:45:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 882 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_4_iter_882.pt
2024-08-04 06:45:26 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 882 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_4_iter_882.pt
[31m===========================================================================[0m
2024-08-04 06:45:28 - [32m[1mINFO   [0m - Training epoch 5
2024-08-04 06:45:43 - [34m[1mLOGS   [0m - Epoch:   5 [     883/10000000], loss: {'classification': 1.8466, 'neural_augmentation': 0.3287, 'total_loss': 2.1753}, LR: [4.7e-05, 4.7e-05], Avg. batch load time: 14.689, Elapsed time: 14.92
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:46:13 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 1.9298, 'neural_augmentation': 0.3338, 'total_loss': 2.2636}
2024-08-04 06:46:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 1.0974, 'neural_augmentation': 0.0, 'total_loss': 1.0974} || top1={'logits': 70.7383} || top5={'logits': 93.2299}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
2024-08-04 06:46:36 - [34m[1mLOGS   [0m - Best checkpoint with score 70.74 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:46:37 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_14.2198.pt
2024-08-04 06:46:37 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_50.4195.pt', 'checkpoint_score_62.9178.pt', 'checkpoint_score_67.1376.pt', 'checkpoint_score_69.5755.pt', 'checkpoint_score_70.7383.pt']
2024-08-04 06:46:48 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:46:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:46:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:46:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 1075 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_5_iter_1075.pt
2024-08-04 06:46:50 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 1075 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_5_iter_1075.pt
[31m===========================================================================[0m
2024-08-04 06:46:52 - [32m[1mINFO   [0m - Training epoch 6
2024-08-04 06:46:55 - [34m[1mLOGS   [0m - Epoch:   6 [    1076/10000000], loss: {'classification': 1.7761, 'neural_augmentation': 0.318, 'total_loss': 2.0941}, LR: [4.6e-05, 4.6e-05], Avg. batch load time: 2.589, Elapsed time:  2.75
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:47:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 1.8559, 'neural_augmentation': 0.3247, 'total_loss': 2.1806}
2024-08-04 06:47:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 1.0552, 'neural_augmentation': 0.0, 'total_loss': 1.0552} || top1={'logits': 71.6225} || top5={'logits': 93.703}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
2024-08-04 06:47:53 - [34m[1mLOGS   [0m - Best checkpoint with score 71.62 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:47:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_50.4195.pt
2024-08-04 06:47:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_62.9178.pt', 'checkpoint_score_67.1376.pt', 'checkpoint_score_69.5755.pt', 'checkpoint_score_70.7383.pt', 'checkpoint_score_71.6225.pt']
2024-08-04 06:48:03 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:48:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:48:05 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:48:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 1257 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_6_iter_1257.pt
2024-08-04 06:48:06 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 1257 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_6_iter_1257.pt
[31m===========================================================================[0m
2024-08-04 06:48:08 - [32m[1mINFO   [0m - Training epoch 7
2024-08-04 06:48:11 - [34m[1mLOGS   [0m - Epoch:   7 [    1258/10000000], loss: {'classification': 1.7853, 'neural_augmentation': 0.321, 'total_loss': 2.1063}, LR: [4.4e-05, 4.4e-05], Avg. batch load time: 3.160, Elapsed time:  3.39
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:48:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 1.7949, 'neural_augmentation': 0.3192, 'total_loss': 2.1141}
2024-08-04 06:49:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 1.0218, 'neural_augmentation': 0.0, 'total_loss': 1.0218} || top1={'logits': 72.7248} || top5={'logits': 94.1074}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:49:06 - [34m[1mLOGS   [0m - Best checkpoint with score 72.72 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:49:07 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_62.9178.pt
2024-08-04 06:49:07 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_67.1376.pt', 'checkpoint_score_69.5755.pt', 'checkpoint_score_70.7383.pt', 'checkpoint_score_71.6225.pt', 'checkpoint_score_72.7248.pt']
2024-08-04 06:49:22 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:49:23 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:49:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:49:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 1425 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_7_iter_1425.pt
2024-08-04 06:49:24 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 1425 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_7_iter_1425.pt
[31m===========================================================================[0m
2024-08-04 06:49:26 - [32m[1mINFO   [0m - Training epoch 8
2024-08-04 06:49:29 - [34m[1mLOGS   [0m - Epoch:   8 [    1426/10000000], loss: {'classification': 1.6346, 'neural_augmentation': 0.3181, 'total_loss': 1.9527}, LR: [4.3e-05, 4.3e-05], Avg. batch load time: 2.323, Elapsed time:  2.64
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:49:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 1.7589, 'neural_augmentation': 0.3125, 'total_loss': 2.0714}
2024-08-04 06:50:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 1.0127, 'neural_augmentation': 0.0, 'total_loss': 1.0127} || top1={'logits': 72.9094} || top5={'logits': 94.2383}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:50:21 - [34m[1mLOGS   [0m - Best checkpoint with score 72.91 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:50:22 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_67.1376.pt
2024-08-04 06:50:22 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_69.5755.pt', 'checkpoint_score_70.7383.pt', 'checkpoint_score_71.6225.pt', 'checkpoint_score_72.7248.pt', 'checkpoint_score_72.9094.pt']
2024-08-04 06:50:33 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:50:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:50:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:50:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 1580 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_8_iter_1580.pt
2024-08-04 06:50:35 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 1580 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_8_iter_1580.pt
[31m===========================================================================[0m
2024-08-04 06:50:37 - [32m[1mINFO   [0m - Training epoch 9
2024-08-04 06:50:39 - [34m[1mLOGS   [0m - Epoch:   9 [    1581/10000000], loss: {'classification': 1.6523, 'neural_augmentation': 0.3399, 'total_loss': 1.9922}, LR: [4.1e-05, 4.1e-05], Avg. batch load time: 1.541, Elapsed time:  1.70
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:51:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 1.7094, 'neural_augmentation': 0.3101, 'total_loss': 2.0195}
2024-08-04 06:51:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 1.0077, 'neural_augmentation': 0.0, 'total_loss': 1.0077} || top1={'logits': 72.8691} || top5={'logits': 94.2047}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:51:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:51:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:51:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 1749 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_9_iter_1749.pt
2024-08-04 06:51:36 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 1749 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_9_iter_1749.pt
[31m===========================================================================[0m
2024-08-04 06:51:38 - [32m[1mINFO   [0m - Training epoch 10
2024-08-04 06:51:46 - [34m[1mLOGS   [0m - Epoch:  10 [    1750/10000000], loss: {'classification': 1.6811, 'neural_augmentation': 0.3244, 'total_loss': 2.0054}, LR: [3.9e-05, 3.9e-05], Avg. batch load time: 5.346, Elapsed time:  7.92
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:52:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 1.6761, 'neural_augmentation': 0.3124, 'total_loss': 1.9885}
2024-08-04 06:52:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 1.0006, 'neural_augmentation': 0.0, 'total_loss': 1.0006} || top1={'logits': 73.0436} || top5={'logits': 94.2181}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:52:52 - [34m[1mLOGS   [0m - Best checkpoint with score 73.04 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:52:52 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_69.5755.pt
2024-08-04 06:52:52 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_70.7383.pt', 'checkpoint_score_71.6225.pt', 'checkpoint_score_72.7248.pt', 'checkpoint_score_72.9094.pt', 'checkpoint_score_73.0436.pt']
2024-08-04 06:53:11 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:53:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:53:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:53:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 1923 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_10_iter_1923.pt
2024-08-04 06:53:13 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 1923 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_10_iter_1923.pt
[31m===========================================================================[0m
2024-08-04 06:53:15 - [32m[1mINFO   [0m - Training epoch 11
2024-08-04 06:53:23 - [34m[1mLOGS   [0m - Epoch:  11 [    1924/10000000], loss: {'classification': 1.7646, 'neural_augmentation': 0.3206, 'total_loss': 2.0852}, LR: [3.7e-05, 3.7e-05], Avg. batch load time: 8.095, Elapsed time:  8.26
2024-08-04 06:53:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 1.6354, 'neural_augmentation': 0.316, 'total_loss': 1.9514}
2024-08-04 06:54:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 0.9905, 'neural_augmentation': 0.0, 'total_loss': 0.9905} || top1={'logits': 73.4782} || top5={'logits': 94.3003}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:54:19 - [34m[1mLOGS   [0m - Best checkpoint with score 73.48 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:54:19 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_70.7383.pt
2024-08-04 06:54:19 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_71.6225.pt', 'checkpoint_score_72.7248.pt', 'checkpoint_score_72.9094.pt', 'checkpoint_score_73.0436.pt', 'checkpoint_score_73.4782.pt']
2024-08-04 06:54:34 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:54:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:54:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:54:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 2101 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_11_iter_2101.pt
2024-08-04 06:54:38 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 2101 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_11_iter_2101.pt
[31m===========================================================================[0m
2024-08-04 06:54:40 - [32m[1mINFO   [0m - Training epoch 12
2024-08-04 06:54:42 - [34m[1mLOGS   [0m - Epoch:  12 [    2102/10000000], loss: {'classification': 1.5369, 'neural_augmentation': 0.3288, 'total_loss': 1.8656}, LR: [3.4e-05, 3.4e-05], Avg. batch load time: 1.631, Elapsed time:  1.79
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:55:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 1.6074, 'neural_augmentation': 0.324, 'total_loss': 1.9314}
2024-08-04 06:55:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 0.9908, 'neural_augmentation': 0.0, 'total_loss': 0.9908} || top1={'logits': 73.3054} || top5={'logits': 94.2903}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
2024-08-04 06:55:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:55:42 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:55:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 2283 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_12_iter_2283.pt
2024-08-04 06:55:43 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 2283 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_12_iter_2283.pt
[31m===========================================================================[0m
2024-08-04 06:55:45 - [32m[1mINFO   [0m - Training epoch 13
2024-08-04 06:55:58 - [34m[1mLOGS   [0m - Epoch:  13 [    2284/10000000], loss: {'classification': 1.6622, 'neural_augmentation': 0.336, 'total_loss': 1.9982}, LR: [3.2e-05, 3.2e-05], Avg. batch load time: 12.183, Elapsed time: 12.59
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
2024-08-04 06:56:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 1.5781, 'neural_augmentation': 0.3365, 'total_loss': 1.9146}
2024-08-04 06:57:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 0.9925, 'neural_augmentation': 0.0, 'total_loss': 0.9925} || top1={'logits': 73.7819} || top5={'logits': 94.2987}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
2024-08-04 06:57:01 - [34m[1mLOGS   [0m - Best checkpoint with score 73.78 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:57:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_71.6225.pt
2024-08-04 06:57:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_72.7248.pt', 'checkpoint_score_72.9094.pt', 'checkpoint_score_73.0436.pt', 'checkpoint_score_73.4782.pt', 'checkpoint_score_73.7819.pt']
2024-08-04 06:57:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:57:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:57:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:57:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 2470 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_13_iter_2470.pt
2024-08-04 06:57:22 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 2470 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_13_iter_2470.pt
[31m===========================================================================[0m
2024-08-04 06:57:24 - [32m[1mINFO   [0m - Training epoch 14
2024-08-04 06:57:28 - [34m[1mLOGS   [0m - Epoch:  14 [    2471/10000000], loss: {'classification': 1.4668, 'neural_augmentation': 0.3455, 'total_loss': 1.8123}, LR: [3e-05, 3e-05], Avg. batch load time: 3.709, Elapsed time:  3.87
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:57:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 1.5587, 'neural_augmentation': 0.3506, 'total_loss': 1.9093}
2024-08-04 06:58:22 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 0.9877, 'neural_augmentation': 0.0, 'total_loss': 0.9877} || top1={'logits': 73.7903} || top5={'logits': 94.255}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read
  warnings.warn(str(msg))
2024-08-04 06:58:23 - [34m[1mLOGS   [0m - Best checkpoint with score 73.79 saved at /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_best.pt
2024-08-04 06:58:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_score_72.7248.pt
2024-08-04 06:58:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_72.9094.pt', 'checkpoint_score_73.0436.pt', 'checkpoint_score_73.4782.pt', 'checkpoint_score_73.7819.pt', 'checkpoint_score_73.7903.pt']
2024-08-04 06:58:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_avg.pt
2024-08-04 06:58:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_last.pt
2024-08-04 06:58:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_last.pt
2024-08-04 06:58:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 2632 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/training_checkpoint_epoch_14_iter_2632.pt
2024-08-04 06:58:48 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 2632 is saved at: /ML-A100/team/mm/models/catlip_data/results_small_dci/9_food200/train/checkpoint_epoch_14_iter_2632.pt
[31m===========================================================================[0m
2024-08-04 06:58:50 - [32m[1mINFO   [0m - Training epoch 15
2024-08-04 06:58:53 - [34m[1mLOGS   [0m - Epoch:  15 [    2633/10000000], loss: {'classification': 1.5073, 'neural_augmentation': 0.3539, 'total_loss': 1.8613}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 2.072, Elapsed time:  2.32
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
2024-08-04 06:59:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 1.5253, 'neural_augmentation': 0.3701, 'total_loss': 1.8953}
2024-08-04 06:59:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 0.9963, 'neural_augmentation': 0.0, 'total_loss': 0.9963} || top1={'logits': 73.6191} || top5={'logits': 94.2097}
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
  warnings.warn(str(msg))
