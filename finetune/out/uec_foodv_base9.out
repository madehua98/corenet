nohup: ignoring input
2024-08-02 01:52:25 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-08-02 01:52:29 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-08-02 01:52:29 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-02 01:52:29 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-02 01:52:29 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-02 01:52:29 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): Foodv(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 103, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-08-02 01:52:29 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-02 01:52:29 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.109G                 | 13.31G     |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  6.929M                |  0.349G    |
|   seg_head.aspp.aspp_layer                |   6.905M               |   0.327G   |
|    seg_head.aspp.aspp_layer.convs         |    6.654M              |    0.315G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    12.315M |
|   seg_head.classifier.block.conv          |   23.175K              |   1.131M   |
|    seg_head.classifier.block.conv.weight  |    (103, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (103,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.673M  |
2024-08-02 01:52:30 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-02 01:52:30 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.blocks1.2.attn.q_norm', 'encoder.blocks1.1.ls2', 'encoder.blocks.1.ls1', 'encoder.neural_augmentor.contrast', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks1.2.attn.attn_drop', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.blocks1.5.ls2', 'encoder.blocks.3.attn.k_norm', 'encoder.neural_augmentor.brightness', 'encoder.blocks.4.ls2', 'encoder.fc_norm', 'encoder.blocks1.5.attn.q_norm', 'encoder.mlp', 'encoder.blocks1.4.attn.k_norm', 'encoder.blocks.0.attn.attn_drop', 'encoder.blocks.5.drop_path2', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.blocks.2.ls2', 'encoder.blocks.6.attn.k_norm', 'encoder.blocks1.1.attn.k_norm', 'encoder.blocks.0.drop_path2', 'encoder.blocks.5.attn.attn_drop', 'encoder.blocks1.4.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.blocks.6.ls2', 'encoder.blocks.6.drop_path2', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.blocks.1.attn.attn_drop', 'encoder.blocks1.3.drop_path1', 'encoder.blocks.3.ls1', 'encoder.blocks.3.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.blocks.6.attn.attn_drop', 'encoder.blocks.4.drop_path1', 'encoder.blocks1.6.ls2', 'encoder.blocks.4.attn.q_norm', 'encoder.blocks1.0.drop_path1', 'encoder.blocks1.5.attn.k_norm', 'encoder.blocks.2.ls1', 'encoder.blocks.1.ls2', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.blocks1.5.drop_path2', 'encoder.blocks1.4.attn.q_norm', 'encoder.blocks.4.drop_path2', 'encoder.neural_augmentor.noise.max_fn', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.blocks1.0.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.blocks.6.drop_path1', 'encoder.blocks1.0.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.blocks1.1.drop_path2', 'encoder.blocks.4.attn.k_norm', 'encoder.blocks1.1.attn.attn_drop', 'encoder.blocks1.2.drop_path1', 'encoder.blocks1.6.attn.attn_drop', 'encoder.blocks.2.attn.k_norm', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.blocks.4.ls1', 'encoder.mlp.2', 'encoder.blocks1.3.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.blocks.6.ls1', 'encoder.blocks1.5.ls1', 'encoder.blocks.1.attn.k_norm', 'encoder.blocks.3.drop_path2', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks1.1.drop_path1', 'encoder.patch_drop', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks1.1.ls1', 'encoder.blocks.5.drop_path1', 'encoder.blocks1.4.drop_path1', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.norm', 'encoder.blocks1.2.drop_path2', 'encoder.blocks1.4.drop_path2', 'encoder.blocks.3.attn.attn_drop', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks.5.attn.k_norm', 'encoder.blocks.2.attn.attn_drop', 'encoder.blocks.0.ls2', 'encoder.blocks.1.drop_path1', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.mlp.1', 'encoder.blocks.6.attn.q_norm', 'encoder.blocks.3.ls2', 'encoder.blocks1.3.drop_path2', 'encoder.blocks1.2.attn.k_norm', 'encoder.blocks1.0.drop_path2', 'encoder.blocks.2.drop_path2', 'encoder.blocks.0.attn.k_norm', 'encoder.blocks1.2.ls2', 'encoder.blocks1.3.ls2', 'encoder.blocks.0.ls1', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.blocks.1.drop_path2', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.blocks1.4.ls2', 'encoder.blocks1.6.drop_path2', 'encoder.blocks.2.attn.q_norm', 'encoder.blocks1.3.attn.k_norm', 'encoder.blocks1.4.ls1', 'encoder.blocks1.2.ls1', 'encoder.blocks1.6.drop_path1', 'encoder.blocks.2.drop_path1', 'encoder.blocks.5.ls2', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.blocks.3.drop_path1', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.blocks1.0.ls2', 'encoder.blocks1.0.ls1', 'encoder.blocks1.5.drop_path1', 'encoder.mlp.0', 'encoder.blocks.5.ls1', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.blocks.0.attn.q_norm', 'encoder.neural_augmentor.noise', 'encoder.norm_pre', 'encoder.blocks1.3.ls1', 'encoder.blocks.1.attn.q_norm', 'encoder.classifier_drop', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.blocks1.3.attn.q_norm', 'encoder.blocks1.6.attn.k_norm', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.neural_augmentor.noise.min_fn', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.blocks.4.attn.attn_drop', 'encoder.blocks1.6.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop', 'encoder.blocks.0.drop_path1', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.neural_augmentor', 'encoder.patch_embed.proj', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.blocks1.6.ls1'}
2024-08-02 01:52:30 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-08-02 01:52:30 - [34m[1mLOGS   [0m - Directory created at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train
2024-08-02 01:52:41 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40010
base
dci
2024-08-02 01:52:41 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40010
base
dci
2024-08-02 01:52:41 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40010
base
dci
2024-08-02 01:52:40 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40010
2024-08-02 01:52:48 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=True 
	num_samples=9000
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=224, w=224), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-02 01:52:48 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=False 
	num_samples=1000
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-02 01:52:48 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-08-02 01:52:48 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=4
)
2024-08-02 01:52:48 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-08-02 01:52:56 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-08-02 01:52:56 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-02 01:52:56 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-02 01:52:56 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-02 01:52:56 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): Foodv(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 103, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-08-02 01:52:56 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-02 01:52:56 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.109G                 | 13.31G     |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  6.929M                |  0.349G    |
|   seg_head.aspp.aspp_layer                |   6.905M               |   0.327G   |
|    seg_head.aspp.aspp_layer.convs         |    6.654M              |    0.315G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    12.315M |
|   seg_head.classifier.block.conv          |   23.175K              |   1.131M   |
|    seg_head.classifier.block.conv.weight  |    (103, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (103,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.673M  |
2024-08-02 01:53:11 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-02 01:53:11 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.mlp.2', 'encoder.blocks.3.attn.attn_drop', 'encoder.blocks1.1.drop_path2', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.blocks.3.drop_path1', 'encoder.blocks.2.attn.q_norm', 'encoder.classifier_drop', 'encoder.blocks.0.drop_path1', 'encoder.blocks1.6.drop_path1', 'encoder.blocks1.4.attn.q_norm', 'encoder.blocks1.6.drop_path2', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.blocks1.2.ls2', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.neural_augmentor.noise.max_fn', 'encoder.blocks1.0.attn.k_norm', 'encoder.blocks.6.attn.attn_drop', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks1.3.drop_path2', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.blocks.1.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.blocks.0.ls1', 'encoder.blocks1.6.attn.k_norm', 'encoder.blocks.6.attn.q_norm', 'encoder.blocks1.2.drop_path1', 'encoder.blocks.3.ls1', 'encoder.blocks.4.attn.attn_drop', 'encoder.blocks.2.attn.k_norm', 'encoder.blocks1.4.drop_path2', 'encoder.blocks.4.attn.q_norm', 'encoder.blocks1.3.drop_path1', 'encoder.blocks1.1.ls1', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.mlp', 'encoder.blocks1.4.ls1', 'encoder.blocks.6.ls1', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks1.1.ls2', 'encoder.blocks.2.ls1', 'encoder.patch_drop', 'encoder.blocks1.6.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.neural_augmentor.contrast', 'encoder.blocks1.5.attn.q_norm', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.blocks.1.attn.attn_drop', 'encoder.blocks.5.ls1', 'encoder.blocks.2.attn.attn_drop', 'encoder.neural_augmentor.brightness', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.mlp.0', 'encoder.blocks.4.drop_path1', 'encoder.blocks.5.ls2', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.blocks1.5.ls2', 'encoder.blocks.3.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.blocks1.5.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.blocks.6.drop_path2', 'encoder.blocks1.2.drop_path2', 'encoder.blocks.5.attn.k_norm', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.blocks.2.drop_path2', 'encoder.blocks1.1.drop_path1', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.blocks1.0.drop_path2', 'encoder.blocks1.3.attn.q_norm', 'encoder.fc_norm', 'encoder.blocks.6.drop_path1', 'encoder.blocks1.0.ls2', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.neural_augmentor', 'encoder.norm_pre', 'encoder.blocks1.4.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.neural_augmentor.noise', 'encoder.blocks1.6.ls1', 'encoder.blocks.4.drop_path2', 'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.blocks1.5.drop_path1', 'encoder.blocks1.2.ls1', 'encoder.blocks.5.drop_path2', 'encoder.blocks1.3.attn.k_norm', 'encoder.blocks.3.ls2', 'encoder.blocks.4.attn.k_norm', 'encoder.blocks1.5.ls1', 'encoder.blocks.1.ls2', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.blocks.5.attn.attn_drop', 'encoder.neural_augmentor.noise.min_fn', 'encoder.blocks.2.drop_path1', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks.1.drop_path1', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks1.0.attn.attn_drop', 'encoder.blocks.3.attn.q_norm', 'encoder.blocks1.2.attn.attn_drop', 'encoder.blocks.2.ls2', 'encoder.blocks1.2.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.blocks1.1.attn.k_norm', 'encoder.blocks1.4.ls2', 'encoder.blocks1.3.attn.attn_drop', 'encoder.blocks1.6.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.blocks.6.attn.k_norm', 'encoder.blocks.0.ls2', 'encoder.blocks1.6.ls2', 'encoder.blocks.5.drop_path1', 'encoder.blocks1.4.attn.attn_drop', 'encoder.blocks1.4.drop_path1', 'encoder.blocks1.3.ls1', 'encoder.blocks.4.ls2', 'encoder.blocks.1.drop_path2', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.norm', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.blocks.1.attn.q_norm', 'encoder.blocks.1.ls1', 'encoder.blocks1.5.drop_path2', 'encoder.blocks1.2.attn.k_norm', 'encoder.blocks.0.attn.q_norm', 'encoder.blocks.3.drop_path2', 'encoder.blocks.0.drop_path2', 'encoder.blocks1.1.attn.attn_drop', 'encoder.blocks.6.ls2', 'encoder.patch_embed.proj', 'encoder.blocks.4.ls1', 'encoder.blocks.0.attn.k_norm', 'encoder.blocks1.3.ls2', 'encoder.mlp.1', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.blocks1.0.ls1', 'encoder.blocks.0.attn.attn_drop', 'encoder.blocks1.0.drop_path1'}
2024-08-02 01:53:11 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - Max. epochs for training: 60
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=60
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-08-02 01:53:12 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt'
2024-08-02 01:53:12 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-02 01:53:14 - [32m[1mINFO   [0m - Training epoch 0
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-08-02 01:56:17 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'segmentation': 4.5877, 'neural_augmentation': 0.2133, 'total_loss': 4.8011}, LR: [1e-06, 1e-06, 1e-06, 1e-06], Avg. batch load time: 179.099, Elapsed time: 183.03
2024-08-02 01:56:29 - [34m[1mLOGS   [0m - Epoch:   0 [     101/10000000], loss: {'segmentation': 4.5024, 'neural_augmentation': 0.2342, 'total_loss': 4.7366}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 1.774, Elapsed time: 194.96
2024-08-02 01:56:42 - [34m[1mLOGS   [0m - Epoch:   0 [     201/10000000], loss: {'segmentation': 4.1936, 'neural_augmentation': 0.2322, 'total_loss': 4.4258}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.891, Elapsed time: 207.81
2024-08-02 01:56:52 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'segmentation': 3.9083, 'neural_augmentation': 0.2301, 'total_loss': 4.1383}
2024-08-02 02:00:00 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'segmentation': 2.8654, 'neural_augmentation': 0.0, 'total_loss': 2.8654} || iou=20.3655
2024-08-02 02:00:01 - [34m[1mLOGS   [0m - Best checkpoint with score 20.37 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:00:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:00:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:00:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_0_iter_282.pt
2024-08-02 02:00:14 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_0_iter_282.pt
[31m===========================================================================[0m
2024-08-02 02:00:16 - [32m[1mINFO   [0m - Training epoch 1
2024-08-02 02:00:17 - [34m[1mLOGS   [0m - Epoch:   1 [     283/10000000], loss: {'segmentation': 2.8787, 'neural_augmentation': 0.2616, 'total_loss': 3.1403}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.649, Elapsed time:  0.79
2024-08-02 02:00:29 - [34m[1mLOGS   [0m - Epoch:   1 [     383/10000000], loss: {'segmentation': 2.7471, 'neural_augmentation': 0.2294, 'total_loss': 2.9765}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.007, Elapsed time: 13.24
2024-08-02 02:00:41 - [34m[1mLOGS   [0m - Epoch:   1 [     483/10000000], loss: {'segmentation': 2.5543, 'neural_augmentation': 0.2306, 'total_loss': 2.7849}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.004, Elapsed time: 25.33
2024-08-02 02:00:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'segmentation': 2.4169, 'neural_augmentation': 0.2316, 'total_loss': 2.6485}
2024-08-02 02:00:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'segmentation': 1.9347, 'neural_augmentation': 0.0, 'total_loss': 1.9347} || iou=48.789
2024-08-02 02:00:55 - [34m[1mLOGS   [0m - Best checkpoint with score 48.79 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:00:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:00:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:01:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_1_iter_564.pt
2024-08-02 02:01:01 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_1_iter_564.pt
[31m===========================================================================[0m
2024-08-02 02:01:03 - [32m[1mINFO   [0m - Training epoch 2
2024-08-02 02:01:03 - [34m[1mLOGS   [0m - Epoch:   2 [     565/10000000], loss: {'segmentation': 1.8338, 'neural_augmentation': 0.1798, 'total_loss': 2.0136}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.360, Elapsed time:  0.48
2024-08-02 02:01:15 - [34m[1mLOGS   [0m - Epoch:   2 [     665/10000000], loss: {'segmentation': 1.8391, 'neural_augmentation': 0.2246, 'total_loss': 2.0637}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.004, Elapsed time: 12.51
2024-08-02 02:01:28 - [34m[1mLOGS   [0m - Epoch:   2 [     765/10000000], loss: {'segmentation': 1.7501, 'neural_augmentation': 0.2249, 'total_loss': 1.975}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 25.16
2024-08-02 02:01:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'segmentation': 1.684, 'neural_augmentation': 0.2257, 'total_loss': 1.9097}
2024-08-02 02:01:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'segmentation': 1.452, 'neural_augmentation': 0.0, 'total_loss': 1.452} || iou=57.8686
2024-08-02 02:01:42 - [34m[1mLOGS   [0m - Best checkpoint with score 57.87 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:01:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:01:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:01:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_2_iter_846.pt
2024-08-02 02:01:48 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_2_iter_846.pt
[31m===========================================================================[0m
2024-08-02 02:01:50 - [32m[1mINFO   [0m - Training epoch 3
2024-08-02 02:01:51 - [34m[1mLOGS   [0m - Epoch:   3 [     847/10000000], loss: {'segmentation': 1.4981, 'neural_augmentation': 0.1817, 'total_loss': 1.6798}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.394, Elapsed time:  0.52
2024-08-02 02:02:04 - [34m[1mLOGS   [0m - Epoch:   3 [     947/10000000], loss: {'segmentation': 1.365, 'neural_augmentation': 0.2187, 'total_loss': 1.5837}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.004, Elapsed time: 13.45
2024-08-02 02:02:16 - [34m[1mLOGS   [0m - Epoch:   3 [    1047/10000000], loss: {'segmentation': 1.3125, 'neural_augmentation': 0.2262, 'total_loss': 1.5387}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 25.60
2024-08-02 02:02:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'segmentation': 1.2738, 'neural_augmentation': 0.2253, 'total_loss': 1.4991}
2024-08-02 02:02:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'segmentation': 1.1047, 'neural_augmentation': 0.0, 'total_loss': 1.1047} || iou=62.6537
2024-08-02 02:02:33 - [34m[1mLOGS   [0m - Best checkpoint with score 62.65 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:02:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:02:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:02:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_3_iter_1128.pt
2024-08-02 02:02:45 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_3_iter_1128.pt
[31m===========================================================================[0m
2024-08-02 02:02:47 - [32m[1mINFO   [0m - Training epoch 4
2024-08-02 02:02:47 - [34m[1mLOGS   [0m - Epoch:   4 [    1129/10000000], loss: {'segmentation': 1.1142, 'neural_augmentation': 0.1928, 'total_loss': 1.3069}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.235, Elapsed time:  0.37
2024-08-02 02:03:00 - [34m[1mLOGS   [0m - Epoch:   4 [    1229/10000000], loss: {'segmentation': 1.0517, 'neural_augmentation': 0.2216, 'total_loss': 1.2732}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.005, Elapsed time: 12.70
2024-08-02 02:03:12 - [34m[1mLOGS   [0m - Epoch:   4 [    1329/10000000], loss: {'segmentation': 1.0261, 'neural_augmentation': 0.2213, 'total_loss': 1.2474}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.003, Elapsed time: 24.69
2024-08-02 02:03:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'segmentation': 1.0005, 'neural_augmentation': 0.2215, 'total_loss': 1.222}
2024-08-02 02:03:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'segmentation': 0.9038, 'neural_augmentation': 0.0, 'total_loss': 0.9038} || iou=64.3686
2024-08-02 02:03:26 - [34m[1mLOGS   [0m - Best checkpoint with score 64.37 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:03:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:03:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:03:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_4_iter_1410.pt
2024-08-02 02:03:31 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_4_iter_1410.pt
[31m===========================================================================[0m
2024-08-02 02:03:33 - [32m[1mINFO   [0m - Training epoch 5
2024-08-02 02:03:34 - [34m[1mLOGS   [0m - Epoch:   5 [    1411/10000000], loss: {'segmentation': 0.9477, 'neural_augmentation': 0.1711, 'total_loss': 1.1188}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.244, Elapsed time:  0.37
2024-08-02 02:03:46 - [34m[1mLOGS   [0m - Epoch:   5 [    1511/10000000], loss: {'segmentation': 0.8488, 'neural_augmentation': 0.2141, 'total_loss': 1.0628}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.003, Elapsed time: 12.29
2024-08-02 02:03:59 - [34m[1mLOGS   [0m - Epoch:   5 [    1611/10000000], loss: {'segmentation': 0.8172, 'neural_augmentation': 0.2183, 'total_loss': 1.0355}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 25.39
2024-08-02 02:04:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'segmentation': 0.7956, 'neural_augmentation': 0.2209, 'total_loss': 1.0165}
2024-08-02 02:04:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'segmentation': 0.8193, 'neural_augmentation': 0.0, 'total_loss': 0.8193} || iou=64.8992
2024-08-02 02:04:13 - [34m[1mLOGS   [0m - Best checkpoint with score 64.90 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:04:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_20.3655.pt
2024-08-02 02:04:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_48.7890.pt', 'checkpoint_score_57.8686.pt', 'checkpoint_score_62.6537.pt', 'checkpoint_score_64.3686.pt', 'checkpoint_score_64.8992.pt']
2024-08-02 02:04:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:04:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:04:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:04:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_5_iter_1692.pt
2024-08-02 02:04:25 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_5_iter_1692.pt
[31m===========================================================================[0m
2024-08-02 02:04:27 - [32m[1mINFO   [0m - Training epoch 6
2024-08-02 02:04:28 - [34m[1mLOGS   [0m - Epoch:   6 [    1693/10000000], loss: {'segmentation': 0.6688, 'neural_augmentation': 0.2152, 'total_loss': 0.884}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.450, Elapsed time:  0.58
2024-08-02 02:04:40 - [34m[1mLOGS   [0m - Epoch:   6 [    1793/10000000], loss: {'segmentation': 0.6764, 'neural_augmentation': 0.2227, 'total_loss': 0.8991}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.005, Elapsed time: 13.08
2024-08-02 02:04:55 - [34m[1mLOGS   [0m - Epoch:   6 [    1893/10000000], loss: {'segmentation': 0.6513, 'neural_augmentation': 0.2247, 'total_loss': 0.876}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.003, Elapsed time: 28.02
2024-08-02 02:05:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'segmentation': 0.6325, 'neural_augmentation': 0.224, 'total_loss': 0.8565}
2024-08-02 02:05:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'segmentation': 0.6943, 'neural_augmentation': 0.0, 'total_loss': 0.6943} || iou=66.53
2024-08-02 02:05:12 - [34m[1mLOGS   [0m - Best checkpoint with score 66.53 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:05:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_48.7890.pt
2024-08-02 02:05:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_57.8686.pt', 'checkpoint_score_62.6537.pt', 'checkpoint_score_64.3686.pt', 'checkpoint_score_64.8992.pt', 'checkpoint_score_66.5300.pt']
2024-08-02 02:05:16 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:05:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:05:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:05:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_6_iter_1974.pt
2024-08-02 02:05:21 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_6_iter_1974.pt
[31m===========================================================================[0m
2024-08-02 02:05:23 - [32m[1mINFO   [0m - Training epoch 7
2024-08-02 02:05:23 - [34m[1mLOGS   [0m - Epoch:   7 [    1975/10000000], loss: {'segmentation': 0.5072, 'neural_augmentation': 0.1916, 'total_loss': 0.6988}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.131, Elapsed time:  0.27
2024-08-02 02:05:35 - [34m[1mLOGS   [0m - Epoch:   7 [    2075/10000000], loss: {'segmentation': 0.5243, 'neural_augmentation': 0.2137, 'total_loss': 0.738}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.002, Elapsed time: 12.45
2024-08-02 02:05:48 - [34m[1mLOGS   [0m - Epoch:   7 [    2175/10000000], loss: {'segmentation': 0.5135, 'neural_augmentation': 0.2149, 'total_loss': 0.7284}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.001, Elapsed time: 25.20
2024-08-02 02:05:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'segmentation': 0.5024, 'neural_augmentation': 0.2153, 'total_loss': 0.7177}
2024-08-02 02:06:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'segmentation': 0.6192, 'neural_augmentation': 0.0, 'total_loss': 0.6192} || iou=67.7395
2024-08-02 02:06:02 - [34m[1mLOGS   [0m - Best checkpoint with score 67.74 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:06:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_57.8686.pt
2024-08-02 02:06:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_62.6537.pt', 'checkpoint_score_64.3686.pt', 'checkpoint_score_64.8992.pt', 'checkpoint_score_66.5300.pt', 'checkpoint_score_67.7395.pt']
2024-08-02 02:06:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:06:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:06:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:06:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_7_iter_2256.pt
2024-08-02 02:06:13 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_7_iter_2256.pt
[31m===========================================================================[0m
2024-08-02 02:06:15 - [32m[1mINFO   [0m - Training epoch 8
2024-08-02 02:06:15 - [34m[1mLOGS   [0m - Epoch:   8 [    2257/10000000], loss: {'segmentation': 0.4005, 'neural_augmentation': 0.2647, 'total_loss': 0.6652}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.226, Elapsed time:  0.39
2024-08-02 02:06:28 - [34m[1mLOGS   [0m - Epoch:   8 [    2357/10000000], loss: {'segmentation': 0.4353, 'neural_augmentation': 0.2166, 'total_loss': 0.6518}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.003, Elapsed time: 13.27
2024-08-02 02:06:41 - [34m[1mLOGS   [0m - Epoch:   8 [    2457/10000000], loss: {'segmentation': 0.4221, 'neural_augmentation': 0.2149, 'total_loss': 0.637}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.001, Elapsed time: 25.92
2024-08-02 02:06:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'segmentation': 0.4132, 'neural_augmentation': 0.2148, 'total_loss': 0.628}
2024-08-02 02:06:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'segmentation': 0.5632, 'neural_augmentation': 0.0, 'total_loss': 0.5632} || iou=68.0548
2024-08-02 02:06:56 - [34m[1mLOGS   [0m - Best checkpoint with score 68.05 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:06:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_62.6537.pt
2024-08-02 02:06:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_64.3686.pt', 'checkpoint_score_64.8992.pt', 'checkpoint_score_66.5300.pt', 'checkpoint_score_67.7395.pt', 'checkpoint_score_68.0548.pt']
2024-08-02 02:07:03 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:07:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:07:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:07:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_8_iter_2538.pt
2024-08-02 02:07:11 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_8_iter_2538.pt
[31m===========================================================================[0m
2024-08-02 02:07:13 - [32m[1mINFO   [0m - Training epoch 9
2024-08-02 02:07:14 - [34m[1mLOGS   [0m - Epoch:   9 [    2539/10000000], loss: {'segmentation': 0.3694, 'neural_augmentation': 0.2603, 'total_loss': 0.6297}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.285, Elapsed time:  0.45
2024-08-02 02:07:29 - [34m[1mLOGS   [0m - Epoch:   9 [    2639/10000000], loss: {'segmentation': 0.3585, 'neural_augmentation': 0.2042, 'total_loss': 0.5627}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.005, Elapsed time: 15.16
2024-08-02 02:07:42 - [34m[1mLOGS   [0m - Epoch:   9 [    2739/10000000], loss: {'segmentation': 0.3537, 'neural_augmentation': 0.2073, 'total_loss': 0.561}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.003, Elapsed time: 28.50
2024-08-02 02:07:52 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'segmentation': 0.3477, 'neural_augmentation': 0.2086, 'total_loss': 0.5562}
2024-08-02 02:07:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'segmentation': 0.5447, 'neural_augmentation': 0.0, 'total_loss': 0.5447} || iou=67.3379
2024-08-02 02:07:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:07:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:07:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_9_iter_2820.pt
2024-08-02 02:08:00 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_9_iter_2820.pt
[31m===========================================================================[0m
2024-08-02 02:08:02 - [32m[1mINFO   [0m - Training epoch 10
2024-08-02 02:08:02 - [34m[1mLOGS   [0m - Epoch:  10 [    2821/10000000], loss: {'segmentation': 0.3268, 'neural_augmentation': 0.1363, 'total_loss': 0.4631}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.430, Elapsed time:  0.55
2024-08-02 02:08:15 - [34m[1mLOGS   [0m - Epoch:  10 [    2921/10000000], loss: {'segmentation': 0.3092, 'neural_augmentation': 0.2036, 'total_loss': 0.5127}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.005, Elapsed time: 13.71
2024-08-02 02:08:27 - [34m[1mLOGS   [0m - Epoch:  10 [    3021/10000000], loss: {'segmentation': 0.3061, 'neural_augmentation': 0.2053, 'total_loss': 0.5114}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.002, Elapsed time: 25.60
2024-08-02 02:08:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'segmentation': 0.3027, 'neural_augmentation': 0.2047, 'total_loss': 0.5075}
2024-08-02 02:08:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'segmentation': 0.5079, 'neural_augmentation': 0.0, 'total_loss': 0.5079} || iou=68.1943
2024-08-02 02:08:41 - [34m[1mLOGS   [0m - Best checkpoint with score 68.19 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:08:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_64.3686.pt
2024-08-02 02:08:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_64.8992.pt', 'checkpoint_score_66.5300.pt', 'checkpoint_score_67.7395.pt', 'checkpoint_score_68.0548.pt', 'checkpoint_score_68.1943.pt']
2024-08-02 02:08:49 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:08:51 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:08:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:08:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_10_iter_3102.pt
2024-08-02 02:08:54 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_10_iter_3102.pt
[31m===========================================================================[0m
2024-08-02 02:08:56 - [32m[1mINFO   [0m - Training epoch 11
2024-08-02 02:08:57 - [34m[1mLOGS   [0m - Epoch:  11 [    3103/10000000], loss: {'segmentation': 0.2986, 'neural_augmentation': 0.1638, 'total_loss': 0.4623}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.520, Elapsed time:  0.66
2024-08-02 02:09:10 - [34m[1mLOGS   [0m - Epoch:  11 [    3203/10000000], loss: {'segmentation': 0.282, 'neural_augmentation': 0.2045, 'total_loss': 0.4865}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.006, Elapsed time: 13.61
2024-08-02 02:09:23 - [34m[1mLOGS   [0m - Epoch:  11 [    3303/10000000], loss: {'segmentation': 0.2715, 'neural_augmentation': 0.2054, 'total_loss': 0.4769}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.003, Elapsed time: 26.43
2024-08-02 02:09:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'segmentation': 0.2683, 'neural_augmentation': 0.2064, 'total_loss': 0.4746}
2024-08-02 02:09:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'segmentation': 0.5015, 'neural_augmentation': 0.0, 'total_loss': 0.5015} || iou=68.3678
2024-08-02 02:09:38 - [34m[1mLOGS   [0m - Best checkpoint with score 68.37 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:09:39 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_64.8992.pt
2024-08-02 02:09:39 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_66.5300.pt', 'checkpoint_score_67.7395.pt', 'checkpoint_score_68.0548.pt', 'checkpoint_score_68.1943.pt', 'checkpoint_score_68.3678.pt']
2024-08-02 02:10:09 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:10:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:10:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:10:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_11_iter_3384.pt
2024-08-02 02:10:13 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_11_iter_3384.pt
[31m===========================================================================[0m
2024-08-02 02:10:15 - [32m[1mINFO   [0m - Training epoch 12
2024-08-02 02:10:15 - [34m[1mLOGS   [0m - Epoch:  12 [    3385/10000000], loss: {'segmentation': 0.2838, 'neural_augmentation': 0.2211, 'total_loss': 0.5049}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.311, Elapsed time:  0.45
2024-08-02 02:10:28 - [34m[1mLOGS   [0m - Epoch:  12 [    3485/10000000], loss: {'segmentation': 0.2454, 'neural_augmentation': 0.2034, 'total_loss': 0.4488}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.004, Elapsed time: 12.56
2024-08-02 02:10:40 - [34m[1mLOGS   [0m - Epoch:  12 [    3585/10000000], loss: {'segmentation': 0.2447, 'neural_augmentation': 0.205, 'total_loss': 0.4497}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.002, Elapsed time: 25.29
2024-08-02 02:10:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'segmentation': 0.2434, 'neural_augmentation': 0.2037, 'total_loss': 0.4471}
2024-08-02 02:10:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'segmentation': 0.5013, 'neural_augmentation': 0.0, 'total_loss': 0.5013} || iou=68.4426
2024-08-02 02:10:54 - [34m[1mLOGS   [0m - Best checkpoint with score 68.44 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:10:54 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_66.5300.pt
2024-08-02 02:10:54 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_67.7395.pt', 'checkpoint_score_68.0548.pt', 'checkpoint_score_68.1943.pt', 'checkpoint_score_68.3678.pt', 'checkpoint_score_68.4426.pt']
2024-08-02 02:10:58 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:11:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:11:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:11:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_12_iter_3666.pt
2024-08-02 02:11:03 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_12_iter_3666.pt
[31m===========================================================================[0m
2024-08-02 02:11:05 - [32m[1mINFO   [0m - Training epoch 13
2024-08-02 02:11:05 - [34m[1mLOGS   [0m - Epoch:  13 [    3667/10000000], loss: {'segmentation': 0.2474, 'neural_augmentation': 0.203, 'total_loss': 0.4504}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.301, Elapsed time:  0.42
2024-08-02 02:11:19 - [34m[1mLOGS   [0m - Epoch:  13 [    3767/10000000], loss: {'segmentation': 0.2247, 'neural_augmentation': 0.1974, 'total_loss': 0.4221}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.003, Elapsed time: 13.67
2024-08-02 02:11:32 - [34m[1mLOGS   [0m - Epoch:  13 [    3867/10000000], loss: {'segmentation': 0.2225, 'neural_augmentation': 0.2027, 'total_loss': 0.4252}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.002, Elapsed time: 26.54
2024-08-02 02:11:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'segmentation': 0.2219, 'neural_augmentation': 0.2025, 'total_loss': 0.4244}
2024-08-02 02:11:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'segmentation': 0.5056, 'neural_augmentation': 0.0, 'total_loss': 0.5056} || iou=68.3343
2024-08-02 02:11:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:11:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:11:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_13_iter_3948.pt
2024-08-02 02:11:51 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_13_iter_3948.pt
[31m===========================================================================[0m
2024-08-02 02:11:53 - [32m[1mINFO   [0m - Training epoch 14
2024-08-02 02:11:54 - [34m[1mLOGS   [0m - Epoch:  14 [    3949/10000000], loss: {'segmentation': 0.1804, 'neural_augmentation': 0.1806, 'total_loss': 0.3611}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.226, Elapsed time:  0.35
2024-08-02 02:12:08 - [34m[1mLOGS   [0m - Epoch:  14 [    4049/10000000], loss: {'segmentation': 0.2081, 'neural_augmentation': 0.2054, 'total_loss': 0.4135}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.003, Elapsed time: 14.37
2024-08-02 02:12:21 - [34m[1mLOGS   [0m - Epoch:  14 [    4149/10000000], loss: {'segmentation': 0.2036, 'neural_augmentation': 0.202, 'total_loss': 0.4056}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.002, Elapsed time: 28.21
2024-08-02 02:12:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'segmentation': 0.2054, 'neural_augmentation': 0.2021, 'total_loss': 0.4075}
2024-08-02 02:12:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'segmentation': 0.5001, 'neural_augmentation': 0.0, 'total_loss': 0.5001} || iou=68.2244
2024-08-02 02:12:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:12:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:12:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_14_iter_4230.pt
2024-08-02 02:12:40 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_14_iter_4230.pt
[31m===========================================================================[0m
2024-08-02 02:12:42 - [32m[1mINFO   [0m - Training epoch 15
2024-08-02 02:12:43 - [34m[1mLOGS   [0m - Epoch:  15 [    4231/10000000], loss: {'segmentation': 0.1958, 'neural_augmentation': 0.2445, 'total_loss': 0.4403}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.402, Elapsed time:  0.52
2024-08-02 02:12:55 - [34m[1mLOGS   [0m - Epoch:  15 [    4331/10000000], loss: {'segmentation': 0.1994, 'neural_augmentation': 0.1994, 'total_loss': 0.3988}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.004, Elapsed time: 12.55
2024-08-02 02:13:08 - [34m[1mLOGS   [0m - Epoch:  15 [    4431/10000000], loss: {'segmentation': 0.2035, 'neural_augmentation': 0.2002, 'total_loss': 0.4037}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.002, Elapsed time: 25.34
2024-08-02 02:13:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'segmentation': 0.2046, 'neural_augmentation': 0.2004, 'total_loss': 0.405}
2024-08-02 02:13:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'segmentation': 0.5033, 'neural_augmentation': 0.0, 'total_loss': 0.5033} || iou=67.6831
2024-08-02 02:13:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:13:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:13:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_15_iter_4512.pt
2024-08-02 02:13:25 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_15_iter_4512.pt
[31m===========================================================================[0m
2024-08-02 02:13:27 - [32m[1mINFO   [0m - Training epoch 16
2024-08-02 02:13:28 - [34m[1mLOGS   [0m - Epoch:  16 [    4513/10000000], loss: {'segmentation': 0.1834, 'neural_augmentation': 0.2177, 'total_loss': 0.4011}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.348, Elapsed time:  0.47
2024-08-02 02:13:41 - [34m[1mLOGS   [0m - Epoch:  16 [    4613/10000000], loss: {'segmentation': 0.1857, 'neural_augmentation': 0.2077, 'total_loss': 0.3934}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.004, Elapsed time: 13.43
2024-08-02 02:13:53 - [34m[1mLOGS   [0m - Epoch:  16 [    4713/10000000], loss: {'segmentation': 0.1873, 'neural_augmentation': 0.2079, 'total_loss': 0.3952}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.002, Elapsed time: 26.12
2024-08-02 02:14:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'segmentation': 0.1865, 'neural_augmentation': 0.208, 'total_loss': 0.3945}
2024-08-02 02:14:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'segmentation': 0.4918, 'neural_augmentation': 0.0, 'total_loss': 0.4918} || iou=68.6211
2024-08-02 02:14:08 - [34m[1mLOGS   [0m - Best checkpoint with score 68.62 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:14:09 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_67.7395.pt
2024-08-02 02:14:09 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.0548.pt', 'checkpoint_score_68.1943.pt', 'checkpoint_score_68.3678.pt', 'checkpoint_score_68.4426.pt', 'checkpoint_score_68.6211.pt']
2024-08-02 02:14:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:14:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:14:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:14:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_16_iter_4794.pt
2024-08-02 02:14:19 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_16_iter_4794.pt
[31m===========================================================================[0m
2024-08-02 02:14:21 - [32m[1mINFO   [0m - Training epoch 17
2024-08-02 02:14:22 - [34m[1mLOGS   [0m - Epoch:  17 [    4795/10000000], loss: {'segmentation': 0.2156, 'neural_augmentation': 0.2178, 'total_loss': 0.4334}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.378, Elapsed time:  0.50
2024-08-02 02:14:37 - [34m[1mLOGS   [0m - Epoch:  17 [    4895/10000000], loss: {'segmentation': 0.1743, 'neural_augmentation': 0.2089, 'total_loss': 0.3832}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.004, Elapsed time: 15.73
2024-08-02 02:14:50 - [34m[1mLOGS   [0m - Epoch:  17 [    4995/10000000], loss: {'segmentation': 0.1747, 'neural_augmentation': 0.2051, 'total_loss': 0.3798}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.002, Elapsed time: 28.98
2024-08-02 02:15:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'segmentation': 0.1748, 'neural_augmentation': 0.2036, 'total_loss': 0.3785}
2024-08-02 02:15:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'segmentation': 0.4822, 'neural_augmentation': 0.0, 'total_loss': 0.4822} || iou=68.3394
2024-08-02 02:15:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:15:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:15:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_17_iter_5076.pt
2024-08-02 02:15:08 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_17_iter_5076.pt
[31m===========================================================================[0m
2024-08-02 02:15:10 - [32m[1mINFO   [0m - Training epoch 18
2024-08-02 02:15:11 - [34m[1mLOGS   [0m - Epoch:  18 [    5077/10000000], loss: {'segmentation': 0.1813, 'neural_augmentation': 0.2235, 'total_loss': 0.4048}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.325, Elapsed time:  0.45
2024-08-02 02:15:23 - [34m[1mLOGS   [0m - Epoch:  18 [    5177/10000000], loss: {'segmentation': 0.1677, 'neural_augmentation': 0.209, 'total_loss': 0.3767}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.004, Elapsed time: 12.47
2024-08-02 02:15:35 - [34m[1mLOGS   [0m - Epoch:  18 [    5277/10000000], loss: {'segmentation': 0.1665, 'neural_augmentation': 0.2099, 'total_loss': 0.3764}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.002, Elapsed time: 25.33
2024-08-02 02:15:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'segmentation': 0.1666, 'neural_augmentation': 0.2099, 'total_loss': 0.3765}
2024-08-02 02:15:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'segmentation': 0.4891, 'neural_augmentation': 0.0, 'total_loss': 0.4891} || iou=68.8388
2024-08-02 02:15:49 - [34m[1mLOGS   [0m - Best checkpoint with score 68.84 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:15:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_68.0548.pt
2024-08-02 02:15:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.1943.pt', 'checkpoint_score_68.3678.pt', 'checkpoint_score_68.4426.pt', 'checkpoint_score_68.6211.pt', 'checkpoint_score_68.8388.pt']
2024-08-02 02:15:54 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:15:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:15:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:15:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_18_iter_5358.pt
2024-08-02 02:15:59 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_18_iter_5358.pt
[31m===========================================================================[0m
2024-08-02 02:16:01 - [32m[1mINFO   [0m - Training epoch 19
2024-08-02 02:16:02 - [34m[1mLOGS   [0m - Epoch:  19 [    5359/10000000], loss: {'segmentation': 0.1383, 'neural_augmentation': 0.2007, 'total_loss': 0.339}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.277, Elapsed time:  0.42
2024-08-02 02:16:15 - [34m[1mLOGS   [0m - Epoch:  19 [    5459/10000000], loss: {'segmentation': 0.1619, 'neural_augmentation': 0.2162, 'total_loss': 0.3781}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.003, Elapsed time: 13.77
2024-08-02 02:16:28 - [34m[1mLOGS   [0m - Epoch:  19 [    5559/10000000], loss: {'segmentation': 0.1597, 'neural_augmentation': 0.2125, 'total_loss': 0.3722}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.002, Elapsed time: 26.48
2024-08-02 02:16:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'segmentation': 0.1589, 'neural_augmentation': 0.2131, 'total_loss': 0.372}
2024-08-02 02:16:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'segmentation': 0.492, 'neural_augmentation': 0.0, 'total_loss': 0.492} || iou=69.3476
2024-08-02 02:16:41 - [34m[1mLOGS   [0m - Best checkpoint with score 69.35 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:16:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_68.1943.pt
2024-08-02 02:16:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.3678.pt', 'checkpoint_score_68.4426.pt', 'checkpoint_score_68.6211.pt', 'checkpoint_score_68.8388.pt', 'checkpoint_score_69.3476.pt']
2024-08-02 02:16:57 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:16:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:17:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:17:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_19_iter_5640.pt
2024-08-02 02:17:06 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_19_iter_5640.pt
[31m===========================================================================[0m
2024-08-02 02:17:08 - [32m[1mINFO   [0m - Training epoch 20
2024-08-02 02:17:09 - [34m[1mLOGS   [0m - Epoch:  20 [    5641/10000000], loss: {'segmentation': 0.1358, 'neural_augmentation': 0.2811, 'total_loss': 0.4169}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.500, Elapsed time:  0.65
2024-08-02 02:17:22 - [34m[1mLOGS   [0m - Epoch:  20 [    5741/10000000], loss: {'segmentation': 0.1553, 'neural_augmentation': 0.2178, 'total_loss': 0.3731}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.006, Elapsed time: 14.00
2024-08-02 02:17:34 - [34m[1mLOGS   [0m - Epoch:  20 [    5841/10000000], loss: {'segmentation': 0.154, 'neural_augmentation': 0.2164, 'total_loss': 0.3704}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.003, Elapsed time: 25.93
2024-08-02 02:17:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'segmentation': 0.1534, 'neural_augmentation': 0.2173, 'total_loss': 0.3707}
2024-08-02 02:17:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'segmentation': 0.4885, 'neural_augmentation': 0.0, 'total_loss': 0.4885} || iou=69.0444
2024-08-02 02:17:50 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:17:51 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:17:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_20_iter_5922.pt
2024-08-02 02:17:53 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_20_iter_5922.pt
[31m===========================================================================[0m
2024-08-02 02:17:55 - [32m[1mINFO   [0m - Training epoch 21
2024-08-02 02:17:56 - [34m[1mLOGS   [0m - Epoch:  21 [    5923/10000000], loss: {'segmentation': 0.1611, 'neural_augmentation': 0.219, 'total_loss': 0.3801}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.271, Elapsed time:  0.39
2024-08-02 02:18:08 - [34m[1mLOGS   [0m - Epoch:  21 [    6023/10000000], loss: {'segmentation': 0.1488, 'neural_augmentation': 0.2286, 'total_loss': 0.3775}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.003, Elapsed time: 12.35
2024-08-02 02:18:20 - [34m[1mLOGS   [0m - Epoch:  21 [    6123/10000000], loss: {'segmentation': 0.1666, 'neural_augmentation': 0.229, 'total_loss': 0.3955}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.002, Elapsed time: 24.42
2024-08-02 02:18:30 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'segmentation': 0.168, 'neural_augmentation': 0.2284, 'total_loss': 0.3965}
2024-08-02 02:18:33 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'segmentation': 0.4916, 'neural_augmentation': 0.0, 'total_loss': 0.4916} || iou=68.7704
2024-08-02 02:18:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:18:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:18:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_21_iter_6204.pt
2024-08-02 02:18:39 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_21_iter_6204.pt
[31m===========================================================================[0m
2024-08-02 02:18:41 - [32m[1mINFO   [0m - Training epoch 22
2024-08-02 02:18:41 - [34m[1mLOGS   [0m - Epoch:  22 [    6205/10000000], loss: {'segmentation': 0.146, 'neural_augmentation': 0.2207, 'total_loss': 0.3667}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.307, Elapsed time:  0.43
2024-08-02 02:18:54 - [34m[1mLOGS   [0m - Epoch:  22 [    6305/10000000], loss: {'segmentation': 0.1499, 'neural_augmentation': 0.2438, 'total_loss': 0.3936}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.003, Elapsed time: 13.32
2024-08-02 02:19:07 - [34m[1mLOGS   [0m - Epoch:  22 [    6405/10000000], loss: {'segmentation': 0.149, 'neural_augmentation': 0.2389, 'total_loss': 0.388}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.002, Elapsed time: 25.75
2024-08-02 02:19:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'segmentation': 0.149, 'neural_augmentation': 0.238, 'total_loss': 0.387}
2024-08-02 02:19:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'segmentation': 0.5041, 'neural_augmentation': 0.0, 'total_loss': 0.5041} || iou=68.4412
2024-08-02 02:19:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:19:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:19:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_22_iter_6486.pt
2024-08-02 02:19:28 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_22_iter_6486.pt
[31m===========================================================================[0m
2024-08-02 02:19:30 - [32m[1mINFO   [0m - Training epoch 23
2024-08-02 02:19:31 - [34m[1mLOGS   [0m - Epoch:  23 [    6487/10000000], loss: {'segmentation': 0.1419, 'neural_augmentation': 0.2612, 'total_loss': 0.403}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.623, Elapsed time:  0.75
2024-08-02 02:19:45 - [34m[1mLOGS   [0m - Epoch:  23 [    6587/10000000], loss: {'segmentation': 0.1462, 'neural_augmentation': 0.2482, 'total_loss': 0.3944}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.007, Elapsed time: 15.04
2024-08-02 02:19:57 - [34m[1mLOGS   [0m - Epoch:  23 [    6687/10000000], loss: {'segmentation': 0.1436, 'neural_augmentation': 0.2454, 'total_loss': 0.389}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.004, Elapsed time: 27.11
2024-08-02 02:20:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'segmentation': 0.1418, 'neural_augmentation': 0.2449, 'total_loss': 0.3867}
2024-08-02 02:20:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'segmentation': 0.4917, 'neural_augmentation': 0.0, 'total_loss': 0.4917} || iou=69.7931
2024-08-02 02:20:11 - [34m[1mLOGS   [0m - Best checkpoint with score 69.79 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:20:11 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_68.3678.pt
2024-08-02 02:20:11 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.4426.pt', 'checkpoint_score_68.6211.pt', 'checkpoint_score_68.8388.pt', 'checkpoint_score_69.3476.pt', 'checkpoint_score_69.7931.pt']
2024-08-02 02:20:16 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:20:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:20:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:20:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 6768 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_23_iter_6768.pt
2024-08-02 02:20:20 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 6768 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_23_iter_6768.pt
[31m===========================================================================[0m
2024-08-02 02:20:22 - [32m[1mINFO   [0m - Training epoch 24
2024-08-02 02:20:23 - [34m[1mLOGS   [0m - Epoch:  24 [    6769/10000000], loss: {'segmentation': 0.1316, 'neural_augmentation': 0.2243, 'total_loss': 0.3559}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.219, Elapsed time:  0.35
2024-08-02 02:20:35 - [34m[1mLOGS   [0m - Epoch:  24 [    6869/10000000], loss: {'segmentation': 0.1371, 'neural_augmentation': 0.2553, 'total_loss': 0.3924}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.003, Elapsed time: 12.40
2024-08-02 02:20:47 - [34m[1mLOGS   [0m - Epoch:  24 [    6969/10000000], loss: {'segmentation': 0.1366, 'neural_augmentation': 0.2547, 'total_loss': 0.3913}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.001, Elapsed time: 24.70
2024-08-02 02:20:57 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'segmentation': 0.1357, 'neural_augmentation': 0.2558, 'total_loss': 0.3916}
2024-08-02 02:21:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'segmentation': 0.4823, 'neural_augmentation': 0.0, 'total_loss': 0.4823} || iou=69.6655
2024-08-02 02:21:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:21:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:21:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 7050 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_24_iter_7050.pt
2024-08-02 02:21:05 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 7050 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_24_iter_7050.pt
[31m===========================================================================[0m
2024-08-02 02:21:07 - [32m[1mINFO   [0m - Training epoch 25
2024-08-02 02:21:07 - [34m[1mLOGS   [0m - Epoch:  25 [    7051/10000000], loss: {'segmentation': 0.1339, 'neural_augmentation': 0.2702, 'total_loss': 0.4041}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.313, Elapsed time:  0.44
2024-08-02 02:21:20 - [34m[1mLOGS   [0m - Epoch:  25 [    7151/10000000], loss: {'segmentation': 0.1323, 'neural_augmentation': 0.2673, 'total_loss': 0.3996}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.003, Elapsed time: 13.22
2024-08-02 02:21:33 - [34m[1mLOGS   [0m - Epoch:  25 [    7251/10000000], loss: {'segmentation': 0.1324, 'neural_augmentation': 0.2668, 'total_loss': 0.3991}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.002, Elapsed time: 25.64
2024-08-02 02:21:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'segmentation': 0.1323, 'neural_augmentation': 0.2673, 'total_loss': 0.3996}
2024-08-02 02:21:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'segmentation': 0.4914, 'neural_augmentation': 0.0, 'total_loss': 0.4914} || iou=70.0155
2024-08-02 02:21:49 - [34m[1mLOGS   [0m - Best checkpoint with score 70.02 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:21:50 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_68.4426.pt
2024-08-02 02:21:50 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.6211.pt', 'checkpoint_score_68.8388.pt', 'checkpoint_score_69.3476.pt', 'checkpoint_score_69.7931.pt', 'checkpoint_score_70.0155.pt']
2024-08-02 02:22:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:22:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:22:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:22:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 7332 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_25_iter_7332.pt
2024-08-02 02:22:17 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 7332 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_25_iter_7332.pt
[31m===========================================================================[0m
2024-08-02 02:22:19 - [32m[1mINFO   [0m - Training epoch 26
2024-08-02 02:22:19 - [34m[1mLOGS   [0m - Epoch:  26 [    7333/10000000], loss: {'segmentation': 0.1233, 'neural_augmentation': 0.2916, 'total_loss': 0.4149}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.315, Elapsed time:  0.44
2024-08-02 02:22:32 - [34m[1mLOGS   [0m - Epoch:  26 [    7433/10000000], loss: {'segmentation': 0.1308, 'neural_augmentation': 0.2813, 'total_loss': 0.4121}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.003, Elapsed time: 12.53
2024-08-02 02:22:44 - [34m[1mLOGS   [0m - Epoch:  26 [    7533/10000000], loss: {'segmentation': 0.1312, 'neural_augmentation': 0.2814, 'total_loss': 0.4126}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.002, Elapsed time: 24.66
2024-08-02 02:22:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'segmentation': 0.1316, 'neural_augmentation': 0.2829, 'total_loss': 0.4146}
2024-08-02 02:22:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'segmentation': 0.5031, 'neural_augmentation': 0.0, 'total_loss': 0.5031} || iou=70.1054
2024-08-02 02:22:58 - [34m[1mLOGS   [0m - Best checkpoint with score 70.11 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_best.pt
2024-08-02 02:22:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_score_68.6211.pt
2024-08-02 02:22:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.8388.pt', 'checkpoint_score_69.3476.pt', 'checkpoint_score_69.7931.pt', 'checkpoint_score_70.0155.pt', 'checkpoint_score_70.1054.pt']
2024-08-02 02:23:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_avg.pt
2024-08-02 02:23:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:23:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:23:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 7614 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_26_iter_7614.pt
2024-08-02 02:23:05 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 7614 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_26_iter_7614.pt
[31m===========================================================================[0m
2024-08-02 02:23:07 - [32m[1mINFO   [0m - Training epoch 27
2024-08-02 02:23:08 - [34m[1mLOGS   [0m - Epoch:  27 [    7615/10000000], loss: {'segmentation': 0.1186, 'neural_augmentation': 0.3534, 'total_loss': 0.472}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.369, Elapsed time:  0.49
2024-08-02 02:23:21 - [34m[1mLOGS   [0m - Epoch:  27 [    7715/10000000], loss: {'segmentation': 0.1266, 'neural_augmentation': 0.2938, 'total_loss': 0.4204}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.004, Elapsed time: 13.55
2024-08-02 02:23:34 - [34m[1mLOGS   [0m - Epoch:  27 [    7815/10000000], loss: {'segmentation': 0.126, 'neural_augmentation': 0.295, 'total_loss': 0.4209}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.002, Elapsed time: 26.22
2024-08-02 02:23:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'segmentation': 0.1262, 'neural_augmentation': 0.2966, 'total_loss': 0.4228}
2024-08-02 02:23:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'segmentation': 0.5048, 'neural_augmentation': 0.0, 'total_loss': 0.5048} || iou=69.2295
2024-08-02 02:23:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:23:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:23:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 7896 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_27_iter_7896.pt
2024-08-02 02:23:51 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 7896 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_27_iter_7896.pt
[31m===========================================================================[0m
2024-08-02 02:23:53 - [32m[1mINFO   [0m - Training epoch 28
2024-08-02 02:23:54 - [34m[1mLOGS   [0m - Epoch:  28 [    7897/10000000], loss: {'segmentation': 0.1222, 'neural_augmentation': 0.3331, 'total_loss': 0.4554}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.317, Elapsed time:  0.45
2024-08-02 02:24:06 - [34m[1mLOGS   [0m - Epoch:  28 [    7997/10000000], loss: {'segmentation': 0.1241, 'neural_augmentation': 0.3123, 'total_loss': 0.4364}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.003, Elapsed time: 12.75
2024-08-02 02:24:21 - [34m[1mLOGS   [0m - Epoch:  28 [    8097/10000000], loss: {'segmentation': 0.1249, 'neural_augmentation': 0.3124, 'total_loss': 0.4374}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.002, Elapsed time: 27.88
2024-08-02 02:24:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'segmentation': 0.1236, 'neural_augmentation': 0.3128, 'total_loss': 0.4364}
2024-08-02 02:24:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'segmentation': 0.4993, 'neural_augmentation': 0.0, 'total_loss': 0.4993} || iou=69.5548
2024-08-02 02:24:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:24:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:24:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_28_iter_8178.pt
2024-08-02 02:24:40 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_28_iter_8178.pt
[31m===========================================================================[0m
2024-08-02 02:24:42 - [32m[1mINFO   [0m - Training epoch 29
2024-08-02 02:24:43 - [34m[1mLOGS   [0m - Epoch:  29 [    8179/10000000], loss: {'segmentation': 0.1109, 'neural_augmentation': 0.3659, 'total_loss': 0.4768}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.292, Elapsed time:  0.41
2024-08-02 02:24:55 - [34m[1mLOGS   [0m - Epoch:  29 [    8279/10000000], loss: {'segmentation': 0.1211, 'neural_augmentation': 0.3326, 'total_loss': 0.4538}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.003, Elapsed time: 12.45
2024-08-02 02:25:07 - [34m[1mLOGS   [0m - Epoch:  29 [    8379/10000000], loss: {'segmentation': 0.1204, 'neural_augmentation': 0.3312, 'total_loss': 0.4516}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.002, Elapsed time: 24.42
2024-08-02 02:25:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'segmentation': 0.1209, 'neural_augmentation': 0.3316, 'total_loss': 0.4525}
2024-08-02 02:25:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'segmentation': 0.5152, 'neural_augmentation': 0.0, 'total_loss': 0.5152} || iou=69.3991
2024-08-02 02:25:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:25:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:25:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 8460 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_29_iter_8460.pt
2024-08-02 02:25:24 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 8460 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_29_iter_8460.pt
[31m===========================================================================[0m
2024-08-02 02:25:26 - [32m[1mINFO   [0m - Training epoch 30
2024-08-02 02:25:26 - [34m[1mLOGS   [0m - Epoch:  30 [    8461/10000000], loss: {'segmentation': 0.1086, 'neural_augmentation': 0.35, 'total_loss': 0.4587}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.143, Elapsed time:  0.27
2024-08-02 02:25:38 - [34m[1mLOGS   [0m - Epoch:  30 [    8561/10000000], loss: {'segmentation': 0.1198, 'neural_augmentation': 0.3452, 'total_loss': 0.4649}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.002, Elapsed time: 12.64
2024-08-02 02:25:51 - [34m[1mLOGS   [0m - Epoch:  30 [    8661/10000000], loss: {'segmentation': 0.1192, 'neural_augmentation': 0.3438, 'total_loss': 0.463}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.001, Elapsed time: 25.56
2024-08-02 02:26:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'segmentation': 0.1188, 'neural_augmentation': 0.3437, 'total_loss': 0.4625}
2024-08-02 02:26:05 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'segmentation': 0.5147, 'neural_augmentation': 0.0, 'total_loss': 0.5147} || iou=68.9105
2024-08-02 02:26:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:26:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:26:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 8742 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_30_iter_8742.pt
2024-08-02 02:26:09 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 8742 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_30_iter_8742.pt
[31m===========================================================================[0m
2024-08-02 02:26:11 - [32m[1mINFO   [0m - Training epoch 31
2024-08-02 02:26:11 - [34m[1mLOGS   [0m - Epoch:  31 [    8743/10000000], loss: {'segmentation': 0.1208, 'neural_augmentation': 0.3678, 'total_loss': 0.4886}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.388, Elapsed time:  0.52
2024-08-02 02:26:24 - [34m[1mLOGS   [0m - Epoch:  31 [    8843/10000000], loss: {'segmentation': 0.1191, 'neural_augmentation': 0.3607, 'total_loss': 0.4798}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.004, Elapsed time: 13.40
2024-08-02 02:26:38 - [34m[1mLOGS   [0m - Epoch:  31 [    8943/10000000], loss: {'segmentation': 0.1163, 'neural_augmentation': 0.3617, 'total_loss': 0.478}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.002, Elapsed time: 26.95
2024-08-02 02:26:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'segmentation': 0.1167, 'neural_augmentation': 0.3633, 'total_loss': 0.48}
2024-08-02 02:26:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'segmentation': 0.5255, 'neural_augmentation': 0.0, 'total_loss': 0.5255} || iou=68.6323
2024-08-02 02:26:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:26:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:27:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 9024 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_31_iter_9024.pt
2024-08-02 02:27:01 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 9024 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_31_iter_9024.pt
[31m===========================================================================[0m
2024-08-02 02:27:03 - [32m[1mINFO   [0m - Training epoch 32
2024-08-02 02:27:04 - [34m[1mLOGS   [0m - Epoch:  32 [    9025/10000000], loss: {'segmentation': 0.1151, 'neural_augmentation': 0.3632, 'total_loss': 0.4783}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.394, Elapsed time:  0.52
2024-08-02 02:27:16 - [34m[1mLOGS   [0m - Epoch:  32 [    9125/10000000], loss: {'segmentation': 0.1156, 'neural_augmentation': 0.3841, 'total_loss': 0.4997}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.004, Elapsed time: 12.57
2024-08-02 02:27:28 - [34m[1mLOGS   [0m - Epoch:  32 [    9225/10000000], loss: {'segmentation': 0.1142, 'neural_augmentation': 0.3846, 'total_loss': 0.4988}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.002, Elapsed time: 24.54
2024-08-02 02:27:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'segmentation': 0.1145, 'neural_augmentation': 0.3834, 'total_loss': 0.4979}
2024-08-02 02:27:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'segmentation': 0.52, 'neural_augmentation': 0.0, 'total_loss': 0.52} || iou=68.9662
2024-08-02 02:27:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_last.pt
2024-08-02 02:27:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_last.pt
2024-08-02 02:27:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 9306 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/training_checkpoint_epoch_32_iter_9306.pt
2024-08-02 02:27:45 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 9306 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_uec_224/train/checkpoint_epoch_32_iter_9306.pt
[31m===========================================================================[0m
2024-08-02 02:27:47 - [32m[1mINFO   [0m - Training epoch 33
2024-08-02 02:27:47 - [34m[1mLOGS   [0m - Epoch:  33 [    9307/10000000], loss: {'segmentation': 0.1134, 'neural_augmentation': 0.3939, 'total_loss': 0.5073}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.412, Elapsed time:  0.53
Terminated
2024-08-02 02:27:50 - [34m[1mLOGS   [0m - Keyboard interruption. Exiting from early training
2024-08-02 02:27:50 - [34m[1mLOGS   [0m - Training took 00:34:37.86
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 8 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
