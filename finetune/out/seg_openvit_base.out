nohup: ignoring input
2024-07-29 17:18:59 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-07-29 17:18:59 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.mode' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-29 17:18:59 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.norm_layer' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-29 17:18:59 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.use_flash_attention' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-29 17:18:59 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.no_cls_token' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
104
2024-07-29 17:19:00 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'model.embeddings.class_embedding', 'model.embeddings.patch_embedding.weight', 'model.embeddings.position_embedding.weight', 'model.pre_layrnorm.weight', 'model.pre_layrnorm.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.layer_norm1.weight', 'model.encoder.layers.0.layer_norm1.bias', 'model.encoder.layers.0.mlp.fc1.weight', 'model.encoder.layers.0.mlp.fc1.bias', 'model.encoder.layers.0.mlp.fc2.weight', 'model.encoder.layers.0.mlp.fc2.bias', 'model.encoder.layers.0.layer_norm2.weight', 'model.encoder.layers.0.layer_norm2.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.layer_norm1.weight', 'model.encoder.layers.1.layer_norm1.bias', 'model.encoder.layers.1.mlp.fc1.weight', 'model.encoder.layers.1.mlp.fc1.bias', 'model.encoder.layers.1.mlp.fc2.weight', 'model.encoder.layers.1.mlp.fc2.bias', 'model.encoder.layers.1.layer_norm2.weight', 'model.encoder.layers.1.layer_norm2.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.layer_norm1.weight', 'model.encoder.layers.2.layer_norm1.bias', 'model.encoder.layers.2.mlp.fc1.weight', 'model.encoder.layers.2.mlp.fc1.bias', 'model.encoder.layers.2.mlp.fc2.weight', 'model.encoder.layers.2.mlp.fc2.bias', 'model.encoder.layers.2.layer_norm2.weight', 'model.encoder.layers.2.layer_norm2.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.layer_norm1.weight', 'model.encoder.layers.3.layer_norm1.bias', 'model.encoder.layers.3.mlp.fc1.weight', 'model.encoder.layers.3.mlp.fc1.bias', 'model.encoder.layers.3.mlp.fc2.weight', 'model.encoder.layers.3.mlp.fc2.bias', 'model.encoder.layers.3.layer_norm2.weight', 'model.encoder.layers.3.layer_norm2.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.layer_norm1.weight', 'model.encoder.layers.4.layer_norm1.bias', 'model.encoder.layers.4.mlp.fc1.weight', 'model.encoder.layers.4.mlp.fc1.bias', 'model.encoder.layers.4.mlp.fc2.weight', 'model.encoder.layers.4.mlp.fc2.bias', 'model.encoder.layers.4.layer_norm2.weight', 'model.encoder.layers.4.layer_norm2.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.layer_norm1.weight', 'model.encoder.layers.5.layer_norm1.bias', 'model.encoder.layers.5.mlp.fc1.weight', 'model.encoder.layers.5.mlp.fc1.bias', 'model.encoder.layers.5.mlp.fc2.weight', 'model.encoder.layers.5.mlp.fc2.bias', 'model.encoder.layers.5.layer_norm2.weight', 'model.encoder.layers.5.layer_norm2.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.layer_norm1.weight', 'model.encoder.layers.6.layer_norm1.bias', 'model.encoder.layers.6.mlp.fc1.weight', 'model.encoder.layers.6.mlp.fc1.bias', 'model.encoder.layers.6.mlp.fc2.weight', 'model.encoder.layers.6.mlp.fc2.bias', 'model.encoder.layers.6.layer_norm2.weight', 'model.encoder.layers.6.layer_norm2.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.layer_norm1.weight', 'model.encoder.layers.7.layer_norm1.bias', 'model.encoder.layers.7.mlp.fc1.weight', 'model.encoder.layers.7.mlp.fc1.bias', 'model.encoder.layers.7.mlp.fc2.weight', 'model.encoder.layers.7.mlp.fc2.bias', 'model.encoder.layers.7.layer_norm2.weight', 'model.encoder.layers.7.layer_norm2.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.layer_norm1.weight', 'model.encoder.layers.8.layer_norm1.bias', 'model.encoder.layers.8.mlp.fc1.weight', 'model.encoder.layers.8.mlp.fc1.bias', 'model.encoder.layers.8.mlp.fc2.weight', 'model.encoder.layers.8.mlp.fc2.bias', 'model.encoder.layers.8.layer_norm2.weight', 'model.encoder.layers.8.layer_norm2.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.layer_norm1.weight', 'model.encoder.layers.9.layer_norm1.bias', 'model.encoder.layers.9.mlp.fc1.weight', 'model.encoder.layers.9.mlp.fc1.bias', 'model.encoder.layers.9.mlp.fc2.weight', 'model.encoder.layers.9.mlp.fc2.bias', 'model.encoder.layers.9.layer_norm2.weight', 'model.encoder.layers.9.layer_norm2.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.layer_norm1.weight', 'model.encoder.layers.10.layer_norm1.bias', 'model.encoder.layers.10.mlp.fc1.weight', 'model.encoder.layers.10.mlp.fc1.bias', 'model.encoder.layers.10.mlp.fc2.weight', 'model.encoder.layers.10.mlp.fc2.bias', 'model.encoder.layers.10.layer_norm2.weight', 'model.encoder.layers.10.layer_norm2.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.layer_norm1.weight', 'model.encoder.layers.11.layer_norm1.bias', 'model.encoder.layers.11.mlp.fc1.weight', 'model.encoder.layers.11.mlp.fc1.bias', 'model.encoder.layers.11.mlp.fc2.weight', 'model.encoder.layers.11.mlp.fc2.bias', 'model.encoder.layers.11.layer_norm2.weight', 'model.encoder.layers.11.layer_norm2.bias', 'model.post_layernorm.weight', 'model.post_layernorm.bias', 'classifier.weight', 'classifier.bias']
2024-07-29 17:19:00 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-29 17:19:00 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.model.embeddings.class_embedding', 'encoder.model.embeddings.patch_embedding.weight', 'encoder.model.embeddings.position_embedding.weight', 'encoder.model.pre_layrnorm.weight', 'encoder.model.pre_layrnorm.bias', 'encoder.model.encoder.layers.0.self_attn.k_proj.weight', 'encoder.model.encoder.layers.0.self_attn.k_proj.bias', 'encoder.model.encoder.layers.0.self_attn.v_proj.weight', 'encoder.model.encoder.layers.0.self_attn.v_proj.bias', 'encoder.model.encoder.layers.0.self_attn.q_proj.weight', 'encoder.model.encoder.layers.0.self_attn.q_proj.bias', 'encoder.model.encoder.layers.0.self_attn.out_proj.weight', 'encoder.model.encoder.layers.0.self_attn.out_proj.bias', 'encoder.model.encoder.layers.0.layer_norm1.weight', 'encoder.model.encoder.layers.0.layer_norm1.bias', 'encoder.model.encoder.layers.0.mlp.fc1.weight', 'encoder.model.encoder.layers.0.mlp.fc1.bias', 'encoder.model.encoder.layers.0.mlp.fc2.weight', 'encoder.model.encoder.layers.0.mlp.fc2.bias', 'encoder.model.encoder.layers.0.layer_norm2.weight', 'encoder.model.encoder.layers.0.layer_norm2.bias', 'encoder.model.encoder.layers.1.self_attn.k_proj.weight', 'encoder.model.encoder.layers.1.self_attn.k_proj.bias', 'encoder.model.encoder.layers.1.self_attn.v_proj.weight', 'encoder.model.encoder.layers.1.self_attn.v_proj.bias', 'encoder.model.encoder.layers.1.self_attn.q_proj.weight', 'encoder.model.encoder.layers.1.self_attn.q_proj.bias', 'encoder.model.encoder.layers.1.self_attn.out_proj.weight', 'encoder.model.encoder.layers.1.self_attn.out_proj.bias', 'encoder.model.encoder.layers.1.layer_norm1.weight', 'encoder.model.encoder.layers.1.layer_norm1.bias', 'encoder.model.encoder.layers.1.mlp.fc1.weight', 'encoder.model.encoder.layers.1.mlp.fc1.bias', 'encoder.model.encoder.layers.1.mlp.fc2.weight', 'encoder.model.encoder.layers.1.mlp.fc2.bias', 'encoder.model.encoder.layers.1.layer_norm2.weight', 'encoder.model.encoder.layers.1.layer_norm2.bias', 'encoder.model.encoder.layers.2.self_attn.k_proj.weight', 'encoder.model.encoder.layers.2.self_attn.k_proj.bias', 'encoder.model.encoder.layers.2.self_attn.v_proj.weight', 'encoder.model.encoder.layers.2.self_attn.v_proj.bias', 'encoder.model.encoder.layers.2.self_attn.q_proj.weight', 'encoder.model.encoder.layers.2.self_attn.q_proj.bias', 'encoder.model.encoder.layers.2.self_attn.out_proj.weight', 'encoder.model.encoder.layers.2.self_attn.out_proj.bias', 'encoder.model.encoder.layers.2.layer_norm1.weight', 'encoder.model.encoder.layers.2.layer_norm1.bias', 'encoder.model.encoder.layers.2.mlp.fc1.weight', 'encoder.model.encoder.layers.2.mlp.fc1.bias', 'encoder.model.encoder.layers.2.mlp.fc2.weight', 'encoder.model.encoder.layers.2.mlp.fc2.bias', 'encoder.model.encoder.layers.2.layer_norm2.weight', 'encoder.model.encoder.layers.2.layer_norm2.bias', 'encoder.model.encoder.layers.3.self_attn.k_proj.weight', 'encoder.model.encoder.layers.3.self_attn.k_proj.bias', 'encoder.model.encoder.layers.3.self_attn.v_proj.weight', 'encoder.model.encoder.layers.3.self_attn.v_proj.bias', 'encoder.model.encoder.layers.3.self_attn.q_proj.weight', 'encoder.model.encoder.layers.3.self_attn.q_proj.bias', 'encoder.model.encoder.layers.3.self_attn.out_proj.weight', 'encoder.model.encoder.layers.3.self_attn.out_proj.bias', 'encoder.model.encoder.layers.3.layer_norm1.weight', 'encoder.model.encoder.layers.3.layer_norm1.bias', 'encoder.model.encoder.layers.3.mlp.fc1.weight', 'encoder.model.encoder.layers.3.mlp.fc1.bias', 'encoder.model.encoder.layers.3.mlp.fc2.weight', 'encoder.model.encoder.layers.3.mlp.fc2.bias', 'encoder.model.encoder.layers.3.layer_norm2.weight', 'encoder.model.encoder.layers.3.layer_norm2.bias', 'encoder.model.encoder.layers.4.self_attn.k_proj.weight', 'encoder.model.encoder.layers.4.self_attn.k_proj.bias', 'encoder.model.encoder.layers.4.self_attn.v_proj.weight', 'encoder.model.encoder.layers.4.self_attn.v_proj.bias', 'encoder.model.encoder.layers.4.self_attn.q_proj.weight', 'encoder.model.encoder.layers.4.self_attn.q_proj.bias', 'encoder.model.encoder.layers.4.self_attn.out_proj.weight', 'encoder.model.encoder.layers.4.self_attn.out_proj.bias', 'encoder.model.encoder.layers.4.layer_norm1.weight', 'encoder.model.encoder.layers.4.layer_norm1.bias', 'encoder.model.encoder.layers.4.mlp.fc1.weight', 'encoder.model.encoder.layers.4.mlp.fc1.bias', 'encoder.model.encoder.layers.4.mlp.fc2.weight', 'encoder.model.encoder.layers.4.mlp.fc2.bias', 'encoder.model.encoder.layers.4.layer_norm2.weight', 'encoder.model.encoder.layers.4.layer_norm2.bias', 'encoder.model.encoder.layers.5.self_attn.k_proj.weight', 'encoder.model.encoder.layers.5.self_attn.k_proj.bias', 'encoder.model.encoder.layers.5.self_attn.v_proj.weight', 'encoder.model.encoder.layers.5.self_attn.v_proj.bias', 'encoder.model.encoder.layers.5.self_attn.q_proj.weight', 'encoder.model.encoder.layers.5.self_attn.q_proj.bias', 'encoder.model.encoder.layers.5.self_attn.out_proj.weight', 'encoder.model.encoder.layers.5.self_attn.out_proj.bias', 'encoder.model.encoder.layers.5.layer_norm1.weight', 'encoder.model.encoder.layers.5.layer_norm1.bias', 'encoder.model.encoder.layers.5.mlp.fc1.weight', 'encoder.model.encoder.layers.5.mlp.fc1.bias', 'encoder.model.encoder.layers.5.mlp.fc2.weight', 'encoder.model.encoder.layers.5.mlp.fc2.bias', 'encoder.model.encoder.layers.5.layer_norm2.weight', 'encoder.model.encoder.layers.5.layer_norm2.bias', 'encoder.model.encoder.layers.6.self_attn.k_proj.weight', 'encoder.model.encoder.layers.6.self_attn.k_proj.bias', 'encoder.model.encoder.layers.6.self_attn.v_proj.weight', 'encoder.model.encoder.layers.6.self_attn.v_proj.bias', 'encoder.model.encoder.layers.6.self_attn.q_proj.weight', 'encoder.model.encoder.layers.6.self_attn.q_proj.bias', 'encoder.model.encoder.layers.6.self_attn.out_proj.weight', 'encoder.model.encoder.layers.6.self_attn.out_proj.bias', 'encoder.model.encoder.layers.6.layer_norm1.weight', 'encoder.model.encoder.layers.6.layer_norm1.bias', 'encoder.model.encoder.layers.6.mlp.fc1.weight', 'encoder.model.encoder.layers.6.mlp.fc1.bias', 'encoder.model.encoder.layers.6.mlp.fc2.weight', 'encoder.model.encoder.layers.6.mlp.fc2.bias', 'encoder.model.encoder.layers.6.layer_norm2.weight', 'encoder.model.encoder.layers.6.layer_norm2.bias', 'encoder.model.encoder.layers.7.self_attn.k_proj.weight', 'encoder.model.encoder.layers.7.self_attn.k_proj.bias', 'encoder.model.encoder.layers.7.self_attn.v_proj.weight', 'encoder.model.encoder.layers.7.self_attn.v_proj.bias', 'encoder.model.encoder.layers.7.self_attn.q_proj.weight', 'encoder.model.encoder.layers.7.self_attn.q_proj.bias', 'encoder.model.encoder.layers.7.self_attn.out_proj.weight', 'encoder.model.encoder.layers.7.self_attn.out_proj.bias', 'encoder.model.encoder.layers.7.layer_norm1.weight', 'encoder.model.encoder.layers.7.layer_norm1.bias', 'encoder.model.encoder.layers.7.mlp.fc1.weight', 'encoder.model.encoder.layers.7.mlp.fc1.bias', 'encoder.model.encoder.layers.7.mlp.fc2.weight', 'encoder.model.encoder.layers.7.mlp.fc2.bias', 'encoder.model.encoder.layers.7.layer_norm2.weight', 'encoder.model.encoder.layers.7.layer_norm2.bias', 'encoder.model.encoder.layers.8.self_attn.k_proj.weight', 'encoder.model.encoder.layers.8.self_attn.k_proj.bias', 'encoder.model.encoder.layers.8.self_attn.v_proj.weight', 'encoder.model.encoder.layers.8.self_attn.v_proj.bias', 'encoder.model.encoder.layers.8.self_attn.q_proj.weight', 'encoder.model.encoder.layers.8.self_attn.q_proj.bias', 'encoder.model.encoder.layers.8.self_attn.out_proj.weight', 'encoder.model.encoder.layers.8.self_attn.out_proj.bias', 'encoder.model.encoder.layers.8.layer_norm1.weight', 'encoder.model.encoder.layers.8.layer_norm1.bias', 'encoder.model.encoder.layers.8.mlp.fc1.weight', 'encoder.model.encoder.layers.8.mlp.fc1.bias', 'encoder.model.encoder.layers.8.mlp.fc2.weight', 'encoder.model.encoder.layers.8.mlp.fc2.bias', 'encoder.model.encoder.layers.8.layer_norm2.weight', 'encoder.model.encoder.layers.8.layer_norm2.bias', 'encoder.model.encoder.layers.9.self_attn.k_proj.weight', 'encoder.model.encoder.layers.9.self_attn.k_proj.bias', 'encoder.model.encoder.layers.9.self_attn.v_proj.weight', 'encoder.model.encoder.layers.9.self_attn.v_proj.bias', 'encoder.model.encoder.layers.9.self_attn.q_proj.weight', 'encoder.model.encoder.layers.9.self_attn.q_proj.bias', 'encoder.model.encoder.layers.9.self_attn.out_proj.weight', 'encoder.model.encoder.layers.9.self_attn.out_proj.bias', 'encoder.model.encoder.layers.9.layer_norm1.weight', 'encoder.model.encoder.layers.9.layer_norm1.bias', 'encoder.model.encoder.layers.9.mlp.fc1.weight', 'encoder.model.encoder.layers.9.mlp.fc1.bias', 'encoder.model.encoder.layers.9.mlp.fc2.weight', 'encoder.model.encoder.layers.9.mlp.fc2.bias', 'encoder.model.encoder.layers.9.layer_norm2.weight', 'encoder.model.encoder.layers.9.layer_norm2.bias', 'encoder.model.encoder.layers.10.self_attn.k_proj.weight', 'encoder.model.encoder.layers.10.self_attn.k_proj.bias', 'encoder.model.encoder.layers.10.self_attn.v_proj.weight', 'encoder.model.encoder.layers.10.self_attn.v_proj.bias', 'encoder.model.encoder.layers.10.self_attn.q_proj.weight', 'encoder.model.encoder.layers.10.self_attn.q_proj.bias', 'encoder.model.encoder.layers.10.self_attn.out_proj.weight', 'encoder.model.encoder.layers.10.self_attn.out_proj.bias', 'encoder.model.encoder.layers.10.layer_norm1.weight', 'encoder.model.encoder.layers.10.layer_norm1.bias', 'encoder.model.encoder.layers.10.mlp.fc1.weight', 'encoder.model.encoder.layers.10.mlp.fc1.bias', 'encoder.model.encoder.layers.10.mlp.fc2.weight', 'encoder.model.encoder.layers.10.mlp.fc2.bias', 'encoder.model.encoder.layers.10.layer_norm2.weight', 'encoder.model.encoder.layers.10.layer_norm2.bias', 'encoder.model.encoder.layers.11.self_attn.k_proj.weight', 'encoder.model.encoder.layers.11.self_attn.k_proj.bias', 'encoder.model.encoder.layers.11.self_attn.v_proj.weight', 'encoder.model.encoder.layers.11.self_attn.v_proj.bias', 'encoder.model.encoder.layers.11.self_attn.q_proj.weight', 'encoder.model.encoder.layers.11.self_attn.q_proj.bias', 'encoder.model.encoder.layers.11.self_attn.out_proj.weight', 'encoder.model.encoder.layers.11.self_attn.out_proj.bias', 'encoder.model.encoder.layers.11.layer_norm1.weight', 'encoder.model.encoder.layers.11.layer_norm1.bias', 'encoder.model.encoder.layers.11.mlp.fc1.weight', 'encoder.model.encoder.layers.11.mlp.fc1.bias', 'encoder.model.encoder.layers.11.mlp.fc2.weight', 'encoder.model.encoder.layers.11.mlp.fc2.bias', 'encoder.model.encoder.layers.11.layer_norm2.weight', 'encoder.model.encoder.layers.11.layer_norm2.bias', 'encoder.model.post_layernorm.weight', 'encoder.model.post_layernorm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): OpenClipViT(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (model): CLIPVisionTransformer(
      (embeddings): CLIPVisionEmbeddings(
        (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (position_embedding): Embedding(197, 768)
      )
      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (encoder): CLIPEncoder(
        (layers): ModuleList(
          (0-11): 12 x CLIPEncoderLayer(
            (self_attn): CLIPAttention(
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): CLIPMLP(
              (activation_fn): QuickGELUActivation()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=16.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   91.065 M
Total trainable parameters =   91.065 M

2024-07-29 17:19:00 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 91.065M                | 18.602G    |
|  encoder                                  |  85.799M               |  17.582G   |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.model                           |   85.799M              |   17.582G  |
|    encoder.model.embeddings               |    0.742M              |    0.116G  |
|    encoder.model.pre_layrnorm             |    1.536K              |    0.756M  |
|    encoder.model.encoder.layers           |    85.054M             |    17.466G |
|    encoder.model.post_layernorm           |    1.536K              |            |
|  seg_head                                 |  5.266M                |  1.02G     |
|   seg_head.aspp.aspp_layer                |   5.242M               |   0.994G   |
|    seg_head.aspp.aspp_layer.convs         |    4.991M              |    0.945G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    49.26M  |
|   seg_head.classifier.block.conv          |   23.4K                |   4.566M   |
|    seg_head.classifier.block.conv.weight  |    (104, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (104,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.873M  |
2024-07-29 17:19:00 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-29 17:19:00 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.neural_augmentor.brightness.max_fn', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.neural_augmentor.contrast', 'encoder.neural_augmentor.noise', 'encoder.neural_augmentor.brightness', 'encoder.model.post_layernorm', 'encoder.neural_augmentor.noise.max_fn', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.neural_augmentor.noise.min_fn', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.neural_augmentor'}
2024-07-29 17:19:00 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::gelu': 6, 'aten::embedding': 1, 'aten::sub': 1, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-29 17:19:00 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-29 17:19:01 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-29 17:19:01 - [34m[1mLOGS   [0m - Directory created at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train
2024-07-29 17:19:03 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40009
104
2024-07-29 17:19:03 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40009
104
2024-07-29 17:19:03 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40009
2024-07-29 17:19:05 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=True 
	num_samples=4983
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=224, w=224), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-29 17:19:05 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=False 
	num_samples=2135
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-29 17:19:05 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-07-29 17:19:05 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-07-29 17:19:05 - [34m[1mLOGS   [0m - Number of data workers: 64
104
2024-07-29 17:19:10 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'model.embeddings.class_embedding', 'model.embeddings.patch_embedding.weight', 'model.embeddings.position_embedding.weight', 'model.pre_layrnorm.weight', 'model.pre_layrnorm.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.layer_norm1.weight', 'model.encoder.layers.0.layer_norm1.bias', 'model.encoder.layers.0.mlp.fc1.weight', 'model.encoder.layers.0.mlp.fc1.bias', 'model.encoder.layers.0.mlp.fc2.weight', 'model.encoder.layers.0.mlp.fc2.bias', 'model.encoder.layers.0.layer_norm2.weight', 'model.encoder.layers.0.layer_norm2.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.layer_norm1.weight', 'model.encoder.layers.1.layer_norm1.bias', 'model.encoder.layers.1.mlp.fc1.weight', 'model.encoder.layers.1.mlp.fc1.bias', 'model.encoder.layers.1.mlp.fc2.weight', 'model.encoder.layers.1.mlp.fc2.bias', 'model.encoder.layers.1.layer_norm2.weight', 'model.encoder.layers.1.layer_norm2.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.layer_norm1.weight', 'model.encoder.layers.2.layer_norm1.bias', 'model.encoder.layers.2.mlp.fc1.weight', 'model.encoder.layers.2.mlp.fc1.bias', 'model.encoder.layers.2.mlp.fc2.weight', 'model.encoder.layers.2.mlp.fc2.bias', 'model.encoder.layers.2.layer_norm2.weight', 'model.encoder.layers.2.layer_norm2.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.layer_norm1.weight', 'model.encoder.layers.3.layer_norm1.bias', 'model.encoder.layers.3.mlp.fc1.weight', 'model.encoder.layers.3.mlp.fc1.bias', 'model.encoder.layers.3.mlp.fc2.weight', 'model.encoder.layers.3.mlp.fc2.bias', 'model.encoder.layers.3.layer_norm2.weight', 'model.encoder.layers.3.layer_norm2.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.layer_norm1.weight', 'model.encoder.layers.4.layer_norm1.bias', 'model.encoder.layers.4.mlp.fc1.weight', 'model.encoder.layers.4.mlp.fc1.bias', 'model.encoder.layers.4.mlp.fc2.weight', 'model.encoder.layers.4.mlp.fc2.bias', 'model.encoder.layers.4.layer_norm2.weight', 'model.encoder.layers.4.layer_norm2.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.layer_norm1.weight', 'model.encoder.layers.5.layer_norm1.bias', 'model.encoder.layers.5.mlp.fc1.weight', 'model.encoder.layers.5.mlp.fc1.bias', 'model.encoder.layers.5.mlp.fc2.weight', 'model.encoder.layers.5.mlp.fc2.bias', 'model.encoder.layers.5.layer_norm2.weight', 'model.encoder.layers.5.layer_norm2.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.layer_norm1.weight', 'model.encoder.layers.6.layer_norm1.bias', 'model.encoder.layers.6.mlp.fc1.weight', 'model.encoder.layers.6.mlp.fc1.bias', 'model.encoder.layers.6.mlp.fc2.weight', 'model.encoder.layers.6.mlp.fc2.bias', 'model.encoder.layers.6.layer_norm2.weight', 'model.encoder.layers.6.layer_norm2.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.layer_norm1.weight', 'model.encoder.layers.7.layer_norm1.bias', 'model.encoder.layers.7.mlp.fc1.weight', 'model.encoder.layers.7.mlp.fc1.bias', 'model.encoder.layers.7.mlp.fc2.weight', 'model.encoder.layers.7.mlp.fc2.bias', 'model.encoder.layers.7.layer_norm2.weight', 'model.encoder.layers.7.layer_norm2.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.layer_norm1.weight', 'model.encoder.layers.8.layer_norm1.bias', 'model.encoder.layers.8.mlp.fc1.weight', 'model.encoder.layers.8.mlp.fc1.bias', 'model.encoder.layers.8.mlp.fc2.weight', 'model.encoder.layers.8.mlp.fc2.bias', 'model.encoder.layers.8.layer_norm2.weight', 'model.encoder.layers.8.layer_norm2.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.layer_norm1.weight', 'model.encoder.layers.9.layer_norm1.bias', 'model.encoder.layers.9.mlp.fc1.weight', 'model.encoder.layers.9.mlp.fc1.bias', 'model.encoder.layers.9.mlp.fc2.weight', 'model.encoder.layers.9.mlp.fc2.bias', 'model.encoder.layers.9.layer_norm2.weight', 'model.encoder.layers.9.layer_norm2.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.layer_norm1.weight', 'model.encoder.layers.10.layer_norm1.bias', 'model.encoder.layers.10.mlp.fc1.weight', 'model.encoder.layers.10.mlp.fc1.bias', 'model.encoder.layers.10.mlp.fc2.weight', 'model.encoder.layers.10.mlp.fc2.bias', 'model.encoder.layers.10.layer_norm2.weight', 'model.encoder.layers.10.layer_norm2.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.layer_norm1.weight', 'model.encoder.layers.11.layer_norm1.bias', 'model.encoder.layers.11.mlp.fc1.weight', 'model.encoder.layers.11.mlp.fc1.bias', 'model.encoder.layers.11.mlp.fc2.weight', 'model.encoder.layers.11.mlp.fc2.bias', 'model.encoder.layers.11.layer_norm2.weight', 'model.encoder.layers.11.layer_norm2.bias', 'model.post_layernorm.weight', 'model.post_layernorm.bias', 'classifier.weight', 'classifier.bias']
2024-07-29 17:19:10 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-29 17:19:10 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.model.embeddings.class_embedding', 'encoder.model.embeddings.patch_embedding.weight', 'encoder.model.embeddings.position_embedding.weight', 'encoder.model.pre_layrnorm.weight', 'encoder.model.pre_layrnorm.bias', 'encoder.model.encoder.layers.0.self_attn.k_proj.weight', 'encoder.model.encoder.layers.0.self_attn.k_proj.bias', 'encoder.model.encoder.layers.0.self_attn.v_proj.weight', 'encoder.model.encoder.layers.0.self_attn.v_proj.bias', 'encoder.model.encoder.layers.0.self_attn.q_proj.weight', 'encoder.model.encoder.layers.0.self_attn.q_proj.bias', 'encoder.model.encoder.layers.0.self_attn.out_proj.weight', 'encoder.model.encoder.layers.0.self_attn.out_proj.bias', 'encoder.model.encoder.layers.0.layer_norm1.weight', 'encoder.model.encoder.layers.0.layer_norm1.bias', 'encoder.model.encoder.layers.0.mlp.fc1.weight', 'encoder.model.encoder.layers.0.mlp.fc1.bias', 'encoder.model.encoder.layers.0.mlp.fc2.weight', 'encoder.model.encoder.layers.0.mlp.fc2.bias', 'encoder.model.encoder.layers.0.layer_norm2.weight', 'encoder.model.encoder.layers.0.layer_norm2.bias', 'encoder.model.encoder.layers.1.self_attn.k_proj.weight', 'encoder.model.encoder.layers.1.self_attn.k_proj.bias', 'encoder.model.encoder.layers.1.self_attn.v_proj.weight', 'encoder.model.encoder.layers.1.self_attn.v_proj.bias', 'encoder.model.encoder.layers.1.self_attn.q_proj.weight', 'encoder.model.encoder.layers.1.self_attn.q_proj.bias', 'encoder.model.encoder.layers.1.self_attn.out_proj.weight', 'encoder.model.encoder.layers.1.self_attn.out_proj.bias', 'encoder.model.encoder.layers.1.layer_norm1.weight', 'encoder.model.encoder.layers.1.layer_norm1.bias', 'encoder.model.encoder.layers.1.mlp.fc1.weight', 'encoder.model.encoder.layers.1.mlp.fc1.bias', 'encoder.model.encoder.layers.1.mlp.fc2.weight', 'encoder.model.encoder.layers.1.mlp.fc2.bias', 'encoder.model.encoder.layers.1.layer_norm2.weight', 'encoder.model.encoder.layers.1.layer_norm2.bias', 'encoder.model.encoder.layers.2.self_attn.k_proj.weight', 'encoder.model.encoder.layers.2.self_attn.k_proj.bias', 'encoder.model.encoder.layers.2.self_attn.v_proj.weight', 'encoder.model.encoder.layers.2.self_attn.v_proj.bias', 'encoder.model.encoder.layers.2.self_attn.q_proj.weight', 'encoder.model.encoder.layers.2.self_attn.q_proj.bias', 'encoder.model.encoder.layers.2.self_attn.out_proj.weight', 'encoder.model.encoder.layers.2.self_attn.out_proj.bias', 'encoder.model.encoder.layers.2.layer_norm1.weight', 'encoder.model.encoder.layers.2.layer_norm1.bias', 'encoder.model.encoder.layers.2.mlp.fc1.weight', 'encoder.model.encoder.layers.2.mlp.fc1.bias', 'encoder.model.encoder.layers.2.mlp.fc2.weight', 'encoder.model.encoder.layers.2.mlp.fc2.bias', 'encoder.model.encoder.layers.2.layer_norm2.weight', 'encoder.model.encoder.layers.2.layer_norm2.bias', 'encoder.model.encoder.layers.3.self_attn.k_proj.weight', 'encoder.model.encoder.layers.3.self_attn.k_proj.bias', 'encoder.model.encoder.layers.3.self_attn.v_proj.weight', 'encoder.model.encoder.layers.3.self_attn.v_proj.bias', 'encoder.model.encoder.layers.3.self_attn.q_proj.weight', 'encoder.model.encoder.layers.3.self_attn.q_proj.bias', 'encoder.model.encoder.layers.3.self_attn.out_proj.weight', 'encoder.model.encoder.layers.3.self_attn.out_proj.bias', 'encoder.model.encoder.layers.3.layer_norm1.weight', 'encoder.model.encoder.layers.3.layer_norm1.bias', 'encoder.model.encoder.layers.3.mlp.fc1.weight', 'encoder.model.encoder.layers.3.mlp.fc1.bias', 'encoder.model.encoder.layers.3.mlp.fc2.weight', 'encoder.model.encoder.layers.3.mlp.fc2.bias', 'encoder.model.encoder.layers.3.layer_norm2.weight', 'encoder.model.encoder.layers.3.layer_norm2.bias', 'encoder.model.encoder.layers.4.self_attn.k_proj.weight', 'encoder.model.encoder.layers.4.self_attn.k_proj.bias', 'encoder.model.encoder.layers.4.self_attn.v_proj.weight', 'encoder.model.encoder.layers.4.self_attn.v_proj.bias', 'encoder.model.encoder.layers.4.self_attn.q_proj.weight', 'encoder.model.encoder.layers.4.self_attn.q_proj.bias', 'encoder.model.encoder.layers.4.self_attn.out_proj.weight', 'encoder.model.encoder.layers.4.self_attn.out_proj.bias', 'encoder.model.encoder.layers.4.layer_norm1.weight', 'encoder.model.encoder.layers.4.layer_norm1.bias', 'encoder.model.encoder.layers.4.mlp.fc1.weight', 'encoder.model.encoder.layers.4.mlp.fc1.bias', 'encoder.model.encoder.layers.4.mlp.fc2.weight', 'encoder.model.encoder.layers.4.mlp.fc2.bias', 'encoder.model.encoder.layers.4.layer_norm2.weight', 'encoder.model.encoder.layers.4.layer_norm2.bias', 'encoder.model.encoder.layers.5.self_attn.k_proj.weight', 'encoder.model.encoder.layers.5.self_attn.k_proj.bias', 'encoder.model.encoder.layers.5.self_attn.v_proj.weight', 'encoder.model.encoder.layers.5.self_attn.v_proj.bias', 'encoder.model.encoder.layers.5.self_attn.q_proj.weight', 'encoder.model.encoder.layers.5.self_attn.q_proj.bias', 'encoder.model.encoder.layers.5.self_attn.out_proj.weight', 'encoder.model.encoder.layers.5.self_attn.out_proj.bias', 'encoder.model.encoder.layers.5.layer_norm1.weight', 'encoder.model.encoder.layers.5.layer_norm1.bias', 'encoder.model.encoder.layers.5.mlp.fc1.weight', 'encoder.model.encoder.layers.5.mlp.fc1.bias', 'encoder.model.encoder.layers.5.mlp.fc2.weight', 'encoder.model.encoder.layers.5.mlp.fc2.bias', 'encoder.model.encoder.layers.5.layer_norm2.weight', 'encoder.model.encoder.layers.5.layer_norm2.bias', 'encoder.model.encoder.layers.6.self_attn.k_proj.weight', 'encoder.model.encoder.layers.6.self_attn.k_proj.bias', 'encoder.model.encoder.layers.6.self_attn.v_proj.weight', 'encoder.model.encoder.layers.6.self_attn.v_proj.bias', 'encoder.model.encoder.layers.6.self_attn.q_proj.weight', 'encoder.model.encoder.layers.6.self_attn.q_proj.bias', 'encoder.model.encoder.layers.6.self_attn.out_proj.weight', 'encoder.model.encoder.layers.6.self_attn.out_proj.bias', 'encoder.model.encoder.layers.6.layer_norm1.weight', 'encoder.model.encoder.layers.6.layer_norm1.bias', 'encoder.model.encoder.layers.6.mlp.fc1.weight', 'encoder.model.encoder.layers.6.mlp.fc1.bias', 'encoder.model.encoder.layers.6.mlp.fc2.weight', 'encoder.model.encoder.layers.6.mlp.fc2.bias', 'encoder.model.encoder.layers.6.layer_norm2.weight', 'encoder.model.encoder.layers.6.layer_norm2.bias', 'encoder.model.encoder.layers.7.self_attn.k_proj.weight', 'encoder.model.encoder.layers.7.self_attn.k_proj.bias', 'encoder.model.encoder.layers.7.self_attn.v_proj.weight', 'encoder.model.encoder.layers.7.self_attn.v_proj.bias', 'encoder.model.encoder.layers.7.self_attn.q_proj.weight', 'encoder.model.encoder.layers.7.self_attn.q_proj.bias', 'encoder.model.encoder.layers.7.self_attn.out_proj.weight', 'encoder.model.encoder.layers.7.self_attn.out_proj.bias', 'encoder.model.encoder.layers.7.layer_norm1.weight', 'encoder.model.encoder.layers.7.layer_norm1.bias', 'encoder.model.encoder.layers.7.mlp.fc1.weight', 'encoder.model.encoder.layers.7.mlp.fc1.bias', 'encoder.model.encoder.layers.7.mlp.fc2.weight', 'encoder.model.encoder.layers.7.mlp.fc2.bias', 'encoder.model.encoder.layers.7.layer_norm2.weight', 'encoder.model.encoder.layers.7.layer_norm2.bias', 'encoder.model.encoder.layers.8.self_attn.k_proj.weight', 'encoder.model.encoder.layers.8.self_attn.k_proj.bias', 'encoder.model.encoder.layers.8.self_attn.v_proj.weight', 'encoder.model.encoder.layers.8.self_attn.v_proj.bias', 'encoder.model.encoder.layers.8.self_attn.q_proj.weight', 'encoder.model.encoder.layers.8.self_attn.q_proj.bias', 'encoder.model.encoder.layers.8.self_attn.out_proj.weight', 'encoder.model.encoder.layers.8.self_attn.out_proj.bias', 'encoder.model.encoder.layers.8.layer_norm1.weight', 'encoder.model.encoder.layers.8.layer_norm1.bias', 'encoder.model.encoder.layers.8.mlp.fc1.weight', 'encoder.model.encoder.layers.8.mlp.fc1.bias', 'encoder.model.encoder.layers.8.mlp.fc2.weight', 'encoder.model.encoder.layers.8.mlp.fc2.bias', 'encoder.model.encoder.layers.8.layer_norm2.weight', 'encoder.model.encoder.layers.8.layer_norm2.bias', 'encoder.model.encoder.layers.9.self_attn.k_proj.weight', 'encoder.model.encoder.layers.9.self_attn.k_proj.bias', 'encoder.model.encoder.layers.9.self_attn.v_proj.weight', 'encoder.model.encoder.layers.9.self_attn.v_proj.bias', 'encoder.model.encoder.layers.9.self_attn.q_proj.weight', 'encoder.model.encoder.layers.9.self_attn.q_proj.bias', 'encoder.model.encoder.layers.9.self_attn.out_proj.weight', 'encoder.model.encoder.layers.9.self_attn.out_proj.bias', 'encoder.model.encoder.layers.9.layer_norm1.weight', 'encoder.model.encoder.layers.9.layer_norm1.bias', 'encoder.model.encoder.layers.9.mlp.fc1.weight', 'encoder.model.encoder.layers.9.mlp.fc1.bias', 'encoder.model.encoder.layers.9.mlp.fc2.weight', 'encoder.model.encoder.layers.9.mlp.fc2.bias', 'encoder.model.encoder.layers.9.layer_norm2.weight', 'encoder.model.encoder.layers.9.layer_norm2.bias', 'encoder.model.encoder.layers.10.self_attn.k_proj.weight', 'encoder.model.encoder.layers.10.self_attn.k_proj.bias', 'encoder.model.encoder.layers.10.self_attn.v_proj.weight', 'encoder.model.encoder.layers.10.self_attn.v_proj.bias', 'encoder.model.encoder.layers.10.self_attn.q_proj.weight', 'encoder.model.encoder.layers.10.self_attn.q_proj.bias', 'encoder.model.encoder.layers.10.self_attn.out_proj.weight', 'encoder.model.encoder.layers.10.self_attn.out_proj.bias', 'encoder.model.encoder.layers.10.layer_norm1.weight', 'encoder.model.encoder.layers.10.layer_norm1.bias', 'encoder.model.encoder.layers.10.mlp.fc1.weight', 'encoder.model.encoder.layers.10.mlp.fc1.bias', 'encoder.model.encoder.layers.10.mlp.fc2.weight', 'encoder.model.encoder.layers.10.mlp.fc2.bias', 'encoder.model.encoder.layers.10.layer_norm2.weight', 'encoder.model.encoder.layers.10.layer_norm2.bias', 'encoder.model.encoder.layers.11.self_attn.k_proj.weight', 'encoder.model.encoder.layers.11.self_attn.k_proj.bias', 'encoder.model.encoder.layers.11.self_attn.v_proj.weight', 'encoder.model.encoder.layers.11.self_attn.v_proj.bias', 'encoder.model.encoder.layers.11.self_attn.q_proj.weight', 'encoder.model.encoder.layers.11.self_attn.q_proj.bias', 'encoder.model.encoder.layers.11.self_attn.out_proj.weight', 'encoder.model.encoder.layers.11.self_attn.out_proj.bias', 'encoder.model.encoder.layers.11.layer_norm1.weight', 'encoder.model.encoder.layers.11.layer_norm1.bias', 'encoder.model.encoder.layers.11.mlp.fc1.weight', 'encoder.model.encoder.layers.11.mlp.fc1.bias', 'encoder.model.encoder.layers.11.mlp.fc2.weight', 'encoder.model.encoder.layers.11.mlp.fc2.bias', 'encoder.model.encoder.layers.11.layer_norm2.weight', 'encoder.model.encoder.layers.11.layer_norm2.bias', 'encoder.model.post_layernorm.weight', 'encoder.model.post_layernorm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-29 17:19:10 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): OpenClipViT(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (model): CLIPVisionTransformer(
      (embeddings): CLIPVisionEmbeddings(
        (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
        (position_embedding): Embedding(197, 768)
      )
      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (encoder): CLIPEncoder(
        (layers): ModuleList(
          (0-11): 12 x CLIPEncoderLayer(
            (self_attn): CLIPAttention(
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): CLIPMLP(
              (activation_fn): QuickGELUActivation()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=16.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=768, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =   91.065 M
Total trainable parameters =   91.065 M

2024-07-29 17:19:10 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-29 17:19:10 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 91.065M                | 18.602G    |
|  encoder                                  |  85.799M               |  17.582G   |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.model                           |   85.799M              |   17.582G  |
|    encoder.model.embeddings               |    0.742M              |    0.116G  |
|    encoder.model.pre_layrnorm             |    1.536K              |    0.756M  |
|    encoder.model.encoder.layers           |    85.054M             |    17.466G |
|    encoder.model.post_layernorm           |    1.536K              |            |
|  seg_head                                 |  5.266M                |  1.02G     |
|   seg_head.aspp.aspp_layer                |   5.242M               |   0.994G   |
|    seg_head.aspp.aspp_layer.convs         |    4.991M              |    0.945G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    49.26M  |
|   seg_head.classifier.block.conv          |   23.4K                |   4.566M   |
|    seg_head.classifier.block.conv.weight  |    (104, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (104,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.873M  |
2024-07-29 17:19:11 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-29 17:19:11 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.neural_augmentor.noise.min_fn', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.neural_augmentor', 'encoder.neural_augmentor.noise', 'encoder.neural_augmentor.noise.max_fn', 'encoder.neural_augmentor.contrast', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.model.post_layernorm', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.neural_augmentor.brightness'}
2024-07-29 17:19:11 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::gelu': 6, 'aten::embedding': 1, 'aten::sub': 1, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - Max. epochs for training: 30
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=30
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-29 17:19:11 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt'
2024-07-29 17:19:11 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-29 17:19:13 - [32m[1mINFO   [0m - Training epoch 0
2024-07-29 17:19:03 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40009
104
2024-07-29 17:21:48 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'segmentation': 4.5518, 'neural_augmentation': 9.0856, 'total_loss': 13.6374}, LR: [1e-06, 1e-06, 1e-06, 1e-06], Avg. batch load time: 150.663, Elapsed time: 155.35
2024-07-29 17:21:56 - [34m[1mLOGS   [0m - Epoch:   0 [     101/10000000], loss: {'segmentation': 4.0265, 'neural_augmentation': 9.8376, 'total_loss': 13.864}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 1.492, Elapsed time: 163.09
2024-07-29 17:22:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'segmentation': 3.7537, 'neural_augmentation': 9.7884, 'total_loss': 13.5421}
2024-07-29 17:24:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'segmentation': 2.6787, 'neural_augmentation': 0.0, 'total_loss': 2.6787} || iou=3.0124
2024-07-29 17:24:36 - [34m[1mLOGS   [0m - Best checkpoint with score 3.01 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:24:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:24:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:24:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 156 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_0_iter_156.pt
2024-07-29 17:24:39 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 156 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_0_iter_156.pt
[31m===========================================================================[0m
2024-07-29 17:24:41 - [32m[1mINFO   [0m - Training epoch 1
2024-07-29 17:24:42 - [34m[1mLOGS   [0m - Epoch:   1 [     157/10000000], loss: {'segmentation': 3.0089, 'neural_augmentation': 10.9372, 'total_loss': 13.9461}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.371, Elapsed time:  0.46
2024-07-29 17:24:49 - [34m[1mLOGS   [0m - Epoch:   1 [     257/10000000], loss: {'segmentation': 2.8809, 'neural_augmentation': 9.824, 'total_loss': 12.7049}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.005, Elapsed time:  8.39
2024-07-29 17:24:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'segmentation': 2.8017, 'neural_augmentation': 9.872, 'total_loss': 12.6737}
2024-07-29 17:24:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'segmentation': 2.1306, 'neural_augmentation': 0.0, 'total_loss': 2.1306} || iou=7.6692
2024-07-29 17:24:58 - [34m[1mLOGS   [0m - Best checkpoint with score 7.67 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:24:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:24:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:25:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 312 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_1_iter_312.pt
2024-07-29 17:25:01 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 312 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_1_iter_312.pt
[31m===========================================================================[0m
2024-07-29 17:25:03 - [32m[1mINFO   [0m - Training epoch 2
2024-07-29 17:25:04 - [34m[1mLOGS   [0m - Epoch:   2 [     313/10000000], loss: {'segmentation': 2.564, 'neural_augmentation': 10.7634, 'total_loss': 13.3274}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.581, Elapsed time:  0.67
2024-07-29 17:25:12 - [34m[1mLOGS   [0m - Epoch:   2 [     413/10000000], loss: {'segmentation': 2.4811, 'neural_augmentation': 9.8643, 'total_loss': 12.3454}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.006, Elapsed time:  8.43
2024-07-29 17:25:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'segmentation': 2.4251, 'neural_augmentation': 9.7345, 'total_loss': 12.1596}
2024-07-29 17:25:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'segmentation': 1.9658, 'neural_augmentation': 0.0, 'total_loss': 1.9658} || iou=10.8204
2024-07-29 17:25:20 - [34m[1mLOGS   [0m - Best checkpoint with score 10.82 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:25:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:25:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:25:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 468 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_2_iter_468.pt
2024-07-29 17:25:23 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 468 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_2_iter_468.pt
[31m===========================================================================[0m
2024-07-29 17:25:25 - [32m[1mINFO   [0m - Training epoch 3
2024-07-29 17:25:26 - [34m[1mLOGS   [0m - Epoch:   3 [     469/10000000], loss: {'segmentation': 2.1838, 'neural_augmentation': 7.8989, 'total_loss': 10.0827}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.144, Elapsed time:  0.25
2024-07-29 17:25:33 - [34m[1mLOGS   [0m - Epoch:   3 [     569/10000000], loss: {'segmentation': 2.1883, 'neural_augmentation': 9.8365, 'total_loss': 12.0248}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.003, Elapsed time:  8.12
2024-07-29 17:25:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'segmentation': 2.1573, 'neural_augmentation': 9.7894, 'total_loss': 11.9467}
2024-07-29 17:25:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'segmentation': 1.6756, 'neural_augmentation': 0.0, 'total_loss': 1.6756} || iou=13.3075
2024-07-29 17:25:42 - [34m[1mLOGS   [0m - Best checkpoint with score 13.31 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:25:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:25:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:25:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 624 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_3_iter_624.pt
2024-07-29 17:25:46 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 624 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_3_iter_624.pt
[31m===========================================================================[0m
2024-07-29 17:25:48 - [32m[1mINFO   [0m - Training epoch 4
2024-07-29 17:25:49 - [34m[1mLOGS   [0m - Epoch:   4 [     625/10000000], loss: {'segmentation': 1.9389, 'neural_augmentation': 9.6972, 'total_loss': 11.636}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.652, Elapsed time:  0.74
2024-07-29 17:25:57 - [34m[1mLOGS   [0m - Epoch:   4 [     725/10000000], loss: {'segmentation': 1.9717, 'neural_augmentation': 9.5431, 'total_loss': 11.5148}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.007, Elapsed time:  8.68
2024-07-29 17:26:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'segmentation': 1.9456, 'neural_augmentation': 9.5656, 'total_loss': 11.5112}
2024-07-29 17:26:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'segmentation': 1.5564, 'neural_augmentation': 0.0, 'total_loss': 1.5564} || iou=14.9952
2024-07-29 17:26:05 - [34m[1mLOGS   [0m - Best checkpoint with score 15.00 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:26:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:26:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:26:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 780 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_4_iter_780.pt
2024-07-29 17:26:09 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 780 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_4_iter_780.pt
[31m===========================================================================[0m
2024-07-29 17:26:11 - [32m[1mINFO   [0m - Training epoch 5
2024-07-29 17:26:11 - [34m[1mLOGS   [0m - Epoch:   5 [     781/10000000], loss: {'segmentation': 1.8453, 'neural_augmentation': 10.2056, 'total_loss': 12.0509}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.450, Elapsed time:  0.54
2024-07-29 17:26:19 - [34m[1mLOGS   [0m - Epoch:   5 [     881/10000000], loss: {'segmentation': 1.7893, 'neural_augmentation': 9.6918, 'total_loss': 11.4811}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.005, Elapsed time:  8.37
2024-07-29 17:26:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'segmentation': 1.7698, 'neural_augmentation': 9.8177, 'total_loss': 11.5874}
2024-07-29 17:26:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'segmentation': 1.4605, 'neural_augmentation': 0.0, 'total_loss': 1.4605} || iou=16.8391
2024-07-29 17:26:27 - [34m[1mLOGS   [0m - Best checkpoint with score 16.84 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:26:27 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_3.0124.pt
2024-07-29 17:26:27 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_7.6692.pt', 'checkpoint_score_10.8204.pt', 'checkpoint_score_13.3075.pt', 'checkpoint_score_14.9952.pt', 'checkpoint_score_16.8391.pt']
2024-07-29 17:26:33 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:26:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:26:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:26:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 936 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_5_iter_936.pt
2024-07-29 17:26:35 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 936 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_5_iter_936.pt
[31m===========================================================================[0m
2024-07-29 17:26:37 - [32m[1mINFO   [0m - Training epoch 6
2024-07-29 17:26:38 - [34m[1mLOGS   [0m - Epoch:   6 [     937/10000000], loss: {'segmentation': 1.7326, 'neural_augmentation': 9.2188, 'total_loss': 10.9514}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.509, Elapsed time:  0.59
2024-07-29 17:26:46 - [34m[1mLOGS   [0m - Epoch:   6 [    1037/10000000], loss: {'segmentation': 1.6535, 'neural_augmentation': 9.7369, 'total_loss': 11.3904}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.005, Elapsed time:  8.45
2024-07-29 17:26:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'segmentation': 1.639, 'neural_augmentation': 9.8183, 'total_loss': 11.4573}
2024-07-29 17:26:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'segmentation': 1.4432, 'neural_augmentation': 0.0, 'total_loss': 1.4432} || iou=17.9716
2024-07-29 17:26:54 - [34m[1mLOGS   [0m - Best checkpoint with score 17.97 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:26:54 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_7.6692.pt
2024-07-29 17:26:54 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_10.8204.pt', 'checkpoint_score_13.3075.pt', 'checkpoint_score_14.9952.pt', 'checkpoint_score_16.8391.pt', 'checkpoint_score_17.9716.pt']
2024-07-29 17:27:00 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:27:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:27:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:27:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 1092 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_6_iter_1092.pt
2024-07-29 17:27:03 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 1092 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_6_iter_1092.pt
[31m===========================================================================[0m
2024-07-29 17:27:05 - [32m[1mINFO   [0m - Training epoch 7
2024-07-29 17:27:06 - [34m[1mLOGS   [0m - Epoch:   7 [    1093/10000000], loss: {'segmentation': 1.4968, 'neural_augmentation': 9.471, 'total_loss': 10.9678}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.584, Elapsed time:  0.68
2024-07-29 17:27:14 - [34m[1mLOGS   [0m - Epoch:   7 [    1193/10000000], loss: {'segmentation': 1.5137, 'neural_augmentation': 9.6375, 'total_loss': 11.1512}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.006, Elapsed time:  8.48
2024-07-29 17:27:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'segmentation': 1.503, 'neural_augmentation': 9.6443, 'total_loss': 11.1473}
2024-07-29 17:27:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'segmentation': 1.353, 'neural_augmentation': 0.0, 'total_loss': 1.353} || iou=18.8468
2024-07-29 17:27:22 - [34m[1mLOGS   [0m - Best checkpoint with score 18.85 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:27:22 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_10.8204.pt
2024-07-29 17:27:22 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_13.3075.pt', 'checkpoint_score_14.9952.pt', 'checkpoint_score_16.8391.pt', 'checkpoint_score_17.9716.pt', 'checkpoint_score_18.8468.pt']
2024-07-29 17:27:28 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:27:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:27:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:27:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 1248 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_7_iter_1248.pt
2024-07-29 17:27:31 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 1248 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_7_iter_1248.pt
[31m===========================================================================[0m
2024-07-29 17:27:33 - [32m[1mINFO   [0m - Training epoch 8
2024-07-29 17:27:33 - [34m[1mLOGS   [0m - Epoch:   8 [    1249/10000000], loss: {'segmentation': 1.4473, 'neural_augmentation': 10.2885, 'total_loss': 11.7357}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.221, Elapsed time:  0.31
2024-07-29 17:27:41 - [34m[1mLOGS   [0m - Epoch:   8 [    1349/10000000], loss: {'segmentation': 1.4152, 'neural_augmentation': 9.5521, 'total_loss': 10.9673}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.003, Elapsed time:  8.15
2024-07-29 17:27:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'segmentation': 1.4053, 'neural_augmentation': 9.5958, 'total_loss': 11.001}
2024-07-29 17:27:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'segmentation': 1.2994, 'neural_augmentation': 0.0, 'total_loss': 1.2994} || iou=19.3236
2024-07-29 17:27:49 - [34m[1mLOGS   [0m - Best checkpoint with score 19.32 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:27:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_13.3075.pt
2024-07-29 17:27:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_14.9952.pt', 'checkpoint_score_16.8391.pt', 'checkpoint_score_17.9716.pt', 'checkpoint_score_18.8468.pt', 'checkpoint_score_19.3236.pt']
2024-07-29 17:27:54 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:27:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:27:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:27:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 1404 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_8_iter_1404.pt
2024-07-29 17:27:56 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 1404 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_8_iter_1404.pt
[31m===========================================================================[0m
2024-07-29 17:27:58 - [32m[1mINFO   [0m - Training epoch 9
2024-07-29 17:27:59 - [34m[1mLOGS   [0m - Epoch:   9 [    1405/10000000], loss: {'segmentation': 1.4449, 'neural_augmentation': 9.3152, 'total_loss': 10.76}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.205, Elapsed time:  0.31
2024-07-29 17:28:06 - [34m[1mLOGS   [0m - Epoch:   9 [    1505/10000000], loss: {'segmentation': 1.3115, 'neural_augmentation': 9.5937, 'total_loss': 10.9052}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.002, Elapsed time:  8.16
2024-07-29 17:28:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'segmentation': 1.316, 'neural_augmentation': 9.6553, 'total_loss': 10.9712}
2024-07-29 17:28:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'segmentation': 1.241, 'neural_augmentation': 0.0, 'total_loss': 1.241} || iou=20.3038
2024-07-29 17:28:15 - [34m[1mLOGS   [0m - Best checkpoint with score 20.30 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:28:15 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_14.9952.pt
2024-07-29 17:28:15 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_16.8391.pt', 'checkpoint_score_17.9716.pt', 'checkpoint_score_18.8468.pt', 'checkpoint_score_19.3236.pt', 'checkpoint_score_20.3038.pt']
2024-07-29 17:28:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:28:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:28:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:28:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 1560 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_9_iter_1560.pt
2024-07-29 17:28:22 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 1560 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_9_iter_1560.pt
[31m===========================================================================[0m
2024-07-29 17:28:24 - [32m[1mINFO   [0m - Training epoch 10
2024-07-29 17:28:25 - [34m[1mLOGS   [0m - Epoch:  10 [    1561/10000000], loss: {'segmentation': 1.2992, 'neural_augmentation': 12.4296, 'total_loss': 13.7288}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.221, Elapsed time:  0.32
2024-07-29 17:28:32 - [34m[1mLOGS   [0m - Epoch:  10 [    1661/10000000], loss: {'segmentation': 1.2516, 'neural_augmentation': 9.5344, 'total_loss': 10.786}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.002, Elapsed time:  8.24
2024-07-29 17:28:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'segmentation': 1.2366, 'neural_augmentation': 9.504, 'total_loss': 10.7406}
2024-07-29 17:28:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'segmentation': 1.2007, 'neural_augmentation': 0.0, 'total_loss': 1.2007} || iou=20.868
2024-07-29 17:28:41 - [34m[1mLOGS   [0m - Best checkpoint with score 20.87 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:28:41 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_16.8391.pt
2024-07-29 17:28:41 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_17.9716.pt', 'checkpoint_score_18.8468.pt', 'checkpoint_score_19.3236.pt', 'checkpoint_score_20.3038.pt', 'checkpoint_score_20.8680.pt']
2024-07-29 17:28:45 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:28:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:28:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:28:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 1716 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_10_iter_1716.pt
2024-07-29 17:28:48 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 1716 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_10_iter_1716.pt
[31m===========================================================================[0m
2024-07-29 17:28:50 - [32m[1mINFO   [0m - Training epoch 11
2024-07-29 17:28:51 - [34m[1mLOGS   [0m - Epoch:  11 [    1717/10000000], loss: {'segmentation': 1.2138, 'neural_augmentation': 11.9639, 'total_loss': 13.1777}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.219, Elapsed time:  0.32
2024-07-29 17:28:59 - [34m[1mLOGS   [0m - Epoch:  11 [    1817/10000000], loss: {'segmentation': 1.1563, 'neural_augmentation': 9.5566, 'total_loss': 10.7129}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.006, Elapsed time:  8.37
2024-07-29 17:29:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'segmentation': 1.1566, 'neural_augmentation': 9.5429, 'total_loss': 10.6995}
2024-07-29 17:29:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'segmentation': 1.1676, 'neural_augmentation': 0.0, 'total_loss': 1.1676} || iou=21.5109
2024-07-29 17:29:07 - [34m[1mLOGS   [0m - Best checkpoint with score 21.51 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:29:07 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_17.9716.pt
2024-07-29 17:29:07 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_18.8468.pt', 'checkpoint_score_19.3236.pt', 'checkpoint_score_20.3038.pt', 'checkpoint_score_20.8680.pt', 'checkpoint_score_21.5109.pt']
2024-07-29 17:29:13 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:29:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:29:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:29:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 1872 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_11_iter_1872.pt
2024-07-29 17:29:15 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 1872 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_11_iter_1872.pt
[31m===========================================================================[0m
2024-07-29 17:29:17 - [32m[1mINFO   [0m - Training epoch 12
2024-07-29 17:29:17 - [34m[1mLOGS   [0m - Epoch:  12 [    1873/10000000], loss: {'segmentation': 1.1146, 'neural_augmentation': 7.9675, 'total_loss': 9.0821}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.125, Elapsed time:  0.23
2024-07-29 17:29:26 - [34m[1mLOGS   [0m - Epoch:  12 [    1973/10000000], loss: {'segmentation': 1.072, 'neural_augmentation': 9.1911, 'total_loss': 10.2631}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.005, Elapsed time:  8.47
2024-07-29 17:29:30 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'segmentation': 1.0761, 'neural_augmentation': 9.2825, 'total_loss': 10.3586}
2024-07-29 17:29:33 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'segmentation': 1.1684, 'neural_augmentation': 0.0, 'total_loss': 1.1684} || iou=22.36
2024-07-29 17:29:34 - [34m[1mLOGS   [0m - Best checkpoint with score 22.36 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:29:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_18.8468.pt
2024-07-29 17:29:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_19.3236.pt', 'checkpoint_score_20.3038.pt', 'checkpoint_score_20.8680.pt', 'checkpoint_score_21.5109.pt', 'checkpoint_score_22.3600.pt']
2024-07-29 17:29:39 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:29:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:29:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:29:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 2028 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_12_iter_2028.pt
2024-07-29 17:29:42 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 2028 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_12_iter_2028.pt
[31m===========================================================================[0m
2024-07-29 17:29:44 - [32m[1mINFO   [0m - Training epoch 13
2024-07-29 17:29:44 - [34m[1mLOGS   [0m - Epoch:  13 [    2029/10000000], loss: {'segmentation': 1.1201, 'neural_augmentation': 10.2146, 'total_loss': 11.3347}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.140, Elapsed time:  0.25
2024-07-29 17:29:52 - [34m[1mLOGS   [0m - Epoch:  13 [    2129/10000000], loss: {'segmentation': 1.033, 'neural_augmentation': 9.4212, 'total_loss': 10.4543}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.004, Elapsed time:  8.37
2024-07-29 17:29:57 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'segmentation': 1.0304, 'neural_augmentation': 9.4922, 'total_loss': 10.5226}
2024-07-29 17:30:00 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'segmentation': 1.1538, 'neural_augmentation': 0.0, 'total_loss': 1.1538} || iou=23.5778
2024-07-29 17:30:01 - [34m[1mLOGS   [0m - Best checkpoint with score 23.58 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:30:01 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_19.3236.pt
2024-07-29 17:30:01 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_20.3038.pt', 'checkpoint_score_20.8680.pt', 'checkpoint_score_21.5109.pt', 'checkpoint_score_22.3600.pt', 'checkpoint_score_23.5778.pt']
2024-07-29 17:30:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:30:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:30:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:30:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 2184 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_13_iter_2184.pt
2024-07-29 17:30:08 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 2184 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_13_iter_2184.pt
[31m===========================================================================[0m
2024-07-29 17:30:10 - [32m[1mINFO   [0m - Training epoch 14
2024-07-29 17:30:11 - [34m[1mLOGS   [0m - Epoch:  14 [    2185/10000000], loss: {'segmentation': 0.9309, 'neural_augmentation': 9.4704, 'total_loss': 10.4013}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.243, Elapsed time:  0.34
2024-07-29 17:30:19 - [34m[1mLOGS   [0m - Epoch:  14 [    2285/10000000], loss: {'segmentation': 0.9769, 'neural_augmentation': 9.4093, 'total_loss': 10.3863}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.004, Elapsed time:  8.31
2024-07-29 17:30:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'segmentation': 0.9779, 'neural_augmentation': 9.3412, 'total_loss': 10.3191}
2024-07-29 17:30:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'segmentation': 1.0939, 'neural_augmentation': 0.0, 'total_loss': 1.0939} || iou=23.9864
2024-07-29 17:30:27 - [34m[1mLOGS   [0m - Best checkpoint with score 23.99 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:30:27 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_20.3038.pt
2024-07-29 17:30:27 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_20.8680.pt', 'checkpoint_score_21.5109.pt', 'checkpoint_score_22.3600.pt', 'checkpoint_score_23.5778.pt', 'checkpoint_score_23.9864.pt']
2024-07-29 17:30:32 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:30:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:30:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:30:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 2340 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_14_iter_2340.pt
2024-07-29 17:30:35 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 2340 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_14_iter_2340.pt
[31m===========================================================================[0m
2024-07-29 17:30:37 - [32m[1mINFO   [0m - Training epoch 15
2024-07-29 17:30:37 - [34m[1mLOGS   [0m - Epoch:  15 [    2341/10000000], loss: {'segmentation': 0.8957, 'neural_augmentation': 10.5527, 'total_loss': 11.4483}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.172, Elapsed time:  0.27
2024-07-29 17:30:45 - [34m[1mLOGS   [0m - Epoch:  15 [    2441/10000000], loss: {'segmentation': 0.924, 'neural_augmentation': 9.3274, 'total_loss': 10.2514}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.004, Elapsed time:  8.32
2024-07-29 17:30:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'segmentation': 0.9167, 'neural_augmentation': 9.3175, 'total_loss': 10.2342}
2024-07-29 17:30:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'segmentation': 1.1114, 'neural_augmentation': 0.0, 'total_loss': 1.1114} || iou=24.1876
2024-07-29 17:30:53 - [34m[1mLOGS   [0m - Best checkpoint with score 24.19 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:30:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_20.8680.pt
2024-07-29 17:30:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_21.5109.pt', 'checkpoint_score_22.3600.pt', 'checkpoint_score_23.5778.pt', 'checkpoint_score_23.9864.pt', 'checkpoint_score_24.1876.pt']
2024-07-29 17:30:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:31:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:31:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:31:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 2496 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_15_iter_2496.pt
2024-07-29 17:31:01 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 2496 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_15_iter_2496.pt
[31m===========================================================================[0m
2024-07-29 17:31:03 - [32m[1mINFO   [0m - Training epoch 16
2024-07-29 17:31:04 - [34m[1mLOGS   [0m - Epoch:  16 [    2497/10000000], loss: {'segmentation': 0.7553, 'neural_augmentation': 8.5067, 'total_loss': 9.262}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.594, Elapsed time:  0.68
2024-07-29 17:31:12 - [34m[1mLOGS   [0m - Epoch:  16 [    2597/10000000], loss: {'segmentation': 0.8702, 'neural_augmentation': 9.2488, 'total_loss': 10.119}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.006, Elapsed time:  8.53
2024-07-29 17:31:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'segmentation': 0.8758, 'neural_augmentation': 9.2168, 'total_loss': 10.0926}
2024-07-29 17:31:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'segmentation': 1.0878, 'neural_augmentation': 0.0, 'total_loss': 1.0878} || iou=24.9301
2024-07-29 17:31:20 - [34m[1mLOGS   [0m - Best checkpoint with score 24.93 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:31:20 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_21.5109.pt
2024-07-29 17:31:20 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_22.3600.pt', 'checkpoint_score_23.5778.pt', 'checkpoint_score_23.9864.pt', 'checkpoint_score_24.1876.pt', 'checkpoint_score_24.9301.pt']
2024-07-29 17:31:25 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:31:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:31:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:31:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 2652 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_16_iter_2652.pt
2024-07-29 17:31:28 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 2652 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_16_iter_2652.pt
[31m===========================================================================[0m
2024-07-29 17:31:30 - [32m[1mINFO   [0m - Training epoch 17
2024-07-29 17:31:31 - [34m[1mLOGS   [0m - Epoch:  17 [    2653/10000000], loss: {'segmentation': 0.858, 'neural_augmentation': 8.0361, 'total_loss': 8.8941}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.617, Elapsed time:  0.70
2024-07-29 17:31:38 - [34m[1mLOGS   [0m - Epoch:  17 [    2753/10000000], loss: {'segmentation': 0.8181, 'neural_augmentation': 9.2391, 'total_loss': 10.0572}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.006, Elapsed time:  8.57
2024-07-29 17:31:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'segmentation': 0.8283, 'neural_augmentation': 9.3589, 'total_loss': 10.1871}
2024-07-29 17:31:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'segmentation': 1.0864, 'neural_augmentation': 0.0, 'total_loss': 1.0864} || iou=25.7099
2024-07-29 17:31:47 - [34m[1mLOGS   [0m - Best checkpoint with score 25.71 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:31:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_22.3600.pt
2024-07-29 17:31:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_23.5778.pt', 'checkpoint_score_23.9864.pt', 'checkpoint_score_24.1876.pt', 'checkpoint_score_24.9301.pt', 'checkpoint_score_25.7099.pt']
2024-07-29 17:31:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:31:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:31:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:31:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 2808 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_17_iter_2808.pt
2024-07-29 17:31:54 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 2808 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_17_iter_2808.pt
[31m===========================================================================[0m
2024-07-29 17:31:56 - [32m[1mINFO   [0m - Training epoch 18
2024-07-29 17:31:56 - [34m[1mLOGS   [0m - Epoch:  18 [    2809/10000000], loss: {'segmentation': 0.7536, 'neural_augmentation': 8.7052, 'total_loss': 9.4589}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.330, Elapsed time:  0.42
2024-07-29 17:32:04 - [34m[1mLOGS   [0m - Epoch:  18 [    2909/10000000], loss: {'segmentation': 0.7713, 'neural_augmentation': 9.0144, 'total_loss': 9.7856}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.004, Elapsed time:  8.28
2024-07-29 17:32:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'segmentation': 0.7727, 'neural_augmentation': 9.0507, 'total_loss': 9.8234}
2024-07-29 17:32:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'segmentation': 1.0721, 'neural_augmentation': 0.0, 'total_loss': 1.0721} || iou=25.9022
2024-07-29 17:32:13 - [34m[1mLOGS   [0m - Best checkpoint with score 25.90 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:32:13 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_23.5778.pt
2024-07-29 17:32:13 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_23.9864.pt', 'checkpoint_score_24.1876.pt', 'checkpoint_score_24.9301.pt', 'checkpoint_score_25.7099.pt', 'checkpoint_score_25.9022.pt']
2024-07-29 17:32:17 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:32:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:32:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:32:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 2964 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_18_iter_2964.pt
2024-07-29 17:32:20 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 2964 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_18_iter_2964.pt
[31m===========================================================================[0m
2024-07-29 17:32:22 - [32m[1mINFO   [0m - Training epoch 19
2024-07-29 17:32:22 - [34m[1mLOGS   [0m - Epoch:  19 [    2965/10000000], loss: {'segmentation': 0.7559, 'neural_augmentation': 11.5839, 'total_loss': 12.3398}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.521, Elapsed time:  0.62
2024-07-29 17:32:30 - [34m[1mLOGS   [0m - Epoch:  19 [    3065/10000000], loss: {'segmentation': 0.7288, 'neural_augmentation': 8.9299, 'total_loss': 9.6588}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.005, Elapsed time:  8.45
2024-07-29 17:32:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'segmentation': 0.7339, 'neural_augmentation': 9.0455, 'total_loss': 9.7794}
2024-07-29 17:32:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'segmentation': 1.0525, 'neural_augmentation': 0.0, 'total_loss': 1.0525} || iou=26.8879
2024-07-29 17:32:38 - [34m[1mLOGS   [0m - Best checkpoint with score 26.89 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:32:39 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_23.9864.pt
2024-07-29 17:32:39 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_24.1876.pt', 'checkpoint_score_24.9301.pt', 'checkpoint_score_25.7099.pt', 'checkpoint_score_25.9022.pt', 'checkpoint_score_26.8879.pt']
2024-07-29 17:32:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:32:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:32:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:32:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 3120 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_19_iter_3120.pt
2024-07-29 17:32:45 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 3120 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_19_iter_3120.pt
[31m===========================================================================[0m
2024-07-29 17:32:47 - [32m[1mINFO   [0m - Training epoch 20
2024-07-29 17:32:48 - [34m[1mLOGS   [0m - Epoch:  20 [    3121/10000000], loss: {'segmentation': 0.5978, 'neural_augmentation': 7.3697, 'total_loss': 7.9675}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.375, Elapsed time:  0.47
2024-07-29 17:32:56 - [34m[1mLOGS   [0m - Epoch:  20 [    3221/10000000], loss: {'segmentation': 0.7162, 'neural_augmentation': 9.3489, 'total_loss': 10.0651}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.004, Elapsed time:  8.40
2024-07-29 17:33:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'segmentation': 0.7099, 'neural_augmentation': 9.3124, 'total_loss': 10.0223}
2024-07-29 17:33:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'segmentation': 1.0508, 'neural_augmentation': 0.0, 'total_loss': 1.0508} || iou=26.9489
2024-07-29 17:33:04 - [34m[1mLOGS   [0m - Best checkpoint with score 26.95 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:33:04 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_24.1876.pt
2024-07-29 17:33:04 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_24.9301.pt', 'checkpoint_score_25.7099.pt', 'checkpoint_score_25.9022.pt', 'checkpoint_score_26.8879.pt', 'checkpoint_score_26.9489.pt']
2024-07-29 17:33:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:33:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:33:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:33:11 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 3276 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_20_iter_3276.pt
2024-07-29 17:33:11 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 3276 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_20_iter_3276.pt
[31m===========================================================================[0m
2024-07-29 17:33:13 - [32m[1mINFO   [0m - Training epoch 21
2024-07-29 17:33:13 - [34m[1mLOGS   [0m - Epoch:  21 [    3277/10000000], loss: {'segmentation': 0.6002, 'neural_augmentation': 9.0915, 'total_loss': 9.6918}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.147, Elapsed time:  0.24
2024-07-29 17:33:21 - [34m[1mLOGS   [0m - Epoch:  21 [    3377/10000000], loss: {'segmentation': 0.6746, 'neural_augmentation': 9.0848, 'total_loss': 9.7594}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.005, Elapsed time:  8.32
2024-07-29 17:33:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'segmentation': 0.6796, 'neural_augmentation': 9.179, 'total_loss': 9.8586}
2024-07-29 17:33:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'segmentation': 1.0408, 'neural_augmentation': 0.0, 'total_loss': 1.0408} || iou=27.5224
2024-07-29 17:33:30 - [34m[1mLOGS   [0m - Best checkpoint with score 27.52 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:33:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_24.9301.pt
2024-07-29 17:33:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_25.7099.pt', 'checkpoint_score_25.9022.pt', 'checkpoint_score_26.8879.pt', 'checkpoint_score_26.9489.pt', 'checkpoint_score_27.5224.pt']
2024-07-29 17:33:34 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:33:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:33:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:33:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 3432 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_21_iter_3432.pt
2024-07-29 17:33:36 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 3432 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_21_iter_3432.pt
[31m===========================================================================[0m
2024-07-29 17:33:38 - [32m[1mINFO   [0m - Training epoch 22
2024-07-29 17:33:39 - [34m[1mLOGS   [0m - Epoch:  22 [    3433/10000000], loss: {'segmentation': 0.526, 'neural_augmentation': 8.8203, 'total_loss': 9.3464}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.264, Elapsed time:  0.36
2024-07-29 17:33:47 - [34m[1mLOGS   [0m - Epoch:  22 [    3533/10000000], loss: {'segmentation': 0.6592, 'neural_augmentation': 9.2134, 'total_loss': 9.8726}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.004, Elapsed time:  8.22
2024-07-29 17:33:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'segmentation': 0.6548, 'neural_augmentation': 9.1676, 'total_loss': 9.8225}
2024-07-29 17:33:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'segmentation': 1.0328, 'neural_augmentation': 0.0, 'total_loss': 1.0328} || iou=27.4977
2024-07-29 17:33:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:33:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:33:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 3588 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_22_iter_3588.pt
2024-07-29 17:33:58 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 3588 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_22_iter_3588.pt
[31m===========================================================================[0m
2024-07-29 17:34:00 - [32m[1mINFO   [0m - Training epoch 23
2024-07-29 17:34:00 - [34m[1mLOGS   [0m - Epoch:  23 [    3589/10000000], loss: {'segmentation': 0.6992, 'neural_augmentation': 12.0981, 'total_loss': 12.7973}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.253, Elapsed time:  0.34
2024-07-29 17:34:08 - [34m[1mLOGS   [0m - Epoch:  23 [    3689/10000000], loss: {'segmentation': 0.6365, 'neural_augmentation': 9.2331, 'total_loss': 9.8696}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.003, Elapsed time:  8.17
2024-07-29 17:34:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'segmentation': 0.6331, 'neural_augmentation': 9.2211, 'total_loss': 9.8541}
2024-07-29 17:34:16 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'segmentation': 1.0447, 'neural_augmentation': 0.0, 'total_loss': 1.0447} || iou=28.1185
2024-07-29 17:34:16 - [34m[1mLOGS   [0m - Best checkpoint with score 28.12 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:34:17 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_25.7099.pt
2024-07-29 17:34:17 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_25.9022.pt', 'checkpoint_score_26.8879.pt', 'checkpoint_score_26.9489.pt', 'checkpoint_score_27.5224.pt', 'checkpoint_score_28.1185.pt']
2024-07-29 17:34:21 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:34:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:34:23 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:34:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 3744 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_23_iter_3744.pt
2024-07-29 17:34:24 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 3744 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_23_iter_3744.pt
[31m===========================================================================[0m
2024-07-29 17:34:26 - [32m[1mINFO   [0m - Training epoch 24
2024-07-29 17:34:26 - [34m[1mLOGS   [0m - Epoch:  24 [    3745/10000000], loss: {'segmentation': 0.6498, 'neural_augmentation': 8.6807, 'total_loss': 9.3304}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.163, Elapsed time:  0.25
2024-07-29 17:34:35 - [34m[1mLOGS   [0m - Epoch:  24 [    3845/10000000], loss: {'segmentation': 0.6141, 'neural_augmentation': 9.1161, 'total_loss': 9.7303}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.004, Elapsed time:  8.39
2024-07-29 17:34:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'segmentation': 0.6133, 'neural_augmentation': 9.1148, 'total_loss': 9.7282}
2024-07-29 17:34:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'segmentation': 1.0443, 'neural_augmentation': 0.0, 'total_loss': 1.0443} || iou=27.8931
2024-07-29 17:34:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:34:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:34:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 3900 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_24_iter_3900.pt
2024-07-29 17:34:46 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 3900 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_24_iter_3900.pt
[31m===========================================================================[0m
2024-07-29 17:34:48 - [32m[1mINFO   [0m - Training epoch 25
2024-07-29 17:34:48 - [34m[1mLOGS   [0m - Epoch:  25 [    3901/10000000], loss: {'segmentation': 0.6325, 'neural_augmentation': 9.043, 'total_loss': 9.6755}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.348, Elapsed time:  0.44
2024-07-29 17:34:56 - [34m[1mLOGS   [0m - Epoch:  25 [    4001/10000000], loss: {'segmentation': 0.5949, 'neural_augmentation': 8.9387, 'total_loss': 9.5336}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.004, Elapsed time:  8.24
2024-07-29 17:35:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'segmentation': 0.596, 'neural_augmentation': 8.943, 'total_loss': 9.5389}
2024-07-29 17:35:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'segmentation': 1.05, 'neural_augmentation': 0.0, 'total_loss': 1.05} || iou=28.1795
2024-07-29 17:35:04 - [34m[1mLOGS   [0m - Best checkpoint with score 28.18 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:35:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_25.9022.pt
2024-07-29 17:35:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_26.8879.pt', 'checkpoint_score_26.9489.pt', 'checkpoint_score_27.5224.pt', 'checkpoint_score_28.1185.pt', 'checkpoint_score_28.1795.pt']
2024-07-29 17:35:11 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:35:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:35:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:35:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 4056 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_25_iter_4056.pt
2024-07-29 17:35:14 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 4056 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_25_iter_4056.pt
[31m===========================================================================[0m
2024-07-29 17:35:16 - [32m[1mINFO   [0m - Training epoch 26
2024-07-29 17:35:16 - [34m[1mLOGS   [0m - Epoch:  26 [    4057/10000000], loss: {'segmentation': 0.5458, 'neural_augmentation': 7.5007, 'total_loss': 8.0465}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.512, Elapsed time:  0.60
2024-07-29 17:35:24 - [34m[1mLOGS   [0m - Epoch:  26 [    4157/10000000], loss: {'segmentation': 0.5906, 'neural_augmentation': 8.9724, 'total_loss': 9.563}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.005, Elapsed time:  8.39
2024-07-29 17:35:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'segmentation': 0.5869, 'neural_augmentation': 8.9539, 'total_loss': 9.5407}
2024-07-29 17:35:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'segmentation': 1.0475, 'neural_augmentation': 0.0, 'total_loss': 1.0475} || iou=28.3234
2024-07-29 17:35:33 - [34m[1mLOGS   [0m - Best checkpoint with score 28.32 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:35:33 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_26.8879.pt
2024-07-29 17:35:33 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_26.9489.pt', 'checkpoint_score_27.5224.pt', 'checkpoint_score_28.1185.pt', 'checkpoint_score_28.1795.pt', 'checkpoint_score_28.3234.pt']
2024-07-29 17:35:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:35:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:35:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:35:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 4212 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_26_iter_4212.pt
2024-07-29 17:35:39 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 4212 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_26_iter_4212.pt
[31m===========================================================================[0m
2024-07-29 17:35:41 - [32m[1mINFO   [0m - Training epoch 27
2024-07-29 17:35:42 - [34m[1mLOGS   [0m - Epoch:  27 [    4213/10000000], loss: {'segmentation': 0.6044, 'neural_augmentation': 8.4713, 'total_loss': 9.0757}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.165, Elapsed time:  0.26
2024-07-29 17:35:50 - [34m[1mLOGS   [0m - Epoch:  27 [    4313/10000000], loss: {'segmentation': 0.5702, 'neural_augmentation': 8.9774, 'total_loss': 9.5476}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.003, Elapsed time:  8.32
2024-07-29 17:35:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'segmentation': 0.5715, 'neural_augmentation': 8.9123, 'total_loss': 9.4839}
2024-07-29 17:35:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'segmentation': 1.0325, 'neural_augmentation': 0.0, 'total_loss': 1.0325} || iou=28.7081
2024-07-29 17:35:58 - [34m[1mLOGS   [0m - Best checkpoint with score 28.71 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:35:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_26.9489.pt
2024-07-29 17:35:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_27.5224.pt', 'checkpoint_score_28.1185.pt', 'checkpoint_score_28.1795.pt', 'checkpoint_score_28.3234.pt', 'checkpoint_score_28.7081.pt']
2024-07-29 17:36:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:36:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:36:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:36:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 4368 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_27_iter_4368.pt
2024-07-29 17:36:05 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 4368 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_27_iter_4368.pt
[31m===========================================================================[0m
2024-07-29 17:36:07 - [32m[1mINFO   [0m - Training epoch 28
2024-07-29 17:36:07 - [34m[1mLOGS   [0m - Epoch:  28 [    4369/10000000], loss: {'segmentation': 0.6469, 'neural_augmentation': 7.0034, 'total_loss': 7.6503}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.154, Elapsed time:  0.25
2024-07-29 17:36:15 - [34m[1mLOGS   [0m - Epoch:  28 [    4469/10000000], loss: {'segmentation': 0.5567, 'neural_augmentation': 8.792, 'total_loss': 9.3488}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.005, Elapsed time:  8.33
2024-07-29 17:36:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'segmentation': 0.5594, 'neural_augmentation': 8.9587, 'total_loss': 9.5181}
2024-07-29 17:36:23 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'segmentation': 1.0332, 'neural_augmentation': 0.0, 'total_loss': 1.0332} || iou=28.6248
2024-07-29 17:36:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:36:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:36:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 4524 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_28_iter_4524.pt
2024-07-29 17:36:26 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 4524 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_28_iter_4524.pt
[31m===========================================================================[0m
2024-07-29 17:36:29 - [32m[1mINFO   [0m - Training epoch 29
2024-07-29 17:36:29 - [34m[1mLOGS   [0m - Epoch:  29 [    4525/10000000], loss: {'segmentation': 0.5528, 'neural_augmentation': 9.4852, 'total_loss': 10.0381}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.543, Elapsed time:  0.63
2024-07-29 17:36:37 - [34m[1mLOGS   [0m - Epoch:  29 [    4625/10000000], loss: {'segmentation': 0.5634, 'neural_augmentation': 8.9717, 'total_loss': 9.5351}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.006, Elapsed time:  8.38
2024-07-29 17:36:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'segmentation': 0.5638, 'neural_augmentation': 8.8977, 'total_loss': 9.4615}
2024-07-29 17:36:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'segmentation': 1.0375, 'neural_augmentation': 0.0, 'total_loss': 1.0375} || iou=28.7529
2024-07-29 17:36:46 - [34m[1mLOGS   [0m - Best checkpoint with score 28.75 saved at /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_best.pt
2024-07-29 17:36:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_score_27.5224.pt
2024-07-29 17:36:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_28.1185.pt', 'checkpoint_score_28.1795.pt', 'checkpoint_score_28.3234.pt', 'checkpoint_score_28.7081.pt', 'checkpoint_score_28.7529.pt']
2024-07-29 17:36:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_avg.pt
2024-07-29 17:36:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_last.pt
2024-07-29 17:36:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_last.pt
2024-07-29 17:36:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 4680 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/training_checkpoint_epoch_29_iter_4680.pt
2024-07-29 17:36:54 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 4680 is saved at: /ML-A100/team/mm/models/catlip_data/openvit_base/seg/train/checkpoint_epoch_29_iter_4680.pt
2024-07-29 17:36:54 - [34m[1mLOGS   [0m - Training took 00:17:43.17
