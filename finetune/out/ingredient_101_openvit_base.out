nohup: ignoring input
2024-07-27 09:29:03 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-07-27 09:29:04 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.mode' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-27 09:29:04 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.norm_layer' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
2024-07-27 09:29:04 - [33m[1mWARNING[0m - UnrecognizedYamlConfigEntry("Yaml config key 'model.classification.openvit.use_flash_attention' was not recognized by argparser. If you think that you have already added argument in corenet/options/opts.py file, then check for typos. If not, then please add it to corenet/options/opts.py."
174
2024-07-27 09:29:07 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'model.embeddings.class_embedding', 'model.embeddings.patch_embedding.weight', 'model.embeddings.position_embedding.weight', 'model.pre_layrnorm.weight', 'model.pre_layrnorm.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.layer_norm1.weight', 'model.encoder.layers.0.layer_norm1.bias', 'model.encoder.layers.0.mlp.fc1.weight', 'model.encoder.layers.0.mlp.fc1.bias', 'model.encoder.layers.0.mlp.fc2.weight', 'model.encoder.layers.0.mlp.fc2.bias', 'model.encoder.layers.0.layer_norm2.weight', 'model.encoder.layers.0.layer_norm2.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.layer_norm1.weight', 'model.encoder.layers.1.layer_norm1.bias', 'model.encoder.layers.1.mlp.fc1.weight', 'model.encoder.layers.1.mlp.fc1.bias', 'model.encoder.layers.1.mlp.fc2.weight', 'model.encoder.layers.1.mlp.fc2.bias', 'model.encoder.layers.1.layer_norm2.weight', 'model.encoder.layers.1.layer_norm2.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.layer_norm1.weight', 'model.encoder.layers.2.layer_norm1.bias', 'model.encoder.layers.2.mlp.fc1.weight', 'model.encoder.layers.2.mlp.fc1.bias', 'model.encoder.layers.2.mlp.fc2.weight', 'model.encoder.layers.2.mlp.fc2.bias', 'model.encoder.layers.2.layer_norm2.weight', 'model.encoder.layers.2.layer_norm2.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.layer_norm1.weight', 'model.encoder.layers.3.layer_norm1.bias', 'model.encoder.layers.3.mlp.fc1.weight', 'model.encoder.layers.3.mlp.fc1.bias', 'model.encoder.layers.3.mlp.fc2.weight', 'model.encoder.layers.3.mlp.fc2.bias', 'model.encoder.layers.3.layer_norm2.weight', 'model.encoder.layers.3.layer_norm2.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.layer_norm1.weight', 'model.encoder.layers.4.layer_norm1.bias', 'model.encoder.layers.4.mlp.fc1.weight', 'model.encoder.layers.4.mlp.fc1.bias', 'model.encoder.layers.4.mlp.fc2.weight', 'model.encoder.layers.4.mlp.fc2.bias', 'model.encoder.layers.4.layer_norm2.weight', 'model.encoder.layers.4.layer_norm2.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.layer_norm1.weight', 'model.encoder.layers.5.layer_norm1.bias', 'model.encoder.layers.5.mlp.fc1.weight', 'model.encoder.layers.5.mlp.fc1.bias', 'model.encoder.layers.5.mlp.fc2.weight', 'model.encoder.layers.5.mlp.fc2.bias', 'model.encoder.layers.5.layer_norm2.weight', 'model.encoder.layers.5.layer_norm2.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.layer_norm1.weight', 'model.encoder.layers.6.layer_norm1.bias', 'model.encoder.layers.6.mlp.fc1.weight', 'model.encoder.layers.6.mlp.fc1.bias', 'model.encoder.layers.6.mlp.fc2.weight', 'model.encoder.layers.6.mlp.fc2.bias', 'model.encoder.layers.6.layer_norm2.weight', 'model.encoder.layers.6.layer_norm2.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.layer_norm1.weight', 'model.encoder.layers.7.layer_norm1.bias', 'model.encoder.layers.7.mlp.fc1.weight', 'model.encoder.layers.7.mlp.fc1.bias', 'model.encoder.layers.7.mlp.fc2.weight', 'model.encoder.layers.7.mlp.fc2.bias', 'model.encoder.layers.7.layer_norm2.weight', 'model.encoder.layers.7.layer_norm2.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.layer_norm1.weight', 'model.encoder.layers.8.layer_norm1.bias', 'model.encoder.layers.8.mlp.fc1.weight', 'model.encoder.layers.8.mlp.fc1.bias', 'model.encoder.layers.8.mlp.fc2.weight', 'model.encoder.layers.8.mlp.fc2.bias', 'model.encoder.layers.8.layer_norm2.weight', 'model.encoder.layers.8.layer_norm2.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.layer_norm1.weight', 'model.encoder.layers.9.layer_norm1.bias', 'model.encoder.layers.9.mlp.fc1.weight', 'model.encoder.layers.9.mlp.fc1.bias', 'model.encoder.layers.9.mlp.fc2.weight', 'model.encoder.layers.9.mlp.fc2.bias', 'model.encoder.layers.9.layer_norm2.weight', 'model.encoder.layers.9.layer_norm2.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.layer_norm1.weight', 'model.encoder.layers.10.layer_norm1.bias', 'model.encoder.layers.10.mlp.fc1.weight', 'model.encoder.layers.10.mlp.fc1.bias', 'model.encoder.layers.10.mlp.fc2.weight', 'model.encoder.layers.10.mlp.fc2.bias', 'model.encoder.layers.10.layer_norm2.weight', 'model.encoder.layers.10.layer_norm2.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.layer_norm1.weight', 'model.encoder.layers.11.layer_norm1.bias', 'model.encoder.layers.11.mlp.fc1.weight', 'model.encoder.layers.11.mlp.fc1.bias', 'model.encoder.layers.11.mlp.fc2.weight', 'model.encoder.layers.11.mlp.fc2.bias', 'model.encoder.layers.11.layer_norm2.weight', 'model.encoder.layers.11.layer_norm2.bias', 'model.post_layernorm.weight', 'model.post_layernorm.bias', 'classifier.weight', 'classifier.bias']
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - [36mModel[0m
OpenClipViT(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (position_embedding): Embedding(197, 768)
    )
    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-11): 12 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=174, bias=True)
)
[31m=================================================================[0m
                        OpenClipViT Summary
[31m=================================================================[0m
Total parameters     =   85.933 M
Total trainable parameters =   85.933 M

2024-07-27 09:29:07 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                 | #parameters or shape   | #flops    |
|:---------------------------------------|:-----------------------|:----------|
| model                                  | 85.933M                | 17.582G   |
|  neural_augmentor                      |  6                     |           |
|   neural_augmentor.brightness          |   2                    |           |
|    neural_augmentor.brightness._low    |    ()                  |           |
|    neural_augmentor.brightness._high   |    ()                  |           |
|   neural_augmentor.contrast            |   2                    |           |
|    neural_augmentor.contrast._low      |    ()                  |           |
|    neural_augmentor.contrast._high     |    ()                  |           |
|   neural_augmentor.noise               |   2                    |           |
|    neural_augmentor.noise._low         |    ()                  |           |
|    neural_augmentor.noise._high        |    ()                  |           |
|  model                                 |  85.799M               |  17.582G  |
|   model.embeddings                     |   0.742M               |   0.116G  |
|    model.embeddings.class_embedding    |    (768,)              |           |
|    model.embeddings.patch_embedding    |    0.59M               |    0.116G |
|    model.embeddings.position_embedding |    0.151M              |    0      |
|   model.pre_layrnorm                   |   1.536K               |   0.756M  |
|    model.pre_layrnorm.weight           |    (768,)              |           |
|    model.pre_layrnorm.bias             |    (768,)              |           |
|   model.encoder.layers                 |   85.054M              |   17.466G |
|    model.encoder.layers.0              |    7.088M              |    1.455G |
|    model.encoder.layers.1              |    7.088M              |    1.455G |
|    model.encoder.layers.2              |    7.088M              |    1.455G |
|    model.encoder.layers.3              |    7.088M              |    1.455G |
|    model.encoder.layers.4              |    7.088M              |    1.455G |
|    model.encoder.layers.5              |    7.088M              |    1.455G |
|    model.encoder.layers.6              |    7.088M              |    1.455G |
|    model.encoder.layers.7              |    7.088M              |    1.455G |
|    model.encoder.layers.8              |    7.088M              |    1.455G |
|    model.encoder.layers.9              |    7.088M              |    1.455G |
|    model.encoder.layers.10             |    7.088M              |    1.455G |
|    model.encoder.layers.11             |    7.088M              |    1.455G |
|   model.post_layernorm                 |   1.536K               |           |
|    model.post_layernorm.weight         |    (768,)              |           |
|    model.post_layernorm.bias           |    (768,)              |           |
|  classifier                            |  0.134M                |  0.134M   |
|   classifier.weight                    |   (174, 768)           |           |
|   classifier.bias                      |   (174,)               |           |
2024-07-27 09:29:07 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-27 09:29:07 - [33m[1mWARNING[0m - Uncalled Modules:
{'neural_augmentor.contrast.min_fn', 'neural_augmentor.noise.min_fn', 'neural_augmentor', 'neural_augmentor.brightness', 'neural_augmentor.brightness.max_fn', 'neural_augmentor.noise.max_fn', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.noise', 'model.post_layernorm', 'neural_augmentor.contrast.max_fn', 'neural_augmentor.contrast'}
2024-07-27 09:29:07 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::embedding': 1, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-27 09:29:07 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-27 09:29:08 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-27 09:29:08 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train
2024-07-27 09:29:13 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:30001
174
2024-07-27 09:29:13 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:30001
174
2024-07-27 09:29:13 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:30001
174
2024-07-27 09:29:13 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:30001
2024-07-27 09:29:18 - [34m[1mLOGS   [0m - Training dataset details are given below
food172ingredient_lassification(
	root=/ML-A100/team/mm/models/food101/food101 
	is_training=True 
	num_samples=75750
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-27 09:29:18 - [34m[1mLOGS   [0m - Validation dataset details are given below
food172ingredient_lassification(
	root=/ML-A100/team/mm/models/food101/food101 
	is_training=False 
	num_samples=25250
	transforms=Compose(
			Resize(size=224, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-27 09:29:18 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=32
	 scales=[(224, 224, 32)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-27 09:29:18 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=50
	 scales=[(224, 224, 50)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-27 09:29:18 - [34m[1mLOGS   [0m - Number of data workers: 64
174
2024-07-27 09:29:27 - [32m[1mINFO   [0m - Trainable parameters: ['neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'model.embeddings.class_embedding', 'model.embeddings.patch_embedding.weight', 'model.embeddings.position_embedding.weight', 'model.pre_layrnorm.weight', 'model.pre_layrnorm.bias', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.layer_norm1.weight', 'model.encoder.layers.0.layer_norm1.bias', 'model.encoder.layers.0.mlp.fc1.weight', 'model.encoder.layers.0.mlp.fc1.bias', 'model.encoder.layers.0.mlp.fc2.weight', 'model.encoder.layers.0.mlp.fc2.bias', 'model.encoder.layers.0.layer_norm2.weight', 'model.encoder.layers.0.layer_norm2.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.1.layer_norm1.weight', 'model.encoder.layers.1.layer_norm1.bias', 'model.encoder.layers.1.mlp.fc1.weight', 'model.encoder.layers.1.mlp.fc1.bias', 'model.encoder.layers.1.mlp.fc2.weight', 'model.encoder.layers.1.mlp.fc2.bias', 'model.encoder.layers.1.layer_norm2.weight', 'model.encoder.layers.1.layer_norm2.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.2.layer_norm1.weight', 'model.encoder.layers.2.layer_norm1.bias', 'model.encoder.layers.2.mlp.fc1.weight', 'model.encoder.layers.2.mlp.fc1.bias', 'model.encoder.layers.2.mlp.fc2.weight', 'model.encoder.layers.2.mlp.fc2.bias', 'model.encoder.layers.2.layer_norm2.weight', 'model.encoder.layers.2.layer_norm2.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.3.layer_norm1.weight', 'model.encoder.layers.3.layer_norm1.bias', 'model.encoder.layers.3.mlp.fc1.weight', 'model.encoder.layers.3.mlp.fc1.bias', 'model.encoder.layers.3.mlp.fc2.weight', 'model.encoder.layers.3.mlp.fc2.bias', 'model.encoder.layers.3.layer_norm2.weight', 'model.encoder.layers.3.layer_norm2.bias', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.4.layer_norm1.weight', 'model.encoder.layers.4.layer_norm1.bias', 'model.encoder.layers.4.mlp.fc1.weight', 'model.encoder.layers.4.mlp.fc1.bias', 'model.encoder.layers.4.mlp.fc2.weight', 'model.encoder.layers.4.mlp.fc2.bias', 'model.encoder.layers.4.layer_norm2.weight', 'model.encoder.layers.4.layer_norm2.bias', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.5.layer_norm1.weight', 'model.encoder.layers.5.layer_norm1.bias', 'model.encoder.layers.5.mlp.fc1.weight', 'model.encoder.layers.5.mlp.fc1.bias', 'model.encoder.layers.5.mlp.fc2.weight', 'model.encoder.layers.5.mlp.fc2.bias', 'model.encoder.layers.5.layer_norm2.weight', 'model.encoder.layers.5.layer_norm2.bias', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.6.layer_norm1.weight', 'model.encoder.layers.6.layer_norm1.bias', 'model.encoder.layers.6.mlp.fc1.weight', 'model.encoder.layers.6.mlp.fc1.bias', 'model.encoder.layers.6.mlp.fc2.weight', 'model.encoder.layers.6.mlp.fc2.bias', 'model.encoder.layers.6.layer_norm2.weight', 'model.encoder.layers.6.layer_norm2.bias', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.layer_norm1.weight', 'model.encoder.layers.7.layer_norm1.bias', 'model.encoder.layers.7.mlp.fc1.weight', 'model.encoder.layers.7.mlp.fc1.bias', 'model.encoder.layers.7.mlp.fc2.weight', 'model.encoder.layers.7.mlp.fc2.bias', 'model.encoder.layers.7.layer_norm2.weight', 'model.encoder.layers.7.layer_norm2.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.8.layer_norm1.weight', 'model.encoder.layers.8.layer_norm1.bias', 'model.encoder.layers.8.mlp.fc1.weight', 'model.encoder.layers.8.mlp.fc1.bias', 'model.encoder.layers.8.mlp.fc2.weight', 'model.encoder.layers.8.mlp.fc2.bias', 'model.encoder.layers.8.layer_norm2.weight', 'model.encoder.layers.8.layer_norm2.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.9.layer_norm1.weight', 'model.encoder.layers.9.layer_norm1.bias', 'model.encoder.layers.9.mlp.fc1.weight', 'model.encoder.layers.9.mlp.fc1.bias', 'model.encoder.layers.9.mlp.fc2.weight', 'model.encoder.layers.9.mlp.fc2.bias', 'model.encoder.layers.9.layer_norm2.weight', 'model.encoder.layers.9.layer_norm2.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.10.layer_norm1.weight', 'model.encoder.layers.10.layer_norm1.bias', 'model.encoder.layers.10.mlp.fc1.weight', 'model.encoder.layers.10.mlp.fc1.bias', 'model.encoder.layers.10.mlp.fc2.weight', 'model.encoder.layers.10.mlp.fc2.bias', 'model.encoder.layers.10.layer_norm2.weight', 'model.encoder.layers.10.layer_norm2.bias', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.layer_norm1.weight', 'model.encoder.layers.11.layer_norm1.bias', 'model.encoder.layers.11.mlp.fc1.weight', 'model.encoder.layers.11.mlp.fc1.bias', 'model.encoder.layers.11.mlp.fc2.weight', 'model.encoder.layers.11.mlp.fc2.bias', 'model.encoder.layers.11.layer_norm2.weight', 'model.encoder.layers.11.layer_norm2.bias', 'model.post_layernorm.weight', 'model.post_layernorm.bias', 'classifier.weight', 'classifier.bias']
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - [36mModel[0m
OpenClipViT(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (position_embedding): Embedding(197, 768)
    )
    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-11): 12 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
          )
          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=174, bias=True)
)
[31m=================================================================[0m
                        OpenClipViT Summary
[31m=================================================================[0m
Total parameters     =   85.933 M
Total trainable parameters =   85.933 M

2024-07-27 09:29:27 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                 | #parameters or shape   | #flops    |
|:---------------------------------------|:-----------------------|:----------|
| model                                  | 85.933M                | 17.582G   |
|  neural_augmentor                      |  6                     |           |
|   neural_augmentor.brightness          |   2                    |           |
|    neural_augmentor.brightness._low    |    ()                  |           |
|    neural_augmentor.brightness._high   |    ()                  |           |
|   neural_augmentor.contrast            |   2                    |           |
|    neural_augmentor.contrast._low      |    ()                  |           |
|    neural_augmentor.contrast._high     |    ()                  |           |
|   neural_augmentor.noise               |   2                    |           |
|    neural_augmentor.noise._low         |    ()                  |           |
|    neural_augmentor.noise._high        |    ()                  |           |
|  model                                 |  85.799M               |  17.582G  |
|   model.embeddings                     |   0.742M               |   0.116G  |
|    model.embeddings.class_embedding    |    (768,)              |           |
|    model.embeddings.patch_embedding    |    0.59M               |    0.116G |
|    model.embeddings.position_embedding |    0.151M              |    0      |
|   model.pre_layrnorm                   |   1.536K               |   0.756M  |
|    model.pre_layrnorm.weight           |    (768,)              |           |
|    model.pre_layrnorm.bias             |    (768,)              |           |
|   model.encoder.layers                 |   85.054M              |   17.466G |
|    model.encoder.layers.0              |    7.088M              |    1.455G |
|    model.encoder.layers.1              |    7.088M              |    1.455G |
|    model.encoder.layers.2              |    7.088M              |    1.455G |
|    model.encoder.layers.3              |    7.088M              |    1.455G |
|    model.encoder.layers.4              |    7.088M              |    1.455G |
|    model.encoder.layers.5              |    7.088M              |    1.455G |
|    model.encoder.layers.6              |    7.088M              |    1.455G |
|    model.encoder.layers.7              |    7.088M              |    1.455G |
|    model.encoder.layers.8              |    7.088M              |    1.455G |
|    model.encoder.layers.9              |    7.088M              |    1.455G |
|    model.encoder.layers.10             |    7.088M              |    1.455G |
|    model.encoder.layers.11             |    7.088M              |    1.455G |
|   model.post_layernorm                 |   1.536K               |           |
|    model.post_layernorm.weight         |    (768,)              |           |
|    model.post_layernorm.bias           |    (768,)              |           |
|  classifier                            |  0.134M                |  0.134M   |
|   classifier.weight                    |   (174, 768)           |           |
|   classifier.bias                      |   (174,)               |           |
2024-07-27 09:29:27 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-27 09:29:27 - [33m[1mWARNING[0m - Uncalled Modules:
{'model.post_layernorm', 'neural_augmentor.noise.max_fn', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.contrast', 'neural_augmentor', 'neural_augmentor.brightness', 'neural_augmentor.contrast.min_fn', 'neural_augmentor.brightness.max_fn', 'neural_augmentor.noise.min_fn', 'neural_augmentor.noise', 'neural_augmentor.contrast.max_fn'}
2024-07-27 09:29:27 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::mul': 48, 'aten::add': 25, 'aten::softmax': 12, 'aten::sigmoid': 12, 'aten::embedding': 1, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	BinaryCrossEntropy(  reduction=batch_mean loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - Max. epochs for training: 60
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=1e-06
 	 max_lr=1e-05
 	 period=60
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-27 09:29:27 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt'
2024-07-27 09:29:27 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-27 09:29:29 - [32m[1mINFO   [0m - Training epoch 0
2024-07-27 09:32:43 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'classification': 121.3117, 'neural_augmentation': 10.1256, 'total_loss': 131.4374}, LR: [1e-06, 1e-06], Avg. batch load time: 191.677, Elapsed time: 194.08
2024-07-27 09:33:21 - [34m[1mLOGS   [0m - Epoch:   0 [     501/10000000], loss: {'classification': 32.7682, 'neural_augmentation': 10.8105, 'total_loss': 43.5787}, LR: [1e-05, 1e-05], Avg. batch load time: 0.383, Elapsed time: 232.04
2024-07-27 09:33:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 30.8039, 'neural_augmentation': 10.8155, 'total_loss': 41.6194}
2024-07-27 09:36:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 18.3386, 'neural_augmentation': 0.0, 'total_loss': 18.3386} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3116, 0.1591, 0.352, 0.1667, 0.0781, 0.5442, 0.3293, 0.2521, 0.4388, 0.4322, 0.1224, 0.4383, 0.1964, 0.3054, 0.1727, 0.1787, 0.4007, 0.5749, 0.1194, 0.3531, 0.1605, 0.1973, 0.1098, 0.3743, 0.381, 0.3098, 0.3358, 0.1867, 0.5201, 0.167, 0.1717, 0.0561, 0.0865, 0.1976, 0.3073, 0.1511, 0.2908, 0.534, 0.3087, 0.0891, 0.7336, 0.1534, 0.254, 0.7775, 0.1422, 0.6488, 0.3098, 0.1223, 0.2339, 0.1938, 0.133, 0.212, 0.4038, 0.3175, 0.3127, 0.4917, 0.6146, 0.1925, 0.2752, 0.0226, 0.1372, 0.27, 0.0834, 0.3909, 0.2881, 0.1485, 0.1548, 0.533, 0.2807, 0.1514, 0.1166, 0.1044, 0.2624, 0.4221, 0.1823, 0.2839, 0.2412, 0.3925, 0.4477, 0.2777, 0.4146, 0.0754, 0.4655, 0.1352, 0.5419, 0.4713, 0.4865, 0.1266, 0.3253, 0.2415, 0.5759, 0.0888, 0.1433, 0.3393, 0.1402, 0.3655, 0.1505, 0.0872, 0.4069, 0.2017, 0.3443, 0.3387, 0.4615, 0.2878, 0.8098, 0.3226, 0.4192, 0.0435, 0.4048, 0.1739, 0.2584, 0.3274, 0.6092, 0.2742, 0.1289, 0.3661, 0.0547, 0.5957, 0.149, 0.7761, 0.3476, 0.2978, 0.2741, 0.6578, 0.5134, 0.0331, 0.4429, 0.3535, 0.1166, 0.1693, 0.0881, 0.1474, 0.0809, 0.11, 0.3899, 0.7699, 0.1514, 0.7881, 0.3727, 0.1775, 0.0748, 0.1242, 0.3478, 0.4238, 0.2638, 0.3764, 0.6043, 0.3153, 0.1264, 0.5494, 0.2008, 0.1821, 0.2599, 0.7843, 0.1582, 0.1678, 0.1982, 0.2564, 0.2198, 0.0795, 0.4576, 0.1907, 0.1402, 0.3805, 0.231, 0.1656, 0.3943, 0.2568, 0.4498, 0.2291, 0.0496, 0.2337, 0.5969, 0.2335], 'AP': [0.2387, 0.077, 0.2794, 0.0875, 0.0308, 0.4917, 0.2705, 0.1651, 0.4067, 0.4114, 0.0584, 0.4462, 0.1103, 0.2303, 0.1011, 0.1167, 0.381, 0.5811, 0.0476, 0.2754, 0.0756, 0.1067, 0.045, 0.3524, 0.3324, 0.2589, 0.266, 0.1147, 0.5321, 0.1023, 0.08, 0.0253, 0.039, 0.1233, 0.2322, 0.0654, 0.1701, 0.5448, 0.269, 0.0383, 0.8173, 0.0675, 0.1325, 0.8399, 0.0722, 0.6881, 0.2728, 0.0574, 0.1496, 0.0956, 0.0554, 0.1934, 0.3881, 0.2908, 0.2669, 0.4997, 0.6541, 0.1209, 0.2113, 0.01, 0.0732, 0.1578, 0.0337, 0.34, 0.2261, 0.0761, 0.0636, 0.5632, 0.2001, 0.0667, 0.0599, 0.0548, 0.1646, 0.4123, 0.0912, 0.1956, 0.1451, 0.3384, 0.4014, 0.1919, 0.411, 0.0293, 0.4617, 0.0735, 0.5389, 0.479, 0.4926, 0.055, 0.3271, 0.1491, 0.6286, 0.0332, 0.0672, 0.3292, 0.0548, 0.3377, 0.0759, 0.0373, 0.4134, 0.1112, 0.3331, 0.2971, 0.4274, 0.2208, 0.8686, 0.2646, 0.3548, 0.0201, 0.4017, 0.0938, 0.1774, 0.2163, 0.6212, 0.2058, 0.0555, 0.3184, 0.0252, 0.612, 0.074, 0.8162, 0.2718, 0.1923, 0.2124, 0.7054, 0.5422, 0.0146, 0.3937, 0.301, 0.0544, 0.0809, 0.0356, 0.0731, 0.0351, 0.0484, 0.3212, 0.8337, 0.0884, 0.8474, 0.3008, 0.0869, 0.0335, 0.06, 0.3354, 0.3956, 0.1872, 0.3351, 0.613, 0.2684, 0.0617, 0.4722, 0.1208, 0.1198, 0.1769, 0.8291, 0.084, 0.0851, 0.1135, 0.1641, 0.1424, 0.0333, 0.4029, 0.0992, 0.0735, 0.3324, 0.1142, 0.0818, 0.3712, 0.1641, 0.4485, 0.1078, 0.0184, 0.1254, 0.5827, 0.1264], 'Recall@P=50': [0.0013, 0.0, 0.0046, 0.004, 0.0, 0.584, 0.0824, 0.012, 0.348, 0.0003, 0.0, 0.3536, 0.004, 0.002, 0.0, 0.008, 0.3304, 0.616, 0.0, 0.008, 0.004, 0.0, 0.0, 0.2088, 0.2733, 0.084, 0.016, 0.0, 0.5138, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0125, 0.0, 0.0, 0.5143, 0.124, 0.0, 0.868, 0.0, 0.0, 0.888, 0.0, 0.708, 0.1627, 0.004, 0.0013, 0.0, 0.0, 0.0884, 0.338, 0.1577, 0.186, 0.4713, 0.744, 0.036, 0.004, 0.0, 0.0, 0.0, 0.0, 0.128, 0.042, 0.002, 0.0, 0.5573, 0.006, 0.0, 0.0, 0.002, 0.0, 0.3344, 0.0, 0.032, 0.0, 0.004, 0.396, 0.004, 0.2926, 0.0, 0.3308, 0.012, 0.588, 0.426, 0.4313, 0.0, 0.1835, 0.008, 0.67, 0.0, 0.008, 0.2184, 0.0, 0.1618, 0.0, 0.004, 0.332, 0.004, 0.2194, 0.174, 0.428, 0.0547, 0.912, 0.0537, 0.35, 0.0, 0.2856, 0.0, 0.016, 0.012, 0.7617, 0.06, 0.0, 0.2493, 0.0, 0.6627, 0.0, 0.86, 0.086, 0.0013, 0.004, 0.72, 0.504, 0.0, 0.388, 0.172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2447, 0.892, 0.0027, 0.904, 0.0167, 0.004, 0.0, 0.0, 0.216, 0.363, 0.0064, 0.244, 0.7628, 0.0013, 0.0, 0.466, 0.012, 0.016, 0.004, 0.896, 0.002, 0.0, 0.0, 0.001, 0.02, 0.0, 0.323, 0.0, 0.004, 0.0948, 0.0, 0.0, 0.266, 0.004, 0.372, 0.0, 0.0, 0.0, 0.0001, 0.016], 'micro': 0.3496, 'macro': 0.2468, 'weighted': 0.3744}
2024-07-27 09:36:57 - [34m[1mLOGS   [0m - Best checkpoint with score 0.25 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:36:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:36:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:36:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 592 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_0_iter_592.pt
2024-07-27 09:37:00 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 592 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_0_iter_592.pt
[31m===========================================================================[0m
2024-07-27 09:37:02 - [32m[1mINFO   [0m - Training epoch 1
2024-07-27 09:37:03 - [34m[1mLOGS   [0m - Epoch:   1 [     593/10000000], loss: {'classification': 19.6469, 'neural_augmentation': 10.1294, 'total_loss': 29.7763}, LR: [1e-05, 1e-05], Avg. batch load time: 0.410, Elapsed time:  0.52
2024-07-27 09:37:40 - [34m[1mLOGS   [0m - Epoch:   1 [    1093/10000000], loss: {'classification': 17.3644, 'neural_augmentation': 10.856, 'total_loss': 28.2204}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.46
2024-07-27 09:37:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 17.0732, 'neural_augmentation': 10.8521, 'total_loss': 27.9253}
2024-07-27 09:38:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 10.6063, 'neural_augmentation': 0.0, 'total_loss': 10.6063} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6317, 0.7193, 0.6126, 0.7323, 0.4411, 0.8898, 0.626, 0.5746, 0.7272, 0.6868, 0.4548, 0.6903, 0.4591, 0.7654, 0.5751, 0.8419, 0.8422, 0.8827, 0.645, 0.7149, 0.6358, 0.4744, 0.6667, 0.7947, 0.6875, 0.6401, 0.7183, 0.7679, 0.7092, 0.5301, 0.4298, 0.3939, 0.6393, 0.7752, 0.6606, 0.6681, 0.788, 0.7418, 0.7274, 0.5981, 0.9798, 0.5331, 0.7714, 0.8805, 0.7933, 0.893, 0.5911, 0.774, 0.5409, 0.814, 0.3846, 0.5608, 0.7398, 0.6389, 0.8017, 0.7628, 0.9346, 0.6333, 0.74, 0.3974, 0.5155, 0.6242, 0.6939, 0.7205, 0.5685, 0.5294, 0.7991, 0.8536, 0.861, 0.2931, 0.6842, 0.5022, 0.8089, 0.7276, 0.7059, 0.5039, 0.5538, 0.7051, 0.8032, 0.8675, 0.6696, 0.8053, 0.6766, 0.4254, 0.8466, 0.8574, 0.684, 0.6527, 0.6204, 0.8092, 0.917, 0.2822, 0.5861, 0.6337, 0.6637, 0.6922, 0.7623, 0.3315, 0.6314, 0.5661, 0.6504, 0.6888, 0.7991, 0.6213, 0.8884, 0.6559, 0.8851, 0.4803, 0.7119, 0.756, 0.5976, 0.8667, 0.7723, 0.6359, 0.3859, 0.7534, 0.3303, 0.811, 0.6395, 0.8884, 0.75, 0.5929, 0.7975, 0.8945, 0.745, 0.4424, 0.8118, 0.7199, 0.554, 0.4784, 0.3815, 0.7712, 0.7821, 0.7038, 0.7595, 0.8921, 0.4652, 0.8861, 0.5461, 0.6112, 0.668, 0.5759, 0.7068, 0.6866, 0.6847, 0.8879, 0.7547, 0.6475, 0.7285, 0.7331, 0.449, 0.4307, 0.6227, 0.8737, 0.7322, 0.4806, 0.5743, 0.6103, 0.8129, 0.6189, 0.6443, 0.7191, 0.4654, 0.689, 0.7343, 0.5548, 0.7613, 0.7318, 0.783, 0.7223, 0.3538, 0.8176, 0.7491, 0.5085], 'AP': [0.6681, 0.7749, 0.6629, 0.7613, 0.3758, 0.9428, 0.6676, 0.579, 0.7945, 0.7482, 0.4522, 0.7619, 0.4296, 0.8326, 0.5983, 0.8878, 0.8972, 0.9406, 0.6648, 0.7703, 0.6638, 0.4805, 0.7112, 0.8632, 0.7354, 0.7009, 0.7594, 0.8319, 0.7933, 0.5413, 0.4011, 0.3266, 0.6533, 0.8223, 0.7126, 0.6981, 0.8522, 0.8239, 0.7919, 0.6029, 0.9929, 0.558, 0.8336, 0.9415, 0.8404, 0.9383, 0.6695, 0.8046, 0.5549, 0.8643, 0.3418, 0.5993, 0.7916, 0.6904, 0.8696, 0.8349, 0.9613, 0.6986, 0.783, 0.3648, 0.5134, 0.6269, 0.7116, 0.7561, 0.6136, 0.5421, 0.8622, 0.9109, 0.9131, 0.2039, 0.7001, 0.5113, 0.8755, 0.7835, 0.758, 0.4966, 0.5724, 0.7822, 0.8624, 0.9172, 0.7254, 0.8592, 0.7642, 0.4167, 0.9159, 0.9201, 0.7586, 0.711, 0.6636, 0.8549, 0.9634, 0.2222, 0.6324, 0.6784, 0.6865, 0.7593, 0.8021, 0.2462, 0.6873, 0.5521, 0.7086, 0.7531, 0.8287, 0.6719, 0.9383, 0.7296, 0.9324, 0.3903, 0.7717, 0.7896, 0.5976, 0.927, 0.8479, 0.6767, 0.3248, 0.8262, 0.2743, 0.8646, 0.6563, 0.9418, 0.8402, 0.6441, 0.8655, 0.9369, 0.8249, 0.4139, 0.883, 0.7716, 0.5641, 0.4683, 0.2834, 0.8224, 0.8594, 0.7637, 0.8305, 0.9448, 0.4599, 0.9446, 0.5898, 0.6447, 0.7213, 0.585, 0.7641, 0.7637, 0.7451, 0.9322, 0.8469, 0.7019, 0.7855, 0.776, 0.4117, 0.4049, 0.6595, 0.9322, 0.8072, 0.4745, 0.5606, 0.673, 0.8627, 0.635, 0.6865, 0.7569, 0.4205, 0.7787, 0.7745, 0.5427, 0.816, 0.8005, 0.8538, 0.7842, 0.3088, 0.872, 0.8346, 0.4975], 'Recall@P=50': [0.75, 0.832, 0.724, 0.78, 0.372, 0.968, 0.752, 0.568, 0.8816, 0.8286, 0.414, 0.8136, 0.388, 0.892, 0.626, 0.924, 0.9312, 0.964, 0.708, 0.844, 0.716, 0.434, 0.74, 0.9112, 0.7893, 0.7208, 0.804, 0.884, 0.8961, 0.5592, 0.364, 0.2, 0.676, 0.844, 0.7865, 0.76, 0.888, 0.9441, 0.837, 0.656, 0.996, 0.552, 0.892, 0.968, 0.88, 0.952, 0.6573, 0.816, 0.56, 0.88, 0.228, 0.5932, 0.834, 0.7509, 0.902, 0.856, 0.964, 0.728, 0.824, 0.276, 0.508, 0.696, 0.732, 0.828, 0.628, 0.544, 0.9, 0.944, 0.926, 0.004, 0.756, 0.484, 0.916, 0.8448, 0.788, 0.504, 0.548, 0.8373, 0.8933, 0.936, 0.7968, 0.896, 0.8524, 0.328, 0.964, 0.948, 0.8607, 0.752, 0.6957, 0.9, 0.978, 0.052, 0.68, 0.6672, 0.7, 0.788, 0.808, 0.016, 0.7087, 0.62, 0.7931, 0.788, 0.856, 0.7293, 0.98, 0.7683, 0.956, 0.34, 0.8272, 0.828, 0.64, 0.94, 0.9627, 0.72, 0.04, 0.8713, 0.004, 0.876, 0.804, 0.964, 0.902, 0.6667, 0.924, 0.952, 0.9297, 0.384, 0.928, 0.828, 0.584, 0.456, 0.008, 0.872, 0.9, 0.804, 0.8713, 0.976, 0.4333, 0.972, 0.592, 0.7, 0.764, 0.636, 0.848, 0.827, 0.8416, 0.948, 0.9742, 0.78, 0.828, 0.826, 0.398, 0.358, 0.6587, 0.972, 0.856, 0.444, 0.6, 0.67, 0.888, 0.696, 0.783, 0.812, 0.408, 0.835, 0.816, 0.552, 0.8707, 0.862, 0.908, 0.86, 0.252, 0.908, 0.9562, 0.488], 'micro': 0.7433, 'macro': 0.7082, 'weighted': 0.7496}
2024-07-27 09:38:13 - [34m[1mLOGS   [0m - Best checkpoint with score 0.71 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:38:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:38:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:38:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 1184 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_1_iter_1184.pt
2024-07-27 09:38:17 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 1184 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_1_iter_1184.pt
[31m===========================================================================[0m
2024-07-27 09:38:19 - [32m[1mINFO   [0m - Training epoch 2
2024-07-27 09:38:19 - [34m[1mLOGS   [0m - Epoch:   2 [    1185/10000000], loss: {'classification': 14.5909, 'neural_augmentation': 10.204, 'total_loss': 24.7949}, LR: [1e-05, 1e-05], Avg. batch load time: 0.643, Elapsed time:  0.73
2024-07-27 09:38:57 - [34m[1mLOGS   [0m - Epoch:   2 [    1685/10000000], loss: {'classification': 14.0297, 'neural_augmentation': 10.795, 'total_loss': 24.8247}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.56
2024-07-27 09:39:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 13.8591, 'neural_augmentation': 10.774, 'total_loss': 24.6331}
2024-07-27 09:39:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 7.5882, 'neural_augmentation': 0.0, 'total_loss': 7.5882} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.7889, 0.7898, 0.73, 0.8866, 0.6476, 0.9148, 0.7569, 0.7453, 0.7964, 0.7529, 0.5847, 0.757, 0.5602, 0.8367, 0.721, 0.9065, 0.8977, 0.9493, 0.8034, 0.8153, 0.7941, 0.6025, 0.795, 0.8627, 0.8179, 0.7785, 0.8148, 0.8912, 0.8011, 0.7563, 0.6362, 0.5667, 0.7366, 0.8602, 0.7559, 0.7489, 0.8703, 0.8039, 0.8052, 0.7593, 0.9899, 0.6567, 0.8537, 0.9225, 0.8633, 0.9165, 0.6823, 0.8475, 0.6362, 0.8661, 0.6239, 0.7283, 0.8955, 0.7501, 0.8779, 0.8323, 0.949, 0.8008, 0.8302, 0.5906, 0.6653, 0.6611, 0.8337, 0.8096, 0.6978, 0.6454, 0.9153, 0.9024, 0.9006, 0.4008, 0.8333, 0.6907, 0.8963, 0.8124, 0.7815, 0.6394, 0.7404, 0.7805, 0.8667, 0.8937, 0.7584, 0.9087, 0.7796, 0.6501, 0.9044, 0.8866, 0.7901, 0.7846, 0.669, 0.8644, 0.942, 0.4526, 0.8056, 0.7242, 0.7931, 0.7833, 0.9121, 0.565, 0.7213, 0.7174, 0.7468, 0.7916, 0.8578, 0.7356, 0.9218, 0.7844, 0.9383, 0.6574, 0.825, 0.8406, 0.7566, 0.9121, 0.8383, 0.7297, 0.4952, 0.838, 0.572, 0.8635, 0.7636, 0.9289, 0.8458, 0.7346, 0.8929, 0.9214, 0.8053, 0.6096, 0.8862, 0.8575, 0.7162, 0.6346, 0.46, 0.8619, 0.8944, 0.7967, 0.8354, 0.9196, 0.687, 0.9253, 0.7177, 0.7728, 0.7991, 0.6741, 0.8105, 0.8017, 0.8144, 0.9148, 0.8151, 0.7415, 0.8942, 0.8251, 0.5879, 0.6238, 0.7576, 0.9265, 0.8732, 0.6525, 0.6843, 0.7321, 0.8848, 0.7537, 0.7816, 0.8363, 0.6411, 0.7646, 0.8547, 0.6843, 0.8362, 0.8717, 0.8449, 0.8624, 0.6591, 0.8861, 0.8164, 0.6229], 'AP': [0.8652, 0.8489, 0.8078, 0.9341, 0.6525, 0.9558, 0.8167, 0.7883, 0.8724, 0.8277, 0.6343, 0.8465, 0.5325, 0.9093, 0.7845, 0.9371, 0.9481, 0.972, 0.827, 0.8721, 0.8388, 0.6478, 0.8622, 0.9328, 0.8687, 0.8441, 0.8745, 0.9415, 0.89, 0.8168, 0.6422, 0.5492, 0.7956, 0.921, 0.8246, 0.7877, 0.9281, 0.8886, 0.8753, 0.7993, 0.9945, 0.6951, 0.9153, 0.9704, 0.9225, 0.9517, 0.7643, 0.8843, 0.6818, 0.9232, 0.645, 0.7954, 0.9441, 0.8273, 0.9361, 0.9019, 0.9778, 0.8581, 0.888, 0.6276, 0.7037, 0.7173, 0.8781, 0.8746, 0.7706, 0.6903, 0.9633, 0.9517, 0.9446, 0.3859, 0.8409, 0.7383, 0.9377, 0.8732, 0.8451, 0.68, 0.7845, 0.8676, 0.9237, 0.9443, 0.8382, 0.9633, 0.8694, 0.6732, 0.9576, 0.9476, 0.8715, 0.8484, 0.738, 0.916, 0.9784, 0.4017, 0.8603, 0.8045, 0.8203, 0.8632, 0.9508, 0.5966, 0.8091, 0.763, 0.8318, 0.8519, 0.8842, 0.8062, 0.9676, 0.8584, 0.963, 0.6893, 0.8898, 0.9095, 0.7988, 0.9553, 0.9193, 0.8119, 0.495, 0.9066, 0.5366, 0.9335, 0.8186, 0.9664, 0.907, 0.8114, 0.9408, 0.9521, 0.8892, 0.6318, 0.9183, 0.9115, 0.7634, 0.6886, 0.374, 0.9219, 0.9552, 0.86, 0.8962, 0.967, 0.717, 0.968, 0.7944, 0.8222, 0.855, 0.7243, 0.8593, 0.8709, 0.892, 0.9568, 0.9065, 0.8187, 0.9401, 0.8731, 0.6074, 0.6587, 0.8073, 0.9656, 0.9344, 0.6828, 0.7255, 0.8136, 0.929, 0.8036, 0.8634, 0.8889, 0.6779, 0.8559, 0.8993, 0.7244, 0.8959, 0.9216, 0.9053, 0.9283, 0.6766, 0.9254, 0.9027, 0.6691], 'Recall@P=50': [0.9147, 0.888, 0.8777, 0.96, 0.652, 0.968, 0.88, 0.844, 0.9464, 0.8978, 0.634, 0.9268, 0.616, 0.956, 0.85, 0.964, 0.968, 0.98, 0.836, 0.916, 0.892, 0.69, 0.892, 0.9624, 0.9, 0.8824, 0.904, 0.972, 0.9586, 0.8712, 0.672, 0.584, 0.856, 0.948, 0.8885, 0.836, 0.952, 0.9796, 0.905, 0.924, 0.996, 0.776, 0.952, 0.984, 0.936, 0.96, 0.8147, 0.896, 0.744, 0.944, 0.704, 0.8389, 0.968, 0.896, 0.95, 0.9313, 0.984, 0.888, 0.932, 0.648, 0.776, 0.768, 0.908, 0.916, 0.8447, 0.724, 0.98, 0.972, 0.954, 0.316, 0.924, 0.766, 0.96, 0.924, 0.888, 0.708, 0.828, 0.9253, 0.9467, 0.956, 0.8937, 0.984, 0.9422, 0.728, 0.99, 0.976, 0.9556, 0.896, 0.7504, 0.952, 0.992, 0.336, 0.904, 0.8432, 0.84, 0.9091, 0.964, 0.612, 0.8673, 0.848, 0.9074, 0.892, 0.9, 0.8707, 0.984, 0.9087, 0.978, 0.764, 0.9272, 0.928, 0.864, 0.972, 0.9867, 0.858, 0.452, 0.9427, 0.64, 0.9687, 0.884, 0.98, 0.946, 0.864, 0.96, 0.96, 0.9677, 0.64, 0.964, 0.936, 0.788, 0.728, 0.024, 0.944, 0.984, 0.896, 0.926, 0.988, 0.796, 0.984, 0.875, 0.88, 0.884, 0.752, 0.904, 0.9, 0.944, 0.972, 0.9912, 0.9027, 0.972, 0.892, 0.682, 0.702, 0.844, 0.984, 0.962, 0.712, 0.776, 0.861, 0.944, 0.904, 0.928, 0.94, 0.696, 0.9215, 0.924, 0.756, 0.93, 0.95, 0.936, 0.944, 0.684, 0.948, 0.9835, 0.688], 'micro': 0.8552, 'macro': 0.8327, 'weighted': 0.8572}
2024-07-27 09:39:30 - [34m[1mLOGS   [0m - Best checkpoint with score 0.83 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:39:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:39:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:39:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 1776 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_2_iter_1776.pt
2024-07-27 09:39:34 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 1776 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_2_iter_1776.pt
[31m===========================================================================[0m
2024-07-27 09:39:36 - [32m[1mINFO   [0m - Training epoch 3
2024-07-27 09:39:37 - [34m[1mLOGS   [0m - Epoch:   3 [    1777/10000000], loss: {'classification': 11.1364, 'neural_augmentation': 10.3238, 'total_loss': 21.4603}, LR: [1e-05, 1e-05], Avg. batch load time: 0.606, Elapsed time:  0.69
2024-07-27 09:40:15 - [34m[1mLOGS   [0m - Epoch:   3 [    2277/10000000], loss: {'classification': 12.3951, 'neural_augmentation': 10.7938, 'total_loss': 23.1889}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.70
2024-07-27 09:40:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 12.2986, 'neural_augmentation': 10.7962, 'total_loss': 23.0948}
2024-07-27 09:40:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 5.9283, 'neural_augmentation': 0.0, 'total_loss': 5.9283} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.864, 0.8197, 0.7976, 0.9339, 0.7422, 0.9315, 0.809, 0.8025, 0.8576, 0.7979, 0.7149, 0.8291, 0.6403, 0.8794, 0.7942, 0.9028, 0.9294, 0.9616, 0.8425, 0.8724, 0.8358, 0.6872, 0.8512, 0.9011, 0.8537, 0.8402, 0.882, 0.9098, 0.8402, 0.8167, 0.6696, 0.6257, 0.8061, 0.8848, 0.8024, 0.8086, 0.8893, 0.8549, 0.8496, 0.7802, 0.996, 0.7276, 0.8761, 0.9405, 0.8934, 0.9309, 0.7495, 0.8802, 0.7076, 0.8866, 0.7013, 0.7957, 0.9335, 0.8116, 0.9157, 0.8839, 0.9549, 0.8571, 0.8571, 0.6631, 0.7243, 0.7636, 0.8625, 0.8718, 0.7753, 0.6978, 0.9424, 0.9038, 0.9207, 0.5243, 0.8485, 0.7624, 0.9087, 0.8362, 0.8233, 0.7532, 0.8009, 0.8382, 0.9033, 0.9317, 0.811, 0.9407, 0.8369, 0.6966, 0.9131, 0.9034, 0.8452, 0.8388, 0.7277, 0.8802, 0.9459, 0.5434, 0.8469, 0.7853, 0.847, 0.8343, 0.94, 0.653, 0.7905, 0.8188, 0.8371, 0.8452, 0.875, 0.8084, 0.932, 0.8446, 0.9461, 0.721, 0.8759, 0.8753, 0.8142, 0.9347, 0.8701, 0.8064, 0.5605, 0.8609, 0.6823, 0.8997, 0.815, 0.9352, 0.8766, 0.7989, 0.9064, 0.9392, 0.8472, 0.6712, 0.8968, 0.8895, 0.7984, 0.7539, 0.5374, 0.8884, 0.9366, 0.8894, 0.8753, 0.9303, 0.7502, 0.9388, 0.8043, 0.8477, 0.8458, 0.7426, 0.8202, 0.8459, 0.8683, 0.9412, 0.8589, 0.8346, 0.9379, 0.8713, 0.6741, 0.7189, 0.8077, 0.9312, 0.9042, 0.749, 0.7672, 0.81, 0.8866, 0.7941, 0.8281, 0.8601, 0.696, 0.8404, 0.9045, 0.7568, 0.8483, 0.9204, 0.8608, 0.8986, 0.7328, 0.8996, 0.8569, 0.687], 'AP': [0.9243, 0.8855, 0.8656, 0.9692, 0.7802, 0.9803, 0.8773, 0.8549, 0.9308, 0.8752, 0.7733, 0.9071, 0.6512, 0.9424, 0.8611, 0.9535, 0.966, 0.983, 0.8869, 0.9263, 0.8889, 0.7616, 0.9165, 0.9564, 0.92, 0.9086, 0.9287, 0.9562, 0.9254, 0.8921, 0.7119, 0.6517, 0.8733, 0.9446, 0.8788, 0.8546, 0.9359, 0.9352, 0.9169, 0.8553, 0.9996, 0.776, 0.9326, 0.9767, 0.9338, 0.9634, 0.8291, 0.9162, 0.7593, 0.9261, 0.7507, 0.8699, 0.9776, 0.892, 0.9537, 0.9376, 0.9836, 0.9182, 0.9045, 0.7219, 0.7721, 0.8306, 0.9193, 0.9246, 0.8485, 0.7587, 0.979, 0.9601, 0.9587, 0.5506, 0.8813, 0.8333, 0.9556, 0.8988, 0.89, 0.79, 0.8511, 0.912, 0.9587, 0.9736, 0.8912, 0.9805, 0.9138, 0.7495, 0.963, 0.9594, 0.9222, 0.9082, 0.8129, 0.9374, 0.9821, 0.5566, 0.9102, 0.8692, 0.8829, 0.9144, 0.9745, 0.7106, 0.8705, 0.8902, 0.9069, 0.9039, 0.9079, 0.8718, 0.9755, 0.9167, 0.9741, 0.7627, 0.941, 0.9423, 0.861, 0.9755, 0.947, 0.8811, 0.5481, 0.9262, 0.6996, 0.9585, 0.8996, 0.9771, 0.9396, 0.8742, 0.9543, 0.9629, 0.9272, 0.7077, 0.9495, 0.9396, 0.8581, 0.8151, 0.5162, 0.9446, 0.9778, 0.9269, 0.9334, 0.9734, 0.8017, 0.9777, 0.8847, 0.8796, 0.9145, 0.7959, 0.9094, 0.9124, 0.9321, 0.9784, 0.9399, 0.8981, 0.9686, 0.921, 0.7365, 0.7728, 0.8693, 0.9761, 0.9546, 0.7983, 0.8276, 0.8859, 0.9272, 0.8697, 0.9114, 0.9113, 0.7515, 0.9185, 0.9369, 0.811, 0.9109, 0.9611, 0.9208, 0.9515, 0.7732, 0.942, 0.9357, 0.7384], 'Recall@P=50': [0.9553, 0.908, 0.9274, 0.98, 0.792, 0.996, 0.9392, 0.88, 0.9744, 0.9357, 0.8, 0.9628, 0.696, 0.976, 0.9, 0.972, 0.9792, 0.984, 0.9, 0.96, 0.92, 0.824, 0.928, 0.9816, 0.952, 0.9408, 0.964, 0.98, 0.9796, 0.9432, 0.736, 0.752, 0.932, 0.968, 0.926, 0.884, 0.96, 0.9916, 0.954, 0.944, 1.0, 0.876, 0.976, 0.988, 0.956, 0.968, 0.892, 0.924, 0.824, 0.948, 0.788, 0.9058, 0.992, 0.9451, 0.972, 0.956, 0.99, 0.944, 0.928, 0.784, 0.836, 0.876, 0.952, 0.952, 0.8973, 0.786, 0.988, 0.98, 0.962, 0.528, 0.948, 0.866, 0.968, 0.9456, 0.924, 0.846, 0.868, 0.9547, 0.976, 0.984, 0.9463, 0.996, 0.9706, 0.788, 0.99, 0.986, 0.9775, 0.936, 0.8461, 0.964, 0.988, 0.568, 0.952, 0.916, 0.884, 0.9615, 0.98, 0.76, 0.9233, 0.952, 0.948, 0.934, 0.932, 0.9307, 0.992, 0.9477, 0.984, 0.828, 0.9648, 0.972, 0.896, 0.992, 0.9934, 0.918, 0.62, 0.964, 0.828, 0.9847, 0.948, 0.988, 0.974, 0.926, 0.968, 0.976, 0.988, 0.744, 0.976, 0.9573, 0.932, 0.856, 0.004, 0.96, 0.992, 0.948, 0.9553, 0.988, 0.8573, 0.988, 0.9343, 0.924, 0.948, 0.84, 0.968, 0.949, 0.9608, 0.988, 0.996, 0.944, 0.98, 0.94, 0.832, 0.818, 0.9107, 0.992, 0.972, 0.832, 0.872, 0.927, 0.944, 0.94, 0.961, 0.936, 0.776, 0.9663, 0.956, 0.86, 0.9453, 0.972, 0.956, 0.972, 0.784, 0.96, 0.9938, 0.776], 'micro': 0.9065, 'macro': 0.8854, 'weighted': 0.9061}
2024-07-27 09:40:48 - [34m[1mLOGS   [0m - Best checkpoint with score 0.89 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:40:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:40:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:40:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 2368 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_3_iter_2368.pt
2024-07-27 09:40:52 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 2368 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_3_iter_2368.pt
[31m===========================================================================[0m
2024-07-27 09:40:54 - [32m[1mINFO   [0m - Training epoch 4
2024-07-27 09:40:54 - [34m[1mLOGS   [0m - Epoch:   4 [    2369/10000000], loss: {'classification': 11.6235, 'neural_augmentation': 9.6786, 'total_loss': 21.3021}, LR: [1e-05, 1e-05], Avg. batch load time: 0.570, Elapsed time:  0.65
2024-07-27 09:41:33 - [34m[1mLOGS   [0m - Epoch:   4 [    2869/10000000], loss: {'classification': 11.3913, 'neural_augmentation': 10.7616, 'total_loss': 22.1529}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.87
2024-07-27 09:41:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 11.315, 'neural_augmentation': 10.7617, 'total_loss': 22.0767}
2024-07-27 09:41:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 5.022, 'neural_augmentation': 0.0, 'total_loss': 5.022} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.8847, 0.8497, 0.8207, 0.9593, 0.8, 0.9407, 0.8344, 0.8148, 0.8926, 0.819, 0.7899, 0.851, 0.6947, 0.8989, 0.8285, 0.9256, 0.9448, 0.9655, 0.8716, 0.8988, 0.8851, 0.7269, 0.8661, 0.925, 0.8706, 0.8772, 0.8986, 0.9218, 0.8643, 0.8313, 0.7474, 0.7207, 0.8528, 0.9084, 0.8247, 0.8134, 0.9006, 0.8773, 0.8676, 0.7983, 0.996, 0.7346, 0.9072, 0.9499, 0.8958, 0.9508, 0.7512, 0.9031, 0.7279, 0.9, 0.7836, 0.8107, 0.9575, 0.8524, 0.9257, 0.8981, 0.9603, 0.8849, 0.876, 0.7146, 0.7383, 0.7638, 0.8907, 0.8849, 0.8113, 0.7513, 0.951, 0.9271, 0.9303, 0.605, 0.877, 0.834, 0.9062, 0.8751, 0.8566, 0.7639, 0.8306, 0.8722, 0.9218, 0.9336, 0.8426, 0.9551, 0.8677, 0.7742, 0.932, 0.9266, 0.8681, 0.8646, 0.757, 0.9137, 0.9611, 0.6055, 0.8743, 0.8171, 0.8739, 0.8698, 0.9535, 0.7017, 0.8313, 0.8319, 0.8636, 0.8482, 0.8889, 0.8163, 0.9455, 0.8677, 0.9514, 0.7751, 0.9026, 0.8898, 0.8316, 0.9412, 0.8897, 0.8222, 0.6031, 0.8828, 0.7269, 0.9163, 0.8276, 0.9444, 0.9041, 0.8371, 0.9047, 0.9491, 0.8643, 0.7427, 0.9167, 0.9078, 0.8404, 0.815, 0.5371, 0.8926, 0.9532, 0.9072, 0.8913, 0.9421, 0.786, 0.9438, 0.8352, 0.8625, 0.8742, 0.7723, 0.879, 0.8586, 0.9033, 0.9455, 0.8785, 0.849, 0.9482, 0.8778, 0.7666, 0.7675, 0.8315, 0.9432, 0.9327, 0.7742, 0.7863, 0.8432, 0.8994, 0.8017, 0.863, 0.8763, 0.7607, 0.8598, 0.9098, 0.7898, 0.878, 0.9259, 0.8907, 0.8913, 0.7805, 0.9139, 0.8752, 0.7639], 'AP': [0.9384, 0.9051, 0.8953, 0.9791, 0.8407, 0.9837, 0.9028, 0.883, 0.9531, 0.8976, 0.8441, 0.9255, 0.7257, 0.9617, 0.8922, 0.9624, 0.9756, 0.9857, 0.9091, 0.9334, 0.9425, 0.7985, 0.9267, 0.9685, 0.9263, 0.9337, 0.935, 0.9673, 0.9424, 0.8991, 0.7923, 0.7499, 0.9158, 0.946, 0.8954, 0.8627, 0.9434, 0.9497, 0.9366, 0.8601, 0.9997, 0.7977, 0.9554, 0.9825, 0.9434, 0.9768, 0.8391, 0.9341, 0.7885, 0.9388, 0.8233, 0.8915, 0.9861, 0.9221, 0.9716, 0.9484, 0.9869, 0.9394, 0.925, 0.7719, 0.8, 0.84, 0.9394, 0.9342, 0.8883, 0.8077, 0.9835, 0.9719, 0.9677, 0.6518, 0.9087, 0.8823, 0.9628, 0.9312, 0.9054, 0.8135, 0.8873, 0.9348, 0.9597, 0.9685, 0.9171, 0.9808, 0.9383, 0.8231, 0.9771, 0.9749, 0.9396, 0.9291, 0.8457, 0.9609, 0.9886, 0.6163, 0.9379, 0.8921, 0.9087, 0.94, 0.9814, 0.7568, 0.9002, 0.9021, 0.9315, 0.9152, 0.9248, 0.8891, 0.9813, 0.9354, 0.9761, 0.8258, 0.9564, 0.9425, 0.8881, 0.9763, 0.9579, 0.8969, 0.6007, 0.9432, 0.7697, 0.9683, 0.9109, 0.9796, 0.9598, 0.9089, 0.9571, 0.9753, 0.9417, 0.7737, 0.9691, 0.951, 0.8985, 0.8648, 0.5105, 0.9446, 0.983, 0.9435, 0.9457, 0.9809, 0.8431, 0.9814, 0.9115, 0.9128, 0.9318, 0.8483, 0.9457, 0.9264, 0.9522, 0.9734, 0.9522, 0.9134, 0.9768, 0.9277, 0.8363, 0.8221, 0.8912, 0.98, 0.9672, 0.8255, 0.8449, 0.9155, 0.9412, 0.8676, 0.9351, 0.9335, 0.8086, 0.9359, 0.9338, 0.8389, 0.9346, 0.958, 0.9489, 0.9587, 0.8354, 0.9538, 0.9488, 0.8011], 'Recall@P=50': [0.9653, 0.936, 0.9509, 0.988, 0.884, 0.992, 0.9496, 0.92, 0.9888, 0.956, 0.872, 0.9732, 0.764, 0.992, 0.93, 0.984, 0.9856, 0.992, 0.924, 0.956, 0.96, 0.844, 0.952, 0.9816, 0.9507, 0.9552, 0.968, 0.98, 0.9892, 0.948, 0.828, 0.816, 0.968, 0.964, 0.934, 0.872, 0.96, 0.9946, 0.964, 0.936, 1.0, 0.88, 0.98, 0.992, 0.952, 0.984, 0.9133, 0.94, 0.8453, 0.956, 0.9, 0.93, 0.99, 0.9549, 0.984, 0.9653, 0.994, 0.964, 0.96, 0.804, 0.868, 0.912, 0.96, 0.964, 0.9327, 0.84, 0.992, 0.984, 0.976, 0.656, 0.952, 0.916, 0.984, 0.9728, 0.936, 0.864, 0.928, 0.9693, 0.9667, 0.98, 0.9663, 0.992, 0.983, 0.888, 0.994, 0.992, 0.9831, 0.956, 0.8983, 0.98, 0.998, 0.668, 0.96, 0.9264, 0.924, 0.9789, 0.992, 0.84, 0.9373, 0.96, 0.9669, 0.936, 0.944, 0.9547, 0.992, 0.9647, 0.986, 0.86, 0.9752, 0.964, 0.932, 0.984, 0.9948, 0.95, 0.708, 0.9687, 0.864, 0.988, 0.96, 0.988, 0.988, 0.948, 0.98, 0.984, 0.9917, 0.812, 0.988, 0.9627, 0.952, 0.91, 0.544, 0.956, 0.992, 0.956, 0.964, 0.992, 0.9, 0.992, 0.9673, 0.948, 0.956, 0.904, 0.976, 0.96, 0.9728, 0.984, 0.9974, 0.9547, 0.984, 0.95, 0.896, 0.876, 0.9387, 0.992, 0.978, 0.86, 0.888, 0.956, 0.956, 0.94, 0.975, 0.964, 0.836, 0.9795, 0.948, 0.88, 0.9593, 0.974, 0.968, 0.984, 0.864, 0.964, 0.9972, 0.836], 'micro': 0.9271, 'macro': 0.9083, 'weighted': 0.926}
2024-07-27 09:42:06 - [34m[1mLOGS   [0m - Best checkpoint with score 0.91 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:42:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:42:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:42:09 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 2960 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_4_iter_2960.pt
2024-07-27 09:42:09 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 2960 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_4_iter_2960.pt
[31m===========================================================================[0m
2024-07-27 09:42:11 - [32m[1mINFO   [0m - Training epoch 5
2024-07-27 09:42:12 - [34m[1mLOGS   [0m - Epoch:   5 [    2961/10000000], loss: {'classification': 9.7301, 'neural_augmentation': 10.0809, 'total_loss': 19.811}, LR: [1e-05, 1e-05], Avg. batch load time: 0.476, Elapsed time:  0.58
2024-07-27 09:42:50 - [34m[1mLOGS   [0m - Epoch:   5 [    3461/10000000], loss: {'classification': 10.5819, 'neural_augmentation': 10.8194, 'total_loss': 21.4013}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.67
2024-07-27 09:42:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 10.5727, 'neural_augmentation': 10.8067, 'total_loss': 21.3795}
2024-07-27 09:43:17 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 4.5839, 'neural_augmentation': 0.0, 'total_loss': 4.5839} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.8916, 0.8607, 0.8402, 0.9518, 0.8457, 0.9441, 0.8557, 0.8614, 0.8915, 0.8365, 0.8282, 0.8782, 0.7453, 0.8995, 0.8438, 0.9293, 0.9527, 0.9658, 0.8894, 0.8898, 0.903, 0.7683, 0.8828, 0.9289, 0.8887, 0.8805, 0.8992, 0.9323, 0.8789, 0.8599, 0.7445, 0.7414, 0.8884, 0.8954, 0.851, 0.8387, 0.9156, 0.8945, 0.8665, 0.8247, 0.996, 0.7743, 0.9118, 0.948, 0.9121, 0.945, 0.7687, 0.9132, 0.7575, 0.9061, 0.8182, 0.8309, 0.9619, 0.8676, 0.9351, 0.9128, 0.9675, 0.8866, 0.8789, 0.7699, 0.7916, 0.8228, 0.8971, 0.898, 0.8349, 0.8004, 0.9619, 0.9235, 0.9268, 0.668, 0.887, 0.8478, 0.935, 0.893, 0.8628, 0.8072, 0.8629, 0.8864, 0.9314, 0.9576, 0.8562, 0.9598, 0.8806, 0.8058, 0.9473, 0.9239, 0.882, 0.8787, 0.8039, 0.8966, 0.9503, 0.6358, 0.903, 0.8252, 0.8814, 0.8884, 0.9572, 0.7571, 0.841, 0.833, 0.8702, 0.8698, 0.8884, 0.8309, 0.9512, 0.8807, 0.9626, 0.8154, 0.9001, 0.8884, 0.8577, 0.961, 0.9055, 0.856, 0.6108, 0.892, 0.7538, 0.921, 0.8547, 0.9499, 0.9024, 0.8495, 0.9212, 0.9467, 0.8736, 0.773, 0.9393, 0.9048, 0.8798, 0.8214, 0.5724, 0.8975, 0.9572, 0.9087, 0.9128, 0.9412, 0.796, 0.9419, 0.8604, 0.8676, 0.8898, 0.8193, 0.8863, 0.8825, 0.8914, 0.9592, 0.8958, 0.8513, 0.9503, 0.8826, 0.7918, 0.8079, 0.8544, 0.9461, 0.9313, 0.794, 0.7936, 0.8603, 0.9175, 0.8423, 0.8769, 0.8831, 0.7696, 0.8767, 0.9162, 0.7983, 0.8849, 0.9409, 0.9076, 0.9167, 0.8379, 0.9231, 0.8878, 0.7594], 'AP': [0.9438, 0.9183, 0.9076, 0.9838, 0.8968, 0.9829, 0.9215, 0.9056, 0.9517, 0.9171, 0.8833, 0.946, 0.7765, 0.9599, 0.9066, 0.9646, 0.9807, 0.9828, 0.9346, 0.9305, 0.9562, 0.8353, 0.9385, 0.9727, 0.9424, 0.9362, 0.9335, 0.9667, 0.9518, 0.9296, 0.8107, 0.794, 0.936, 0.9561, 0.9141, 0.8899, 0.96, 0.9606, 0.9297, 0.9041, 0.9999, 0.8402, 0.9646, 0.9805, 0.9465, 0.9783, 0.8611, 0.9413, 0.8209, 0.941, 0.8727, 0.9072, 0.9887, 0.935, 0.9731, 0.9633, 0.9892, 0.9425, 0.9392, 0.818, 0.8365, 0.8846, 0.9439, 0.9304, 0.9024, 0.8567, 0.9876, 0.9731, 0.9643, 0.7236, 0.9326, 0.8952, 0.9675, 0.9446, 0.9212, 0.8512, 0.9061, 0.9469, 0.9686, 0.9725, 0.9321, 0.9872, 0.9475, 0.8685, 0.9807, 0.9761, 0.9508, 0.9401, 0.882, 0.9638, 0.987, 0.676, 0.9463, 0.9014, 0.9276, 0.9514, 0.9836, 0.8176, 0.9105, 0.9019, 0.9337, 0.9225, 0.9285, 0.9029, 0.9796, 0.9424, 0.9809, 0.8683, 0.9562, 0.9536, 0.9074, 0.9779, 0.9667, 0.9188, 0.6382, 0.9533, 0.7867, 0.9717, 0.923, 0.9794, 0.962, 0.9207, 0.9631, 0.9781, 0.9434, 0.8246, 0.9731, 0.9476, 0.9281, 0.8735, 0.5622, 0.9573, 0.987, 0.954, 0.9549, 0.98, 0.8604, 0.982, 0.9298, 0.921, 0.9452, 0.8696, 0.9485, 0.9432, 0.9545, 0.974, 0.9616, 0.921, 0.9839, 0.9369, 0.8614, 0.8566, 0.9136, 0.9808, 0.977, 0.8378, 0.8543, 0.9278, 0.9458, 0.9077, 0.9428, 0.9418, 0.8258, 0.9446, 0.9467, 0.8573, 0.9395, 0.9667, 0.9578, 0.9696, 0.8879, 0.9556, 0.9584, 0.819], 'Recall@P=50': [0.9607, 0.94, 0.9577, 0.988, 0.928, 0.996, 0.9576, 0.944, 0.984, 0.9692, 0.922, 0.9784, 0.808, 0.982, 0.944, 0.984, 0.988, 0.984, 0.96, 0.948, 0.972, 0.87, 0.964, 0.9848, 0.9667, 0.9568, 0.96, 0.992, 0.9912, 0.9632, 0.856, 0.856, 0.972, 0.976, 0.9515, 0.92, 0.972, 0.9956, 0.96, 0.96, 1.0, 0.9, 0.992, 0.988, 0.96, 0.992, 0.9267, 0.948, 0.88, 0.948, 0.924, 0.9442, 0.996, 0.9674, 0.986, 0.98, 0.994, 0.968, 0.968, 0.884, 0.904, 0.92, 0.96, 0.956, 0.948, 0.89, 0.992, 0.988, 0.97, 0.776, 0.96, 0.922, 0.984, 0.9752, 0.94, 0.002, 0.932, 0.9747, 0.9747, 0.972, 0.9705, 0.992, 0.9856, 0.908, 0.998, 0.994, 0.9884, 0.976, 0.933, 0.988, 0.992, 0.744, 0.964, 0.9368, 0.936, 0.9833, 0.992, 0.884, 0.9527, 0.932, 0.9686, 0.94, 0.956, 0.956, 0.992, 0.9683, 0.99, 0.912, 0.98, 0.98, 0.936, 0.98, 0.9966, 0.946, 0.74, 0.9807, 0.88, 0.9913, 0.96, 0.988, 0.986, 0.952, 0.972, 0.988, 0.9943, 0.86, 0.988, 0.96, 0.96, 0.934, 0.664, 0.98, 0.992, 0.968, 0.966, 0.992, 0.92, 0.992, 0.9737, 0.944, 0.984, 0.908, 0.984, 0.967, 0.9784, 0.972, 0.9971, 0.9653, 0.988, 0.956, 0.914, 0.898, 0.944, 0.992, 0.992, 0.88, 0.888, 0.964, 0.952, 0.96, 0.976, 0.972, 0.88, 0.9798, 0.952, 0.9, 0.9627, 0.976, 0.984, 0.992, 0.916, 0.96, 0.9973, 0.88], 'micro': 0.9365, 'macro': 0.9228, 'weighted': 0.9379}
2024-07-27 09:43:27 - [34m[1mLOGS   [0m - Best checkpoint with score 0.92 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:43:27 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.2468.pt
2024-07-27 09:43:27 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.7082.pt', 'checkpoint_score_0.8327.pt', 'checkpoint_score_0.8854.pt', 'checkpoint_score_0.9083.pt', 'checkpoint_score_0.9228.pt']
2024-07-27 09:43:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:43:30 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:43:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:43:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 3552 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_5_iter_3552.pt
2024-07-27 09:43:31 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 3552 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_5_iter_3552.pt
[31m===========================================================================[0m
2024-07-27 09:43:33 - [32m[1mINFO   [0m - Training epoch 6
2024-07-27 09:43:34 - [34m[1mLOGS   [0m - Epoch:   6 [    3553/10000000], loss: {'classification': 12.1671, 'neural_augmentation': 11.8301, 'total_loss': 23.9972}, LR: [1e-05, 1e-05], Avg. batch load time: 0.745, Elapsed time:  0.83
2024-07-27 09:44:12 - [34m[1mLOGS   [0m - Epoch:   6 [    4053/10000000], loss: {'classification': 10.0844, 'neural_augmentation': 10.7958, 'total_loss': 20.8802}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.43
2024-07-27 09:44:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 10.0799, 'neural_augmentation': 10.8001, 'total_loss': 20.8801}
2024-07-27 09:44:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 4.2212, 'neural_augmentation': 0.0, 'total_loss': 4.2212} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9063, 0.8577, 0.8537, 0.9553, 0.846, 0.9587, 0.8599, 0.862, 0.9061, 0.8557, 0.8507, 0.8876, 0.7713, 0.9093, 0.862, 0.9339, 0.9476, 0.9657, 0.9011, 0.9068, 0.9121, 0.7898, 0.9026, 0.9354, 0.8956, 0.8846, 0.9098, 0.944, 0.8847, 0.8657, 0.7773, 0.7623, 0.8862, 0.9179, 0.8601, 0.8398, 0.9286, 0.9024, 0.8723, 0.8594, 0.998, 0.7935, 0.9006, 0.9412, 0.9218, 0.9476, 0.7802, 0.9211, 0.77, 0.9068, 0.7883, 0.8514, 0.9688, 0.883, 0.9248, 0.9198, 0.9688, 0.913, 0.8797, 0.7837, 0.7904, 0.8409, 0.9061, 0.9129, 0.8573, 0.7872, 0.9533, 0.9192, 0.9387, 0.6998, 0.8976, 0.8608, 0.9333, 0.8867, 0.8554, 0.8227, 0.8553, 0.8985, 0.9375, 0.9526, 0.8666, 0.9553, 0.8859, 0.7903, 0.9432, 0.932, 0.8945, 0.9032, 0.8149, 0.9128, 0.9618, 0.6819, 0.8971, 0.8439, 0.9053, 0.8929, 0.9579, 0.7823, 0.8542, 0.8566, 0.8903, 0.8789, 0.9008, 0.8475, 0.9368, 0.8929, 0.9571, 0.7859, 0.9138, 0.9182, 0.856, 0.9535, 0.911, 0.867, 0.6403, 0.8941, 0.7816, 0.9275, 0.8776, 0.9433, 0.9077, 0.8639, 0.9292, 0.9493, 0.8856, 0.8009, 0.9381, 0.9271, 0.867, 0.8499, 0.5761, 0.9126, 0.9497, 0.9298, 0.9101, 0.9381, 0.8147, 0.9368, 0.8766, 0.8908, 0.9124, 0.8371, 0.8889, 0.8853, 0.9149, 0.9528, 0.9043, 0.8892, 0.9493, 0.8917, 0.8034, 0.8055, 0.8573, 0.9442, 0.9279, 0.8274, 0.8362, 0.8736, 0.9062, 0.8648, 0.8839, 0.8838, 0.7808, 0.8834, 0.9344, 0.8233, 0.8996, 0.9396, 0.8852, 0.9102, 0.8571, 0.9259, 0.8997, 0.7796], 'AP': [0.9597, 0.9112, 0.922, 0.9873, 0.9033, 0.9856, 0.9266, 0.9027, 0.9657, 0.9295, 0.903, 0.949, 0.8113, 0.966, 0.913, 0.9672, 0.9804, 0.9895, 0.9442, 0.9448, 0.9576, 0.8599, 0.9571, 0.9765, 0.9448, 0.9462, 0.9486, 0.9752, 0.957, 0.931, 0.8222, 0.813, 0.9352, 0.9578, 0.9223, 0.894, 0.9543, 0.9647, 0.9262, 0.9174, 0.9988, 0.8568, 0.9625, 0.9793, 0.9562, 0.9812, 0.8659, 0.948, 0.8356, 0.9506, 0.8462, 0.9217, 0.9922, 0.9479, 0.9684, 0.9659, 0.9893, 0.9598, 0.9409, 0.8519, 0.8529, 0.9076, 0.9547, 0.9485, 0.9242, 0.8488, 0.9843, 0.9708, 0.9728, 0.7478, 0.9326, 0.8956, 0.9723, 0.9418, 0.9133, 0.8754, 0.8944, 0.9567, 0.9721, 0.9742, 0.9337, 0.981, 0.9529, 0.8482, 0.9823, 0.9802, 0.9579, 0.955, 0.8915, 0.9647, 0.9898, 0.7251, 0.952, 0.9141, 0.9404, 0.9533, 0.9902, 0.8184, 0.9196, 0.9279, 0.9485, 0.934, 0.9387, 0.9183, 0.9774, 0.9496, 0.9851, 0.8579, 0.9616, 0.9547, 0.898, 0.9768, 0.9695, 0.9343, 0.6475, 0.9528, 0.814, 0.9728, 0.936, 0.9801, 0.9664, 0.9271, 0.9717, 0.9806, 0.9532, 0.8546, 0.9738, 0.9586, 0.9283, 0.8842, 0.5784, 0.955, 0.9852, 0.9619, 0.9562, 0.9778, 0.8751, 0.9799, 0.944, 0.9293, 0.9557, 0.8953, 0.9489, 0.9457, 0.9682, 0.9756, 0.9671, 0.9353, 0.9851, 0.9362, 0.8835, 0.8531, 0.9179, 0.9794, 0.9729, 0.875, 0.8871, 0.9383, 0.9544, 0.9157, 0.9478, 0.9455, 0.8241, 0.9478, 0.9618, 0.879, 0.949, 0.9765, 0.9388, 0.9709, 0.8975, 0.9596, 0.9653, 0.8164], 'Recall@P=50': [0.972, 0.94, 0.9669, 0.996, 0.948, 0.992, 0.9624, 0.928, 0.9904, 0.9794, 0.954, 0.9792, 0.84, 0.99, 0.944, 0.98, 0.9872, 0.992, 0.964, 0.952, 0.98, 0.902, 0.98, 0.9896, 0.964, 0.9688, 0.96, 0.988, 0.9927, 0.9648, 0.864, 0.868, 0.972, 0.968, 0.958, 0.932, 0.968, 0.9972, 0.958, 0.948, 1.0, 0.892, 0.984, 0.992, 0.964, 0.992, 0.9267, 0.952, 0.8947, 0.968, 0.896, 0.9595, 0.996, 0.9737, 0.982, 0.978, 0.994, 0.98, 0.964, 0.892, 0.9, 0.956, 0.968, 0.964, 0.96, 0.884, 0.988, 0.9867, 0.98, 0.804, 0.968, 0.938, 0.988, 0.976, 0.932, 0.922, 0.9, 0.9787, 0.9827, 0.976, 0.9695, 0.992, 0.9906, 0.9, 0.994, 0.996, 0.9882, 0.972, 0.9322, 0.988, 0.994, 0.776, 0.968, 0.9472, 0.956, 0.9815, 0.996, 0.904, 0.9527, 0.972, 0.9783, 0.956, 0.964, 0.9627, 0.992, 0.975, 0.992, 0.908, 0.9824, 0.968, 0.932, 0.98, 0.9972, 0.962, 0.756, 0.98, 0.9, 0.99, 0.964, 0.988, 0.99, 0.9553, 0.992, 0.996, 0.9937, 0.88, 0.984, 0.9667, 0.976, 0.924, 0.66, 0.964, 0.996, 0.976, 0.9693, 0.988, 0.9173, 0.992, 0.9807, 0.952, 0.984, 0.936, 0.992, 0.975, 0.984, 0.976, 0.9983, 0.968, 0.988, 0.948, 0.934, 0.904, 0.9573, 0.992, 0.988, 0.904, 0.932, 0.97, 0.972, 0.948, 0.981, 0.964, 0.876, 0.9795, 0.98, 0.908, 0.9733, 0.988, 0.952, 0.996, 0.928, 0.972, 0.9979, 0.868], 'micro': 0.9451, 'macro': 0.9298, 'weighted': 0.9446}
2024-07-27 09:44:41 - [34m[1mLOGS   [0m - Best checkpoint with score 0.93 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:44:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.7082.pt
2024-07-27 09:44:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.8327.pt', 'checkpoint_score_0.8854.pt', 'checkpoint_score_0.9083.pt', 'checkpoint_score_0.9228.pt', 'checkpoint_score_0.9298.pt']
2024-07-27 09:44:44 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:44:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:44:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:44:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 4144 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_6_iter_4144.pt
2024-07-27 09:44:46 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 4144 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_6_iter_4144.pt
[31m===========================================================================[0m
2024-07-27 09:44:48 - [32m[1mINFO   [0m - Training epoch 7
2024-07-27 09:44:48 - [34m[1mLOGS   [0m - Epoch:   7 [    4145/10000000], loss: {'classification': 10.076, 'neural_augmentation': 10.6496, 'total_loss': 20.7256}, LR: [1e-05, 1e-05], Avg. batch load time: 0.316, Elapsed time:  0.42
2024-07-27 09:45:26 - [34m[1mLOGS   [0m - Epoch:   7 [    4645/10000000], loss: {'classification': 9.6753, 'neural_augmentation': 10.6949, 'total_loss': 20.3702}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.50
2024-07-27 09:45:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 9.6601, 'neural_augmentation': 10.7179, 'total_loss': 20.3781}
2024-07-27 09:45:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 3.8153, 'neural_augmentation': 0.0, 'total_loss': 3.8153} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9174, 0.8589, 0.8675, 0.9478, 0.8679, 0.961, 0.8668, 0.8632, 0.9189, 0.8674, 0.858, 0.8958, 0.7795, 0.9162, 0.8775, 0.9407, 0.9531, 0.9639, 0.9011, 0.9165, 0.9148, 0.8051, 0.908, 0.944, 0.897, 0.9002, 0.9121, 0.9499, 0.8998, 0.8836, 0.8088, 0.7764, 0.9113, 0.9284, 0.8623, 0.8565, 0.9325, 0.9094, 0.8944, 0.8619, 0.998, 0.7984, 0.9177, 0.9558, 0.9051, 0.9493, 0.793, 0.9275, 0.7855, 0.9061, 0.8377, 0.8628, 0.9596, 0.8985, 0.9396, 0.9228, 0.9728, 0.9008, 0.8945, 0.8245, 0.7866, 0.8549, 0.9231, 0.912, 0.8631, 0.7966, 0.9633, 0.9265, 0.9394, 0.69, 0.9058, 0.8734, 0.9333, 0.9022, 0.856, 0.8509, 0.8662, 0.9098, 0.9367, 0.9567, 0.8764, 0.9613, 0.8929, 0.8333, 0.948, 0.9468, 0.9015, 0.8912, 0.8197, 0.92, 0.9659, 0.6935, 0.9234, 0.8579, 0.9011, 0.9044, 0.9701, 0.7949, 0.8584, 0.8934, 0.8924, 0.8882, 0.9095, 0.8591, 0.9499, 0.9011, 0.9611, 0.8112, 0.9209, 0.9303, 0.8692, 0.9504, 0.9142, 0.8656, 0.6616, 0.9006, 0.7803, 0.9349, 0.8847, 0.9493, 0.917, 0.8802, 0.9284, 0.9593, 0.8988, 0.8264, 0.9328, 0.9256, 0.9084, 0.8496, 0.5952, 0.925, 0.9615, 0.9228, 0.9133, 0.9474, 0.8204, 0.952, 0.886, 0.8798, 0.898, 0.8463, 0.9014, 0.8991, 0.9265, 0.9571, 0.9092, 0.8966, 0.953, 0.8911, 0.8317, 0.8342, 0.8816, 0.9507, 0.9414, 0.8276, 0.8507, 0.8738, 0.9039, 0.8612, 0.8846, 0.9016, 0.8126, 0.8963, 0.9402, 0.8436, 0.905, 0.9448, 0.8992, 0.9172, 0.876, 0.9333, 0.907, 0.8069], 'AP': [0.9669, 0.9195, 0.9354, 0.9837, 0.9233, 0.9895, 0.9362, 0.9068, 0.9711, 0.9402, 0.9199, 0.9576, 0.8297, 0.9662, 0.9284, 0.9717, 0.9852, 0.9884, 0.9538, 0.9544, 0.9584, 0.8729, 0.9569, 0.9787, 0.9506, 0.9523, 0.9581, 0.9811, 0.9659, 0.948, 0.8598, 0.8369, 0.9566, 0.965, 0.9297, 0.9122, 0.9636, 0.9691, 0.951, 0.9174, 1.0, 0.8707, 0.9748, 0.9861, 0.9523, 0.9812, 0.8807, 0.9545, 0.8516, 0.9482, 0.8943, 0.9378, 0.9899, 0.9559, 0.9766, 0.9716, 0.9891, 0.9551, 0.9515, 0.8686, 0.8687, 0.9203, 0.9627, 0.9546, 0.9295, 0.8733, 0.9877, 0.9774, 0.9744, 0.7629, 0.9392, 0.9127, 0.9747, 0.9552, 0.9212, 0.8948, 0.9047, 0.96, 0.9778, 0.9819, 0.9459, 0.9895, 0.9606, 0.8914, 0.9829, 0.9837, 0.9632, 0.9545, 0.8999, 0.975, 0.9914, 0.74, 0.963, 0.9217, 0.948, 0.9632, 0.9918, 0.8615, 0.9259, 0.944, 0.9523, 0.9409, 0.9435, 0.9273, 0.9845, 0.9566, 0.9875, 0.8803, 0.9664, 0.9656, 0.9069, 0.9838, 0.9731, 0.9349, 0.6808, 0.9604, 0.8236, 0.9768, 0.9468, 0.9851, 0.9668, 0.9464, 0.971, 0.9809, 0.9626, 0.8689, 0.9688, 0.9632, 0.957, 0.9002, 0.6232, 0.964, 0.9874, 0.9648, 0.9619, 0.9839, 0.882, 0.986, 0.9513, 0.9359, 0.9535, 0.9107, 0.9637, 0.9533, 0.9719, 0.9831, 0.9712, 0.9476, 0.9814, 0.9401, 0.9008, 0.8835, 0.9353, 0.9858, 0.9795, 0.8868, 0.8955, 0.9435, 0.9521, 0.9137, 0.9519, 0.9542, 0.8723, 0.958, 0.9737, 0.8895, 0.9579, 0.98, 0.959, 0.9717, 0.9242, 0.9636, 0.9704, 0.8702], 'Recall@P=50': [0.986, 0.94, 0.972, 0.996, 0.94, 0.996, 0.9688, 0.932, 0.9928, 0.9834, 0.97, 0.9844, 0.852, 0.988, 0.948, 0.984, 0.992, 0.992, 0.968, 0.96, 0.976, 0.92, 0.976, 0.9896, 0.972, 0.9704, 0.968, 0.992, 0.9945, 0.9784, 0.892, 0.88, 0.98, 0.968, 0.9645, 0.952, 0.98, 0.9978, 0.974, 0.96, 1.0, 0.92, 0.992, 0.992, 0.964, 0.992, 0.944, 0.956, 0.908, 0.968, 0.936, 0.9705, 0.998, 0.976, 0.992, 0.9867, 0.992, 0.98, 0.976, 0.904, 0.916, 0.968, 0.972, 0.964, 0.9687, 0.922, 0.996, 0.992, 0.984, 0.832, 0.972, 0.94, 0.988, 0.9808, 0.952, 0.952, 0.936, 0.9853, 0.9907, 0.988, 0.9795, 1.0, 0.9916, 0.924, 0.996, 0.996, 0.9913, 0.984, 0.9522, 0.988, 0.996, 0.784, 0.968, 0.952, 0.972, 0.9909, 1.0, 0.924, 0.9593, 0.972, 0.9829, 0.95, 0.964, 0.976, 0.992, 0.9753, 0.994, 0.92, 0.9824, 0.984, 0.936, 0.992, 0.9986, 0.97, 0.004, 0.9827, 0.916, 0.992, 0.972, 0.992, 0.992, 0.9793, 0.976, 0.988, 0.9947, 0.884, 0.98, 0.9747, 0.976, 0.938, 0.704, 0.968, 1.0, 0.984, 0.978, 0.992, 0.932, 0.992, 0.9817, 0.968, 0.984, 0.952, 0.992, 0.977, 0.9872, 0.992, 0.9992, 0.976, 0.992, 0.958, 0.942, 0.92, 0.9627, 0.992, 0.994, 0.916, 0.928, 0.977, 0.968, 0.96, 0.979, 0.972, 0.908, 0.9852, 0.984, 0.916, 0.9787, 0.99, 0.98, 0.992, 0.948, 0.968, 0.9987, 0.896], 'micro': 0.9543, 'macro': 0.9396, 'weighted': 0.9526}
2024-07-27 09:45:59 - [34m[1mLOGS   [0m - Best checkpoint with score 0.94 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:45:59 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.8327.pt
2024-07-27 09:45:59 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.8854.pt', 'checkpoint_score_0.9083.pt', 'checkpoint_score_0.9228.pt', 'checkpoint_score_0.9298.pt', 'checkpoint_score_0.9396.pt']
2024-07-27 09:46:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:46:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:46:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:46:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 4736 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_7_iter_4736.pt
2024-07-27 09:46:03 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 4736 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_7_iter_4736.pt
[31m===========================================================================[0m
2024-07-27 09:46:05 - [32m[1mINFO   [0m - Training epoch 8
2024-07-27 09:46:06 - [34m[1mLOGS   [0m - Epoch:   8 [    4737/10000000], loss: {'classification': 7.3983, 'neural_augmentation': 10.71, 'total_loss': 18.1083}, LR: [1e-05, 1e-05], Avg. batch load time: 0.729, Elapsed time:  0.81
2024-07-27 09:46:43 - [34m[1mLOGS   [0m - Epoch:   8 [    5237/10000000], loss: {'classification': 9.3252, 'neural_augmentation': 10.6886, 'total_loss': 20.0138}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.39
2024-07-27 09:46:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 9.3249, 'neural_augmentation': 10.6995, 'total_loss': 20.0244}
2024-07-27 09:47:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 3.7217, 'neural_augmentation': 0.0, 'total_loss': 3.7217} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9129, 0.8547, 0.877, 0.9598, 0.8763, 0.9654, 0.8725, 0.8773, 0.9141, 0.868, 0.8574, 0.8969, 0.7692, 0.9205, 0.8802, 0.9228, 0.9525, 0.9737, 0.9265, 0.9196, 0.917, 0.8044, 0.8992, 0.9389, 0.9083, 0.9048, 0.918, 0.952, 0.8995, 0.8768, 0.8215, 0.795, 0.9041, 0.9266, 0.8667, 0.8644, 0.935, 0.9123, 0.8903, 0.8875, 0.996, 0.82, 0.9333, 0.9597, 0.9095, 0.9478, 0.7989, 0.9224, 0.7797, 0.8974, 0.848, 0.8614, 0.9635, 0.9004, 0.9298, 0.926, 0.9736, 0.9106, 0.9045, 0.814, 0.8134, 0.8571, 0.9212, 0.916, 0.8786, 0.805, 0.9624, 0.9383, 0.9357, 0.7252, 0.9053, 0.8584, 0.932, 0.9027, 0.8662, 0.8491, 0.8589, 0.9111, 0.9416, 0.9593, 0.878, 0.9622, 0.8977, 0.8484, 0.9466, 0.9461, 0.9056, 0.8968, 0.8197, 0.9374, 0.9598, 0.7124, 0.9194, 0.8588, 0.9237, 0.9063, 0.9637, 0.8125, 0.8654, 0.8952, 0.9064, 0.8922, 0.9057, 0.8615, 0.96, 0.9033, 0.9647, 0.807, 0.9271, 0.9247, 0.8519, 0.9555, 0.9182, 0.8779, 0.6776, 0.9122, 0.7842, 0.9381, 0.8967, 0.9593, 0.9157, 0.867, 0.9347, 0.9572, 0.8991, 0.8167, 0.9512, 0.9342, 0.8972, 0.853, 0.597, 0.9263, 0.9619, 0.915, 0.92, 0.9543, 0.8348, 0.9562, 0.8866, 0.8893, 0.9016, 0.8468, 0.9054, 0.9049, 0.917, 0.9577, 0.9138, 0.8801, 0.9592, 0.9034, 0.8347, 0.8496, 0.8918, 0.9577, 0.9473, 0.8354, 0.8403, 0.8828, 0.9016, 0.8725, 0.8879, 0.905, 0.8233, 0.8957, 0.9317, 0.8417, 0.8906, 0.9431, 0.9006, 0.9259, 0.8765, 0.9275, 0.909, 0.8145], 'AP': [0.9673, 0.9241, 0.943, 0.9899, 0.9401, 0.9889, 0.9351, 0.9152, 0.9709, 0.9418, 0.9239, 0.9584, 0.8249, 0.9692, 0.9299, 0.9685, 0.9848, 0.9912, 0.9611, 0.9551, 0.9577, 0.8754, 0.9549, 0.9798, 0.9536, 0.9554, 0.9607, 0.9777, 0.9663, 0.9383, 0.8671, 0.8435, 0.9568, 0.9691, 0.9362, 0.919, 0.9692, 0.9714, 0.9463, 0.9269, 0.9998, 0.8834, 0.9759, 0.9881, 0.9537, 0.9853, 0.8848, 0.9573, 0.8474, 0.9464, 0.9037, 0.9349, 0.9925, 0.9583, 0.9747, 0.9741, 0.9922, 0.9595, 0.9481, 0.8631, 0.8831, 0.9228, 0.9583, 0.9608, 0.9441, 0.877, 0.9899, 0.981, 0.9728, 0.8032, 0.928, 0.9048, 0.9684, 0.9526, 0.9259, 0.8922, 0.9119, 0.9632, 0.9795, 0.984, 0.9495, 0.9904, 0.9614, 0.9068, 0.9855, 0.9853, 0.967, 0.9563, 0.8994, 0.9761, 0.9917, 0.7575, 0.9581, 0.9268, 0.9584, 0.963, 0.9911, 0.871, 0.9342, 0.9507, 0.9584, 0.9448, 0.9448, 0.9297, 0.9866, 0.9617, 0.9876, 0.8839, 0.9712, 0.9697, 0.9111, 0.9867, 0.9754, 0.9447, 0.699, 0.9622, 0.8291, 0.9807, 0.956, 0.9871, 0.9693, 0.9347, 0.9686, 0.9847, 0.9641, 0.8636, 0.9794, 0.9676, 0.9546, 0.9008, 0.5817, 0.9673, 0.9889, 0.9639, 0.9646, 0.986, 0.8932, 0.9882, 0.9511, 0.93, 0.958, 0.9076, 0.9688, 0.962, 0.9705, 0.9859, 0.971, 0.941, 0.989, 0.9497, 0.9016, 0.8951, 0.9378, 0.9868, 0.9832, 0.8899, 0.8955, 0.9464, 0.9529, 0.9191, 0.9543, 0.952, 0.8618, 0.959, 0.9699, 0.8912, 0.954, 0.9793, 0.9536, 0.972, 0.9377, 0.9613, 0.9718, 0.8663], 'Recall@P=50': [0.9847, 0.948, 0.9749, 0.996, 0.964, 0.992, 0.972, 0.944, 0.9936, 0.9858, 0.972, 0.9848, 0.856, 0.99, 0.956, 0.984, 0.992, 0.996, 0.976, 0.968, 0.98, 0.922, 0.976, 0.9936, 0.968, 0.9712, 0.984, 0.992, 0.9947, 0.9704, 0.896, 0.928, 0.98, 0.988, 0.971, 0.952, 0.976, 0.9981, 0.978, 0.948, 1.0, 0.924, 0.992, 0.992, 0.968, 0.992, 0.952, 0.96, 0.9093, 0.964, 0.932, 0.9674, 0.998, 0.9789, 0.992, 0.9873, 0.994, 0.98, 0.968, 0.884, 0.924, 0.976, 0.968, 0.972, 0.9753, 0.93, 0.996, 0.9947, 0.982, 0.836, 0.968, 0.932, 0.98, 0.98, 0.96, 0.002, 0.944, 0.9853, 0.988, 0.984, 0.9868, 0.996, 0.9912, 0.924, 0.994, 0.994, 0.9916, 0.984, 0.9574, 0.992, 0.998, 0.796, 0.96, 0.9576, 0.972, 0.988, 0.996, 0.952, 0.964, 0.976, 0.9806, 0.954, 0.968, 0.9733, 0.992, 0.9817, 0.992, 0.932, 0.9848, 0.984, 0.948, 0.996, 0.9989, 0.976, 0.824, 0.9827, 0.904, 0.9947, 0.988, 0.992, 0.992, 0.9647, 0.98, 0.992, 0.996, 0.88, 0.992, 0.9733, 0.976, 0.932, 0.732, 0.98, 0.996, 0.98, 0.9773, 0.992, 0.9387, 0.992, 0.9833, 0.956, 0.988, 0.944, 1.0, 0.985, 0.988, 0.996, 0.9993, 0.972, 0.996, 0.97, 0.94, 0.916, 0.9573, 0.992, 0.994, 0.92, 0.924, 0.982, 0.968, 0.952, 0.985, 0.964, 0.884, 0.99, 0.984, 0.916, 0.98, 0.99, 0.984, 0.992, 0.972, 0.968, 0.9992, 0.9], 'micro': 0.9551, 'macro': 0.9419, 'weighted': 0.9545}
2024-07-27 09:47:16 - [34m[1mLOGS   [0m - Best checkpoint with score 0.94 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:47:17 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.8854.pt
2024-07-27 09:47:17 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9083.pt', 'checkpoint_score_0.9228.pt', 'checkpoint_score_0.9298.pt', 'checkpoint_score_0.9396.pt', 'checkpoint_score_0.9419.pt']
2024-07-27 09:47:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:47:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:47:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:47:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 5328 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_8_iter_5328.pt
2024-07-27 09:47:21 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 5328 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_8_iter_5328.pt
[31m===========================================================================[0m
2024-07-27 09:47:23 - [32m[1mINFO   [0m - Training epoch 9
2024-07-27 09:47:24 - [34m[1mLOGS   [0m - Epoch:   9 [    5329/10000000], loss: {'classification': 8.006, 'neural_augmentation': 10.7374, 'total_loss': 18.7434}, LR: [1e-05, 1e-05], Avg. batch load time: 0.783, Elapsed time:  0.87
2024-07-27 09:48:01 - [34m[1mLOGS   [0m - Epoch:   9 [    5829/10000000], loss: {'classification': 9.0569, 'neural_augmentation': 10.7262, 'total_loss': 19.7831}, LR: [1e-05, 1e-05], Avg. batch load time: 0.002, Elapsed time: 38.38
2024-07-27 09:48:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 9.0234, 'neural_augmentation': 10.7156, 'total_loss': 19.739}
2024-07-27 09:48:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 3.4475, 'neural_augmentation': 0.0, 'total_loss': 3.4475} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9199, 0.8699, 0.8765, 0.9655, 0.8758, 0.9637, 0.8855, 0.846, 0.9264, 0.8707, 0.8635, 0.9107, 0.7817, 0.9391, 0.8811, 0.9381, 0.9625, 0.9739, 0.9158, 0.9172, 0.9298, 0.8316, 0.9187, 0.9442, 0.9198, 0.9062, 0.9199, 0.9553, 0.9078, 0.8924, 0.8085, 0.7952, 0.9131, 0.935, 0.8798, 0.8661, 0.939, 0.9211, 0.8955, 0.88, 1.0, 0.8356, 0.9379, 0.972, 0.9069, 0.9549, 0.8038, 0.9347, 0.804, 0.8925, 0.8512, 0.8798, 0.9726, 0.9068, 0.9406, 0.9326, 0.978, 0.9237, 0.9091, 0.833, 0.8364, 0.8822, 0.9286, 0.918, 0.879, 0.8139, 0.9636, 0.9416, 0.9336, 0.7784, 0.9051, 0.8893, 0.9443, 0.9089, 0.8683, 0.8702, 0.8601, 0.9132, 0.9457, 0.9615, 0.8807, 0.9636, 0.9077, 0.8537, 0.959, 0.954, 0.909, 0.9175, 0.8123, 0.9484, 0.9664, 0.7362, 0.9218, 0.8806, 0.9174, 0.9164, 0.9715, 0.8206, 0.881, 0.8856, 0.9083, 0.9072, 0.9172, 0.8728, 0.9701, 0.9084, 0.9543, 0.8207, 0.9414, 0.924, 0.8417, 0.9615, 0.9268, 0.9032, 0.6951, 0.9157, 0.7915, 0.9445, 0.8839, 0.9718, 0.9354, 0.8927, 0.9493, 0.953, 0.8982, 0.8314, 0.9579, 0.9285, 0.9068, 0.8687, 0.6083, 0.9298, 0.9603, 0.9293, 0.9243, 0.9697, 0.8378, 0.9735, 0.8972, 0.8852, 0.9177, 0.8516, 0.9144, 0.9213, 0.9295, 0.9613, 0.9197, 0.892, 0.9676, 0.9215, 0.8506, 0.8557, 0.893, 0.9758, 0.9556, 0.8486, 0.8428, 0.8997, 0.9072, 0.8703, 0.901, 0.913, 0.8191, 0.9084, 0.936, 0.8476, 0.9189, 0.944, 0.9125, 0.9167, 0.8792, 0.9385, 0.9175, 0.8102], 'AP': [0.9703, 0.9335, 0.9418, 0.9895, 0.9368, 0.9887, 0.9429, 0.9115, 0.9742, 0.9435, 0.9258, 0.9647, 0.8439, 0.9806, 0.9352, 0.9746, 0.9863, 0.9929, 0.9612, 0.9582, 0.9616, 0.9, 0.9585, 0.9825, 0.9644, 0.9594, 0.961, 0.9856, 0.9699, 0.9543, 0.873, 0.8754, 0.9542, 0.9737, 0.9446, 0.9244, 0.9705, 0.9745, 0.9533, 0.93, 1.0, 0.8936, 0.9829, 0.9895, 0.9532, 0.9825, 0.8896, 0.9579, 0.8657, 0.9432, 0.9121, 0.9458, 0.9939, 0.9635, 0.9769, 0.976, 0.9938, 0.9604, 0.9511, 0.8833, 0.8946, 0.9341, 0.9648, 0.9616, 0.9437, 0.885, 0.9903, 0.9802, 0.9713, 0.8317, 0.9367, 0.93, 0.9759, 0.9607, 0.9337, 0.91, 0.9107, 0.966, 0.9809, 0.9872, 0.9506, 0.9907, 0.9661, 0.9159, 0.9869, 0.9864, 0.969, 0.956, 0.8912, 0.9845, 0.9904, 0.7799, 0.9636, 0.9378, 0.9576, 0.9684, 0.9911, 0.875, 0.9404, 0.9536, 0.9575, 0.9498, 0.9484, 0.9389, 0.9883, 0.9625, 0.9864, 0.9039, 0.9769, 0.9759, 0.9064, 0.987, 0.9783, 0.9526, 0.7227, 0.9652, 0.8576, 0.982, 0.9579, 0.9871, 0.98, 0.9522, 0.9716, 0.9819, 0.9632, 0.8842, 0.9813, 0.9674, 0.9579, 0.9138, 0.6089, 0.9728, 0.9903, 0.969, 0.9656, 0.988, 0.9064, 0.9898, 0.9582, 0.9366, 0.9594, 0.9088, 0.9731, 0.9671, 0.9726, 0.9874, 0.9767, 0.9523, 0.9893, 0.9595, 0.9163, 0.9117, 0.9434, 0.9871, 0.988, 0.8976, 0.9006, 0.9578, 0.9503, 0.9266, 0.9598, 0.9527, 0.876, 0.9651, 0.9772, 0.8977, 0.9635, 0.9802, 0.9597, 0.9757, 0.9383, 0.9617, 0.9753, 0.8794], 'Recall@P=50': [0.986, 0.96, 0.9749, 0.992, 0.964, 0.988, 0.9768, 0.944, 0.9952, 0.9825, 0.964, 0.9884, 0.86, 0.994, 0.962, 0.984, 0.9944, 0.996, 0.976, 0.972, 0.976, 0.93, 0.976, 0.9952, 0.9747, 0.9776, 0.968, 0.996, 0.995, 0.9792, 0.908, 0.916, 0.972, 0.992, 0.9725, 0.96, 0.98, 0.9994, 0.975, 0.96, 1.0, 0.932, 0.992, 0.992, 0.968, 0.992, 0.9533, 0.964, 0.9187, 0.96, 0.94, 0.9726, 0.996, 0.98, 0.992, 0.988, 0.996, 0.976, 0.968, 0.912, 0.928, 0.98, 0.976, 0.972, 0.974, 0.938, 0.996, 0.992, 0.984, 0.888, 0.984, 0.956, 0.992, 0.9848, 0.968, 0.002, 0.948, 0.9867, 0.992, 0.996, 0.9884, 1.0, 0.9928, 0.948, 0.996, 0.996, 0.9942, 0.98, 0.9513, 0.996, 0.996, 0.84, 0.976, 0.9696, 0.976, 0.992, 0.996, 0.952, 0.9667, 0.984, 0.9846, 0.966, 0.972, 0.976, 0.992, 0.9823, 0.996, 0.952, 0.9872, 0.996, 0.944, 0.992, 0.9989, 0.974, 0.836, 0.9873, 0.932, 0.9927, 0.992, 0.988, 0.992, 0.9793, 0.988, 0.992, 0.996, 0.904, 0.988, 0.98, 0.976, 0.94, 0.004, 0.988, 0.996, 0.98, 0.98, 0.992, 0.9533, 0.992, 0.9867, 0.964, 0.984, 0.936, 0.996, 0.983, 0.988, 0.992, 0.9983, 0.9787, 0.992, 0.97, 0.946, 0.936, 0.968, 0.988, 0.994, 0.932, 0.932, 0.985, 0.972, 0.96, 0.989, 0.964, 0.904, 0.9902, 0.988, 0.924, 0.9787, 0.988, 0.976, 0.992, 0.976, 0.972, 0.9989, 0.916], 'micro': 0.9606, 'macro': 0.9475, 'weighted': 0.9593}
2024-07-27 09:48:33 - [34m[1mLOGS   [0m - Best checkpoint with score 0.95 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:48:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9083.pt
2024-07-27 09:48:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9228.pt', 'checkpoint_score_0.9298.pt', 'checkpoint_score_0.9396.pt', 'checkpoint_score_0.9419.pt', 'checkpoint_score_0.9475.pt']
2024-07-27 09:48:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:48:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:48:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:48:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 5920 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_9_iter_5920.pt
2024-07-27 09:48:38 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 5920 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_9_iter_5920.pt
[31m===========================================================================[0m
2024-07-27 09:48:40 - [32m[1mINFO   [0m - Training epoch 10
2024-07-27 09:48:41 - [34m[1mLOGS   [0m - Epoch:  10 [    5921/10000000], loss: {'classification': 7.7045, 'neural_augmentation': 11.838, 'total_loss': 19.5425}, LR: [9e-06, 9e-06], Avg. batch load time: 0.943, Elapsed time:  1.03
2024-07-27 09:49:18 - [34m[1mLOGS   [0m - Epoch:  10 [    6421/10000000], loss: {'classification': 8.7394, 'neural_augmentation': 10.692, 'total_loss': 19.4313}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.55
2024-07-27 09:49:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 8.7253, 'neural_augmentation': 10.6691, 'total_loss': 19.3943}
2024-07-27 09:49:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 3.362, 'neural_augmentation': 0.0, 'total_loss': 3.362} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9289, 0.8683, 0.8928, 0.9671, 0.9038, 0.9643, 0.8847, 0.883, 0.9227, 0.8763, 0.8804, 0.903, 0.8076, 0.932, 0.8921, 0.9405, 0.9573, 0.978, 0.9163, 0.9253, 0.935, 0.8241, 0.9079, 0.951, 0.9258, 0.914, 0.9256, 0.9528, 0.9121, 0.8939, 0.8217, 0.809, 0.9072, 0.9309, 0.8758, 0.8667, 0.9228, 0.9238, 0.9038, 0.8845, 0.996, 0.8249, 0.9447, 0.9695, 0.9066, 0.9456, 0.7967, 0.932, 0.8231, 0.9065, 0.867, 0.8836, 0.9721, 0.918, 0.9508, 0.9327, 0.9777, 0.916, 0.9006, 0.8225, 0.8327, 0.8807, 0.9344, 0.9209, 0.882, 0.8417, 0.9643, 0.9486, 0.9413, 0.7732, 0.9184, 0.8891, 0.9446, 0.9235, 0.8745, 0.8667, 0.8834, 0.9189, 0.9533, 0.9677, 0.8917, 0.9622, 0.9102, 0.8534, 0.9592, 0.9511, 0.9161, 0.9139, 0.8449, 0.949, 0.9617, 0.7404, 0.9369, 0.878, 0.9103, 0.9193, 0.9675, 0.8306, 0.8833, 0.9038, 0.9081, 0.9093, 0.9144, 0.8755, 0.9655, 0.9142, 0.9587, 0.8309, 0.939, 0.9298, 0.8755, 0.9618, 0.933, 0.902, 0.6957, 0.9159, 0.8083, 0.9422, 0.9014, 0.9675, 0.9345, 0.8951, 0.9469, 0.9504, 0.9096, 0.8302, 0.9503, 0.9332, 0.9155, 0.8681, 0.6204, 0.9333, 0.9659, 0.9331, 0.9296, 0.9676, 0.8442, 0.9677, 0.8999, 0.8903, 0.9243, 0.8703, 0.9165, 0.9144, 0.929, 0.9679, 0.9226, 0.9001, 0.9655, 0.9236, 0.8548, 0.8557, 0.8897, 0.9676, 0.9559, 0.8578, 0.8565, 0.9013, 0.9117, 0.8656, 0.9072, 0.9016, 0.8337, 0.9097, 0.9426, 0.8528, 0.9115, 0.9538, 0.9388, 0.9162, 0.9042, 0.9306, 0.9222, 0.8305], 'AP': [0.9727, 0.9325, 0.9538, 0.9901, 0.9478, 0.9961, 0.95, 0.9204, 0.9746, 0.9485, 0.9384, 0.9637, 0.8611, 0.9771, 0.9352, 0.9731, 0.9873, 0.9926, 0.9578, 0.965, 0.97, 0.8987, 0.964, 0.9864, 0.9663, 0.9581, 0.9662, 0.9792, 0.9717, 0.9479, 0.871, 0.8805, 0.9562, 0.9714, 0.944, 0.9267, 0.9657, 0.9767, 0.9605, 0.9292, 0.9998, 0.8985, 0.9848, 0.9909, 0.9618, 0.9801, 0.8888, 0.9658, 0.8823, 0.9564, 0.9183, 0.9465, 0.9935, 0.966, 0.984, 0.9745, 0.9923, 0.9653, 0.9511, 0.8851, 0.8945, 0.9366, 0.9694, 0.9669, 0.9477, 0.8985, 0.9907, 0.9836, 0.9725, 0.8267, 0.9416, 0.9277, 0.9749, 0.9685, 0.9348, 0.9147, 0.9197, 0.9673, 0.9835, 0.9879, 0.9564, 0.9917, 0.9703, 0.9153, 0.9885, 0.986, 0.9715, 0.965, 0.9178, 0.9844, 0.9922, 0.7989, 0.9685, 0.9374, 0.9569, 0.9723, 0.9943, 0.8938, 0.9424, 0.9581, 0.9618, 0.9534, 0.9544, 0.9387, 0.9886, 0.9661, 0.9894, 0.8959, 0.9745, 0.97, 0.9185, 0.9871, 0.9808, 0.9571, 0.7345, 0.9671, 0.8638, 0.982, 0.9586, 0.9893, 0.9776, 0.9524, 0.9747, 0.9806, 0.9687, 0.8897, 0.9783, 0.9699, 0.9572, 0.9068, 0.6297, 0.9705, 0.9915, 0.9628, 0.971, 0.988, 0.903, 0.9912, 0.9595, 0.9365, 0.9678, 0.9277, 0.9733, 0.9668, 0.9745, 0.9891, 0.9764, 0.9511, 0.99, 0.9612, 0.9199, 0.9021, 0.9482, 0.9878, 0.9868, 0.907, 0.9097, 0.9593, 0.9637, 0.9235, 0.9652, 0.9503, 0.8824, 0.9668, 0.9727, 0.9058, 0.9644, 0.9838, 0.9719, 0.9637, 0.9427, 0.9643, 0.9768, 0.8794], 'Recall@P=50': [0.9873, 0.96, 0.9771, 0.996, 0.968, 1.0, 0.9768, 0.96, 0.992, 0.9843, 0.968, 0.9904, 0.868, 0.992, 0.96, 0.988, 0.9952, 0.992, 0.976, 0.98, 0.988, 0.928, 0.988, 0.996, 0.9747, 0.9736, 0.984, 0.984, 0.9956, 0.9712, 0.896, 0.932, 0.984, 0.98, 0.973, 0.956, 0.98, 0.999, 0.985, 0.952, 1.0, 0.952, 1.0, 0.996, 0.976, 0.984, 0.9507, 0.976, 0.924, 0.984, 0.936, 0.9747, 0.998, 0.9806, 0.994, 0.9873, 0.996, 0.988, 0.964, 0.916, 0.948, 0.976, 0.988, 0.98, 0.978, 0.944, 0.996, 0.996, 0.98, 0.904, 0.976, 0.944, 0.984, 0.9856, 0.964, 0.002, 0.956, 0.9933, 0.9933, 0.996, 0.9863, 1.0, 0.9944, 0.948, 1.0, 0.996, 0.9938, 0.988, 0.9617, 1.0, 0.998, 0.856, 0.98, 0.9616, 0.968, 0.9935, 0.996, 0.948, 0.9713, 0.988, 0.9846, 0.968, 0.972, 0.9787, 0.992, 0.9823, 0.996, 0.94, 0.9864, 0.98, 0.964, 0.992, 0.9989, 0.98, 0.852, 0.9867, 0.948, 0.9947, 0.992, 0.992, 0.992, 0.9747, 0.988, 0.988, 0.9967, 0.912, 0.988, 0.9787, 0.976, 0.94, 0.008, 0.98, 0.996, 0.968, 0.982, 0.992, 0.9507, 0.996, 0.9847, 0.964, 0.988, 0.956, 1.0, 0.989, 0.9928, 0.996, 0.9993, 0.9773, 0.996, 0.974, 0.944, 0.928, 0.9733, 0.992, 0.994, 0.932, 0.936, 0.988, 0.984, 0.956, 0.986, 0.968, 0.9, 0.9888, 0.984, 0.94, 0.988, 0.992, 0.992, 0.98, 0.968, 0.984, 0.9987, 0.912], 'micro': 0.9626, 'macro': 0.9503, 'weighted': 0.9618}
2024-07-27 09:49:51 - [34m[1mLOGS   [0m - Best checkpoint with score 0.95 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:49:51 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9228.pt
2024-07-27 09:49:51 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9298.pt', 'checkpoint_score_0.9396.pt', 'checkpoint_score_0.9419.pt', 'checkpoint_score_0.9475.pt', 'checkpoint_score_0.9503.pt']
2024-07-27 09:49:53 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:49:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:49:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:49:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 6512 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_10_iter_6512.pt
2024-07-27 09:49:55 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 6512 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_10_iter_6512.pt
[31m===========================================================================[0m
2024-07-27 09:49:57 - [32m[1mINFO   [0m - Training epoch 11
2024-07-27 09:49:57 - [34m[1mLOGS   [0m - Epoch:  11 [    6513/10000000], loss: {'classification': 7.1431, 'neural_augmentation': 10.4175, 'total_loss': 17.5606}, LR: [9e-06, 9e-06], Avg. batch load time: 0.521, Elapsed time:  0.62
2024-07-27 09:50:35 - [34m[1mLOGS   [0m - Epoch:  11 [    7013/10000000], loss: {'classification': 8.4842, 'neural_augmentation': 10.5931, 'total_loss': 19.0773}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.67
2024-07-27 09:50:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 8.5085, 'neural_augmentation': 10.6229, 'total_loss': 19.1314}
2024-07-27 09:51:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 3.1429, 'neural_augmentation': 0.0, 'total_loss': 3.1429} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9313, 0.8861, 0.8982, 0.9755, 0.9057, 0.9757, 0.8919, 0.8577, 0.9316, 0.8877, 0.8876, 0.9176, 0.7974, 0.9354, 0.8993, 0.9395, 0.9623, 0.978, 0.9292, 0.9286, 0.9419, 0.8517, 0.925, 0.9527, 0.9249, 0.9122, 0.9278, 0.961, 0.9097, 0.9045, 0.827, 0.8281, 0.9117, 0.9414, 0.8923, 0.881, 0.9271, 0.9275, 0.9016, 0.882, 0.996, 0.835, 0.9412, 0.9698, 0.9156, 0.9595, 0.8008, 0.9435, 0.8262, 0.9174, 0.8687, 0.8894, 0.9787, 0.916, 0.9455, 0.9351, 0.9734, 0.9298, 0.9076, 0.8319, 0.8414, 0.8834, 0.9366, 0.9312, 0.8996, 0.8401, 0.9661, 0.9441, 0.9392, 0.7727, 0.9155, 0.8849, 0.9443, 0.9255, 0.8884, 0.8604, 0.8506, 0.9231, 0.9538, 0.9654, 0.9024, 0.9673, 0.9151, 0.8768, 0.9565, 0.9557, 0.9158, 0.9256, 0.8511, 0.9421, 0.9659, 0.748, 0.9314, 0.8829, 0.9231, 0.9208, 0.9699, 0.8185, 0.8886, 0.9095, 0.9183, 0.9095, 0.9275, 0.8703, 0.9658, 0.9193, 0.9574, 0.8398, 0.9431, 0.9409, 0.8504, 0.9615, 0.9338, 0.9104, 0.6994, 0.9169, 0.8095, 0.9442, 0.9015, 0.9679, 0.9368, 0.8955, 0.9441, 0.9558, 0.9158, 0.8365, 0.9484, 0.9427, 0.9076, 0.8704, 0.6041, 0.9417, 0.968, 0.936, 0.9306, 0.9695, 0.8602, 0.9684, 0.9094, 0.896, 0.9289, 0.8857, 0.9234, 0.9254, 0.9318, 0.9652, 0.9303, 0.8956, 0.9671, 0.9234, 0.8559, 0.8602, 0.9048, 0.9695, 0.9519, 0.8547, 0.8659, 0.8956, 0.9153, 0.8755, 0.9122, 0.9135, 0.8362, 0.9177, 0.9419, 0.8606, 0.9176, 0.9535, 0.9116, 0.9209, 0.9032, 0.9489, 0.9241, 0.8323], 'AP': [0.9754, 0.944, 0.955, 0.9937, 0.953, 0.9939, 0.9534, 0.9182, 0.9801, 0.9572, 0.9408, 0.9692, 0.8582, 0.98, 0.9461, 0.9716, 0.9891, 0.9915, 0.9667, 0.9716, 0.9717, 0.9104, 0.9737, 0.987, 0.9646, 0.9621, 0.972, 0.982, 0.9722, 0.9609, 0.8904, 0.898, 0.9571, 0.9733, 0.9535, 0.9357, 0.9722, 0.9796, 0.9621, 0.9391, 0.9999, 0.9029, 0.9828, 0.9872, 0.9663, 0.9887, 0.8926, 0.9672, 0.8867, 0.9642, 0.9176, 0.9544, 0.9943, 0.9683, 0.9813, 0.9785, 0.9925, 0.9747, 0.9605, 0.8875, 0.9017, 0.9417, 0.9703, 0.9715, 0.9566, 0.9199, 0.9907, 0.9826, 0.9771, 0.8481, 0.9513, 0.9257, 0.9776, 0.9653, 0.9434, 0.9124, 0.9144, 0.971, 0.9847, 0.987, 0.9622, 0.9927, 0.972, 0.9189, 0.9911, 0.9898, 0.9741, 0.9729, 0.9293, 0.9835, 0.9927, 0.8171, 0.9706, 0.9444, 0.9657, 0.9735, 0.9938, 0.8892, 0.9474, 0.9652, 0.968, 0.9538, 0.96, 0.9389, 0.986, 0.9684, 0.9898, 0.9197, 0.9772, 0.975, 0.9123, 0.988, 0.9824, 0.9597, 0.7347, 0.9702, 0.8674, 0.9837, 0.9637, 0.9852, 0.9802, 0.9547, 0.9761, 0.9854, 0.9729, 0.8915, 0.9815, 0.973, 0.96, 0.9195, 0.6079, 0.972, 0.9908, 0.9677, 0.9718, 0.9856, 0.9187, 0.9871, 0.9674, 0.934, 0.9743, 0.9344, 0.978, 0.9686, 0.9793, 0.9883, 0.9816, 0.9555, 0.9923, 0.9564, 0.9298, 0.9116, 0.9477, 0.9853, 0.9841, 0.9078, 0.9128, 0.9597, 0.967, 0.9353, 0.9669, 0.962, 0.8957, 0.9722, 0.9741, 0.9089, 0.9644, 0.9847, 0.9642, 0.9742, 0.9506, 0.9675, 0.9786, 0.8914], 'Recall@P=50': [0.9893, 0.98, 0.9817, 0.996, 0.964, 1.0, 0.9784, 0.956, 0.9968, 0.9895, 0.972, 0.9896, 0.88, 0.992, 0.968, 0.988, 0.996, 0.992, 0.972, 0.984, 0.984, 0.936, 0.988, 0.9976, 0.972, 0.9832, 0.988, 0.992, 0.9961, 0.9832, 0.924, 0.948, 0.98, 0.984, 0.982, 0.956, 0.988, 0.9994, 0.987, 0.968, 1.0, 0.952, 0.992, 0.988, 0.988, 0.996, 0.9547, 0.968, 0.9333, 0.988, 0.94, 0.9811, 0.996, 0.9851, 0.992, 0.99, 0.994, 0.984, 0.98, 0.928, 0.936, 0.98, 0.984, 0.992, 0.98, 0.956, 0.996, 0.992, 0.986, 0.912, 0.976, 0.938, 0.988, 0.9872, 0.972, 0.964, 0.96, 0.9893, 0.9947, 0.996, 0.9884, 0.996, 0.9956, 0.936, 1.0, 0.998, 0.9964, 0.988, 0.9722, 0.992, 1.0, 0.88, 0.98, 0.9736, 0.976, 0.9949, 0.996, 0.94, 0.9753, 0.996, 0.9886, 0.974, 0.976, 0.976, 0.988, 0.9877, 0.998, 0.964, 0.9848, 0.988, 0.952, 0.992, 0.999, 0.976, 0.004, 0.988, 0.928, 0.9967, 1.0, 0.988, 0.992, 0.9787, 0.988, 0.996, 0.997, 0.924, 0.992, 0.9827, 0.984, 0.948, 0.744, 0.984, 0.996, 0.976, 0.9813, 0.988, 0.9627, 0.988, 0.9897, 0.956, 0.988, 0.964, 1.0, 0.986, 0.9928, 0.996, 0.9993, 0.9773, 0.996, 0.966, 0.97, 0.932, 0.9627, 0.988, 0.992, 0.944, 0.952, 0.987, 0.988, 0.96, 0.99, 0.976, 0.92, 0.9925, 0.984, 0.94, 0.984, 0.992, 0.984, 0.996, 0.968, 0.976, 0.9994, 0.92], 'micro': 0.9668, 'macro': 0.954, 'weighted': 0.9654}
2024-07-27 09:51:11 - [34m[1mLOGS   [0m - Best checkpoint with score 0.95 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:51:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9298.pt
2024-07-27 09:51:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9396.pt', 'checkpoint_score_0.9419.pt', 'checkpoint_score_0.9475.pt', 'checkpoint_score_0.9503.pt', 'checkpoint_score_0.9540.pt']
2024-07-27 09:51:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:51:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:51:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:51:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 7104 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_11_iter_7104.pt
2024-07-27 09:51:16 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 7104 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_11_iter_7104.pt
[31m===========================================================================[0m
2024-07-27 09:51:18 - [32m[1mINFO   [0m - Training epoch 12
2024-07-27 09:51:19 - [34m[1mLOGS   [0m - Epoch:  12 [    7105/10000000], loss: {'classification': 8.3241, 'neural_augmentation': 9.8423, 'total_loss': 18.1664}, LR: [9e-06, 9e-06], Avg. batch load time: 0.811, Elapsed time:  0.89
2024-07-27 09:51:56 - [34m[1mLOGS   [0m - Epoch:  12 [    7605/10000000], loss: {'classification': 8.2427, 'neural_augmentation': 10.6621, 'total_loss': 18.9048}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.50
2024-07-27 09:52:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 8.2506, 'neural_augmentation': 10.6691, 'total_loss': 18.9198}
2024-07-27 09:52:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 3.1427, 'neural_augmentation': 0.0, 'total_loss': 3.1427} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9292, 0.8681, 0.8937, 0.9735, 0.92, 0.9738, 0.898, 0.8583, 0.9302, 0.8846, 0.8684, 0.9133, 0.7938, 0.9405, 0.9113, 0.9331, 0.9647, 0.978, 0.9314, 0.9374, 0.9383, 0.8486, 0.9179, 0.9541, 0.9259, 0.9159, 0.9358, 0.9551, 0.9173, 0.9018, 0.8392, 0.8635, 0.9365, 0.9372, 0.8884, 0.8875, 0.9296, 0.9282, 0.9068, 0.8902, 0.998, 0.8364, 0.9388, 0.9675, 0.9272, 0.9539, 0.8168, 0.9419, 0.8167, 0.9177, 0.8615, 0.8881, 0.9767, 0.9142, 0.9403, 0.94, 0.975, 0.9199, 0.9215, 0.8571, 0.8307, 0.8793, 0.93, 0.9385, 0.8963, 0.8509, 0.9701, 0.9395, 0.9415, 0.7871, 0.9199, 0.8841, 0.9424, 0.9146, 0.8727, 0.8658, 0.8534, 0.9223, 0.9549, 0.9611, 0.8937, 0.9741, 0.9118, 0.8683, 0.9568, 0.955, 0.9196, 0.9253, 0.8544, 0.944, 0.9728, 0.7556, 0.9256, 0.885, 0.9298, 0.9205, 0.9661, 0.8212, 0.8941, 0.8958, 0.9175, 0.9106, 0.9246, 0.8741, 0.9633, 0.9184, 0.9633, 0.8571, 0.9403, 0.935, 0.8571, 0.9641, 0.9353, 0.9098, 0.7182, 0.9167, 0.8092, 0.9479, 0.8907, 0.9657, 0.9401, 0.899, 0.9407, 0.9532, 0.9185, 0.8529, 0.952, 0.9426, 0.9405, 0.8589, 0.6349, 0.9429, 0.9681, 0.9301, 0.9337, 0.9657, 0.8556, 0.9613, 0.9066, 0.8903, 0.919, 0.877, 0.9275, 0.9266, 0.9366, 0.9639, 0.9287, 0.9061, 0.9755, 0.9206, 0.871, 0.8583, 0.9048, 0.961, 0.9541, 0.8468, 0.8541, 0.9054, 0.9224, 0.8902, 0.9071, 0.9272, 0.8458, 0.9179, 0.929, 0.8679, 0.9156, 0.9493, 0.9215, 0.9202, 0.9189, 0.9443, 0.9242, 0.8354], 'AP': [0.974, 0.9258, 0.9535, 0.9915, 0.9608, 0.9936, 0.9537, 0.9256, 0.9773, 0.9546, 0.9338, 0.967, 0.8508, 0.9816, 0.9485, 0.9732, 0.988, 0.9934, 0.9586, 0.9714, 0.9715, 0.9078, 0.9632, 0.986, 0.9675, 0.9608, 0.973, 0.9828, 0.9747, 0.9613, 0.8912, 0.902, 0.9688, 0.9714, 0.9514, 0.9331, 0.9717, 0.9798, 0.9581, 0.9447, 1.0, 0.8977, 0.9808, 0.9892, 0.965, 0.9855, 0.9043, 0.9667, 0.8874, 0.9602, 0.9175, 0.9526, 0.9933, 0.9651, 0.9763, 0.9785, 0.9942, 0.965, 0.9605, 0.8971, 0.9, 0.9451, 0.9648, 0.9738, 0.9507, 0.9136, 0.9918, 0.9822, 0.9735, 0.8527, 0.9419, 0.9268, 0.9798, 0.9606, 0.9256, 0.9196, 0.9212, 0.9716, 0.984, 0.9899, 0.959, 0.9921, 0.9702, 0.919, 0.9869, 0.9883, 0.9748, 0.9648, 0.9244, 0.9804, 0.9936, 0.8189, 0.9655, 0.9442, 0.9544, 0.9734, 0.9918, 0.88, 0.9511, 0.9587, 0.9694, 0.9507, 0.9567, 0.9371, 0.9875, 0.9688, 0.9909, 0.9135, 0.9767, 0.9709, 0.9193, 0.9899, 0.9827, 0.9578, 0.7626, 0.9673, 0.8758, 0.9843, 0.9575, 0.9876, 0.9808, 0.9596, 0.976, 0.9847, 0.9735, 0.8999, 0.9819, 0.9746, 0.9743, 0.9043, 0.6259, 0.9713, 0.9916, 0.9726, 0.9712, 0.988, 0.9168, 0.9887, 0.966, 0.943, 0.9656, 0.9324, 0.9798, 0.9718, 0.9782, 0.9907, 0.981, 0.9557, 0.9903, 0.9637, 0.9339, 0.9118, 0.9506, 0.9868, 0.9868, 0.9035, 0.9111, 0.9641, 0.963, 0.9419, 0.965, 0.9622, 0.8943, 0.9709, 0.9701, 0.9063, 0.9677, 0.9815, 0.9641, 0.9774, 0.9611, 0.9752, 0.9778, 0.8942], 'Recall@P=50': [0.984, 0.952, 0.9823, 0.996, 0.972, 1.0, 0.9768, 0.96, 0.9928, 0.9886, 0.976, 0.9892, 0.852, 0.996, 0.974, 0.988, 0.9976, 0.996, 0.968, 0.984, 0.976, 0.934, 0.98, 0.996, 0.98, 0.9736, 0.984, 0.996, 0.9965, 0.9904, 0.928, 0.936, 0.98, 0.988, 0.98, 0.96, 0.996, 0.9992, 0.98, 0.98, 1.0, 0.952, 0.992, 0.992, 0.98, 0.992, 0.96, 0.968, 0.9333, 0.98, 0.948, 0.9774, 0.998, 0.9834, 0.99, 0.988, 0.998, 0.98, 0.98, 0.936, 0.948, 0.98, 0.968, 0.98, 0.978, 0.954, 0.996, 0.9933, 0.978, 0.908, 0.976, 0.952, 0.992, 0.9816, 0.948, 0.958, 0.952, 0.9907, 0.9947, 0.996, 0.9858, 0.996, 0.9936, 0.944, 0.996, 0.996, 0.9947, 0.976, 0.9652, 0.992, 1.0, 0.872, 0.972, 0.9712, 0.964, 0.9945, 0.996, 0.948, 0.9753, 0.992, 0.9886, 0.96, 0.968, 0.976, 0.992, 0.984, 0.998, 0.944, 0.9896, 0.984, 0.944, 0.996, 0.9994, 0.972, 0.004, 0.988, 0.956, 0.994, 0.988, 0.988, 0.996, 0.9833, 0.988, 0.992, 0.997, 0.932, 0.988, 0.984, 0.988, 0.942, 0.784, 0.984, 0.996, 0.992, 0.9833, 0.992, 0.9627, 0.992, 0.989, 0.976, 0.988, 0.968, 0.996, 0.987, 0.9912, 0.996, 0.9989, 0.9787, 0.992, 0.982, 0.97, 0.95, 0.976, 0.992, 0.994, 0.928, 0.928, 0.984, 0.98, 0.976, 0.989, 0.976, 0.928, 0.9912, 0.98, 0.916, 0.984, 0.988, 0.992, 1.0, 0.972, 0.984, 0.9991, 0.936], 'micro': 0.9661, 'macro': 0.9539, 'weighted': 0.965}
2024-07-27 09:52:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:52:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:52:29 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 7696 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_12_iter_7696.pt
2024-07-27 09:52:30 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 7696 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_12_iter_7696.pt
[31m===========================================================================[0m
2024-07-27 09:52:32 - [32m[1mINFO   [0m - Training epoch 13
2024-07-27 09:52:33 - [34m[1mLOGS   [0m - Epoch:  13 [    7697/10000000], loss: {'classification': 9.0466, 'neural_augmentation': 10.4872, 'total_loss': 19.5339}, LR: [9e-06, 9e-06], Avg. batch load time: 0.723, Elapsed time:  0.81
2024-07-27 09:53:10 - [34m[1mLOGS   [0m - Epoch:  13 [    8197/10000000], loss: {'classification': 8.0756, 'neural_augmentation': 10.5678, 'total_loss': 18.6434}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.31
2024-07-27 09:53:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 8.1004, 'neural_augmentation': 10.5712, 'total_loss': 18.6716}
2024-07-27 09:53:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 3.0357, 'neural_augmentation': 0.0, 'total_loss': 3.0357} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9285, 0.8875, 0.906, 0.9715, 0.9208, 0.9735, 0.9027, 0.8747, 0.9366, 0.8904, 0.8755, 0.9217, 0.7946, 0.9419, 0.9087, 0.94, 0.9642, 0.9817, 0.917, 0.932, 0.9426, 0.8411, 0.9246, 0.9518, 0.9317, 0.9172, 0.9296, 0.9572, 0.9256, 0.9054, 0.8313, 0.8429, 0.9385, 0.9375, 0.8932, 0.8947, 0.938, 0.9323, 0.904, 0.8831, 0.996, 0.8097, 0.9356, 0.9669, 0.9212, 0.9533, 0.8069, 0.9439, 0.8251, 0.9212, 0.8735, 0.8945, 0.9735, 0.9198, 0.9384, 0.9382, 0.9768, 0.9289, 0.9148, 0.8481, 0.8161, 0.9012, 0.9409, 0.9261, 0.8921, 0.8384, 0.9684, 0.9423, 0.9533, 0.7778, 0.9212, 0.8875, 0.9402, 0.925, 0.8848, 0.8837, 0.8708, 0.9245, 0.9524, 0.9654, 0.9032, 0.9679, 0.9175, 0.8732, 0.9584, 0.9535, 0.9215, 0.9287, 0.8687, 0.9352, 0.9736, 0.7521, 0.9325, 0.8904, 0.9146, 0.9257, 0.9741, 0.8354, 0.8933, 0.8925, 0.9229, 0.9151, 0.9344, 0.8771, 0.9637, 0.9182, 0.9652, 0.8555, 0.9444, 0.938, 0.8701, 0.9597, 0.9343, 0.9197, 0.7064, 0.9147, 0.809, 0.9476, 0.8861, 0.9695, 0.9426, 0.9033, 0.9448, 0.953, 0.9149, 0.8466, 0.956, 0.9381, 0.932, 0.8765, 0.6129, 0.9372, 0.9685, 0.9315, 0.9312, 0.9714, 0.8637, 0.9679, 0.9144, 0.905, 0.936, 0.8889, 0.9325, 0.931, 0.9364, 0.9631, 0.9329, 0.9139, 0.9697, 0.9344, 0.866, 0.863, 0.9137, 0.9735, 0.9527, 0.8471, 0.8566, 0.9031, 0.9189, 0.8898, 0.9143, 0.9177, 0.8484, 0.9208, 0.9385, 0.8577, 0.9257, 0.9575, 0.915, 0.9237, 0.9189, 0.9467, 0.9265, 0.8374], 'AP': [0.9725, 0.939, 0.958, 0.9909, 0.9649, 0.9916, 0.9575, 0.9189, 0.9816, 0.957, 0.9348, 0.9715, 0.8502, 0.9833, 0.9439, 0.976, 0.9876, 0.9946, 0.9632, 0.9717, 0.9792, 0.9089, 0.9642, 0.9856, 0.9722, 0.964, 0.9718, 0.978, 0.9781, 0.9607, 0.886, 0.9051, 0.9679, 0.9735, 0.9539, 0.9418, 0.9728, 0.9811, 0.9581, 0.9384, 0.9999, 0.8851, 0.9826, 0.9924, 0.9625, 0.9857, 0.8946, 0.9699, 0.8853, 0.9571, 0.9259, 0.9545, 0.9931, 0.9679, 0.9768, 0.9806, 0.9957, 0.9622, 0.9648, 0.8969, 0.8883, 0.953, 0.9699, 0.9725, 0.9525, 0.9057, 0.9917, 0.9833, 0.9795, 0.8409, 0.9433, 0.929, 0.9792, 0.9687, 0.9411, 0.9267, 0.9187, 0.9698, 0.9859, 0.9912, 0.9644, 0.9915, 0.9727, 0.9281, 0.9899, 0.9891, 0.9751, 0.9633, 0.9372, 0.9816, 0.994, 0.8085, 0.9712, 0.9479, 0.9607, 0.9753, 0.9942, 0.8718, 0.9513, 0.9595, 0.9735, 0.957, 0.9644, 0.9432, 0.9915, 0.9702, 0.9892, 0.924, 0.9808, 0.9755, 0.9158, 0.991, 0.9821, 0.9671, 0.7567, 0.9679, 0.8747, 0.9854, 0.9595, 0.9923, 0.9834, 0.9637, 0.9759, 0.9856, 0.9728, 0.9012, 0.9842, 0.9717, 0.9664, 0.9182, 0.6213, 0.972, 0.991, 0.9712, 0.972, 0.9919, 0.9191, 0.9923, 0.9682, 0.9523, 0.9587, 0.9305, 0.9824, 0.9761, 0.9806, 0.9912, 0.9824, 0.9631, 0.9915, 0.9705, 0.9313, 0.9136, 0.9556, 0.9918, 0.9867, 0.9094, 0.915, 0.9657, 0.9605, 0.9327, 0.9655, 0.9651, 0.8897, 0.9726, 0.9747, 0.9127, 0.972, 0.9861, 0.9634, 0.9785, 0.9664, 0.9727, 0.9796, 0.8946], 'Recall@P=50': [0.9867, 0.96, 0.98, 0.996, 0.976, 0.996, 0.9808, 0.944, 0.9968, 0.9883, 0.972, 0.99, 0.852, 0.994, 0.968, 0.984, 0.9936, 0.996, 0.976, 0.988, 0.992, 0.948, 0.98, 0.9968, 0.9853, 0.976, 0.988, 0.988, 0.9972, 0.9824, 0.92, 0.928, 0.984, 0.988, 0.981, 0.96, 0.988, 0.9994, 0.982, 0.972, 1.0, 0.92, 0.992, 0.996, 0.972, 0.996, 0.9613, 0.968, 0.9347, 0.968, 0.96, 0.9795, 0.998, 0.9886, 0.988, 0.99, 0.998, 0.98, 0.984, 0.928, 0.92, 0.992, 0.976, 0.984, 0.98, 0.95, 0.996, 0.9947, 0.986, 0.888, 0.972, 0.954, 0.992, 0.9848, 0.972, 0.962, 0.952, 0.988, 0.9947, 0.996, 0.9911, 0.996, 0.9976, 0.956, 0.998, 0.996, 0.9969, 0.984, 0.9765, 0.996, 1.0, 0.86, 0.984, 0.9744, 0.968, 0.9949, 0.996, 0.952, 0.9773, 0.988, 0.9926, 0.97, 0.98, 0.9813, 0.996, 0.9913, 0.998, 0.952, 0.9904, 0.996, 0.944, 1.0, 0.9983, 0.988, 0.004, 0.9893, 0.948, 0.9967, 0.988, 0.996, 0.994, 0.9893, 0.988, 0.992, 0.9973, 0.948, 0.992, 0.988, 0.988, 0.948, 0.76, 0.984, 0.996, 0.976, 0.9833, 0.996, 0.9533, 0.996, 0.991, 0.992, 0.988, 0.96, 1.0, 0.992, 0.9936, 1.0, 0.9994, 0.988, 1.0, 0.982, 0.962, 0.942, 0.98, 0.996, 0.996, 0.932, 0.94, 0.988, 0.972, 0.968, 0.989, 0.98, 0.912, 0.9925, 0.98, 0.936, 0.9867, 0.992, 0.988, 0.996, 0.984, 0.98, 0.9994, 0.928], 'micro': 0.9683, 'macro': 0.9553, 'weighted': 0.9668}
2024-07-27 09:53:41 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:53:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9396.pt
2024-07-27 09:53:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9419.pt', 'checkpoint_score_0.9475.pt', 'checkpoint_score_0.9503.pt', 'checkpoint_score_0.9540.pt', 'checkpoint_score_0.9553.pt']
2024-07-27 09:53:44 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:53:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:53:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:53:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 8288 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_13_iter_8288.pt
2024-07-27 09:53:47 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 8288 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_13_iter_8288.pt
[31m===========================================================================[0m
2024-07-27 09:53:49 - [32m[1mINFO   [0m - Training epoch 14
2024-07-27 09:53:50 - [34m[1mLOGS   [0m - Epoch:  14 [    8289/10000000], loss: {'classification': 7.736, 'neural_augmentation': 9.1597, 'total_loss': 16.8956}, LR: [9e-06, 9e-06], Avg. batch load time: 0.401, Elapsed time:  0.50
2024-07-27 09:54:27 - [34m[1mLOGS   [0m - Epoch:  14 [    8789/10000000], loss: {'classification': 7.9296, 'neural_augmentation': 10.5895, 'total_loss': 18.5192}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.36
2024-07-27 09:54:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 7.9034, 'neural_augmentation': 10.5714, 'total_loss': 18.4748}
2024-07-27 09:54:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 3.0135, 'neural_augmentation': 0.0, 'total_loss': 3.0135} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9274, 0.8966, 0.9031, 0.9658, 0.914, 0.9798, 0.9022, 0.8602, 0.9317, 0.8935, 0.8909, 0.9196, 0.8084, 0.9364, 0.9007, 0.9472, 0.9626, 0.9759, 0.9409, 0.9325, 0.9491, 0.8497, 0.9243, 0.9546, 0.9316, 0.9101, 0.9298, 0.9631, 0.9261, 0.9046, 0.8228, 0.8519, 0.9172, 0.9325, 0.8962, 0.8824, 0.9333, 0.9317, 0.9052, 0.8861, 0.996, 0.8156, 0.9355, 0.9679, 0.9314, 0.9588, 0.8142, 0.95, 0.8294, 0.932, 0.8654, 0.891, 0.9779, 0.9233, 0.932, 0.9352, 0.9749, 0.9206, 0.9218, 0.8419, 0.8195, 0.8986, 0.9372, 0.9275, 0.9035, 0.8517, 0.9659, 0.9382, 0.9506, 0.7846, 0.9163, 0.8778, 0.9485, 0.9237, 0.893, 0.8873, 0.8553, 0.9257, 0.9546, 0.9654, 0.903, 0.9698, 0.9194, 0.8747, 0.962, 0.9542, 0.925, 0.9256, 0.8676, 0.9328, 0.978, 0.7672, 0.9358, 0.8786, 0.9295, 0.9248, 0.9737, 0.8458, 0.8929, 0.9087, 0.9225, 0.9108, 0.9205, 0.8805, 0.9701, 0.9251, 0.9616, 0.8656, 0.9426, 0.9342, 0.8571, 0.9598, 0.939, 0.9174, 0.7189, 0.9177, 0.8218, 0.948, 0.9061, 0.9721, 0.9414, 0.9086, 0.9487, 0.9655, 0.9194, 0.8475, 0.9537, 0.9435, 0.9165, 0.8671, 0.6279, 0.935, 0.9701, 0.9381, 0.9285, 0.9699, 0.8699, 0.972, 0.9129, 0.8917, 0.9283, 0.8889, 0.9286, 0.9281, 0.9342, 0.9597, 0.9354, 0.9041, 0.9675, 0.9281, 0.8718, 0.8646, 0.903, 0.9698, 0.9485, 0.8559, 0.8565, 0.9024, 0.9317, 0.8894, 0.9117, 0.9221, 0.8344, 0.92, 0.9474, 0.8619, 0.9292, 0.9597, 0.9031, 0.9243, 0.9068, 0.9304, 0.9284, 0.8326], 'AP': [0.9744, 0.942, 0.9592, 0.992, 0.9524, 0.9948, 0.958, 0.9179, 0.9807, 0.9596, 0.9408, 0.9698, 0.8597, 0.9836, 0.9428, 0.9792, 0.9862, 0.9943, 0.9657, 0.9673, 0.9727, 0.9154, 0.9635, 0.988, 0.9683, 0.9657, 0.9677, 0.9874, 0.9769, 0.9594, 0.8789, 0.9105, 0.9572, 0.9749, 0.9558, 0.9356, 0.9727, 0.9813, 0.9588, 0.9352, 0.9999, 0.8877, 0.977, 0.988, 0.9714, 0.9876, 0.9033, 0.9723, 0.8951, 0.9651, 0.9212, 0.9571, 0.994, 0.9678, 0.9766, 0.981, 0.9945, 0.96, 0.9588, 0.8986, 0.8914, 0.9487, 0.9664, 0.9691, 0.9561, 0.9194, 0.9929, 0.9805, 0.977, 0.8628, 0.9405, 0.9317, 0.9763, 0.9668, 0.9411, 0.9267, 0.9145, 0.9732, 0.9861, 0.9874, 0.9628, 0.9926, 0.973, 0.9214, 0.9907, 0.9885, 0.9766, 0.9619, 0.9375, 0.9805, 0.9927, 0.8332, 0.9682, 0.9443, 0.9603, 0.9754, 0.9937, 0.8914, 0.9512, 0.9619, 0.9701, 0.9521, 0.9623, 0.9414, 0.9888, 0.9707, 0.9908, 0.9176, 0.9796, 0.9769, 0.9157, 0.9871, 0.9831, 0.963, 0.7699, 0.9685, 0.878, 0.9843, 0.9622, 0.9882, 0.9826, 0.9632, 0.9736, 0.9872, 0.9739, 0.9023, 0.9855, 0.978, 0.9584, 0.921, 0.6536, 0.9753, 0.9926, 0.9717, 0.9703, 0.9881, 0.9251, 0.9887, 0.9678, 0.9442, 0.9656, 0.9347, 0.9807, 0.9735, 0.9779, 0.9905, 0.9825, 0.9605, 0.9918, 0.9654, 0.9354, 0.9217, 0.9534, 0.9881, 0.9858, 0.9118, 0.9084, 0.9617, 0.9713, 0.935, 0.9665, 0.9584, 0.8838, 0.9728, 0.9774, 0.9102, 0.9699, 0.9843, 0.9586, 0.979, 0.9532, 0.9679, 0.9801, 0.8867], 'Recall@P=50': [0.9907, 0.956, 0.9789, 0.992, 0.964, 0.996, 0.984, 0.956, 0.9944, 0.988, 0.976, 0.9884, 0.876, 0.996, 0.962, 0.992, 0.9952, 0.996, 0.972, 0.976, 0.988, 0.946, 0.98, 0.996, 0.98, 0.984, 0.976, 0.996, 0.997, 0.9824, 0.92, 0.94, 0.98, 0.984, 0.979, 0.956, 0.984, 0.9988, 0.983, 0.972, 1.0, 0.928, 0.984, 0.992, 0.984, 0.996, 0.96, 0.976, 0.9333, 0.984, 0.948, 0.9784, 0.996, 0.9834, 0.99, 0.9927, 0.996, 0.976, 0.98, 0.924, 0.932, 0.976, 0.98, 0.984, 0.9793, 0.96, 0.996, 0.9947, 0.982, 0.912, 0.972, 0.966, 0.988, 0.9848, 0.964, 0.964, 0.956, 0.992, 0.9947, 0.992, 0.9863, 0.996, 0.9968, 0.944, 1.0, 0.996, 0.9975, 0.984, 0.9757, 0.992, 0.996, 0.88, 0.98, 0.9672, 0.96, 0.9945, 0.996, 0.932, 0.9753, 0.988, 0.9886, 0.966, 0.984, 0.9747, 0.992, 0.9883, 1.0, 0.948, 0.9904, 0.992, 0.96, 0.992, 0.9987, 0.982, 0.876, 0.9887, 0.944, 0.9953, 0.992, 0.992, 0.994, 0.9867, 0.98, 0.996, 0.9967, 0.932, 0.996, 0.9853, 0.984, 0.964, 0.812, 0.98, 0.996, 0.984, 0.9853, 0.992, 0.9547, 0.992, 0.99, 0.976, 0.988, 0.964, 0.996, 0.987, 0.9896, 1.0, 0.9988, 0.988, 1.0, 0.974, 0.964, 0.958, 0.9747, 0.992, 0.994, 0.936, 0.932, 0.986, 0.984, 0.976, 0.99, 0.968, 0.908, 0.993, 0.984, 0.94, 0.988, 0.99, 0.988, 0.992, 0.968, 0.976, 0.9995, 0.928], 'micro': 0.9683, 'macro': 0.9556, 'weighted': 0.9671}
2024-07-27 09:55:00 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:55:01 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9419.pt
2024-07-27 09:55:01 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9475.pt', 'checkpoint_score_0.9503.pt', 'checkpoint_score_0.9540.pt', 'checkpoint_score_0.9553.pt', 'checkpoint_score_0.9556.pt']
2024-07-27 09:55:03 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:55:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:55:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:55:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 8880 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_14_iter_8880.pt
2024-07-27 09:55:06 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 8880 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_14_iter_8880.pt
[31m===========================================================================[0m
2024-07-27 09:55:08 - [32m[1mINFO   [0m - Training epoch 15
2024-07-27 09:55:09 - [34m[1mLOGS   [0m - Epoch:  15 [    8881/10000000], loss: {'classification': 7.1045, 'neural_augmentation': 10.9024, 'total_loss': 18.0069}, LR: [9e-06, 9e-06], Avg. batch load time: 0.678, Elapsed time:  0.76
2024-07-27 09:55:46 - [34m[1mLOGS   [0m - Epoch:  15 [    9381/10000000], loss: {'classification': 7.7434, 'neural_augmentation': 10.5584, 'total_loss': 18.3018}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.36
2024-07-27 09:55:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 7.7416, 'neural_augmentation': 10.5804, 'total_loss': 18.322}
2024-07-27 09:56:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 2.8406, 'neural_augmentation': 0.0, 'total_loss': 2.8406} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9371, 0.9006, 0.9049, 0.9698, 0.9262, 0.9778, 0.9067, 0.8683, 0.9388, 0.9007, 0.8829, 0.924, 0.8094, 0.9421, 0.9072, 0.9442, 0.9676, 0.9761, 0.9308, 0.9293, 0.9421, 0.8652, 0.9355, 0.9491, 0.9299, 0.9215, 0.9256, 0.9535, 0.9257, 0.9102, 0.8402, 0.8559, 0.9282, 0.9344, 0.8972, 0.8789, 0.9378, 0.9329, 0.9072, 0.898, 0.996, 0.846, 0.9465, 0.9757, 0.9284, 0.9506, 0.8115, 0.9448, 0.8345, 0.924, 0.8763, 0.9056, 0.9758, 0.9218, 0.9438, 0.9397, 0.98, 0.94, 0.9168, 0.8437, 0.8455, 0.9165, 0.9352, 0.9203, 0.909, 0.8691, 0.976, 0.9465, 0.946, 0.7856, 0.9132, 0.9, 0.9431, 0.9263, 0.8989, 0.8952, 0.871, 0.9332, 0.9547, 0.9655, 0.9096, 0.9759, 0.9201, 0.8758, 0.9596, 0.9579, 0.928, 0.9296, 0.8652, 0.9405, 0.9707, 0.7722, 0.939, 0.892, 0.9286, 0.9231, 0.9799, 0.8438, 0.9024, 0.9038, 0.9246, 0.913, 0.9253, 0.8808, 0.9717, 0.926, 0.9627, 0.8694, 0.948, 0.9434, 0.8704, 0.9641, 0.9404, 0.9301, 0.7152, 0.9223, 0.8235, 0.9502, 0.902, 0.9779, 0.9388, 0.9157, 0.9476, 0.9485, 0.9215, 0.8534, 0.9488, 0.9398, 0.9216, 0.8788, 0.65, 0.94, 0.9737, 0.9375, 0.9302, 0.9697, 0.8741, 0.9714, 0.919, 0.9121, 0.9419, 0.8898, 0.9237, 0.934, 0.9405, 0.9718, 0.9378, 0.9137, 0.9654, 0.9361, 0.8822, 0.8746, 0.9132, 0.9757, 0.957, 0.8637, 0.8667, 0.9024, 0.9295, 0.8871, 0.9169, 0.918, 0.8421, 0.9244, 0.9516, 0.8692, 0.9332, 0.9569, 0.9144, 0.9339, 0.9253, 0.9465, 0.9308, 0.8491], 'AP': [0.9762, 0.9453, 0.9618, 0.9924, 0.9615, 0.9971, 0.9589, 0.9223, 0.9827, 0.9641, 0.9499, 0.9745, 0.8681, 0.985, 0.9498, 0.9776, 0.9889, 0.9959, 0.9717, 0.9652, 0.9811, 0.9242, 0.9682, 0.9848, 0.9707, 0.9684, 0.9675, 0.9837, 0.9797, 0.9661, 0.8926, 0.9126, 0.9692, 0.9777, 0.9582, 0.933, 0.9737, 0.9827, 0.9611, 0.9397, 0.9999, 0.9139, 0.9834, 0.9924, 0.9653, 0.9865, 0.9009, 0.9741, 0.899, 0.9613, 0.929, 0.9621, 0.9941, 0.9719, 0.9797, 0.9822, 0.9953, 0.969, 0.9656, 0.9002, 0.9135, 0.9588, 0.9691, 0.9654, 0.9617, 0.9304, 0.99, 0.9853, 0.9741, 0.8683, 0.9443, 0.9384, 0.9839, 0.968, 0.9462, 0.9353, 0.9197, 0.978, 0.986, 0.9878, 0.9685, 0.9905, 0.9742, 0.9275, 0.9907, 0.9896, 0.9784, 0.9703, 0.9417, 0.9816, 0.9948, 0.8444, 0.9715, 0.9531, 0.9681, 0.9758, 0.9932, 0.9028, 0.9571, 0.9597, 0.9742, 0.9569, 0.9627, 0.9441, 0.9914, 0.973, 0.9896, 0.9232, 0.9821, 0.9789, 0.919, 0.9886, 0.9847, 0.9704, 0.7608, 0.9705, 0.8857, 0.9864, 0.9593, 0.992, 0.9841, 0.9685, 0.9831, 0.9866, 0.9748, 0.901, 0.985, 0.9747, 0.9698, 0.9292, 0.6425, 0.9784, 0.9904, 0.9753, 0.9732, 0.9914, 0.9339, 0.992, 0.9717, 0.9541, 0.9697, 0.9431, 0.9805, 0.9748, 0.9819, 0.989, 0.9849, 0.9671, 0.9924, 0.9669, 0.9405, 0.9288, 0.959, 0.9913, 0.9872, 0.9195, 0.9219, 0.9637, 0.9653, 0.9341, 0.966, 0.9679, 0.8988, 0.9752, 0.9767, 0.9188, 0.9758, 0.985, 0.973, 0.9805, 0.9608, 0.9698, 0.9826, 0.9015], 'Recall@P=50': [0.9887, 0.964, 0.9834, 0.996, 0.968, 1.0, 0.9808, 0.96, 0.9952, 0.9895, 0.982, 0.9924, 0.888, 0.996, 0.968, 0.992, 0.9952, 1.0, 0.984, 0.98, 0.996, 0.952, 0.98, 0.9936, 0.9827, 0.984, 0.984, 0.992, 0.9979, 0.9872, 0.928, 0.932, 0.988, 0.992, 0.984, 0.96, 0.988, 0.9997, 0.978, 0.972, 1.0, 0.956, 0.992, 0.996, 0.976, 0.996, 0.9627, 0.984, 0.9387, 0.964, 0.948, 0.9826, 0.996, 0.9886, 0.988, 0.9947, 0.998, 0.984, 0.984, 0.94, 0.956, 0.984, 0.984, 0.98, 0.9847, 0.972, 0.996, 0.9973, 0.984, 0.92, 0.976, 0.968, 0.996, 0.9856, 0.968, 0.968, 0.956, 0.996, 0.9933, 0.992, 0.9905, 0.996, 0.9964, 0.94, 0.998, 0.996, 0.9964, 0.988, 0.9826, 0.996, 0.998, 0.884, 0.984, 0.9744, 0.98, 0.9935, 0.996, 0.956, 0.978, 0.984, 0.9943, 0.972, 0.98, 0.9787, 0.996, 0.9897, 0.996, 0.952, 0.992, 0.996, 0.956, 0.992, 0.9985, 0.982, 0.88, 0.9873, 0.96, 0.996, 0.984, 0.996, 0.996, 0.99, 0.996, 0.996, 0.996, 0.94, 0.992, 0.988, 0.988, 0.968, 0.808, 0.988, 0.996, 0.98, 0.9867, 0.996, 0.9667, 0.996, 0.9917, 0.992, 0.988, 0.96, 0.996, 0.987, 0.9928, 0.992, 0.9998, 0.992, 1.0, 0.974, 0.966, 0.96, 0.976, 0.996, 0.996, 0.944, 0.944, 0.986, 0.976, 0.968, 0.99, 0.984, 0.932, 0.9935, 0.98, 0.944, 0.9887, 0.986, 1.0, 1.0, 0.964, 0.972, 0.9994, 0.94], 'micro': 0.9717, 'macro': 0.9592, 'weighted': 0.97}
2024-07-27 09:56:18 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:56:19 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9475.pt
2024-07-27 09:56:19 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9503.pt', 'checkpoint_score_0.9540.pt', 'checkpoint_score_0.9553.pt', 'checkpoint_score_0.9556.pt', 'checkpoint_score_0.9592.pt']
2024-07-27 09:56:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:56:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:56:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:56:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 9472 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_15_iter_9472.pt
2024-07-27 09:56:24 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 9472 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_15_iter_9472.pt
[31m===========================================================================[0m
2024-07-27 09:56:26 - [32m[1mINFO   [0m - Training epoch 16
2024-07-27 09:56:27 - [34m[1mLOGS   [0m - Epoch:  16 [    9473/10000000], loss: {'classification': 7.2928, 'neural_augmentation': 10.0521, 'total_loss': 17.3449}, LR: [9e-06, 9e-06], Avg. batch load time: 0.722, Elapsed time:  0.81
2024-07-27 09:57:04 - [34m[1mLOGS   [0m - Epoch:  16 [    9973/10000000], loss: {'classification': 7.5565, 'neural_augmentation': 10.5412, 'total_loss': 18.0978}, LR: [9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 38.39
2024-07-27 09:57:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 7.5445, 'neural_augmentation': 10.5124, 'total_loss': 18.0569}
2024-07-27 09:57:30 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 2.9541, 'neural_augmentation': 0.0, 'total_loss': 2.9541} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9326, 0.8973, 0.908, 0.968, 0.9256, 0.9737, 0.9086, 0.8654, 0.9411, 0.8966, 0.8898, 0.9218, 0.8052, 0.9388, 0.9025, 0.9551, 0.9687, 0.982, 0.9331, 0.9339, 0.9398, 0.8578, 0.9256, 0.9556, 0.9231, 0.9191, 0.9352, 0.9499, 0.9266, 0.9063, 0.8511, 0.8742, 0.9212, 0.9277, 0.8999, 0.8898, 0.9495, 0.9317, 0.9015, 0.879, 0.998, 0.8499, 0.9516, 0.9701, 0.9308, 0.9551, 0.8154, 0.9547, 0.8349, 0.937, 0.8732, 0.9008, 0.9741, 0.9239, 0.9387, 0.9425, 0.9797, 0.932, 0.9009, 0.8337, 0.8457, 0.9118, 0.9352, 0.9315, 0.9064, 0.8712, 0.9734, 0.9405, 0.9466, 0.8292, 0.9163, 0.8882, 0.9328, 0.9233, 0.8968, 0.8969, 0.8679, 0.9394, 0.9499, 0.9608, 0.9073, 0.9739, 0.9191, 0.8707, 0.956, 0.9585, 0.9305, 0.9237, 0.8775, 0.9478, 0.9726, 0.7664, 0.9409, 0.884, 0.9339, 0.9266, 0.9756, 0.8358, 0.8989, 0.9065, 0.9252, 0.911, 0.9314, 0.8823, 0.968, 0.9228, 0.9598, 0.888, 0.9418, 0.9263, 0.8743, 0.9639, 0.9425, 0.9272, 0.7064, 0.9205, 0.8131, 0.9438, 0.9043, 0.9736, 0.9382, 0.9128, 0.93, 0.9541, 0.924, 0.8449, 0.9461, 0.937, 0.917, 0.8842, 0.626, 0.9237, 0.9737, 0.9556, 0.9265, 0.9717, 0.8803, 0.9737, 0.9133, 0.9102, 0.9243, 0.8934, 0.932, 0.9326, 0.9363, 0.9636, 0.9369, 0.9106, 0.9719, 0.9292, 0.8917, 0.8696, 0.9085, 0.9719, 0.955, 0.8681, 0.8674, 0.8948, 0.9264, 0.8765, 0.9129, 0.8963, 0.839, 0.9208, 0.9426, 0.8686, 0.9253, 0.9494, 0.9095, 0.9372, 0.9269, 0.9419, 0.9299, 0.8494], 'AP': [0.9736, 0.9448, 0.9654, 0.9926, 0.9642, 0.9949, 0.961, 0.9245, 0.9808, 0.9611, 0.948, 0.9718, 0.8702, 0.9779, 0.9437, 0.9812, 0.99, 0.9944, 0.9677, 0.9696, 0.9739, 0.9234, 0.9601, 0.9866, 0.9654, 0.9681, 0.9715, 0.9811, 0.9782, 0.9621, 0.8883, 0.9228, 0.9713, 0.9783, 0.9579, 0.9356, 0.9749, 0.9818, 0.9577, 0.9302, 1.0, 0.918, 0.9833, 0.9916, 0.9672, 0.9883, 0.9086, 0.9757, 0.8942, 0.9659, 0.9341, 0.9581, 0.995, 0.9733, 0.9806, 0.9821, 0.9956, 0.9623, 0.9549, 0.9101, 0.9185, 0.9619, 0.9712, 0.9708, 0.9648, 0.9258, 0.9924, 0.9832, 0.9765, 0.8771, 0.9366, 0.94, 0.9742, 0.9669, 0.9475, 0.9391, 0.9245, 0.9784, 0.9843, 0.9905, 0.9668, 0.993, 0.9742, 0.9338, 0.9895, 0.9887, 0.9787, 0.9627, 0.9425, 0.9836, 0.9944, 0.8325, 0.9718, 0.9444, 0.9662, 0.9757, 0.9921, 0.9089, 0.9539, 0.9649, 0.9715, 0.9488, 0.9615, 0.9461, 0.9911, 0.973, 0.9906, 0.9368, 0.9798, 0.979, 0.9233, 0.9924, 0.9853, 0.9734, 0.7711, 0.9713, 0.8744, 0.9848, 0.9677, 0.9903, 0.975, 0.9664, 0.9737, 0.9882, 0.976, 0.9122, 0.9814, 0.9738, 0.9707, 0.9269, 0.6439, 0.9776, 0.9931, 0.9803, 0.9729, 0.9901, 0.9371, 0.9917, 0.9692, 0.9556, 0.9622, 0.941, 0.9758, 0.9747, 0.9797, 0.9935, 0.9847, 0.963, 0.9926, 0.9655, 0.9451, 0.9287, 0.9568, 0.9898, 0.9878, 0.9109, 0.9068, 0.9582, 0.9673, 0.9242, 0.9645, 0.9528, 0.891, 0.9742, 0.9761, 0.9101, 0.9725, 0.9838, 0.9643, 0.9809, 0.9666, 0.9734, 0.9812, 0.8924], 'Recall@P=50': [0.9853, 0.96, 0.9869, 0.996, 0.972, 0.996, 0.984, 0.96, 0.9952, 0.9883, 0.98, 0.9932, 0.888, 0.994, 0.966, 0.988, 0.9944, 0.996, 0.972, 0.984, 0.988, 0.952, 0.98, 0.9944, 0.976, 0.9848, 0.988, 0.992, 0.9961, 0.9816, 0.924, 0.952, 0.988, 0.996, 0.979, 0.948, 0.992, 0.999, 0.98, 0.96, 1.0, 0.96, 0.992, 0.996, 0.976, 0.996, 0.968, 0.98, 0.9467, 0.972, 0.952, 0.9763, 0.998, 0.9914, 0.996, 0.992, 0.998, 0.976, 0.98, 0.956, 0.968, 0.992, 0.976, 0.984, 0.988, 0.966, 0.996, 0.9987, 0.982, 0.924, 0.972, 0.966, 0.988, 0.9848, 0.98, 0.97, 0.956, 0.996, 0.992, 1.0, 0.9889, 0.996, 0.9964, 0.956, 0.994, 0.994, 0.9976, 0.984, 0.9791, 0.992, 0.996, 0.896, 0.98, 0.9664, 0.968, 0.9953, 0.996, 0.968, 0.976, 0.984, 0.9891, 0.96, 0.976, 0.976, 0.996, 0.9893, 0.998, 0.968, 0.992, 1.0, 0.948, 1.0, 0.9989, 0.99, 0.004, 0.99, 0.932, 0.9947, 0.992, 0.996, 0.99, 0.988, 0.988, 0.996, 0.9963, 0.948, 0.988, 0.984, 0.988, 0.962, 0.804, 0.996, 0.996, 0.988, 0.9853, 0.996, 0.968, 0.996, 0.9907, 0.992, 0.988, 0.96, 0.984, 0.986, 0.992, 1.0, 0.9993, 0.9947, 0.996, 0.972, 0.966, 0.958, 0.9733, 0.996, 0.994, 0.936, 0.928, 0.988, 0.976, 0.964, 0.988, 0.972, 0.928, 0.9942, 0.98, 0.932, 0.9887, 0.992, 0.996, 0.996, 0.98, 0.98, 0.9993, 0.924], 'micro': 0.9696, 'macro': 0.9585, 'weighted': 0.9692}
2024-07-27 09:57:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:57:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:57:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 10064 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_16_iter_10064.pt
2024-07-27 09:57:39 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 10064 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_16_iter_10064.pt
[31m===========================================================================[0m
2024-07-27 09:57:41 - [32m[1mINFO   [0m - Training epoch 17
2024-07-27 09:57:42 - [34m[1mLOGS   [0m - Epoch:  17 [   10065/10000000], loss: {'classification': 7.8308, 'neural_augmentation': 11.3526, 'total_loss': 19.1834}, LR: [8e-06, 8e-06], Avg. batch load time: 0.527, Elapsed time:  0.62
2024-07-27 09:58:20 - [34m[1mLOGS   [0m - Epoch:  17 [   10565/10000000], loss: {'classification': 7.3393, 'neural_augmentation': 10.4918, 'total_loss': 17.8311}, LR: [8e-06, 8e-06], Avg. batch load time: 0.002, Elapsed time: 38.28
2024-07-27 09:58:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 7.3685, 'neural_augmentation': 10.4969, 'total_loss': 17.8653}
2024-07-27 09:58:49 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 2.8067, 'neural_augmentation': 0.0, 'total_loss': 2.8067} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9413, 0.8964, 0.9047, 0.9757, 0.9172, 0.9819, 0.9136, 0.876, 0.9366, 0.9043, 0.9001, 0.9232, 0.8258, 0.9355, 0.8981, 0.9489, 0.9689, 0.9839, 0.9485, 0.9384, 0.9366, 0.8696, 0.9256, 0.9549, 0.9349, 0.9205, 0.9306, 0.9639, 0.9296, 0.9117, 0.8282, 0.8589, 0.9323, 0.9319, 0.9003, 0.9023, 0.9555, 0.935, 0.9133, 0.8945, 0.996, 0.8401, 0.9497, 0.972, 0.924, 0.9654, 0.8188, 0.9587, 0.8272, 0.9253, 0.8852, 0.9062, 0.9797, 0.927, 0.9475, 0.9377, 0.9849, 0.9266, 0.9126, 0.8627, 0.8337, 0.912, 0.938, 0.9328, 0.9053, 0.8811, 0.976, 0.9451, 0.9418, 0.7939, 0.9215, 0.8983, 0.9457, 0.9299, 0.8975, 0.8828, 0.8727, 0.9328, 0.9591, 0.9649, 0.9128, 0.9761, 0.9219, 0.8866, 0.965, 0.9551, 0.9275, 0.9253, 0.8758, 0.9461, 0.9778, 0.7958, 0.9402, 0.8943, 0.9465, 0.9233, 0.9782, 0.8589, 0.8974, 0.9167, 0.9255, 0.9146, 0.9306, 0.8827, 0.9677, 0.9291, 0.9622, 0.8898, 0.9491, 0.9331, 0.8763, 0.9651, 0.9444, 0.9285, 0.7195, 0.925, 0.8226, 0.9442, 0.9246, 0.9683, 0.9354, 0.9133, 0.9516, 0.9621, 0.9254, 0.8571, 0.9443, 0.9403, 0.9261, 0.8745, 0.627, 0.9293, 0.978, 0.9414, 0.9336, 0.9676, 0.8745, 0.9676, 0.916, 0.8996, 0.9265, 0.8971, 0.9315, 0.9336, 0.9416, 0.9693, 0.9391, 0.909, 0.9755, 0.9344, 0.8819, 0.8671, 0.9071, 0.9673, 0.9579, 0.8686, 0.8721, 0.9054, 0.9212, 0.8908, 0.9224, 0.914, 0.8391, 0.9232, 0.9507, 0.8665, 0.9305, 0.9592, 0.9194, 0.9289, 0.9286, 0.9435, 0.9326, 0.8374], 'AP': [0.9785, 0.9486, 0.9635, 0.9913, 0.9646, 0.9969, 0.9615, 0.9236, 0.9807, 0.9649, 0.9435, 0.9725, 0.8783, 0.9811, 0.9506, 0.98, 0.9902, 0.994, 0.9732, 0.9732, 0.9756, 0.9309, 0.9663, 0.9883, 0.9731, 0.97, 0.9738, 0.9885, 0.9797, 0.9646, 0.8976, 0.919, 0.9687, 0.9768, 0.9599, 0.9449, 0.9818, 0.9832, 0.9665, 0.94, 0.9999, 0.9086, 0.9827, 0.9887, 0.9679, 0.9873, 0.9081, 0.9754, 0.8904, 0.9672, 0.9319, 0.9635, 0.9937, 0.9701, 0.9853, 0.9805, 0.9951, 0.9679, 0.9614, 0.914, 0.9077, 0.9626, 0.9674, 0.9761, 0.9618, 0.93, 0.9908, 0.9849, 0.9799, 0.8622, 0.9476, 0.938, 0.9795, 0.972, 0.9505, 0.9345, 0.9187, 0.9763, 0.9871, 0.9933, 0.9692, 0.9924, 0.9762, 0.9342, 0.9921, 0.9896, 0.9791, 0.9687, 0.9444, 0.9832, 0.9952, 0.8618, 0.969, 0.9524, 0.9707, 0.9768, 0.9946, 0.9073, 0.9553, 0.9671, 0.9711, 0.9588, 0.9621, 0.9427, 0.9879, 0.9756, 0.9901, 0.9316, 0.9831, 0.978, 0.921, 0.9932, 0.9855, 0.971, 0.7831, 0.9724, 0.8697, 0.9855, 0.9696, 0.9873, 0.9809, 0.9669, 0.9789, 0.9884, 0.9765, 0.9151, 0.9845, 0.9815, 0.9706, 0.9178, 0.6361, 0.9758, 0.9913, 0.9764, 0.9734, 0.9874, 0.9322, 0.9883, 0.9687, 0.9555, 0.9621, 0.9412, 0.9807, 0.9777, 0.9792, 0.9932, 0.9852, 0.9654, 0.9902, 0.9713, 0.9436, 0.9232, 0.9573, 0.9871, 0.9874, 0.9199, 0.9203, 0.967, 0.9675, 0.9398, 0.9707, 0.9615, 0.9, 0.9753, 0.9814, 0.915, 0.9736, 0.9883, 0.9712, 0.9821, 0.9661, 0.971, 0.9828, 0.8992], 'Recall@P=50': [0.9913, 0.976, 0.9874, 0.992, 0.98, 1.0, 0.984, 0.948, 0.9944, 0.9895, 0.978, 0.992, 0.896, 0.992, 0.972, 0.984, 0.9944, 0.996, 0.984, 0.988, 0.992, 0.954, 0.988, 0.9976, 0.9813, 0.9864, 0.988, 0.996, 0.9961, 0.9872, 0.94, 0.96, 0.988, 0.988, 0.983, 0.968, 0.992, 0.9992, 0.986, 0.976, 1.0, 0.952, 0.992, 0.992, 0.98, 0.992, 0.9733, 0.984, 0.9413, 0.984, 0.948, 0.9832, 0.998, 0.9914, 0.994, 0.992, 0.998, 0.984, 0.98, 0.94, 0.948, 0.988, 0.976, 0.992, 0.986, 0.958, 0.992, 0.9947, 0.988, 0.916, 0.984, 0.954, 0.984, 0.9856, 0.98, 0.978, 0.96, 0.992, 0.996, 1.0, 0.9889, 0.996, 0.9968, 0.956, 0.998, 0.996, 0.9978, 0.988, 0.9826, 0.996, 1.0, 0.932, 0.98, 0.976, 0.976, 0.9942, 0.996, 0.96, 0.9807, 0.988, 0.9869, 0.976, 0.972, 0.9787, 0.992, 0.9913, 0.996, 0.948, 0.9944, 0.988, 0.956, 1.0, 0.9993, 0.988, 0.892, 0.9873, 0.96, 0.996, 0.984, 0.992, 0.994, 0.9873, 0.988, 0.992, 0.9973, 0.944, 0.996, 0.992, 0.992, 0.954, 0.768, 0.988, 0.996, 0.984, 0.9847, 0.992, 0.9653, 0.992, 0.99, 0.988, 0.988, 0.968, 0.996, 0.989, 0.9912, 1.0, 0.9997, 0.9947, 0.992, 0.984, 0.972, 0.952, 0.9693, 0.992, 0.994, 0.952, 0.956, 0.985, 0.976, 0.976, 0.993, 0.976, 0.94, 0.994, 0.988, 0.948, 0.9887, 0.994, 0.992, 0.996, 0.984, 0.972, 0.9993, 0.952], 'micro': 0.9721, 'macro': 0.9601, 'weighted': 0.9706}
2024-07-27 09:58:56 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 09:58:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9503.pt
2024-07-27 09:58:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9540.pt', 'checkpoint_score_0.9553.pt', 'checkpoint_score_0.9556.pt', 'checkpoint_score_0.9592.pt', 'checkpoint_score_0.9601.pt']
2024-07-27 09:58:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 09:59:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 09:59:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 09:59:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 10656 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_17_iter_10656.pt
2024-07-27 09:59:03 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 10656 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_17_iter_10656.pt
[31m===========================================================================[0m
2024-07-27 09:59:05 - [32m[1mINFO   [0m - Training epoch 18
2024-07-27 09:59:05 - [34m[1mLOGS   [0m - Epoch:  18 [   10657/10000000], loss: {'classification': 7.7964, 'neural_augmentation': 11.5997, 'total_loss': 19.3961}, LR: [8e-06, 8e-06], Avg. batch load time: 0.362, Elapsed time:  0.59
2024-07-27 10:00:43 - [34m[1mLOGS   [0m - Epoch:  18 [   11157/10000000], loss: {'classification': 7.2236, 'neural_augmentation': 10.4964, 'total_loss': 17.72}, LR: [8e-06, 8e-06], Avg. batch load time: 0.001, Elapsed time: 98.66
2024-07-27 10:01:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 7.2442, 'neural_augmentation': 10.5009, 'total_loss': 17.7451}
2024-07-27 10:01:30 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 2.7562, 'neural_augmentation': 0.0, 'total_loss': 2.7562} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.931, 0.9011, 0.9119, 0.968, 0.9221, 0.9779, 0.916, 0.8697, 0.94, 0.9055, 0.9018, 0.924, 0.815, 0.9487, 0.9038, 0.9558, 0.9666, 0.9817, 0.9402, 0.9278, 0.9514, 0.8765, 0.9234, 0.9589, 0.9322, 0.9216, 0.9274, 0.9651, 0.9316, 0.9176, 0.8445, 0.8589, 0.9215, 0.9398, 0.9016, 0.9059, 0.9469, 0.9363, 0.9137, 0.8824, 0.996, 0.8458, 0.9448, 0.9703, 0.9306, 0.9621, 0.8182, 0.948, 0.8492, 0.9271, 0.8784, 0.8991, 0.9759, 0.9269, 0.9487, 0.947, 0.9746, 0.9253, 0.9198, 0.8468, 0.8417, 0.9185, 0.9342, 0.9291, 0.9127, 0.8658, 0.9696, 0.9499, 0.954, 0.8042, 0.9228, 0.8953, 0.9465, 0.9311, 0.9079, 0.9049, 0.8667, 0.9323, 0.9584, 0.9669, 0.9092, 0.9715, 0.9264, 0.8694, 0.9642, 0.9591, 0.9248, 0.9231, 0.877, 0.9433, 0.979, 0.7765, 0.9323, 0.8947, 0.9371, 0.9312, 0.9738, 0.8565, 0.9028, 0.9151, 0.9297, 0.9136, 0.932, 0.8838, 0.9684, 0.9281, 0.9641, 0.8821, 0.9491, 0.9409, 0.8619, 0.9652, 0.9448, 0.9248, 0.7422, 0.9236, 0.8392, 0.9536, 0.9053, 0.9702, 0.9464, 0.9099, 0.9487, 0.9618, 0.9255, 0.8617, 0.9539, 0.9402, 0.9136, 0.882, 0.6342, 0.9469, 0.9714, 0.9459, 0.939, 0.9684, 0.8933, 0.9685, 0.9194, 0.8981, 0.9287, 0.9, 0.9375, 0.9307, 0.9426, 0.9692, 0.9399, 0.9124, 0.9673, 0.9372, 0.8765, 0.8755, 0.9158, 0.9703, 0.9558, 0.8654, 0.8763, 0.9142, 0.9303, 0.8848, 0.9178, 0.9193, 0.8502, 0.9286, 0.952, 0.8717, 0.9307, 0.9585, 0.9256, 0.9333, 0.9265, 0.9551, 0.9363, 0.8432], 'AP': [0.9777, 0.9477, 0.9668, 0.9927, 0.9652, 0.9967, 0.9621, 0.9236, 0.9827, 0.9676, 0.9527, 0.9721, 0.8716, 0.985, 0.9499, 0.98, 0.9898, 0.9955, 0.9703, 0.9749, 0.9816, 0.9332, 0.973, 0.9897, 0.9738, 0.9732, 0.9774, 0.9881, 0.9812, 0.9663, 0.9032, 0.9213, 0.9688, 0.9795, 0.9607, 0.9511, 0.9803, 0.9839, 0.9648, 0.9372, 0.9999, 0.9086, 0.9793, 0.9891, 0.9696, 0.9879, 0.9059, 0.9764, 0.9139, 0.9685, 0.9245, 0.959, 0.994, 0.9751, 0.9832, 0.9833, 0.9951, 0.9719, 0.9612, 0.9161, 0.9086, 0.963, 0.9709, 0.9754, 0.9624, 0.9259, 0.9912, 0.9844, 0.9806, 0.8796, 0.9547, 0.9464, 0.9818, 0.9727, 0.9502, 0.9445, 0.9186, 0.9792, 0.987, 0.9934, 0.9679, 0.9924, 0.9774, 0.9241, 0.9906, 0.9884, 0.979, 0.9738, 0.9429, 0.9793, 0.9949, 0.8575, 0.9699, 0.9541, 0.9658, 0.9785, 0.993, 0.9088, 0.957, 0.9659, 0.9752, 0.9598, 0.9653, 0.9472, 0.9886, 0.9744, 0.9869, 0.9321, 0.9819, 0.98, 0.9201, 0.9918, 0.9865, 0.971, 0.7737, 0.9712, 0.8876, 0.9863, 0.9648, 0.9885, 0.9845, 0.9657, 0.9827, 0.9877, 0.9794, 0.9185, 0.9834, 0.9793, 0.9672, 0.9338, 0.6479, 0.9789, 0.9919, 0.9806, 0.9757, 0.9883, 0.9411, 0.9889, 0.9712, 0.9507, 0.9739, 0.9426, 0.9842, 0.976, 0.9809, 0.9935, 0.9857, 0.9657, 0.9921, 0.9728, 0.941, 0.9367, 0.9575, 0.9881, 0.9873, 0.9192, 0.9211, 0.9683, 0.9736, 0.9363, 0.9702, 0.9616, 0.9049, 0.9778, 0.9824, 0.9205, 0.9753, 0.9875, 0.9728, 0.9815, 0.9668, 0.9773, 0.9843, 0.9048], 'Recall@P=50': [0.9927, 0.964, 0.9863, 0.996, 0.972, 1.0, 0.9824, 0.968, 0.996, 0.9917, 0.978, 0.9912, 0.904, 0.996, 0.966, 0.984, 0.9952, 0.996, 0.988, 0.988, 0.988, 0.954, 0.992, 0.9976, 0.984, 0.9904, 0.992, 0.996, 0.9977, 0.984, 0.92, 0.96, 0.988, 0.992, 0.9835, 0.968, 0.996, 0.9993, 0.989, 0.976, 1.0, 0.96, 0.996, 0.992, 0.972, 0.992, 0.9707, 0.988, 0.9493, 0.98, 0.936, 0.9847, 0.996, 0.9914, 0.994, 0.992, 0.998, 0.988, 0.984, 0.952, 0.952, 0.992, 0.984, 0.988, 0.9813, 0.962, 0.996, 0.996, 0.986, 0.932, 0.976, 0.972, 0.992, 0.9896, 0.972, 0.98, 0.972, 0.996, 0.9947, 1.0, 0.9921, 0.996, 0.9964, 0.944, 1.0, 0.996, 0.9985, 0.992, 0.9817, 0.996, 0.998, 0.928, 0.98, 0.9728, 0.98, 0.996, 0.992, 0.944, 0.98, 0.988, 0.9926, 0.972, 0.98, 0.9787, 0.992, 0.9903, 0.99, 0.952, 0.9912, 0.996, 0.956, 1.0, 0.9992, 0.988, 0.004, 0.988, 0.956, 0.9947, 0.992, 0.992, 0.996, 0.9893, 0.992, 0.992, 0.997, 0.956, 0.992, 0.9893, 0.992, 0.964, 0.008, 0.996, 0.996, 0.992, 0.9873, 0.992, 0.9733, 0.992, 0.991, 0.984, 0.992, 0.964, 0.996, 0.99, 0.9928, 1.0, 0.9994, 0.9853, 0.996, 0.982, 0.982, 0.97, 0.9707, 0.992, 0.998, 0.948, 0.948, 0.986, 0.984, 0.972, 0.991, 0.984, 0.94, 0.9955, 0.988, 0.956, 0.988, 0.992, 0.996, 0.996, 0.972, 0.984, 0.9995, 0.948], 'micro': 0.9731, 'macro': 0.9615, 'weighted': 0.9718}
2024-07-27 10:01:36 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:01:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9540.pt
2024-07-27 10:01:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9553.pt', 'checkpoint_score_0.9556.pt', 'checkpoint_score_0.9592.pt', 'checkpoint_score_0.9601.pt', 'checkpoint_score_0.9615.pt']
2024-07-27 10:01:38 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:01:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:01:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:01:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 11248 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_18_iter_11248.pt
2024-07-27 10:01:41 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 11248 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_18_iter_11248.pt
[31m===========================================================================[0m
2024-07-27 10:01:43 - [32m[1mINFO   [0m - Training epoch 19
2024-07-27 10:01:43 - [34m[1mLOGS   [0m - Epoch:  19 [   11249/10000000], loss: {'classification': 6.982, 'neural_augmentation': 10.3772, 'total_loss': 17.3592}, LR: [8e-06, 8e-06], Avg. batch load time: 0.384, Elapsed time:  0.53
2024-07-27 10:03:34 - [34m[1mLOGS   [0m - Epoch:  19 [   11749/10000000], loss: {'classification': 7.125, 'neural_augmentation': 10.4807, 'total_loss': 17.6057}, LR: [8e-06, 8e-06], Avg. batch load time: 0.002, Elapsed time: 111.50
2024-07-27 10:03:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 7.1028, 'neural_augmentation': 10.4765, 'total_loss': 17.5793}
2024-07-27 10:04:22 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 2.8629, 'neural_augmentation': 0.0, 'total_loss': 2.8629} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9369, 0.8992, 0.9057, 0.982, 0.938, 0.9818, 0.9096, 0.8771, 0.9352, 0.8978, 0.8985, 0.9219, 0.8174, 0.9486, 0.9168, 0.9537, 0.9697, 0.9797, 0.9369, 0.9289, 0.9474, 0.8685, 0.9197, 0.9536, 0.9328, 0.9207, 0.9222, 0.9572, 0.9288, 0.9092, 0.8537, 0.8405, 0.9231, 0.9463, 0.8988, 0.9053, 0.9489, 0.9335, 0.9087, 0.8798, 0.996, 0.8458, 0.9333, 0.9679, 0.9298, 0.9633, 0.8177, 0.9555, 0.8433, 0.9366, 0.871, 0.9007, 0.9859, 0.9224, 0.9517, 0.9436, 0.9768, 0.9123, 0.9218, 0.8618, 0.85, 0.9131, 0.9311, 0.9253, 0.907, 0.8724, 0.9699, 0.9492, 0.9545, 0.8154, 0.9183, 0.8948, 0.9452, 0.9304, 0.9064, 0.8961, 0.888, 0.9365, 0.9571, 0.9671, 0.8983, 0.9739, 0.925, 0.8758, 0.9527, 0.9556, 0.9258, 0.9206, 0.8675, 0.9333, 0.9731, 0.7677, 0.9311, 0.9, 0.936, 0.9222, 0.976, 0.8531, 0.9058, 0.9128, 0.9298, 0.91, 0.9303, 0.8869, 0.9679, 0.928, 0.9664, 0.8834, 0.9501, 0.9526, 0.882, 0.9649, 0.9427, 0.9324, 0.7311, 0.9248, 0.8172, 0.9477, 0.9087, 0.9679, 0.9506, 0.9109, 0.9487, 0.9633, 0.9209, 0.8639, 0.9621, 0.9375, 0.9237, 0.8793, 0.636, 0.9458, 0.9662, 0.9407, 0.9317, 0.9659, 0.8633, 0.9641, 0.9181, 0.8917, 0.9145, 0.8953, 0.9428, 0.9367, 0.9454, 0.9648, 0.9377, 0.9162, 0.9801, 0.9297, 0.8839, 0.8619, 0.9141, 0.9659, 0.9476, 0.8565, 0.8601, 0.9057, 0.9306, 0.8836, 0.922, 0.9224, 0.8625, 0.9176, 0.9467, 0.8617, 0.9389, 0.9614, 0.9352, 0.9234, 0.9402, 0.9485, 0.9335, 0.8601], 'AP': [0.9756, 0.9484, 0.9622, 0.9926, 0.9614, 0.9976, 0.9617, 0.9277, 0.9811, 0.9615, 0.9538, 0.9734, 0.8723, 0.9843, 0.9509, 0.9806, 0.99, 0.9936, 0.969, 0.9693, 0.9791, 0.9254, 0.9588, 0.9868, 0.9734, 0.9706, 0.9709, 0.988, 0.9787, 0.9618, 0.9047, 0.916, 0.9712, 0.9755, 0.959, 0.9483, 0.9736, 0.982, 0.9634, 0.9372, 0.9999, 0.9103, 0.9793, 0.9894, 0.9765, 0.9885, 0.9062, 0.9762, 0.9011, 0.9757, 0.9296, 0.9613, 0.9944, 0.9709, 0.9813, 0.9829, 0.9945, 0.9591, 0.9639, 0.9219, 0.9118, 0.9577, 0.9709, 0.9702, 0.9639, 0.9284, 0.9944, 0.9857, 0.9835, 0.881, 0.9508, 0.945, 0.9816, 0.9732, 0.9513, 0.9383, 0.9255, 0.9795, 0.9868, 0.9885, 0.9618, 0.9947, 0.977, 0.9293, 0.9891, 0.99, 0.9786, 0.9651, 0.9371, 0.9792, 0.9953, 0.8474, 0.9724, 0.9546, 0.9666, 0.9762, 0.9931, 0.9136, 0.9558, 0.9646, 0.9741, 0.9585, 0.9615, 0.949, 0.9879, 0.9742, 0.9896, 0.9257, 0.9815, 0.9778, 0.9278, 0.9902, 0.9858, 0.9701, 0.7684, 0.9731, 0.88, 0.9853, 0.9635, 0.9881, 0.9849, 0.9668, 0.9819, 0.9876, 0.975, 0.9213, 0.9848, 0.978, 0.9676, 0.925, 0.6474, 0.9754, 0.9934, 0.976, 0.9741, 0.9891, 0.9255, 0.9882, 0.9691, 0.9512, 0.9627, 0.9441, 0.9862, 0.9778, 0.9826, 0.9911, 0.9842, 0.9641, 0.9937, 0.9695, 0.9445, 0.917, 0.96, 0.988, 0.9869, 0.9242, 0.9233, 0.9674, 0.9775, 0.9376, 0.9709, 0.9653, 0.9069, 0.9723, 0.9788, 0.9233, 0.9778, 0.9864, 0.976, 0.9772, 0.9651, 0.9776, 0.9833, 0.9058], 'Recall@P=50': [0.986, 0.968, 0.9874, 0.996, 0.964, 1.0, 0.9848, 0.956, 0.9952, 0.9902, 0.984, 0.9932, 0.872, 0.992, 0.966, 0.992, 0.9976, 0.996, 0.972, 0.98, 0.992, 0.948, 0.992, 0.996, 0.984, 0.9872, 0.98, 0.996, 0.9982, 0.9832, 0.924, 0.956, 0.984, 0.98, 0.98, 0.968, 0.984, 0.9994, 0.986, 0.968, 1.0, 0.956, 0.988, 0.996, 0.988, 0.996, 0.9707, 0.984, 0.9413, 0.992, 0.948, 0.9858, 0.994, 0.9874, 0.992, 0.992, 0.998, 0.988, 0.98, 0.964, 0.948, 0.988, 0.988, 0.98, 0.9847, 0.956, 1.0, 0.9947, 0.99, 0.932, 0.968, 0.968, 0.992, 0.9896, 0.98, 0.974, 0.964, 0.996, 0.992, 0.992, 0.99, 1.0, 0.9966, 0.944, 0.998, 0.998, 0.998, 0.988, 0.9783, 0.992, 0.998, 0.912, 0.988, 0.9736, 0.976, 0.9956, 0.996, 0.96, 0.9753, 0.988, 0.9903, 0.972, 0.98, 0.9827, 0.992, 0.9877, 0.996, 0.94, 0.9904, 0.988, 0.956, 0.996, 0.9992, 0.988, 0.004, 0.988, 0.956, 0.9947, 0.996, 0.992, 0.992, 0.99, 0.996, 0.992, 0.9967, 0.952, 0.992, 0.9907, 0.984, 0.952, 0.776, 0.98, 0.996, 0.988, 0.9873, 0.996, 0.9627, 0.992, 0.9887, 0.988, 0.992, 0.968, 1.0, 0.988, 0.9904, 0.996, 0.9992, 0.988, 0.996, 0.98, 0.976, 0.956, 0.976, 0.992, 0.994, 0.964, 0.956, 0.986, 0.988, 0.968, 0.993, 0.98, 0.928, 0.9938, 0.992, 0.96, 0.9893, 0.992, 0.992, 0.992, 0.976, 0.988, 0.9995, 0.924], 'micro': 0.9713, 'macro': 0.9605, 'weighted': 0.9704}
2024-07-27 10:04:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:04:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:04:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 11840 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_19_iter_11840.pt
2024-07-27 10:04:30 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 11840 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_19_iter_11840.pt
[31m===========================================================================[0m
2024-07-27 10:04:32 - [32m[1mINFO   [0m - Training epoch 20
2024-07-27 10:04:33 - [34m[1mLOGS   [0m - Epoch:  20 [   11841/10000000], loss: {'classification': 6.4224, 'neural_augmentation': 11.9583, 'total_loss': 18.3807}, LR: [8e-06, 8e-06], Avg. batch load time: 0.422, Elapsed time:  0.62
2024-07-27 10:06:22 - [34m[1mLOGS   [0m - Epoch:  20 [   12341/10000000], loss: {'classification': 7.0127, 'neural_augmentation': 10.5675, 'total_loss': 17.5801}, LR: [8e-06, 8e-06], Avg. batch load time: 0.001, Elapsed time: 109.64
2024-07-27 10:06:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 7.0222, 'neural_augmentation': 10.548, 'total_loss': 17.5703}
2024-07-27 10:07:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 2.6869, 'neural_augmentation': 0.0, 'total_loss': 2.6869} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9396, 0.9043, 0.9153, 0.982, 0.9448, 0.9817, 0.9188, 0.8683, 0.935, 0.9091, 0.9027, 0.9274, 0.815, 0.9414, 0.9172, 0.9501, 0.9719, 0.9818, 0.9412, 0.9393, 0.9497, 0.8673, 0.9299, 0.9599, 0.9328, 0.9262, 0.9429, 0.964, 0.9327, 0.9148, 0.8535, 0.8631, 0.9306, 0.9393, 0.906, 0.8996, 0.9495, 0.9369, 0.9155, 0.8818, 0.996, 0.8387, 0.9491, 0.9736, 0.9256, 0.9544, 0.8208, 0.9502, 0.845, 0.9243, 0.8927, 0.9057, 0.986, 0.9286, 0.9484, 0.9444, 0.9808, 0.9304, 0.9347, 0.8542, 0.8399, 0.9167, 0.9369, 0.9374, 0.9157, 0.8813, 0.972, 0.9496, 0.948, 0.8126, 0.9256, 0.9001, 0.9493, 0.9306, 0.9032, 0.8919, 0.873, 0.9413, 0.9646, 0.9755, 0.9149, 0.9721, 0.9274, 0.8819, 0.9552, 0.9606, 0.929, 0.935, 0.8809, 0.9514, 0.9758, 0.8016, 0.9366, 0.8991, 0.94, 0.9304, 0.9818, 0.8617, 0.9013, 0.9063, 0.9308, 0.9142, 0.9323, 0.8841, 0.9737, 0.9341, 0.973, 0.8848, 0.9476, 0.939, 0.8701, 0.9693, 0.9447, 0.9244, 0.7377, 0.93, 0.8273, 0.9516, 0.9024, 0.9737, 0.9472, 0.9207, 0.9489, 0.9565, 0.93, 0.8571, 0.96, 0.9458, 0.9274, 0.8896, 0.6634, 0.9429, 0.9719, 0.94, 0.9355, 0.9736, 0.8861, 0.9721, 0.9206, 0.914, 0.939, 0.8935, 0.9357, 0.9384, 0.9443, 0.9735, 0.9407, 0.9225, 0.9801, 0.9368, 0.8873, 0.8839, 0.9032, 0.9737, 0.9517, 0.8542, 0.8589, 0.9122, 0.9218, 0.8784, 0.9232, 0.9342, 0.8589, 0.9255, 0.9487, 0.8535, 0.9363, 0.9572, 0.9234, 0.9339, 0.9416, 0.9455, 0.9378, 0.8595], 'AP': [0.9797, 0.9496, 0.9669, 0.9937, 0.9716, 0.998, 0.9674, 0.9234, 0.9822, 0.969, 0.9553, 0.9736, 0.881, 0.9821, 0.9534, 0.9825, 0.9906, 0.9958, 0.9709, 0.98, 0.9803, 0.9286, 0.97, 0.9894, 0.9735, 0.9731, 0.9808, 0.9862, 0.9816, 0.9667, 0.9065, 0.934, 0.9718, 0.9756, 0.9629, 0.9516, 0.9783, 0.9836, 0.9669, 0.9421, 0.9999, 0.8977, 0.9855, 0.9864, 0.9702, 0.9873, 0.9119, 0.9768, 0.9038, 0.9691, 0.9357, 0.9633, 0.9954, 0.9754, 0.9828, 0.9833, 0.9966, 0.9704, 0.9647, 0.9169, 0.8919, 0.9614, 0.9704, 0.982, 0.9674, 0.9354, 0.993, 0.9848, 0.9806, 0.886, 0.9484, 0.9489, 0.9844, 0.9729, 0.9511, 0.9425, 0.9239, 0.9786, 0.9908, 0.9927, 0.9712, 0.9928, 0.9776, 0.9324, 0.9898, 0.9911, 0.9809, 0.9725, 0.9469, 0.9852, 0.9952, 0.8685, 0.9719, 0.956, 0.969, 0.9793, 0.9939, 0.9165, 0.9581, 0.9696, 0.974, 0.9623, 0.9669, 0.9506, 0.9854, 0.9775, 0.9904, 0.932, 0.9825, 0.9759, 0.9251, 0.9939, 0.986, 0.9716, 0.7881, 0.9721, 0.8856, 0.9867, 0.968, 0.984, 0.9833, 0.9697, 0.9815, 0.9865, 0.9792, 0.9178, 0.9846, 0.9806, 0.9711, 0.9336, 0.6669, 0.9757, 0.9921, 0.979, 0.9783, 0.985, 0.9379, 0.9849, 0.9738, 0.9559, 0.9698, 0.9444, 0.9827, 0.981, 0.9838, 0.9942, 0.9863, 0.9675, 0.9936, 0.9727, 0.9485, 0.9364, 0.955, 0.9859, 0.9885, 0.9175, 0.9192, 0.971, 0.9701, 0.9402, 0.9715, 0.9656, 0.9101, 0.9765, 0.9812, 0.9162, 0.9758, 0.9874, 0.9709, 0.9838, 0.9731, 0.9726, 0.9845, 0.9078], 'Recall@P=50': [0.992, 0.976, 0.9834, 0.996, 0.98, 1.0, 0.9888, 0.952, 0.9944, 0.9932, 0.98, 0.9908, 0.916, 0.992, 0.974, 0.992, 0.9968, 0.996, 0.976, 0.992, 0.992, 0.954, 0.984, 0.9992, 0.9787, 0.9864, 1.0, 0.996, 0.9982, 0.9856, 0.936, 0.972, 0.988, 0.984, 0.981, 0.976, 0.988, 0.9988, 0.983, 0.976, 1.0, 0.94, 0.996, 0.988, 0.984, 0.996, 0.972, 0.984, 0.948, 0.988, 0.96, 0.9805, 0.998, 0.9909, 0.996, 0.992, 1.0, 0.984, 0.98, 0.94, 0.908, 0.984, 0.98, 1.0, 0.9867, 0.966, 0.996, 0.9933, 0.986, 0.936, 0.984, 0.966, 0.996, 0.9896, 0.976, 0.976, 0.968, 0.996, 0.9973, 0.996, 0.9889, 0.996, 0.9984, 0.968, 1.0, 0.998, 0.9982, 0.988, 0.9774, 1.0, 1.0, 0.924, 0.98, 0.9704, 0.976, 0.9956, 0.996, 0.968, 0.9767, 0.996, 0.9909, 0.978, 0.984, 0.98, 0.988, 0.9923, 0.994, 0.952, 0.9904, 0.988, 0.964, 1.0, 0.9987, 0.988, 0.904, 0.988, 0.952, 0.994, 0.996, 0.98, 0.994, 0.9907, 0.996, 0.996, 0.998, 0.944, 0.992, 0.9893, 0.992, 0.966, 0.852, 0.988, 0.996, 0.996, 0.99, 0.984, 0.968, 0.984, 0.991, 0.988, 0.988, 0.96, 1.0, 0.991, 0.9944, 1.0, 0.9995, 0.992, 0.996, 0.978, 0.976, 0.966, 0.976, 0.984, 0.996, 0.956, 0.952, 0.993, 0.984, 0.968, 0.992, 0.98, 0.952, 0.9955, 0.992, 0.956, 0.9853, 0.994, 0.996, 1.0, 0.984, 0.976, 0.9994, 0.948], 'micro': 0.9742, 'macro': 0.9627, 'weighted': 0.9728}
2024-07-27 10:07:12 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:07:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9553.pt
2024-07-27 10:07:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9556.pt', 'checkpoint_score_0.9592.pt', 'checkpoint_score_0.9601.pt', 'checkpoint_score_0.9615.pt', 'checkpoint_score_0.9627.pt']
2024-07-27 10:07:15 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:07:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:07:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:07:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 12432 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_20_iter_12432.pt
2024-07-27 10:07:17 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 12432 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_20_iter_12432.pt
[31m===========================================================================[0m
2024-07-27 10:07:19 - [32m[1mINFO   [0m - Training epoch 21
2024-07-27 10:07:20 - [34m[1mLOGS   [0m - Epoch:  21 [   12433/10000000], loss: {'classification': 5.674, 'neural_augmentation': 9.9401, 'total_loss': 15.6141}, LR: [8e-06, 8e-06], Avg. batch load time: 0.574, Elapsed time:  0.79
2024-07-27 10:09:10 - [34m[1mLOGS   [0m - Epoch:  21 [   12933/10000000], loss: {'classification': 6.8478, 'neural_augmentation': 10.4227, 'total_loss': 17.2706}, LR: [8e-06, 8e-06], Avg. batch load time: 0.002, Elapsed time: 110.84
2024-07-27 10:09:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 6.8392, 'neural_augmentation': 10.4344, 'total_loss': 17.2735}
2024-07-27 10:09:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 2.6566, 'neural_augmentation': 0.0, 'total_loss': 2.6566} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9395, 0.8992, 0.9109, 0.9838, 0.9336, 0.9819, 0.9169, 0.8848, 0.9414, 0.9072, 0.9089, 0.9271, 0.8122, 0.9479, 0.9184, 0.956, 0.9731, 0.984, 0.9508, 0.945, 0.9551, 0.8758, 0.9231, 0.959, 0.9392, 0.9253, 0.9416, 0.9514, 0.9326, 0.9127, 0.8577, 0.8811, 0.9296, 0.9385, 0.9073, 0.9008, 0.9469, 0.9387, 0.9143, 0.8933, 0.996, 0.841, 0.9497, 0.9679, 0.9331, 0.9549, 0.8237, 0.9478, 0.8466, 0.9315, 0.8871, 0.9059, 0.9828, 0.9261, 0.9523, 0.9467, 0.981, 0.9322, 0.9275, 0.8671, 0.8382, 0.9172, 0.9336, 0.9467, 0.9134, 0.8685, 0.9759, 0.9468, 0.9563, 0.8218, 0.917, 0.911, 0.9438, 0.9339, 0.9076, 0.8964, 0.8704, 0.9408, 0.9562, 0.9633, 0.9173, 0.9743, 0.9302, 0.8866, 0.9607, 0.9574, 0.928, 0.9322, 0.8858, 0.9491, 0.976, 0.8043, 0.9339, 0.9036, 0.951, 0.9336, 0.9839, 0.8504, 0.9041, 0.9106, 0.9339, 0.9137, 0.9328, 0.8912, 0.9676, 0.9349, 0.9709, 0.8732, 0.9535, 0.9393, 0.8778, 0.9649, 0.9463, 0.93, 0.7455, 0.9278, 0.8317, 0.9498, 0.9106, 0.968, 0.951, 0.9162, 0.9495, 0.9553, 0.9275, 0.8635, 0.9528, 0.9394, 0.919, 0.8907, 0.6554, 0.9414, 0.9741, 0.9461, 0.9403, 0.9679, 0.8866, 0.9697, 0.9247, 0.9087, 0.929, 0.9008, 0.9421, 0.9313, 0.9445, 0.9669, 0.9411, 0.9168, 0.9838, 0.935, 0.8935, 0.8826, 0.9202, 0.9696, 0.955, 0.8656, 0.8723, 0.9171, 0.9315, 0.8929, 0.9269, 0.9292, 0.8594, 0.9306, 0.9409, 0.8679, 0.9452, 0.9615, 0.9277, 0.9331, 0.9395, 0.9446, 0.9382, 0.8596], 'AP': [0.9792, 0.95, 0.9681, 0.9943, 0.9683, 0.9968, 0.9656, 0.9287, 0.9847, 0.9685, 0.9562, 0.9743, 0.8777, 0.9852, 0.9592, 0.9845, 0.9933, 0.9968, 0.9737, 0.9775, 0.9783, 0.9362, 0.9597, 0.9882, 0.9757, 0.975, 0.9776, 0.9819, 0.9818, 0.9644, 0.9143, 0.9289, 0.9698, 0.9816, 0.9653, 0.9461, 0.9768, 0.9846, 0.967, 0.9435, 0.9999, 0.9062, 0.9824, 0.9852, 0.9705, 0.9861, 0.912, 0.9741, 0.9087, 0.9677, 0.9307, 0.9657, 0.9951, 0.974, 0.9869, 0.9836, 0.9959, 0.9569, 0.9623, 0.9214, 0.9036, 0.9609, 0.9698, 0.9777, 0.9656, 0.9306, 0.9919, 0.9843, 0.979, 0.8889, 0.9455, 0.95, 0.9812, 0.9734, 0.9511, 0.9368, 0.9225, 0.9766, 0.9883, 0.9918, 0.9749, 0.9928, 0.9795, 0.9311, 0.9889, 0.9883, 0.9803, 0.9641, 0.9512, 0.9826, 0.9947, 0.8882, 0.97, 0.9595, 0.9719, 0.9794, 0.9959, 0.9189, 0.9589, 0.962, 0.9758, 0.9621, 0.9619, 0.9487, 0.9856, 0.9775, 0.9914, 0.9344, 0.9827, 0.9836, 0.928, 0.9907, 0.9872, 0.9713, 0.7868, 0.9729, 0.8802, 0.984, 0.9631, 0.9852, 0.9844, 0.9713, 0.9811, 0.9855, 0.979, 0.9188, 0.9843, 0.9792, 0.9687, 0.9335, 0.6689, 0.9812, 0.9906, 0.9797, 0.9787, 0.9853, 0.9377, 0.9856, 0.9743, 0.9623, 0.959, 0.9515, 0.9857, 0.9776, 0.9844, 0.9899, 0.9873, 0.9687, 0.9939, 0.9718, 0.9482, 0.9342, 0.9589, 0.9852, 0.9857, 0.9266, 0.9275, 0.9687, 0.9698, 0.9412, 0.9733, 0.9652, 0.9169, 0.9784, 0.9782, 0.9281, 0.9802, 0.9878, 0.973, 0.9819, 0.9719, 0.9717, 0.9844, 0.9124], 'Recall@P=50': [0.99, 0.976, 0.9891, 0.996, 0.976, 1.0, 0.9856, 0.964, 0.9976, 0.9929, 0.98, 0.9916, 0.888, 0.994, 0.974, 0.992, 0.9976, 1.0, 0.976, 0.984, 0.988, 0.966, 0.984, 0.996, 0.9827, 0.9936, 0.984, 0.996, 0.9973, 0.9848, 0.936, 0.956, 0.984, 0.988, 0.987, 0.956, 0.988, 0.9994, 0.986, 0.98, 1.0, 0.944, 0.992, 0.988, 0.98, 0.996, 0.972, 0.98, 0.94, 0.972, 0.944, 0.9832, 0.996, 0.9909, 0.996, 0.994, 1.0, 0.98, 0.984, 0.952, 0.944, 0.992, 0.98, 0.984, 0.984, 0.962, 0.996, 0.996, 0.982, 0.932, 0.972, 0.97, 0.992, 0.9848, 0.968, 0.974, 0.968, 0.992, 0.9947, 1.0, 0.9926, 0.996, 0.9972, 0.936, 0.996, 0.998, 0.9982, 0.984, 0.9852, 0.992, 0.998, 0.936, 0.98, 0.9816, 0.976, 0.9967, 0.996, 0.972, 0.976, 0.984, 0.9903, 0.97, 0.976, 0.98, 0.992, 0.994, 0.996, 0.956, 0.9912, 1.0, 0.964, 0.996, 0.999, 0.988, 0.892, 0.988, 0.96, 0.992, 0.98, 0.984, 0.996, 0.9933, 0.992, 0.996, 0.9973, 0.948, 0.992, 0.9907, 0.984, 0.97, 0.82, 0.988, 0.996, 0.996, 0.992, 0.992, 0.9667, 0.988, 0.9913, 0.988, 0.984, 0.972, 1.0, 0.988, 0.9944, 0.996, 0.9996, 0.9933, 0.996, 0.974, 0.98, 0.97, 0.9733, 0.992, 0.994, 0.948, 0.952, 0.988, 0.98, 0.976, 0.991, 0.98, 0.94, 0.9948, 0.988, 0.956, 0.992, 0.992, 1.0, 1.0, 0.984, 0.984, 0.9998, 0.928], 'micro': 0.9747, 'macro': 0.9629, 'weighted': 0.9733}
2024-07-27 10:10:03 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:10:03 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9556.pt
2024-07-27 10:10:03 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9592.pt', 'checkpoint_score_0.9601.pt', 'checkpoint_score_0.9615.pt', 'checkpoint_score_0.9627.pt', 'checkpoint_score_0.9629.pt']
2024-07-27 10:10:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:10:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:10:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:10:07 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 13024 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_21_iter_13024.pt
2024-07-27 10:10:07 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 13024 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_21_iter_13024.pt
[31m===========================================================================[0m
2024-07-27 10:10:09 - [32m[1mINFO   [0m - Training epoch 22
2024-07-27 10:10:10 - [34m[1mLOGS   [0m - Epoch:  22 [   13025/10000000], loss: {'classification': 7.5225, 'neural_augmentation': 11.9347, 'total_loss': 19.4572}, LR: [7e-06, 7e-06], Avg. batch load time: 0.782, Elapsed time:  0.95
2024-07-27 10:12:03 - [34m[1mLOGS   [0m - Epoch:  22 [   13525/10000000], loss: {'classification': 6.6507, 'neural_augmentation': 10.3861, 'total_loss': 17.0368}, LR: [7e-06, 7e-06], Avg. batch load time: 0.002, Elapsed time: 114.02
2024-07-27 10:12:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 6.6733, 'neural_augmentation': 10.3899, 'total_loss': 17.0633}
2024-07-27 10:12:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 2.6344, 'neural_augmentation': 0.0, 'total_loss': 2.6344} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9416, 0.8994, 0.9167, 0.9796, 0.9357, 0.9839, 0.9176, 0.8706, 0.9443, 0.911, 0.9085, 0.924, 0.8155, 0.9494, 0.9264, 0.9506, 0.9693, 0.9798, 0.9429, 0.9412, 0.9553, 0.8662, 0.9274, 0.9613, 0.9372, 0.9259, 0.9424, 0.9679, 0.9336, 0.9193, 0.8742, 0.8652, 0.9225, 0.9393, 0.9049, 0.9072, 0.9537, 0.9374, 0.9176, 0.8866, 0.994, 0.8634, 0.9463, 0.9677, 0.9302, 0.9616, 0.8352, 0.959, 0.8472, 0.9224, 0.8798, 0.9081, 0.981, 0.9308, 0.9488, 0.9472, 0.9788, 0.9342, 0.9278, 0.8696, 0.8645, 0.916, 0.9375, 0.94, 0.916, 0.8724, 0.9723, 0.9506, 0.9533, 0.839, 0.9221, 0.8926, 0.9514, 0.9265, 0.9053, 0.9019, 0.8717, 0.9448, 0.9609, 0.9691, 0.9158, 0.9741, 0.9295, 0.878, 0.9571, 0.959, 0.9326, 0.9358, 0.8819, 0.9505, 0.9748, 0.8175, 0.9389, 0.9035, 0.9388, 0.9324, 0.9744, 0.8674, 0.9085, 0.9146, 0.9317, 0.9242, 0.9363, 0.8935, 0.9655, 0.9362, 0.9691, 0.8807, 0.9524, 0.9371, 0.8735, 0.9715, 0.9491, 0.9343, 0.749, 0.9308, 0.8233, 0.9472, 0.9125, 0.9701, 0.9488, 0.9177, 0.9532, 0.9577, 0.9251, 0.8696, 0.952, 0.9472, 0.9207, 0.8875, 0.6565, 0.9419, 0.9703, 0.9442, 0.9407, 0.9633, 0.8893, 0.9684, 0.9253, 0.9113, 0.9314, 0.8957, 0.9499, 0.9375, 0.9472, 0.9736, 0.9444, 0.9201, 0.9738, 0.9402, 0.8975, 0.8759, 0.9132, 0.9665, 0.9592, 0.8731, 0.8822, 0.9141, 0.9286, 0.8834, 0.9225, 0.9275, 0.8718, 0.9302, 0.9518, 0.8792, 0.9417, 0.9615, 0.9253, 0.9301, 0.9383, 0.9347, 0.9378, 0.8638], 'AP': [0.9806, 0.9465, 0.9683, 0.9912, 0.9651, 0.997, 0.9663, 0.9296, 0.9857, 0.9704, 0.9534, 0.972, 0.8739, 0.9865, 0.9568, 0.9819, 0.9921, 0.9943, 0.9744, 0.9824, 0.9831, 0.9311, 0.9679, 0.9897, 0.9773, 0.9772, 0.983, 0.9859, 0.983, 0.9678, 0.9127, 0.9271, 0.9701, 0.98, 0.9642, 0.9526, 0.9797, 0.9847, 0.9704, 0.934, 0.9999, 0.9189, 0.9833, 0.9907, 0.9711, 0.9856, 0.9185, 0.9771, 0.9148, 0.9687, 0.9333, 0.9647, 0.9946, 0.9739, 0.9864, 0.984, 0.9945, 0.9669, 0.962, 0.9228, 0.919, 0.9653, 0.9647, 0.9839, 0.9672, 0.9317, 0.9906, 0.9866, 0.9799, 0.8992, 0.9548, 0.949, 0.9842, 0.9721, 0.9484, 0.9467, 0.9219, 0.9788, 0.9886, 0.9926, 0.9719, 0.9906, 0.9802, 0.9313, 0.9884, 0.989, 0.9819, 0.969, 0.9497, 0.9836, 0.9949, 0.8854, 0.9659, 0.9581, 0.9742, 0.9792, 0.9946, 0.9082, 0.9609, 0.9658, 0.977, 0.9629, 0.9696, 0.9515, 0.9895, 0.9772, 0.9926, 0.9289, 0.9841, 0.9811, 0.9301, 0.994, 0.9879, 0.9739, 0.7861, 0.975, 0.8847, 0.9857, 0.9655, 0.9902, 0.986, 0.9691, 0.985, 0.9852, 0.9781, 0.9221, 0.984, 0.9787, 0.9719, 0.9361, 0.6805, 0.9791, 0.9904, 0.9813, 0.9796, 0.9893, 0.943, 0.9905, 0.9741, 0.9632, 0.9684, 0.9468, 0.989, 0.9796, 0.9836, 0.9938, 0.9872, 0.9705, 0.9903, 0.9752, 0.9471, 0.9319, 0.9583, 0.9901, 0.9876, 0.9286, 0.9293, 0.9702, 0.9712, 0.933, 0.97, 0.964, 0.914, 0.9787, 0.9787, 0.9286, 0.9788, 0.9873, 0.9756, 0.9849, 0.9675, 0.9731, 0.9848, 0.9126], 'Recall@P=50': [0.9927, 0.968, 0.9909, 0.996, 0.972, 1.0, 0.9832, 0.956, 0.9968, 0.9935, 0.982, 0.9896, 0.892, 0.996, 0.972, 0.988, 0.9992, 0.996, 0.984, 0.996, 0.992, 0.962, 0.98, 0.9968, 0.988, 0.9896, 1.0, 0.996, 0.9989, 0.9864, 0.928, 0.944, 0.992, 0.992, 0.9885, 0.96, 0.988, 0.9989, 0.989, 0.96, 1.0, 0.956, 0.988, 0.992, 0.984, 0.992, 0.9707, 0.984, 0.952, 0.984, 0.944, 0.9832, 0.996, 0.992, 0.996, 0.994, 0.998, 0.98, 0.98, 0.96, 0.956, 0.984, 0.968, 1.0, 0.9887, 0.962, 0.992, 0.9947, 0.982, 0.936, 0.976, 0.976, 0.992, 0.9888, 0.968, 0.968, 0.972, 0.996, 0.9933, 0.996, 0.9926, 0.996, 0.9976, 0.94, 0.998, 0.996, 0.9982, 0.984, 0.9783, 0.992, 0.998, 0.928, 0.976, 0.98, 0.988, 0.9964, 0.996, 0.968, 0.9867, 0.988, 0.9943, 0.972, 0.984, 0.9813, 0.992, 0.992, 0.998, 0.952, 0.992, 0.996, 0.972, 1.0, 0.9994, 0.99, 0.004, 0.9873, 0.948, 0.994, 0.992, 0.992, 0.996, 0.9893, 0.996, 0.992, 0.998, 0.96, 0.992, 0.988, 0.992, 0.966, 0.84, 0.992, 0.996, 0.992, 0.9893, 0.992, 0.968, 0.992, 0.9943, 0.992, 0.988, 0.964, 1.0, 0.991, 0.9936, 0.996, 0.9996, 0.9907, 0.992, 0.982, 0.978, 0.968, 0.98, 0.992, 0.996, 0.948, 0.944, 0.99, 0.988, 0.96, 0.99, 0.98, 0.94, 0.996, 0.984, 0.956, 0.9907, 0.99, 0.996, 1.0, 0.972, 0.98, 0.9999, 0.936], 'micro': 0.9751, 'macro': 0.964, 'weighted': 0.9739}
2024-07-27 10:12:58 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:12:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9592.pt
2024-07-27 10:12:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9601.pt', 'checkpoint_score_0.9615.pt', 'checkpoint_score_0.9627.pt', 'checkpoint_score_0.9629.pt', 'checkpoint_score_0.9640.pt']
2024-07-27 10:13:00 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:13:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:13:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:13:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 13616 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_22_iter_13616.pt
2024-07-27 10:13:03 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 13616 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_22_iter_13616.pt
[31m===========================================================================[0m
2024-07-27 10:13:05 - [32m[1mINFO   [0m - Training epoch 23
2024-07-27 10:13:05 - [34m[1mLOGS   [0m - Epoch:  23 [   13617/10000000], loss: {'classification': 7.6268, 'neural_augmentation': 9.4122, 'total_loss': 17.039}, LR: [7e-06, 7e-06], Avg. batch load time: 0.409, Elapsed time:  0.59
2024-07-27 10:14:52 - [34m[1mLOGS   [0m - Epoch:  23 [   14117/10000000], loss: {'classification': 6.6049, 'neural_augmentation': 10.4208, 'total_loss': 17.0257}, LR: [7e-06, 7e-06], Avg. batch load time: 0.002, Elapsed time: 107.32
2024-07-27 10:15:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 6.6177, 'neural_augmentation': 10.4463, 'total_loss': 17.064}
2024-07-27 10:15:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 2.6232, 'neural_augmentation': 0.0, 'total_loss': 2.6232} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9439, 0.9076, 0.9184, 0.978, 0.9457, 0.984, 0.9197, 0.8701, 0.9484, 0.9131, 0.8951, 0.9255, 0.817, 0.9535, 0.9156, 0.9518, 0.9763, 0.9819, 0.9388, 0.9393, 0.9588, 0.8597, 0.9336, 0.9573, 0.9423, 0.9281, 0.9402, 0.9636, 0.9378, 0.9233, 0.8547, 0.8683, 0.9267, 0.9516, 0.9098, 0.9031, 0.9555, 0.9415, 0.9227, 0.8866, 0.996, 0.8507, 0.9383, 0.9756, 0.9293, 0.9593, 0.8271, 0.959, 0.8465, 0.9259, 0.8862, 0.9079, 0.983, 0.9241, 0.965, 0.9504, 0.9828, 0.93, 0.9212, 0.8633, 0.8495, 0.9261, 0.9487, 0.9409, 0.9166, 0.8735, 0.9798, 0.9504, 0.9516, 0.845, 0.9228, 0.9004, 0.9472, 0.9344, 0.9121, 0.9068, 0.8768, 0.9418, 0.9613, 0.968, 0.9181, 0.9781, 0.9318, 0.8916, 0.9559, 0.9561, 0.9296, 0.9376, 0.8923, 0.9376, 0.9772, 0.8117, 0.9465, 0.9011, 0.935, 0.9333, 0.988, 0.8476, 0.9019, 0.9262, 0.9317, 0.9251, 0.935, 0.8916, 0.9739, 0.9306, 0.9673, 0.8834, 0.9525, 0.9478, 0.877, 0.9657, 0.949, 0.9318, 0.7475, 0.9285, 0.8201, 0.9459, 0.9339, 0.9757, 0.9525, 0.9224, 0.9472, 0.9602, 0.9289, 0.875, 0.9539, 0.9437, 0.9243, 0.8821, 0.6426, 0.952, 0.98, 0.948, 0.9427, 0.9715, 0.8893, 0.972, 0.9286, 0.9014, 0.9393, 0.901, 0.9461, 0.9316, 0.9449, 0.9677, 0.9443, 0.9245, 0.976, 0.9369, 0.898, 0.8808, 0.9233, 0.9715, 0.9596, 0.8766, 0.888, 0.9187, 0.9286, 0.8813, 0.9208, 0.9205, 0.8609, 0.9313, 0.9576, 0.8857, 0.9452, 0.9634, 0.9388, 0.9478, 0.9444, 0.9497, 0.938, 0.8589], 'AP': [0.9802, 0.9494, 0.9675, 0.9912, 0.9759, 0.997, 0.9674, 0.9284, 0.9868, 0.9706, 0.9421, 0.9741, 0.8778, 0.9869, 0.959, 0.9801, 0.9936, 0.9956, 0.9727, 0.9824, 0.981, 0.9289, 0.9752, 0.9875, 0.9809, 0.9742, 0.9825, 0.982, 0.9823, 0.9682, 0.9221, 0.9305, 0.9716, 0.9796, 0.9655, 0.9492, 0.9796, 0.9851, 0.9696, 0.9393, 0.9999, 0.9123, 0.9831, 0.9909, 0.9741, 0.9894, 0.9108, 0.9775, 0.9105, 0.9728, 0.9267, 0.9639, 0.9935, 0.9719, 0.9876, 0.9841, 0.9961, 0.9738, 0.9626, 0.9181, 0.9111, 0.9605, 0.9711, 0.9825, 0.9652, 0.9319, 0.9923, 0.9868, 0.9833, 0.8929, 0.9536, 0.9472, 0.9836, 0.9733, 0.9517, 0.9452, 0.9165, 0.9801, 0.9891, 0.9896, 0.9744, 0.993, 0.9803, 0.926, 0.9898, 0.9912, 0.9803, 0.9764, 0.9531, 0.9827, 0.9957, 0.8829, 0.9752, 0.9577, 0.9711, 0.981, 0.9964, 0.8796, 0.9593, 0.9722, 0.9753, 0.9623, 0.966, 0.9496, 0.9903, 0.9763, 0.9922, 0.9315, 0.985, 0.9815, 0.929, 0.9908, 0.9875, 0.968, 0.7988, 0.9754, 0.8864, 0.9854, 0.9732, 0.9906, 0.9851, 0.9714, 0.983, 0.99, 0.9789, 0.9196, 0.9845, 0.9792, 0.9703, 0.9241, 0.6605, 0.9796, 0.9925, 0.9792, 0.9803, 0.99, 0.9409, 0.9901, 0.9758, 0.9565, 0.9756, 0.9491, 0.9865, 0.9788, 0.984, 0.9906, 0.9869, 0.9699, 0.9916, 0.9754, 0.9473, 0.9231, 0.9621, 0.9901, 0.989, 0.9281, 0.9288, 0.9708, 0.9748, 0.9381, 0.9705, 0.9645, 0.9206, 0.9791, 0.9829, 0.9264, 0.9802, 0.9902, 0.9753, 0.9864, 0.9765, 0.975, 0.9849, 0.9206], 'Recall@P=50': [0.9893, 0.968, 0.9869, 0.996, 0.984, 1.0, 0.98, 0.964, 0.9984, 0.9935, 0.972, 0.9908, 0.892, 0.994, 0.972, 0.988, 0.9984, 1.0, 0.976, 1.0, 0.992, 0.962, 0.984, 0.9976, 0.9907, 0.9896, 0.996, 0.988, 0.9975, 0.9808, 0.944, 0.952, 0.988, 0.992, 0.9855, 0.972, 0.992, 0.9993, 0.985, 0.968, 1.0, 0.952, 0.988, 0.992, 0.984, 0.996, 0.9667, 0.98, 0.9547, 0.984, 0.936, 0.9832, 0.994, 0.9863, 0.998, 0.9933, 1.0, 0.984, 0.976, 0.944, 0.944, 0.976, 0.984, 0.992, 0.9813, 0.96, 0.996, 0.996, 0.99, 0.928, 0.988, 0.972, 0.996, 0.9864, 0.976, 0.97, 0.96, 0.9907, 0.996, 0.992, 0.9926, 0.996, 0.9972, 0.936, 0.998, 0.998, 0.9984, 0.988, 0.9826, 0.992, 0.998, 0.92, 0.992, 0.9768, 0.976, 0.9971, 0.996, 0.956, 0.9787, 0.996, 0.992, 0.974, 0.984, 0.9813, 0.992, 0.991, 0.998, 0.96, 0.9936, 0.992, 0.968, 0.992, 0.9987, 0.978, 0.004, 0.99, 0.94, 0.9953, 0.996, 0.992, 0.992, 0.986, 0.996, 0.996, 0.9967, 0.956, 0.992, 0.988, 0.984, 0.956, 0.804, 0.984, 0.996, 0.992, 0.9907, 0.992, 0.972, 0.992, 0.992, 0.984, 0.984, 0.96, 0.996, 0.988, 0.9912, 0.992, 0.9996, 0.9867, 0.996, 0.984, 0.97, 0.96, 0.9733, 0.992, 0.996, 0.952, 0.948, 0.989, 0.996, 0.968, 0.988, 0.984, 0.94, 0.995, 0.988, 0.944, 0.9907, 0.992, 0.992, 0.996, 0.984, 0.984, 0.9995, 0.948], 'micro': 0.9754, 'macro': 0.964, 'weighted': 0.9739}
2024-07-27 10:15:47 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:15:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:15:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:15:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 14208 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_23_iter_14208.pt
2024-07-27 10:15:49 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 14208 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_23_iter_14208.pt
[31m===========================================================================[0m
2024-07-27 10:15:51 - [32m[1mINFO   [0m - Training epoch 24
2024-07-27 10:15:52 - [34m[1mLOGS   [0m - Epoch:  24 [   14209/10000000], loss: {'classification': 5.6601, 'neural_augmentation': 10.8443, 'total_loss': 16.5044}, LR: [7e-06, 7e-06], Avg. batch load time: 0.579, Elapsed time:  0.75
2024-07-27 10:17:44 - [34m[1mLOGS   [0m - Epoch:  24 [   14709/10000000], loss: {'classification': 6.4198, 'neural_augmentation': 10.3679, 'total_loss': 16.7876}, LR: [7e-06, 7e-06], Avg. batch load time: 0.001, Elapsed time: 112.96
2024-07-27 10:18:05 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 6.4282, 'neural_augmentation': 10.36, 'total_loss': 16.7883}
2024-07-27 10:18:33 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 2.5859, 'neural_augmentation': 0.0, 'total_loss': 2.5859} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9443, 0.9038, 0.9177, 0.9839, 0.9381, 0.9821, 0.9153, 0.8785, 0.9478, 0.9107, 0.9089, 0.9277, 0.8124, 0.9427, 0.9194, 0.9493, 0.9691, 0.9817, 0.9383, 0.9435, 0.9577, 0.8733, 0.9366, 0.9587, 0.9386, 0.9258, 0.9474, 0.9611, 0.9371, 0.9221, 0.8632, 0.8832, 0.9243, 0.9395, 0.9127, 0.8986, 0.9463, 0.9423, 0.9187, 0.9035, 0.998, 0.8554, 0.9537, 0.9703, 0.9381, 0.9679, 0.8379, 0.9608, 0.8538, 0.9371, 0.8763, 0.9103, 0.9839, 0.9329, 0.9502, 0.9497, 0.9828, 0.9312, 0.9253, 0.8571, 0.8548, 0.9246, 0.9395, 0.9455, 0.9182, 0.8774, 0.9778, 0.9526, 0.9572, 0.8406, 0.9209, 0.9074, 0.9457, 0.9342, 0.9083, 0.9051, 0.8832, 0.9452, 0.9573, 0.9718, 0.9206, 0.976, 0.9304, 0.8769, 0.965, 0.9658, 0.933, 0.9388, 0.8896, 0.9495, 0.9799, 0.8223, 0.9414, 0.9028, 0.9352, 0.9318, 0.9859, 0.8654, 0.9117, 0.9102, 0.9348, 0.9277, 0.9256, 0.8912, 0.9681, 0.9357, 0.9677, 0.8794, 0.9521, 0.9421, 0.8848, 0.9672, 0.9486, 0.9329, 0.7519, 0.9285, 0.8323, 0.9533, 0.9087, 0.9683, 0.9427, 0.9198, 0.9493, 0.964, 0.9301, 0.8577, 0.9584, 0.9448, 0.9296, 0.8863, 0.6411, 0.9416, 0.972, 0.9474, 0.9405, 0.9681, 0.89, 0.9701, 0.928, 0.9197, 0.938, 0.9006, 0.9514, 0.9373, 0.9464, 0.9712, 0.9447, 0.9229, 0.9839, 0.9329, 0.9002, 0.8882, 0.9108, 0.972, 0.9628, 0.8795, 0.8805, 0.9193, 0.9376, 0.8975, 0.9311, 0.9265, 0.8724, 0.9311, 0.9563, 0.8805, 0.9371, 0.9658, 0.9243, 0.9431, 0.94, 0.9443, 0.938, 0.8696], 'AP': [0.9816, 0.949, 0.9691, 0.9899, 0.9682, 0.9977, 0.9651, 0.9311, 0.9866, 0.9698, 0.9599, 0.9755, 0.8734, 0.9842, 0.9587, 0.9814, 0.99, 0.9947, 0.9717, 0.979, 0.9821, 0.9341, 0.9736, 0.9886, 0.9747, 0.9767, 0.9792, 0.9852, 0.9828, 0.9699, 0.9132, 0.9331, 0.974, 0.98, 0.9668, 0.9507, 0.979, 0.9858, 0.9669, 0.9436, 1.0, 0.9059, 0.9873, 0.9889, 0.9733, 0.9889, 0.9163, 0.9815, 0.9162, 0.9718, 0.9311, 0.967, 0.9934, 0.978, 0.9841, 0.9858, 0.9964, 0.9725, 0.9547, 0.9152, 0.9084, 0.9593, 0.9746, 0.9794, 0.965, 0.9336, 0.9925, 0.9848, 0.9801, 0.8934, 0.9438, 0.9561, 0.9851, 0.9733, 0.9495, 0.9416, 0.9296, 0.9817, 0.9906, 0.9948, 0.9745, 0.9937, 0.9796, 0.9283, 0.992, 0.9927, 0.9816, 0.9748, 0.9564, 0.9868, 0.9962, 0.8835, 0.9774, 0.9591, 0.9683, 0.9803, 0.9957, 0.9279, 0.9632, 0.9672, 0.9765, 0.9642, 0.9651, 0.9516, 0.988, 0.9769, 0.9897, 0.9331, 0.9838, 0.9812, 0.9304, 0.9947, 0.9879, 0.9719, 0.8156, 0.9727, 0.8977, 0.988, 0.9686, 0.9885, 0.9835, 0.9721, 0.985, 0.988, 0.9796, 0.9157, 0.9884, 0.9815, 0.9715, 0.9374, 0.6782, 0.979, 0.9924, 0.9763, 0.9782, 0.9872, 0.9446, 0.988, 0.9746, 0.9627, 0.9744, 0.9494, 0.9872, 0.977, 0.9824, 0.9956, 0.9874, 0.9723, 0.9889, 0.9692, 0.9509, 0.9375, 0.9601, 0.9883, 0.991, 0.924, 0.9242, 0.9737, 0.9756, 0.9427, 0.9735, 0.9543, 0.9174, 0.9798, 0.9794, 0.9248, 0.9803, 0.9884, 0.9709, 0.9857, 0.9711, 0.9769, 0.9845, 0.9141], 'Recall@P=50': [0.9893, 0.972, 0.9863, 0.988, 0.976, 1.0, 0.9784, 0.96, 0.9984, 0.9929, 0.98, 0.9948, 0.904, 0.996, 0.974, 0.996, 0.9936, 0.996, 0.976, 0.992, 0.992, 0.964, 0.984, 0.9936, 0.9827, 0.9936, 0.992, 0.992, 0.9988, 0.9864, 0.936, 0.96, 0.992, 0.988, 0.9865, 0.964, 0.988, 0.9989, 0.985, 0.964, 1.0, 0.94, 0.992, 0.996, 0.98, 0.992, 0.964, 0.984, 0.9493, 0.98, 0.948, 0.9847, 0.994, 0.9909, 0.994, 0.9927, 0.998, 0.988, 0.972, 0.94, 0.944, 0.976, 0.988, 0.988, 0.9827, 0.964, 0.996, 0.9933, 0.986, 0.912, 0.976, 0.98, 0.996, 0.9888, 0.98, 0.97, 0.964, 0.9907, 0.9947, 1.0, 0.9937, 0.996, 0.9986, 0.944, 1.0, 0.996, 0.9969, 0.988, 0.9904, 0.992, 0.998, 0.932, 0.992, 0.9816, 0.972, 0.9967, 0.996, 0.964, 0.9853, 0.98, 0.992, 0.984, 0.98, 0.984, 0.992, 0.99, 0.998, 0.96, 0.9936, 0.992, 0.96, 1.0, 0.9993, 0.982, 0.912, 0.988, 0.96, 0.9973, 0.996, 0.992, 0.996, 0.9907, 0.996, 0.992, 0.998, 0.956, 0.996, 0.9907, 0.992, 0.976, 0.004, 0.988, 0.996, 0.984, 0.9913, 0.988, 0.972, 0.992, 0.9927, 0.984, 0.984, 0.972, 0.996, 0.988, 0.9888, 1.0, 0.9998, 0.9933, 0.988, 0.98, 0.974, 0.968, 0.9733, 0.992, 0.996, 0.948, 0.948, 0.993, 0.984, 0.972, 0.991, 0.964, 0.948, 0.9955, 0.984, 0.948, 0.988, 0.99, 0.992, 1.0, 0.98, 0.988, 0.9996, 0.948], 'micro': 0.976, 'macro': 0.9647, 'weighted': 0.9745}
2024-07-27 10:18:39 - [34m[1mLOGS   [0m - Best checkpoint with score 0.96 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:18:39 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9601.pt
2024-07-27 10:18:39 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9615.pt', 'checkpoint_score_0.9627.pt', 'checkpoint_score_0.9629.pt', 'checkpoint_score_0.9640.pt', 'checkpoint_score_0.9647.pt']
2024-07-27 10:18:41 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:18:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:18:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:18:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 14800 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_24_iter_14800.pt
2024-07-27 10:18:44 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 14800 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_24_iter_14800.pt
[31m===========================================================================[0m
2024-07-27 10:18:46 - [32m[1mINFO   [0m - Training epoch 25
2024-07-27 10:18:46 - [34m[1mLOGS   [0m - Epoch:  25 [   14801/10000000], loss: {'classification': 6.6798, 'neural_augmentation': 8.9437, 'total_loss': 15.6235}, LR: [7e-06, 7e-06], Avg. batch load time: 0.421, Elapsed time:  0.60
2024-07-27 10:20:40 - [34m[1mLOGS   [0m - Epoch:  25 [   15301/10000000], loss: {'classification': 6.33, 'neural_augmentation': 10.3434, 'total_loss': 16.6734}, LR: [7e-06, 7e-06], Avg. batch load time: 0.002, Elapsed time: 114.08
2024-07-27 10:21:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 6.3403, 'neural_augmentation': 10.3091, 'total_loss': 16.6494}
2024-07-27 10:21:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 2.569, 'neural_augmentation': 0.0, 'total_loss': 2.569} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9439, 0.9129, 0.9196, 0.9718, 0.9317, 0.9819, 0.9248, 0.8784, 0.9408, 0.9065, 0.8996, 0.9281, 0.809, 0.9529, 0.9201, 0.953, 0.9706, 0.9796, 0.9469, 0.9431, 0.9497, 0.8665, 0.9405, 0.96, 0.9406, 0.9284, 0.9431, 0.9654, 0.9337, 0.9217, 0.8683, 0.875, 0.9301, 0.9398, 0.9058, 0.9044, 0.9516, 0.9414, 0.9236, 0.9002, 0.998, 0.8652, 0.9421, 0.9679, 0.935, 0.9636, 0.8346, 0.9567, 0.8542, 0.9295, 0.8833, 0.9098, 0.978, 0.9364, 0.9514, 0.9432, 0.9819, 0.9369, 0.926, 0.844, 0.8706, 0.929, 0.9395, 0.939, 0.9194, 0.8835, 0.982, 0.9452, 0.95, 0.8323, 0.9283, 0.9113, 0.9499, 0.9277, 0.9168, 0.9026, 0.8763, 0.9433, 0.9641, 0.9719, 0.9161, 0.9841, 0.9329, 0.8798, 0.9596, 0.9529, 0.9327, 0.9429, 0.8822, 0.9341, 0.976, 0.8009, 0.9393, 0.9002, 0.945, 0.9363, 0.982, 0.8723, 0.9113, 0.9175, 0.9334, 0.9257, 0.939, 0.8904, 0.968, 0.9328, 0.9684, 0.8924, 0.9506, 0.9369, 0.8765, 0.9755, 0.9474, 0.934, 0.7495, 0.9334, 0.833, 0.9499, 0.9215, 0.9738, 0.9488, 0.9261, 0.9505, 0.9637, 0.9276, 0.8495, 0.956, 0.9457, 0.93, 0.8902, 0.6554, 0.9431, 0.9819, 0.9461, 0.9401, 0.9697, 0.9015, 0.9695, 0.9325, 0.9175, 0.9371, 0.9053, 0.9533, 0.9393, 0.9412, 0.9754, 0.9471, 0.921, 0.9697, 0.9356, 0.9007, 0.8844, 0.9162, 0.9676, 0.9584, 0.8846, 0.8843, 0.9187, 0.9331, 0.8942, 0.9276, 0.9272, 0.8678, 0.9309, 0.9597, 0.8814, 0.9408, 0.9659, 0.924, 0.9395, 0.9247, 0.9469, 0.938, 0.8642], 'AP': [0.9823, 0.9531, 0.969, 0.9882, 0.9632, 0.9979, 0.9701, 0.9261, 0.9846, 0.9695, 0.9566, 0.9758, 0.8729, 0.987, 0.9623, 0.9787, 0.9916, 0.9946, 0.9729, 0.9801, 0.9818, 0.9354, 0.9797, 0.9869, 0.9771, 0.9742, 0.9811, 0.9854, 0.982, 0.9707, 0.9224, 0.9361, 0.9723, 0.9753, 0.9636, 0.954, 0.9771, 0.9862, 0.9686, 0.9488, 1.0, 0.9232, 0.9831, 0.9899, 0.9734, 0.9852, 0.9169, 0.9784, 0.9166, 0.9726, 0.9347, 0.9657, 0.9915, 0.9773, 0.9836, 0.9855, 0.9962, 0.9777, 0.9594, 0.9152, 0.9203, 0.9651, 0.9736, 0.9819, 0.9692, 0.9432, 0.992, 0.9852, 0.979, 0.8939, 0.9536, 0.9541, 0.9853, 0.9701, 0.9536, 0.9464, 0.9245, 0.9824, 0.9916, 0.995, 0.9728, 0.9934, 0.9813, 0.9351, 0.9903, 0.989, 0.9823, 0.9801, 0.9502, 0.9816, 0.9947, 0.8783, 0.9745, 0.9608, 0.9719, 0.9807, 0.995, 0.9247, 0.964, 0.9694, 0.9763, 0.9663, 0.972, 0.9517, 0.989, 0.9765, 0.9925, 0.9388, 0.9835, 0.9764, 0.9277, 0.994, 0.9875, 0.9734, 0.8084, 0.9761, 0.9051, 0.9872, 0.9695, 0.9894, 0.986, 0.9737, 0.9832, 0.986, 0.9792, 0.9155, 0.9868, 0.9822, 0.9748, 0.9341, 0.6982, 0.9759, 0.9925, 0.9798, 0.9791, 0.9888, 0.9467, 0.9892, 0.9765, 0.9618, 0.9793, 0.9537, 0.9869, 0.9808, 0.9828, 0.9947, 0.9881, 0.9705, 0.9863, 0.9742, 0.9528, 0.9355, 0.9619, 0.9886, 0.9897, 0.9311, 0.9301, 0.9734, 0.9744, 0.9478, 0.973, 0.9632, 0.9206, 0.9795, 0.9822, 0.9319, 0.9796, 0.989, 0.9713, 0.9841, 0.9651, 0.9721, 0.9851, 0.9185], 'Recall@P=50': [0.9913, 0.976, 0.9891, 0.988, 0.972, 1.0, 0.9864, 0.948, 0.9976, 0.9945, 0.978, 0.9912, 0.888, 0.998, 0.976, 0.988, 0.9968, 0.996, 0.98, 0.992, 0.992, 0.966, 0.992, 0.9936, 0.984, 0.988, 0.992, 0.992, 0.9973, 0.9888, 0.956, 0.96, 0.992, 0.988, 0.986, 0.968, 0.988, 0.9992, 0.981, 0.976, 1.0, 0.964, 0.996, 0.992, 0.984, 0.992, 0.9693, 0.984, 0.9547, 0.984, 0.964, 0.9832, 0.994, 0.9926, 0.992, 0.9953, 1.0, 0.988, 0.98, 0.956, 0.956, 0.988, 0.976, 0.996, 0.9913, 0.968, 0.996, 0.9947, 0.984, 0.916, 0.972, 0.97, 0.996, 0.9856, 0.972, 0.978, 0.956, 0.9973, 0.9973, 1.0, 0.9926, 0.996, 0.9978, 0.96, 0.998, 0.994, 0.9985, 0.988, 0.9809, 0.992, 0.998, 0.932, 0.98, 0.9848, 0.98, 0.996, 0.996, 0.968, 0.986, 0.988, 0.9931, 0.976, 0.984, 0.9773, 0.992, 0.99, 1.0, 0.96, 0.9944, 0.984, 0.952, 1.0, 0.9992, 0.986, 0.004, 0.9893, 0.972, 0.998, 0.98, 0.992, 0.994, 0.9893, 0.996, 0.992, 0.9973, 0.956, 0.996, 0.9893, 0.992, 0.968, 0.832, 0.984, 0.996, 0.988, 0.9907, 0.992, 0.9773, 0.992, 0.9927, 0.992, 0.988, 0.976, 1.0, 0.991, 0.9928, 1.0, 0.9996, 0.9933, 0.988, 0.984, 0.978, 0.962, 0.98, 0.992, 0.996, 0.952, 0.948, 0.993, 0.988, 0.976, 0.991, 0.98, 0.948, 0.996, 0.988, 0.96, 0.992, 0.994, 0.988, 0.996, 0.976, 0.98, 0.9996, 0.944], 'micro': 0.9762, 'macro': 0.9656, 'weighted': 0.975}
2024-07-27 10:21:34 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:21:35 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9615.pt
2024-07-27 10:21:35 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9627.pt', 'checkpoint_score_0.9629.pt', 'checkpoint_score_0.9640.pt', 'checkpoint_score_0.9647.pt', 'checkpoint_score_0.9656.pt']
2024-07-27 10:21:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:21:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:21:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:21:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 15392 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_25_iter_15392.pt
2024-07-27 10:21:39 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 15392 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_25_iter_15392.pt
[31m===========================================================================[0m
2024-07-27 10:21:41 - [32m[1mINFO   [0m - Training epoch 26
2024-07-27 10:21:42 - [34m[1mLOGS   [0m - Epoch:  26 [   15393/10000000], loss: {'classification': 6.1603, 'neural_augmentation': 9.3816, 'total_loss': 15.5419}, LR: [6e-06, 6e-06], Avg. batch load time: 0.511, Elapsed time:  0.79
2024-07-27 10:23:30 - [34m[1mLOGS   [0m - Epoch:  26 [   15893/10000000], loss: {'classification': 6.2237, 'neural_augmentation': 10.3177, 'total_loss': 16.5414}, LR: [6e-06, 6e-06], Avg. batch load time: 0.002, Elapsed time: 108.89
2024-07-27 10:23:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 6.2302, 'neural_augmentation': 10.3152, 'total_loss': 16.5455}
2024-07-27 10:24:17 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 2.5262, 'neural_augmentation': 0.0, 'total_loss': 2.5262} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9483, 0.9076, 0.9184, 0.9779, 0.9402, 0.9821, 0.9281, 0.8839, 0.946, 0.9131, 0.91, 0.9311, 0.817, 0.9483, 0.9155, 0.9491, 0.9709, 0.9819, 0.9506, 0.9497, 0.9535, 0.8765, 0.9485, 0.9625, 0.9467, 0.9311, 0.9497, 0.9576, 0.9363, 0.9172, 0.8648, 0.8844, 0.932, 0.9485, 0.909, 0.8996, 0.9539, 0.9424, 0.9218, 0.8966, 0.998, 0.8627, 0.9574, 0.976, 0.9358, 0.9657, 0.8432, 0.9542, 0.8566, 0.9325, 0.8841, 0.9124, 0.982, 0.9309, 0.9491, 0.9567, 0.9819, 0.945, 0.9336, 0.8549, 0.8637, 0.9347, 0.9485, 0.9499, 0.923, 0.8762, 0.9782, 0.9561, 0.9516, 0.8402, 0.9218, 0.9017, 0.9474, 0.9404, 0.9087, 0.8921, 0.8875, 0.9469, 0.9662, 0.9777, 0.9232, 0.9763, 0.9331, 0.8889, 0.9639, 0.9675, 0.9369, 0.9489, 0.8865, 0.9518, 0.9839, 0.8058, 0.9419, 0.9049, 0.9482, 0.937, 0.9822, 0.8708, 0.9143, 0.9293, 0.9377, 0.9261, 0.9271, 0.8981, 0.9759, 0.9364, 0.9739, 0.8795, 0.9534, 0.9484, 0.8807, 0.9779, 0.9491, 0.9387, 0.7378, 0.93, 0.8417, 0.9535, 0.9265, 0.9778, 0.9499, 0.9212, 0.9555, 0.9615, 0.9286, 0.8486, 0.9543, 0.9427, 0.9317, 0.8931, 0.669, 0.9469, 0.9802, 0.948, 0.9391, 0.9779, 0.8965, 0.9757, 0.9304, 0.9117, 0.9487, 0.9008, 0.9463, 0.9449, 0.9487, 0.9739, 0.9458, 0.9297, 0.9759, 0.9438, 0.8988, 0.8854, 0.9136, 0.9799, 0.967, 0.8857, 0.8921, 0.9283, 0.9347, 0.8956, 0.9257, 0.9331, 0.8729, 0.9336, 0.9531, 0.8912, 0.9433, 0.9666, 0.9325, 0.9442, 0.9397, 0.9448, 0.9418, 0.8674], 'AP': [0.9818, 0.9535, 0.9704, 0.9921, 0.9712, 0.9984, 0.9708, 0.9272, 0.9851, 0.9699, 0.9621, 0.976, 0.8783, 0.9862, 0.9576, 0.9805, 0.9905, 0.9952, 0.9743, 0.9771, 0.9842, 0.935, 0.9762, 0.988, 0.977, 0.9758, 0.978, 0.9879, 0.9834, 0.97, 0.9167, 0.9422, 0.975, 0.9814, 0.9649, 0.9512, 0.9752, 0.9861, 0.9684, 0.9442, 1.0, 0.921, 0.9863, 0.9895, 0.9773, 0.9864, 0.9203, 0.9794, 0.9169, 0.9768, 0.9342, 0.968, 0.9936, 0.9788, 0.9842, 0.9874, 0.9954, 0.9732, 0.9636, 0.9244, 0.9212, 0.9707, 0.972, 0.9803, 0.9679, 0.9346, 0.9952, 0.987, 0.9809, 0.8891, 0.9458, 0.9532, 0.982, 0.9753, 0.9543, 0.9459, 0.9187, 0.9821, 0.992, 0.9908, 0.975, 0.9958, 0.9812, 0.9339, 0.9922, 0.9916, 0.9837, 0.9786, 0.9522, 0.9863, 0.9956, 0.8677, 0.9738, 0.96, 0.9742, 0.9806, 0.9963, 0.9305, 0.9638, 0.9726, 0.9774, 0.9652, 0.9645, 0.9566, 0.9897, 0.979, 0.9913, 0.9382, 0.9845, 0.982, 0.9255, 0.9904, 0.9882, 0.9744, 0.8017, 0.9758, 0.8972, 0.9876, 0.9721, 0.9889, 0.9849, 0.9716, 0.9815, 0.9879, 0.9794, 0.9209, 0.9867, 0.9836, 0.9724, 0.9402, 0.6776, 0.981, 0.9943, 0.9834, 0.98, 0.988, 0.9493, 0.9896, 0.9753, 0.9594, 0.9755, 0.9527, 0.9852, 0.981, 0.9847, 0.9919, 0.9876, 0.9706, 0.9908, 0.9753, 0.9532, 0.9358, 0.9589, 0.9887, 0.991, 0.9324, 0.932, 0.9749, 0.9775, 0.943, 0.9746, 0.9662, 0.9181, 0.9798, 0.9838, 0.934, 0.9805, 0.9906, 0.9724, 0.9867, 0.9722, 0.9764, 0.986, 0.9162], 'Recall@P=50': [0.9907, 0.972, 0.9886, 0.996, 0.976, 1.0, 0.9848, 0.96, 0.9976, 0.9945, 0.986, 0.992, 0.896, 0.996, 0.976, 0.988, 0.9944, 0.996, 0.984, 0.992, 0.992, 0.96, 0.984, 0.9936, 0.984, 0.9912, 0.996, 0.996, 0.9982, 0.988, 0.948, 0.972, 0.988, 0.992, 0.9885, 0.968, 0.988, 0.9994, 0.985, 0.976, 1.0, 0.96, 0.992, 0.992, 0.988, 0.996, 0.9653, 0.988, 0.9573, 0.988, 0.952, 0.9847, 0.996, 0.9926, 0.994, 0.996, 0.998, 0.988, 0.984, 0.968, 0.944, 0.988, 0.984, 0.996, 0.988, 0.972, 1.0, 0.9947, 0.986, 0.94, 0.964, 0.976, 0.992, 0.9896, 0.98, 0.972, 0.96, 0.9933, 0.9973, 0.996, 0.9911, 1.0, 0.9982, 0.948, 0.998, 0.998, 0.9987, 0.984, 0.9791, 0.992, 0.998, 0.9, 0.984, 0.9824, 0.98, 0.9964, 0.996, 0.976, 0.984, 0.984, 0.9931, 0.976, 0.984, 0.9813, 0.992, 0.9913, 0.998, 0.968, 0.992, 0.988, 0.96, 0.992, 0.9992, 0.986, 0.92, 0.99, 0.976, 0.9953, 0.988, 0.992, 0.994, 0.9913, 0.992, 0.996, 0.997, 0.964, 0.992, 0.9907, 0.988, 0.978, 0.82, 0.984, 0.996, 0.996, 0.988, 0.992, 0.972, 0.992, 0.9933, 0.98, 0.988, 0.968, 1.0, 0.991, 0.996, 0.992, 0.9997, 0.9853, 0.988, 0.982, 0.98, 0.966, 0.9813, 0.992, 0.996, 0.956, 0.956, 0.994, 0.992, 0.972, 0.99, 0.984, 0.944, 0.996, 0.988, 0.956, 0.994, 0.994, 0.988, 1.0, 0.98, 0.98, 0.9993, 0.944], 'micro': 0.9769, 'macro': 0.966, 'weighted': 0.9755}
2024-07-27 10:24:23 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:24:23 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9627.pt
2024-07-27 10:24:23 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9629.pt', 'checkpoint_score_0.9640.pt', 'checkpoint_score_0.9647.pt', 'checkpoint_score_0.9656.pt', 'checkpoint_score_0.9660.pt']
2024-07-27 10:24:25 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:24:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:24:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:24:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 15984 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_26_iter_15984.pt
2024-07-27 10:24:27 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 15984 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_26_iter_15984.pt
[31m===========================================================================[0m
2024-07-27 10:24:29 - [32m[1mINFO   [0m - Training epoch 27
2024-07-27 10:24:30 - [34m[1mLOGS   [0m - Epoch:  27 [   15985/10000000], loss: {'classification': 5.706, 'neural_augmentation': 9.9245, 'total_loss': 15.6305}, LR: [6e-06, 6e-06], Avg. batch load time: 0.384, Elapsed time:  0.66
2024-07-27 10:26:24 - [34m[1mLOGS   [0m - Epoch:  27 [   16485/10000000], loss: {'classification': 6.1334, 'neural_augmentation': 10.2957, 'total_loss': 16.429}, LR: [6e-06, 6e-06], Avg. batch load time: 0.001, Elapsed time: 114.90
2024-07-27 10:26:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 6.1302, 'neural_augmentation': 10.289, 'total_loss': 16.4192}
2024-07-27 10:27:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 2.4809, 'neural_augmentation': 0.0, 'total_loss': 2.4809} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9467, 0.8994, 0.9306, 0.9801, 0.9369, 0.9839, 0.925, 0.8857, 0.9419, 0.9146, 0.9163, 0.9274, 0.8089, 0.9569, 0.9199, 0.9482, 0.9699, 0.9781, 0.9514, 0.9459, 0.9501, 0.8671, 0.9383, 0.9608, 0.9495, 0.9268, 0.9438, 0.9549, 0.9388, 0.9241, 0.8771, 0.8828, 0.9312, 0.9446, 0.9134, 0.9237, 0.9505, 0.943, 0.9215, 0.9008, 0.998, 0.8668, 0.9377, 0.972, 0.9331, 0.961, 0.8373, 0.959, 0.8521, 0.9295, 0.8813, 0.9181, 0.979, 0.941, 0.9454, 0.9521, 0.9848, 0.938, 0.9309, 0.8623, 0.8491, 0.9274, 0.9409, 0.9455, 0.9218, 0.8905, 0.9801, 0.9474, 0.9567, 0.8417, 0.9222, 0.905, 0.9524, 0.9348, 0.901, 0.9098, 0.8805, 0.9457, 0.9579, 0.9657, 0.9213, 0.9761, 0.9317, 0.8761, 0.9585, 0.9565, 0.9368, 0.9429, 0.8988, 0.9357, 0.979, 0.8124, 0.9395, 0.9069, 0.9489, 0.9387, 0.9859, 0.8684, 0.9093, 0.9202, 0.9353, 0.9278, 0.9431, 0.9041, 0.9737, 0.94, 0.9706, 0.9014, 0.9543, 0.9429, 0.8846, 0.9649, 0.9513, 0.9383, 0.7478, 0.9329, 0.8417, 0.951, 0.9214, 0.9778, 0.957, 0.9242, 0.9541, 0.9634, 0.934, 0.872, 0.9556, 0.9521, 0.9274, 0.8771, 0.6667, 0.9433, 0.9763, 0.9541, 0.9413, 0.9717, 0.8911, 0.9757, 0.9344, 0.9209, 0.9376, 0.9133, 0.9495, 0.9427, 0.9504, 0.9691, 0.9474, 0.9268, 0.98, 0.9461, 0.9002, 0.8866, 0.9194, 0.9736, 0.9545, 0.8922, 0.8936, 0.9217, 0.9272, 0.8936, 0.9288, 0.9298, 0.8842, 0.9358, 0.9556, 0.8898, 0.9417, 0.9633, 0.9243, 0.9446, 0.9395, 0.9551, 0.9434, 0.8714], 'AP': [0.9825, 0.9532, 0.9728, 0.9927, 0.9752, 0.9971, 0.9711, 0.9215, 0.9866, 0.9722, 0.9644, 0.9763, 0.881, 0.9872, 0.9605, 0.9834, 0.9915, 0.9965, 0.9747, 0.9834, 0.9847, 0.9339, 0.9772, 0.9896, 0.9801, 0.9762, 0.9829, 0.9825, 0.9846, 0.9716, 0.921, 0.9391, 0.9732, 0.9806, 0.9673, 0.9573, 0.9768, 0.9865, 0.9686, 0.9475, 0.9999, 0.9221, 0.9817, 0.9906, 0.9782, 0.9883, 0.9182, 0.981, 0.9193, 0.9775, 0.9393, 0.9682, 0.9934, 0.9806, 0.9842, 0.9869, 0.9968, 0.9734, 0.962, 0.9328, 0.9223, 0.9683, 0.9699, 0.9839, 0.9706, 0.9424, 0.995, 0.9854, 0.9844, 0.8936, 0.9473, 0.9499, 0.9869, 0.9758, 0.9532, 0.9516, 0.9152, 0.9838, 0.99, 0.9928, 0.9751, 0.9953, 0.9811, 0.9371, 0.9901, 0.9898, 0.9837, 0.9783, 0.9582, 0.9805, 0.9951, 0.8794, 0.9713, 0.9633, 0.9739, 0.9824, 0.9955, 0.9293, 0.9633, 0.9719, 0.9792, 0.9661, 0.9684, 0.9586, 0.9897, 0.9792, 0.9933, 0.9419, 0.9862, 0.9811, 0.9205, 0.9928, 0.989, 0.9769, 0.814, 0.9758, 0.8999, 0.9868, 0.9728, 0.9891, 0.9866, 0.9744, 0.9858, 0.9877, 0.9803, 0.9323, 0.9857, 0.9848, 0.9741, 0.9342, 0.7003, 0.9816, 0.9946, 0.981, 0.9801, 0.9887, 0.9485, 0.9895, 0.9762, 0.9649, 0.9774, 0.955, 0.9872, 0.9825, 0.9846, 0.9929, 0.9887, 0.9739, 0.9921, 0.9778, 0.9533, 0.9357, 0.9644, 0.9887, 0.9887, 0.9346, 0.9345, 0.9734, 0.9798, 0.9477, 0.9749, 0.9638, 0.921, 0.9814, 0.9833, 0.9335, 0.9812, 0.9893, 0.9709, 0.9868, 0.976, 0.9812, 0.9869, 0.9196], 'Recall@P=50': [0.9907, 0.972, 0.9886, 0.996, 0.984, 1.0, 0.9896, 0.96, 0.9984, 0.9929, 0.988, 0.9936, 0.92, 0.994, 0.976, 0.988, 0.996, 1.0, 0.98, 1.0, 0.996, 0.966, 0.988, 0.996, 0.9853, 0.9912, 1.0, 0.988, 0.9981, 0.9864, 0.944, 0.96, 0.988, 0.992, 0.9865, 0.968, 0.98, 0.9993, 0.986, 0.976, 1.0, 0.964, 0.988, 0.996, 0.988, 0.992, 0.9627, 0.992, 0.96, 0.992, 0.956, 0.9832, 0.992, 0.9926, 0.994, 0.9967, 1.0, 0.984, 0.98, 0.964, 0.968, 0.988, 0.984, 1.0, 0.9867, 0.966, 1.0, 0.996, 0.992, 0.928, 0.984, 0.978, 0.996, 0.9912, 0.972, 0.976, 0.964, 0.9947, 0.996, 0.996, 0.9916, 1.0, 0.9984, 0.96, 0.996, 0.998, 0.9987, 0.984, 0.9843, 0.988, 0.998, 0.916, 0.984, 0.984, 0.976, 0.9971, 0.996, 0.972, 0.986, 0.988, 0.9949, 0.984, 0.98, 0.9813, 0.992, 0.9907, 1.0, 0.952, 0.9936, 0.992, 0.964, 0.996, 0.9993, 0.99, 0.932, 0.9907, 0.972, 0.9953, 0.996, 0.988, 0.994, 0.9907, 0.996, 0.992, 0.997, 0.96, 0.992, 0.9933, 0.988, 0.974, 0.828, 0.992, 0.996, 0.988, 0.992, 0.992, 0.9733, 0.988, 0.9937, 0.988, 0.988, 0.968, 0.996, 0.991, 0.9928, 0.996, 0.9999, 0.9933, 0.996, 0.984, 0.982, 0.972, 0.984, 0.992, 0.994, 0.952, 0.952, 0.991, 0.996, 0.972, 0.99, 0.98, 0.94, 0.9962, 0.988, 0.948, 0.994, 0.994, 0.988, 1.0, 0.984, 0.992, 0.9995, 0.94], 'micro': 0.9779, 'macro': 0.9672, 'weighted': 0.9765}
2024-07-27 10:27:17 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:27:18 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9629.pt
2024-07-27 10:27:18 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9640.pt', 'checkpoint_score_0.9647.pt', 'checkpoint_score_0.9656.pt', 'checkpoint_score_0.9660.pt', 'checkpoint_score_0.9672.pt']
2024-07-27 10:27:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:27:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:27:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:27:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 16576 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_27_iter_16576.pt
2024-07-27 10:27:22 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 16576 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_27_iter_16576.pt
[31m===========================================================================[0m
2024-07-27 10:27:24 - [32m[1mINFO   [0m - Training epoch 28
2024-07-27 10:27:24 - [34m[1mLOGS   [0m - Epoch:  28 [   16577/10000000], loss: {'classification': 5.6729, 'neural_augmentation': 10.5168, 'total_loss': 16.1896}, LR: [6e-06, 6e-06], Avg. batch load time: 0.417, Elapsed time:  0.63
2024-07-27 10:29:17 - [34m[1mLOGS   [0m - Epoch:  28 [   17077/10000000], loss: {'classification': 5.9836, 'neural_augmentation': 10.3136, 'total_loss': 16.2972}, LR: [6e-06, 6e-06], Avg. batch load time: 0.002, Elapsed time: 113.33
2024-07-27 10:29:35 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 5.9691, 'neural_augmentation': 10.3019, 'total_loss': 16.271}
2024-07-27 10:30:05 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 2.5583, 'neural_augmentation': 0.0, 'total_loss': 2.5583} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9446, 0.9079, 0.926, 0.9821, 0.9366, 0.976, 0.9242, 0.887, 0.9447, 0.9169, 0.9114, 0.9292, 0.8222, 0.9469, 0.9183, 0.953, 0.9727, 0.9837, 0.9465, 0.9472, 0.9631, 0.8662, 0.9361, 0.9565, 0.9362, 0.9263, 0.9495, 0.9579, 0.9377, 0.9222, 0.8577, 0.8852, 0.9253, 0.9491, 0.9114, 0.9199, 0.9443, 0.9427, 0.9189, 0.8805, 0.998, 0.8465, 0.9407, 0.9681, 0.9278, 0.9697, 0.8338, 0.9631, 0.843, 0.9218, 0.897, 0.913, 0.98, 0.9337, 0.951, 0.9458, 0.9838, 0.9339, 0.9405, 0.8497, 0.8482, 0.9323, 0.9372, 0.9497, 0.9203, 0.8796, 0.9762, 0.9455, 0.9493, 0.8519, 0.917, 0.9072, 0.9448, 0.9336, 0.9114, 0.9093, 0.8842, 0.9414, 0.9616, 0.9759, 0.9217, 0.9781, 0.934, 0.902, 0.9585, 0.9603, 0.9361, 0.9341, 0.8947, 0.9414, 0.9791, 0.8008, 0.9345, 0.8972, 0.9446, 0.9292, 0.9839, 0.874, 0.9086, 0.9087, 0.9369, 0.9209, 0.9298, 0.8846, 0.9655, 0.9355, 0.9659, 0.881, 0.9554, 0.9489, 0.88, 0.9778, 0.9506, 0.942, 0.7551, 0.9298, 0.829, 0.9468, 0.9136, 0.9695, 0.9484, 0.9252, 0.9493, 0.9735, 0.9323, 0.8505, 0.9556, 0.9448, 0.9283, 0.8958, 0.6603, 0.9508, 0.9741, 0.9488, 0.9382, 0.9641, 0.8966, 0.9659, 0.9313, 0.9125, 0.9345, 0.8956, 0.943, 0.9369, 0.954, 0.9758, 0.9465, 0.9242, 0.9819, 0.935, 0.9028, 0.8793, 0.9227, 0.9738, 0.9545, 0.8755, 0.8761, 0.9125, 0.9246, 0.8776, 0.9283, 0.9426, 0.8577, 0.9339, 0.9593, 0.88, 0.9477, 0.967, 0.9231, 0.9412, 0.9393, 0.9405, 0.9418, 0.862], 'AP': [0.9797, 0.9531, 0.9729, 0.9934, 0.9701, 0.9946, 0.9718, 0.9293, 0.9866, 0.9709, 0.9589, 0.9758, 0.8785, 0.9867, 0.9565, 0.9793, 0.9925, 0.997, 0.9704, 0.9787, 0.9856, 0.9287, 0.9773, 0.9871, 0.977, 0.9736, 0.9793, 0.9836, 0.9836, 0.9697, 0.908, 0.9382, 0.9685, 0.9847, 0.9666, 0.9569, 0.9697, 0.9862, 0.9671, 0.9351, 0.9999, 0.9196, 0.9833, 0.9885, 0.9736, 0.991, 0.9153, 0.9791, 0.9076, 0.9714, 0.9423, 0.9662, 0.9947, 0.9786, 0.9838, 0.9858, 0.9971, 0.9736, 0.9683, 0.9204, 0.9198, 0.9707, 0.9695, 0.9795, 0.9702, 0.9359, 0.9939, 0.9836, 0.9829, 0.905, 0.9433, 0.9528, 0.9822, 0.974, 0.9541, 0.9494, 0.9253, 0.985, 0.9902, 0.9934, 0.9741, 0.9939, 0.9804, 0.9427, 0.9915, 0.9915, 0.9831, 0.9773, 0.9568, 0.9815, 0.9963, 0.8781, 0.9717, 0.9582, 0.9692, 0.9793, 0.9924, 0.9256, 0.9609, 0.9681, 0.9786, 0.9674, 0.9663, 0.9516, 0.988, 0.9776, 0.9935, 0.9314, 0.983, 0.9847, 0.929, 0.9926, 0.9884, 0.977, 0.8158, 0.9732, 0.8926, 0.986, 0.9677, 0.9876, 0.9866, 0.9725, 0.9811, 0.9913, 0.9809, 0.9188, 0.9849, 0.9834, 0.969, 0.9399, 0.6904, 0.9844, 0.9926, 0.9835, 0.9802, 0.9868, 0.9476, 0.9882, 0.9755, 0.9654, 0.9759, 0.9496, 0.9862, 0.9804, 0.9855, 0.9949, 0.9881, 0.9731, 0.9939, 0.9736, 0.9485, 0.9322, 0.965, 0.9874, 0.9873, 0.9323, 0.9331, 0.9717, 0.974, 0.9337, 0.9749, 0.969, 0.9069, 0.979, 0.983, 0.9323, 0.9787, 0.9878, 0.9705, 0.9866, 0.9699, 0.9764, 0.9864, 0.9047], 'Recall@P=50': [0.9893, 0.972, 0.9891, 0.996, 0.976, 0.996, 0.9872, 0.96, 0.9968, 0.9917, 0.986, 0.9928, 0.912, 0.992, 0.976, 0.984, 0.996, 1.0, 0.972, 0.984, 0.992, 0.96, 0.988, 0.9944, 0.988, 0.992, 0.984, 0.996, 0.9979, 0.9856, 0.936, 0.96, 0.992, 0.996, 0.986, 0.964, 0.976, 0.9989, 0.985, 0.956, 1.0, 0.964, 0.992, 0.992, 0.984, 0.996, 0.968, 0.98, 0.9493, 0.984, 0.944, 0.9847, 0.996, 0.992, 0.994, 0.996, 1.0, 0.988, 0.984, 0.952, 0.964, 0.992, 0.976, 0.984, 0.988, 0.966, 1.0, 0.9947, 0.99, 0.928, 0.972, 0.97, 0.992, 0.9888, 0.968, 0.982, 0.968, 0.9947, 0.9947, 1.0, 0.9895, 1.0, 0.998, 0.944, 0.998, 0.996, 0.9987, 0.988, 0.9843, 0.988, 0.998, 0.94, 0.98, 0.9792, 0.968, 0.9956, 0.992, 0.964, 0.9827, 0.988, 0.9937, 0.982, 0.98, 0.984, 0.992, 0.991, 0.998, 0.964, 0.9928, 0.992, 0.964, 0.996, 0.9992, 0.986, 0.932, 0.9907, 0.956, 0.9947, 0.988, 0.992, 0.994, 0.9873, 0.992, 0.996, 0.9983, 0.96, 0.988, 0.992, 0.992, 0.976, 0.864, 0.992, 0.996, 0.996, 0.9927, 0.992, 0.9733, 0.992, 0.9923, 0.984, 0.988, 0.964, 0.996, 0.992, 0.992, 1.0, 0.9993, 0.992, 0.996, 0.984, 0.972, 0.958, 0.976, 0.992, 0.994, 0.956, 0.964, 0.992, 0.988, 0.956, 0.993, 0.98, 0.936, 0.9965, 0.988, 0.956, 0.9867, 0.99, 0.992, 0.996, 0.976, 0.98, 0.9996, 0.936], 'micro': 0.9766, 'macro': 0.9655, 'weighted': 0.9752}
2024-07-27 10:30:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:30:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:30:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 17168 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_28_iter_17168.pt
2024-07-27 10:30:12 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 17168 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_28_iter_17168.pt
[31m===========================================================================[0m
2024-07-27 10:30:14 - [32m[1mINFO   [0m - Training epoch 29
2024-07-27 10:30:15 - [34m[1mLOGS   [0m - Epoch:  29 [   17169/10000000], loss: {'classification': 4.6039, 'neural_augmentation': 9.125, 'total_loss': 13.7288}, LR: [6e-06, 6e-06], Avg. batch load time: 0.660, Elapsed time:  0.85
2024-07-27 10:32:05 - [34m[1mLOGS   [0m - Epoch:  29 [   17669/10000000], loss: {'classification': 5.9079, 'neural_augmentation': 10.27, 'total_loss': 16.1779}, LR: [6e-06, 6e-06], Avg. batch load time: 0.002, Elapsed time: 111.24
2024-07-27 10:32:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 5.92, 'neural_augmentation': 10.2711, 'total_loss': 16.1911}
2024-07-27 10:32:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 2.5668, 'neural_augmentation': 0.0, 'total_loss': 2.5668} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9472, 0.9117, 0.9252, 0.9798, 0.9416, 0.986, 0.9236, 0.8802, 0.9457, 0.9139, 0.9146, 0.9284, 0.8273, 0.9521, 0.9139, 0.9549, 0.9699, 0.988, 0.939, 0.9463, 0.9613, 0.8807, 0.9354, 0.9586, 0.9388, 0.9311, 0.9446, 0.959, 0.9377, 0.9247, 0.867, 0.8857, 0.92, 0.9448, 0.9156, 0.9243, 0.9489, 0.9437, 0.9226, 0.8802, 0.998, 0.8646, 0.9355, 0.9679, 0.9275, 0.9613, 0.832, 0.959, 0.8402, 0.9284, 0.8907, 0.9144, 0.983, 0.9425, 0.9443, 0.9504, 0.987, 0.9421, 0.9339, 0.8596, 0.8626, 0.9244, 0.9429, 0.9506, 0.9232, 0.8863, 0.9742, 0.945, 0.9511, 0.8471, 0.9218, 0.9112, 0.9533, 0.9372, 0.9162, 0.8919, 0.88, 0.9472, 0.9634, 0.968, 0.9207, 0.9738, 0.9313, 0.8889, 0.9565, 0.9574, 0.9343, 0.9377, 0.8922, 0.9309, 0.9769, 0.8261, 0.9383, 0.9086, 0.9383, 0.9322, 0.9776, 0.8655, 0.9082, 0.9202, 0.9363, 0.931, 0.9331, 0.8906, 0.9715, 0.9374, 0.9708, 0.8884, 0.9483, 0.9407, 0.8871, 0.9697, 0.9491, 0.9415, 0.7456, 0.9268, 0.8474, 0.954, 0.9155, 0.9698, 0.9543, 0.9238, 0.951, 0.9611, 0.9337, 0.8588, 0.9622, 0.95, 0.9224, 0.8924, 0.6569, 0.945, 0.972, 0.9541, 0.9365, 0.9717, 0.8931, 0.9735, 0.9325, 0.9237, 0.9398, 0.9158, 0.9472, 0.9371, 0.951, 0.9699, 0.9459, 0.9243, 0.978, 0.9398, 0.9061, 0.885, 0.9216, 0.9715, 0.9527, 0.8884, 0.8967, 0.9251, 0.9262, 0.884, 0.9308, 0.9344, 0.8737, 0.9326, 0.9524, 0.887, 0.9454, 0.9586, 0.9206, 0.9458, 0.9355, 0.9369, 0.9405, 0.8667], 'AP': [0.9794, 0.9513, 0.9725, 0.9955, 0.9746, 0.9979, 0.9691, 0.9202, 0.986, 0.9721, 0.9653, 0.9765, 0.8845, 0.9872, 0.9583, 0.9823, 0.9915, 0.997, 0.9754, 0.9805, 0.9845, 0.9386, 0.9754, 0.9892, 0.9759, 0.9764, 0.9811, 0.9875, 0.9833, 0.9696, 0.9169, 0.9425, 0.9676, 0.979, 0.9683, 0.9537, 0.9754, 0.9863, 0.9681, 0.9405, 0.9999, 0.9341, 0.9775, 0.9894, 0.9697, 0.986, 0.9165, 0.9797, 0.9112, 0.9685, 0.9446, 0.9684, 0.9955, 0.9778, 0.9837, 0.9853, 0.997, 0.9708, 0.964, 0.9155, 0.9309, 0.9626, 0.9698, 0.9831, 0.9688, 0.9364, 0.9952, 0.9837, 0.979, 0.9011, 0.957, 0.9519, 0.9849, 0.9754, 0.9563, 0.9395, 0.9131, 0.9803, 0.9906, 0.9912, 0.9742, 0.9956, 0.9814, 0.9436, 0.9894, 0.9892, 0.9829, 0.9761, 0.958, 0.9775, 0.9959, 0.8883, 0.9725, 0.9616, 0.9731, 0.9805, 0.9919, 0.9267, 0.9604, 0.9672, 0.9762, 0.9657, 0.9617, 0.9567, 0.9886, 0.9785, 0.9942, 0.9369, 0.9844, 0.9804, 0.9205, 0.9914, 0.9882, 0.9739, 0.8222, 0.9742, 0.9036, 0.9877, 0.9675, 0.9889, 0.9872, 0.972, 0.9828, 0.9875, 0.9812, 0.9117, 0.9861, 0.9842, 0.968, 0.939, 0.7062, 0.9776, 0.9949, 0.9816, 0.9798, 0.9886, 0.9459, 0.9887, 0.975, 0.9658, 0.9753, 0.9587, 0.9885, 0.9799, 0.9845, 0.9927, 0.9878, 0.9718, 0.995, 0.9744, 0.9518, 0.9387, 0.963, 0.989, 0.987, 0.9303, 0.9341, 0.9749, 0.9713, 0.9412, 0.9753, 0.9664, 0.9124, 0.9786, 0.9825, 0.9311, 0.9808, 0.985, 0.973, 0.9863, 0.9745, 0.9746, 0.9861, 0.9131], 'Recall@P=50': [0.9887, 0.972, 0.9909, 0.996, 0.98, 1.0, 0.988, 0.96, 0.996, 0.9929, 0.988, 0.9944, 0.924, 0.996, 0.974, 0.988, 0.9968, 1.0, 0.988, 0.992, 0.988, 0.964, 0.984, 0.9976, 0.9867, 0.9904, 0.992, 0.992, 0.9973, 0.9848, 0.948, 0.964, 0.992, 0.988, 0.988, 0.964, 0.984, 0.9992, 0.985, 0.96, 1.0, 0.984, 0.992, 0.992, 0.98, 0.992, 0.9613, 0.988, 0.9573, 0.98, 0.968, 0.9853, 0.996, 0.9914, 0.99, 0.9947, 0.998, 0.984, 0.984, 0.952, 0.976, 0.984, 0.984, 0.996, 0.988, 0.964, 1.0, 0.996, 0.99, 0.936, 0.98, 0.972, 0.996, 0.988, 0.976, 0.976, 0.956, 0.9947, 0.9947, 0.996, 0.9926, 1.0, 0.9978, 0.964, 0.998, 0.994, 0.998, 0.988, 0.9878, 0.992, 0.998, 0.932, 0.98, 0.98, 0.98, 0.9953, 0.992, 0.972, 0.9827, 0.984, 0.9931, 0.974, 0.976, 0.988, 0.992, 0.9923, 0.998, 0.96, 0.9952, 0.988, 0.948, 0.996, 0.9994, 0.986, 0.948, 0.9913, 0.964, 0.9973, 0.984, 0.992, 0.996, 0.9887, 0.992, 0.992, 0.9977, 0.952, 0.992, 0.9933, 0.984, 0.97, 0.884, 0.984, 1.0, 0.992, 0.9927, 0.992, 0.9747, 0.992, 0.9913, 0.984, 0.988, 0.976, 1.0, 0.993, 0.9912, 1.0, 0.9997, 0.9907, 1.0, 0.984, 0.97, 0.966, 0.9787, 0.992, 0.998, 0.948, 0.952, 0.994, 0.988, 0.976, 0.993, 0.984, 0.944, 0.996, 0.988, 0.94, 0.9907, 0.99, 0.992, 0.996, 0.98, 0.98, 0.9996, 0.94], 'micro': 0.9764, 'macro': 0.9661, 'weighted': 0.9755}
2024-07-27 10:33:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:33:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:33:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 17760 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_29_iter_17760.pt
2024-07-27 10:33:01 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 17760 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_29_iter_17760.pt
[31m===========================================================================[0m
2024-07-27 10:33:03 - [32m[1mINFO   [0m - Training epoch 30
2024-07-27 10:33:04 - [34m[1mLOGS   [0m - Epoch:  30 [   17761/10000000], loss: {'classification': 5.9957, 'neural_augmentation': 9.3132, 'total_loss': 15.3089}, LR: [5e-06, 5e-06], Avg. batch load time: 0.802, Elapsed time:  0.99
2024-07-27 10:34:55 - [34m[1mLOGS   [0m - Epoch:  30 [   18261/10000000], loss: {'classification': 5.7819, 'neural_augmentation': 10.1893, 'total_loss': 15.9712}, LR: [5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 112.17
2024-07-27 10:35:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'classification': 5.8007, 'neural_augmentation': 10.2091, 'total_loss': 16.0099}
2024-07-27 10:35:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'classification': 2.5368, 'neural_augmentation': 0.0, 'total_loss': 2.5368} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9481, 0.9163, 0.927, 0.9802, 0.94, 0.9759, 0.9255, 0.8765, 0.946, 0.9164, 0.9118, 0.9282, 0.8276, 0.9513, 0.9215, 0.9485, 0.9714, 0.9838, 0.95, 0.9414, 0.9592, 0.8826, 0.9402, 0.957, 0.9453, 0.929, 0.9424, 0.9597, 0.9415, 0.924, 0.8675, 0.8916, 0.9328, 0.9467, 0.9149, 0.9234, 0.9539, 0.943, 0.9234, 0.8763, 0.998, 0.8577, 0.9412, 0.9717, 0.9325, 0.9675, 0.8299, 0.9595, 0.8603, 0.93, 0.8884, 0.9176, 0.983, 0.9404, 0.9459, 0.9484, 0.985, 0.9312, 0.9296, 0.8722, 0.8454, 0.9267, 0.9417, 0.9433, 0.9271, 0.8916, 0.9802, 0.9424, 0.9605, 0.83, 0.9117, 0.9125, 0.9482, 0.9304, 0.9205, 0.9137, 0.8839, 0.9422, 0.9582, 0.9657, 0.9276, 0.9802, 0.9366, 0.8858, 0.9565, 0.9641, 0.9349, 0.9447, 0.8947, 0.9433, 0.978, 0.8129, 0.9409, 0.9101, 0.9512, 0.9347, 0.9839, 0.8692, 0.9104, 0.9132, 0.9385, 0.9252, 0.9429, 0.8967, 0.9697, 0.9359, 0.9687, 0.8893, 0.9526, 0.9487, 0.8826, 0.9652, 0.9504, 0.9403, 0.7736, 0.9253, 0.84, 0.9481, 0.9158, 0.9718, 0.9478, 0.93, 0.9503, 0.9717, 0.9325, 0.8619, 0.9584, 0.9458, 0.9336, 0.8843, 0.669, 0.9506, 0.9822, 0.9497, 0.9382, 0.9697, 0.9015, 0.9698, 0.9325, 0.9228, 0.9349, 0.8933, 0.9499, 0.9378, 0.9511, 0.9673, 0.9458, 0.9344, 0.9798, 0.9437, 0.9096, 0.8887, 0.9216, 0.9717, 0.957, 0.8875, 0.8903, 0.9222, 0.9312, 0.8793, 0.9295, 0.9278, 0.8729, 0.935, 0.9551, 0.8861, 0.9462, 0.9649, 0.9228, 0.9409, 0.9424, 0.9565, 0.9413, 0.8742], 'AP': [0.9811, 0.9561, 0.9732, 0.993, 0.9694, 0.9968, 0.9705, 0.9263, 0.9843, 0.9723, 0.9605, 0.9752, 0.8774, 0.9853, 0.9604, 0.981, 0.9928, 0.9967, 0.9777, 0.9796, 0.9851, 0.94, 0.9763, 0.988, 0.9784, 0.9761, 0.9787, 0.9847, 0.9847, 0.9685, 0.9194, 0.9367, 0.9731, 0.9817, 0.9685, 0.9586, 0.984, 0.9869, 0.9669, 0.9399, 1.0, 0.9198, 0.9853, 0.9885, 0.9771, 0.9827, 0.9141, 0.9804, 0.9178, 0.9738, 0.9445, 0.9675, 0.9949, 0.976, 0.9824, 0.9853, 0.9965, 0.9726, 0.9692, 0.9266, 0.9206, 0.9618, 0.9696, 0.981, 0.9728, 0.9393, 0.9958, 0.9827, 0.9842, 0.8915, 0.9497, 0.9558, 0.9844, 0.9733, 0.9564, 0.9504, 0.925, 0.9809, 0.989, 0.9883, 0.9752, 0.9963, 0.9819, 0.9426, 0.9904, 0.9898, 0.9832, 0.9778, 0.9542, 0.9844, 0.9948, 0.8806, 0.9701, 0.9627, 0.9767, 0.9815, 0.9929, 0.9224, 0.9638, 0.9734, 0.9793, 0.9623, 0.9682, 0.9578, 0.9885, 0.9782, 0.994, 0.939, 0.9844, 0.9828, 0.927, 0.9882, 0.9889, 0.9757, 0.8377, 0.972, 0.8978, 0.9845, 0.9739, 0.9876, 0.9847, 0.9746, 0.9832, 0.985, 0.9813, 0.923, 0.9851, 0.9846, 0.9738, 0.9418, 0.697, 0.9815, 0.9953, 0.9817, 0.9791, 0.988, 0.9532, 0.9882, 0.976, 0.9637, 0.9763, 0.9516, 0.9868, 0.9808, 0.9845, 0.9898, 0.9881, 0.9736, 0.9935, 0.9749, 0.9525, 0.9421, 0.9663, 0.9875, 0.99, 0.9291, 0.9307, 0.9724, 0.9756, 0.94, 0.9752, 0.9703, 0.9152, 0.9802, 0.9862, 0.9318, 0.9823, 0.9905, 0.9701, 0.9826, 0.9702, 0.9774, 0.9866, 0.9163], 'Recall@P=50': [0.9873, 0.976, 0.992, 0.996, 0.98, 1.0, 0.988, 0.944, 0.9984, 0.9951, 0.99, 0.9932, 0.892, 0.994, 0.978, 0.988, 0.9984, 1.0, 0.984, 0.988, 0.992, 0.966, 0.984, 0.9968, 0.9853, 0.9904, 0.988, 0.992, 0.9981, 0.9832, 0.948, 0.968, 0.988, 0.988, 0.9875, 0.968, 0.992, 0.9992, 0.982, 0.952, 1.0, 0.98, 0.996, 0.992, 0.988, 0.992, 0.9587, 0.988, 0.9613, 0.988, 0.964, 0.9837, 0.998, 0.9897, 0.99, 0.996, 1.0, 0.984, 0.984, 0.952, 0.984, 0.976, 0.988, 0.992, 0.99, 0.966, 1.0, 0.9933, 0.988, 0.936, 0.984, 0.976, 0.992, 0.9872, 0.98, 0.974, 0.952, 0.9933, 0.996, 0.992, 0.9911, 1.0, 0.998, 0.964, 0.998, 0.994, 0.9989, 0.988, 0.9817, 0.992, 0.998, 0.932, 0.992, 0.9856, 0.98, 0.996, 0.992, 0.98, 0.9833, 0.992, 0.9926, 0.974, 0.98, 0.9813, 0.992, 0.9907, 1.0, 0.96, 0.992, 0.996, 0.948, 0.992, 0.9993, 0.984, 0.94, 0.988, 0.956, 0.9953, 0.996, 0.992, 0.994, 0.9907, 0.992, 0.992, 0.9983, 0.964, 0.992, 0.9933, 0.988, 0.976, 0.876, 0.992, 1.0, 0.992, 0.99, 0.992, 0.9787, 0.992, 0.9923, 0.984, 0.984, 0.972, 0.996, 0.992, 0.9912, 0.996, 0.9997, 0.9947, 0.992, 0.984, 0.978, 0.97, 0.98, 0.992, 0.998, 0.936, 0.956, 0.991, 0.992, 0.96, 0.991, 0.984, 0.944, 0.9962, 0.988, 0.944, 0.9933, 0.994, 0.988, 0.992, 0.98, 0.984, 0.9995, 0.94], 'micro': 0.9771, 'macro': 0.9667, 'weighted': 0.976}
2024-07-27 10:35:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:35:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:35:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 18352 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_30_iter_18352.pt
2024-07-27 10:35:51 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 18352 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_30_iter_18352.pt
[31m===========================================================================[0m
2024-07-27 10:35:53 - [32m[1mINFO   [0m - Training epoch 31
2024-07-27 10:35:53 - [34m[1mLOGS   [0m - Epoch:  31 [   18353/10000000], loss: {'classification': 4.7212, 'neural_augmentation': 10.5579, 'total_loss': 15.2791}, LR: [5e-06, 5e-06], Avg. batch load time: 0.710, Elapsed time:  0.92
2024-07-27 10:37:39 - [34m[1mLOGS   [0m - Epoch:  31 [   18853/10000000], loss: {'classification': 5.7213, 'neural_augmentation': 10.2299, 'total_loss': 15.9512}, LR: [5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 106.89
2024-07-27 10:37:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'classification': 5.7279, 'neural_augmentation': 10.2246, 'total_loss': 15.9525}
2024-07-27 10:38:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'classification': 2.5007, 'neural_augmentation': 0.0, 'total_loss': 2.5007} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9468, 0.9076, 0.9225, 0.98, 0.937, 0.9859, 0.9276, 0.8719, 0.9433, 0.9194, 0.9168, 0.9314, 0.8142, 0.9527, 0.9136, 0.9598, 0.972, 0.9859, 0.9424, 0.9446, 0.9576, 0.8762, 0.9352, 0.9587, 0.9473, 0.9348, 0.9448, 0.9637, 0.9413, 0.9308, 0.8565, 0.8871, 0.9312, 0.9478, 0.9154, 0.9146, 0.9553, 0.9435, 0.9183, 0.8979, 0.998, 0.8583, 0.9503, 0.9703, 0.9336, 0.9634, 0.8371, 0.9618, 0.857, 0.9267, 0.8739, 0.9151, 0.9807, 0.9388, 0.9538, 0.9572, 0.9839, 0.9383, 0.9328, 0.8643, 0.8663, 0.9323, 0.9375, 0.9429, 0.9252, 0.8909, 0.9723, 0.9478, 0.9557, 0.8534, 0.9135, 0.9145, 0.9487, 0.9367, 0.9079, 0.9091, 0.8721, 0.9484, 0.9627, 0.9676, 0.9261, 0.9743, 0.9351, 0.8737, 0.9638, 0.9615, 0.9359, 0.9402, 0.8964, 0.9426, 0.9798, 0.8192, 0.9397, 0.9082, 0.9446, 0.9384, 0.988, 0.875, 0.9113, 0.9114, 0.9391, 0.9221, 0.9429, 0.8934, 0.968, 0.9381, 0.9737, 0.8978, 0.9552, 0.9463, 0.869, 0.9697, 0.9519, 0.9409, 0.7722, 0.9377, 0.8415, 0.9557, 0.9202, 0.9696, 0.9511, 0.9273, 0.9484, 0.9677, 0.9294, 0.8571, 0.9608, 0.9506, 0.935, 0.895, 0.6622, 0.9448, 0.9743, 0.9463, 0.9418, 0.9703, 0.9049, 0.968, 0.9323, 0.9194, 0.9363, 0.9091, 0.9495, 0.9468, 0.9523, 0.9677, 0.9468, 0.9238, 0.9799, 0.9408, 0.9085, 0.8909, 0.9198, 0.9684, 0.9612, 0.883, 0.8833, 0.9253, 0.932, 0.8994, 0.9253, 0.9284, 0.853, 0.932, 0.9616, 0.8889, 0.9471, 0.9708, 0.9234, 0.939, 0.9367, 0.9433, 0.9434, 0.8632], 'AP': [0.9826, 0.959, 0.9722, 0.9938, 0.972, 0.9974, 0.97, 0.9204, 0.9866, 0.9722, 0.9649, 0.9763, 0.8819, 0.9884, 0.9591, 0.9827, 0.9921, 0.996, 0.9768, 0.9821, 0.9848, 0.9409, 0.9723, 0.9883, 0.979, 0.9769, 0.9822, 0.9879, 0.9844, 0.9723, 0.9104, 0.9391, 0.9736, 0.9817, 0.9692, 0.9548, 0.9798, 0.9868, 0.9692, 0.9426, 0.9999, 0.9289, 0.9837, 0.9906, 0.9726, 0.9865, 0.9225, 0.9808, 0.924, 0.9713, 0.9396, 0.9687, 0.9955, 0.9805, 0.9832, 0.9878, 0.9972, 0.9642, 0.9641, 0.924, 0.9298, 0.967, 0.9727, 0.982, 0.9711, 0.9388, 0.9942, 0.9853, 0.9837, 0.9066, 0.9489, 0.9566, 0.9845, 0.9745, 0.9621, 0.9533, 0.9174, 0.9837, 0.9923, 0.9946, 0.9757, 0.9943, 0.9813, 0.936, 0.9898, 0.9905, 0.9833, 0.9724, 0.9577, 0.9828, 0.9957, 0.8832, 0.974, 0.9637, 0.9747, 0.9817, 0.9964, 0.9334, 0.9649, 0.9709, 0.9798, 0.9677, 0.968, 0.9576, 0.9903, 0.979, 0.9947, 0.9351, 0.985, 0.9827, 0.9207, 0.9945, 0.989, 0.9766, 0.8156, 0.9747, 0.8858, 0.9857, 0.9711, 0.9903, 0.9887, 0.9745, 0.9842, 0.9874, 0.98, 0.926, 0.986, 0.9855, 0.9743, 0.9432, 0.703, 0.9813, 0.9928, 0.9826, 0.9802, 0.9893, 0.9501, 0.9907, 0.976, 0.9639, 0.9714, 0.9536, 0.9899, 0.9823, 0.9847, 0.9944, 0.9881, 0.9742, 0.9938, 0.9768, 0.9569, 0.9414, 0.9657, 0.9896, 0.989, 0.9303, 0.9295, 0.9733, 0.9741, 0.9437, 0.9745, 0.9664, 0.9134, 0.9796, 0.9851, 0.9308, 0.9824, 0.9908, 0.9712, 0.9869, 0.9725, 0.9789, 0.9867, 0.9108], 'Recall@P=50': [0.9913, 0.98, 0.9886, 0.996, 0.984, 1.0, 0.9856, 0.944, 0.9976, 0.9932, 0.984, 0.9932, 0.916, 0.994, 0.976, 0.992, 0.996, 1.0, 0.988, 0.992, 0.992, 0.972, 0.988, 0.9968, 0.988, 0.9912, 0.996, 0.996, 0.9986, 0.9864, 0.944, 0.976, 0.988, 0.984, 0.988, 0.972, 0.988, 0.9992, 0.983, 0.964, 1.0, 0.98, 0.988, 0.992, 0.984, 0.988, 0.9747, 0.984, 0.9613, 0.98, 0.964, 0.9837, 0.996, 0.9926, 0.99, 0.996, 1.0, 0.98, 0.984, 0.948, 0.98, 0.988, 0.988, 0.988, 0.99, 0.964, 1.0, 0.9933, 0.99, 0.944, 0.968, 0.976, 0.992, 0.9888, 0.988, 0.982, 0.952, 0.996, 0.9987, 1.0, 0.9916, 1.0, 0.9982, 0.956, 0.998, 0.996, 0.9989, 0.988, 0.9809, 0.988, 0.998, 0.928, 0.984, 0.984, 0.98, 0.9956, 0.996, 0.968, 0.9873, 0.992, 0.9937, 0.98, 0.984, 0.9853, 0.992, 0.9907, 0.998, 0.956, 0.9944, 0.996, 0.952, 1.0, 0.9996, 0.99, 0.912, 0.988, 0.936, 0.9947, 0.988, 0.992, 0.996, 0.99, 0.992, 0.992, 0.9983, 0.952, 0.992, 0.9907, 0.992, 0.974, 0.86, 0.992, 0.996, 0.988, 0.9907, 0.992, 0.9787, 0.996, 0.9927, 0.992, 0.984, 0.968, 1.0, 0.991, 0.9936, 1.0, 0.9997, 0.9933, 0.996, 0.986, 0.984, 0.97, 0.984, 0.992, 0.994, 0.956, 0.952, 0.989, 0.988, 0.976, 0.991, 0.984, 0.948, 0.9958, 0.988, 0.952, 0.9913, 0.994, 0.988, 1.0, 0.984, 0.992, 0.9996, 0.944], 'micro': 0.9775, 'macro': 0.9672, 'weighted': 0.9765}
2024-07-27 10:38:32 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:38:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:38:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:38:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 18944 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_31_iter_18944.pt
2024-07-27 10:38:34 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 18944 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_31_iter_18944.pt
[31m===========================================================================[0m
2024-07-27 10:38:36 - [32m[1mINFO   [0m - Training epoch 32
2024-07-27 10:38:37 - [34m[1mLOGS   [0m - Epoch:  32 [   18945/10000000], loss: {'classification': 5.2344, 'neural_augmentation': 9.759, 'total_loss': 14.9934}, LR: [5e-06, 5e-06], Avg. batch load time: 0.564, Elapsed time:  0.65
2024-07-27 10:39:14 - [34m[1mLOGS   [0m - Epoch:  32 [   19445/10000000], loss: {'classification': 5.6207, 'neural_augmentation': 10.1911, 'total_loss': 15.8118}, LR: [5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 38.24
2024-07-27 10:39:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'classification': 5.6434, 'neural_augmentation': 10.2091, 'total_loss': 15.8525}
2024-07-27 10:39:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'classification': 2.4854, 'neural_augmentation': 0.0, 'total_loss': 2.4854} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9472, 0.913, 0.9202, 0.9839, 0.9433, 0.984, 0.9302, 0.8755, 0.9473, 0.9196, 0.9054, 0.9311, 0.8225, 0.95, 0.9172, 0.9518, 0.9746, 0.9859, 0.951, 0.9469, 0.9567, 0.8767, 0.9318, 0.9643, 0.9431, 0.9312, 0.9474, 0.9639, 0.9407, 0.9325, 0.8601, 0.8944, 0.9194, 0.953, 0.917, 0.9095, 0.9497, 0.9427, 0.9288, 0.904, 0.998, 0.8755, 0.9386, 0.9622, 0.9442, 0.9634, 0.8404, 0.9631, 0.8495, 0.9444, 0.8992, 0.9182, 0.9839, 0.939, 0.959, 0.9554, 0.9849, 0.9379, 0.9308, 0.8653, 0.8643, 0.9433, 0.9505, 0.9463, 0.9273, 0.8903, 0.9737, 0.9544, 0.9627, 0.8445, 0.929, 0.9148, 0.9484, 0.94, 0.9163, 0.9095, 0.8726, 0.9513, 0.9641, 0.9698, 0.9222, 0.9743, 0.9379, 0.8975, 0.9568, 0.9576, 0.9364, 0.9349, 0.9003, 0.9357, 0.98, 0.8272, 0.9505, 0.9014, 0.9497, 0.9363, 0.9839, 0.8583, 0.9068, 0.9211, 0.9351, 0.9285, 0.9448, 0.898, 0.9699, 0.9407, 0.9704, 0.8922, 0.9493, 0.9508, 0.8717, 0.9698, 0.9529, 0.9413, 0.7659, 0.9354, 0.8445, 0.952, 0.9214, 0.9696, 0.951, 0.933, 0.9467, 0.9696, 0.9358, 0.8667, 0.9505, 0.9478, 0.9218, 0.8873, 0.6746, 0.9553, 0.9744, 0.9482, 0.9437, 0.9658, 0.9047, 0.9659, 0.9357, 0.9256, 0.9344, 0.9175, 0.9467, 0.9421, 0.9532, 0.9696, 0.9476, 0.9283, 0.9839, 0.9448, 0.9042, 0.8749, 0.9294, 0.9697, 0.9513, 0.8807, 0.8852, 0.9249, 0.9416, 0.8987, 0.9338, 0.9342, 0.8589, 0.9367, 0.9621, 0.8907, 0.9459, 0.9717, 0.9407, 0.9518, 0.9455, 0.9421, 0.9458, 0.8583], 'AP': [0.9803, 0.9558, 0.97, 0.9921, 0.9769, 0.997, 0.9721, 0.9271, 0.9867, 0.974, 0.9553, 0.9778, 0.8863, 0.9869, 0.9588, 0.9828, 0.9925, 0.9958, 0.9756, 0.9847, 0.9827, 0.938, 0.9685, 0.9902, 0.9781, 0.9761, 0.9842, 0.9873, 0.9848, 0.9741, 0.9151, 0.9387, 0.9651, 0.9767, 0.9688, 0.9542, 0.982, 0.9864, 0.9729, 0.9527, 1.0, 0.9342, 0.9824, 0.9876, 0.9763, 0.9887, 0.9239, 0.9807, 0.9219, 0.9743, 0.9439, 0.9703, 0.9943, 0.9763, 0.9885, 0.9875, 0.9965, 0.9663, 0.9675, 0.9253, 0.934, 0.9733, 0.9772, 0.9842, 0.9731, 0.9405, 0.9949, 0.9864, 0.9828, 0.906, 0.9533, 0.9542, 0.9832, 0.9775, 0.9596, 0.9529, 0.9191, 0.9837, 0.9919, 0.9945, 0.9765, 0.9955, 0.9829, 0.94, 0.9912, 0.9907, 0.984, 0.9725, 0.9604, 0.9813, 0.9969, 0.8893, 0.979, 0.9603, 0.9739, 0.9819, 0.9964, 0.9171, 0.9628, 0.9756, 0.9783, 0.9666, 0.971, 0.9619, 0.9881, 0.9799, 0.9926, 0.9357, 0.9833, 0.9791, 0.9267, 0.9938, 0.9889, 0.9777, 0.8229, 0.9762, 0.8976, 0.9865, 0.9767, 0.988, 0.9868, 0.9761, 0.9829, 0.9889, 0.9832, 0.9258, 0.9849, 0.9836, 0.9664, 0.939, 0.6924, 0.9772, 0.9937, 0.9833, 0.9829, 0.988, 0.9521, 0.988, 0.9774, 0.9674, 0.9696, 0.9603, 0.9882, 0.9803, 0.9851, 0.9944, 0.9889, 0.9721, 0.9925, 0.9769, 0.9571, 0.9328, 0.9675, 0.9882, 0.9882, 0.9321, 0.9298, 0.9743, 0.9764, 0.9531, 0.9755, 0.9703, 0.9148, 0.9813, 0.983, 0.9328, 0.9827, 0.9896, 0.9748, 0.9847, 0.976, 0.9764, 0.9874, 0.912], 'Recall@P=50': [0.9933, 0.976, 0.9857, 0.992, 0.984, 1.0, 0.9864, 0.956, 0.9976, 0.9948, 0.976, 0.9936, 0.908, 0.996, 0.972, 0.992, 0.9976, 1.0, 0.976, 0.996, 0.988, 0.966, 0.984, 0.9984, 0.9853, 0.988, 0.996, 0.996, 0.9989, 0.9904, 0.948, 0.972, 0.984, 0.976, 0.987, 0.968, 0.992, 0.999, 0.987, 0.972, 1.0, 0.976, 0.992, 0.992, 0.988, 0.992, 0.9667, 0.988, 0.9573, 0.984, 0.964, 0.9874, 0.996, 0.9891, 0.996, 0.9947, 1.0, 0.984, 0.984, 0.968, 0.98, 0.988, 0.984, 0.996, 0.9887, 0.96, 1.0, 0.996, 0.99, 0.952, 0.984, 0.972, 0.988, 0.9904, 0.972, 0.984, 0.956, 0.996, 0.9987, 1.0, 0.9932, 1.0, 0.9988, 0.96, 1.0, 0.996, 0.9985, 0.984, 0.9878, 0.996, 0.998, 0.932, 0.992, 0.9832, 0.976, 0.9975, 0.996, 0.968, 0.9813, 0.992, 0.992, 0.98, 0.98, 0.992, 0.992, 0.9923, 0.998, 0.956, 0.992, 0.988, 0.956, 1.0, 0.999, 0.988, 0.944, 0.99, 0.952, 0.996, 0.992, 0.992, 0.996, 0.9907, 0.992, 0.992, 0.998, 0.972, 0.992, 0.9933, 0.984, 0.972, 0.848, 0.988, 0.996, 0.992, 0.994, 0.992, 0.9773, 0.992, 0.9923, 0.992, 0.984, 0.968, 1.0, 0.99, 0.9928, 1.0, 0.9997, 0.988, 0.992, 0.984, 0.986, 0.97, 0.9813, 0.992, 0.994, 0.96, 0.964, 0.994, 0.988, 0.976, 0.992, 0.988, 0.936, 0.9962, 0.988, 0.964, 0.9893, 0.992, 0.996, 0.996, 0.984, 0.984, 0.9995, 0.94], 'micro': 0.9781, 'macro': 0.9676, 'weighted': 0.9769}
2024-07-27 10:39:46 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:39:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9640.pt
2024-07-27 10:39:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9647.pt', 'checkpoint_score_0.9656.pt', 'checkpoint_score_0.9660.pt', 'checkpoint_score_0.9672.pt', 'checkpoint_score_0.9676.pt']
2024-07-27 10:39:49 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:39:50 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:39:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:39:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 19536 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_32_iter_19536.pt
2024-07-27 10:39:51 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 19536 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_32_iter_19536.pt
[31m===========================================================================[0m
2024-07-27 10:39:53 - [32m[1mINFO   [0m - Training epoch 33
2024-07-27 10:39:54 - [34m[1mLOGS   [0m - Epoch:  33 [   19537/10000000], loss: {'classification': 3.8357, 'neural_augmentation': 8.8599, 'total_loss': 12.6956}, LR: [5e-06, 5e-06], Avg. batch load time: 0.309, Elapsed time:  0.41
2024-07-27 10:40:31 - [34m[1mLOGS   [0m - Epoch:  33 [   20037/10000000], loss: {'classification': 5.5316, 'neural_augmentation': 10.1331, 'total_loss': 15.6647}, LR: [5e-06, 5e-06], Avg. batch load time: 0.001, Elapsed time: 38.09
2024-07-27 10:40:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'classification': 5.5415, 'neural_augmentation': 10.1198, 'total_loss': 15.6613}
2024-07-27 10:40:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'classification': 2.4867, 'neural_augmentation': 0.0, 'total_loss': 2.4867} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9479, 0.9193, 0.9317, 0.9778, 0.9323, 0.9839, 0.9285, 0.8678, 0.9505, 0.9208, 0.9213, 0.9317, 0.8214, 0.958, 0.9206, 0.9512, 0.9746, 0.986, 0.9485, 0.9487, 0.9551, 0.8737, 0.9347, 0.9596, 0.9413, 0.9278, 0.9493, 0.9662, 0.9411, 0.9274, 0.8686, 0.884, 0.9287, 0.9549, 0.9148, 0.9106, 0.9435, 0.9456, 0.9273, 0.8996, 0.998, 0.8739, 0.9429, 0.9615, 0.9358, 0.9677, 0.8458, 0.9631, 0.8504, 0.9344, 0.8879, 0.919, 0.981, 0.9397, 0.9573, 0.9534, 0.9839, 0.9388, 0.9287, 0.8676, 0.8773, 0.945, 0.9463, 0.9469, 0.925, 0.8858, 0.9742, 0.9409, 0.9586, 0.8498, 0.9268, 0.9152, 0.9535, 0.9342, 0.9212, 0.9062, 0.8724, 0.9486, 0.9662, 0.9761, 0.9252, 0.9742, 0.9366, 0.8903, 0.9624, 0.9582, 0.938, 0.9366, 0.9025, 0.9429, 0.9769, 0.8243, 0.9441, 0.9083, 0.9493, 0.9393, 0.988, 0.8867, 0.9075, 0.9281, 0.9359, 0.9302, 0.9508, 0.896, 0.9636, 0.9396, 0.9717, 0.8889, 0.9552, 0.9491, 0.8753, 0.9743, 0.9522, 0.9444, 0.7674, 0.9314, 0.8538, 0.9579, 0.9314, 0.9611, 0.9553, 0.9308, 0.9512, 0.9715, 0.934, 0.8613, 0.9637, 0.9444, 0.9268, 0.881, 0.6901, 0.9532, 0.9723, 0.9444, 0.9452, 0.9634, 0.9027, 0.9595, 0.9344, 0.9355, 0.9347, 0.924, 0.9467, 0.9382, 0.9512, 0.972, 0.9501, 0.9299, 0.976, 0.9337, 0.8979, 0.8866, 0.9314, 0.9597, 0.9581, 0.8893, 0.8857, 0.9347, 0.9393, 0.8986, 0.9319, 0.9322, 0.8692, 0.9386, 0.9576, 0.8894, 0.9487, 0.9737, 0.9268, 0.9431, 0.9325, 0.9452, 0.9469, 0.8667], 'AP': [0.9824, 0.9551, 0.9749, 0.9932, 0.9722, 0.9984, 0.9707, 0.9246, 0.9868, 0.9741, 0.9637, 0.9769, 0.886, 0.9869, 0.9607, 0.9795, 0.9906, 0.9967, 0.9784, 0.9802, 0.9804, 0.9383, 0.9729, 0.988, 0.9727, 0.9764, 0.9799, 0.9884, 0.9845, 0.9716, 0.9209, 0.9413, 0.9719, 0.9835, 0.9684, 0.9531, 0.9779, 0.9865, 0.9707, 0.9489, 0.9999, 0.9285, 0.9849, 0.9807, 0.9743, 0.986, 0.926, 0.98, 0.9154, 0.9716, 0.9389, 0.9695, 0.9952, 0.9813, 0.9868, 0.9864, 0.9964, 0.968, 0.9584, 0.9232, 0.9304, 0.9708, 0.9756, 0.9799, 0.9723, 0.9406, 0.9948, 0.9783, 0.9822, 0.9105, 0.9435, 0.9578, 0.9808, 0.974, 0.957, 0.9512, 0.9175, 0.9829, 0.9938, 0.9961, 0.9757, 0.9949, 0.9813, 0.9362, 0.9909, 0.9885, 0.9841, 0.9748, 0.9599, 0.9844, 0.9942, 0.8945, 0.9757, 0.9638, 0.9763, 0.9832, 0.9965, 0.9331, 0.9616, 0.9696, 0.9771, 0.9682, 0.972, 0.9592, 0.9816, 0.9776, 0.993, 0.9319, 0.9826, 0.9835, 0.928, 0.9965, 0.9894, 0.9776, 0.8221, 0.9708, 0.9035, 0.9877, 0.9716, 0.9787, 0.9873, 0.9776, 0.9795, 0.9877, 0.982, 0.9205, 0.9862, 0.9842, 0.9704, 0.9398, 0.7085, 0.9844, 0.9937, 0.9798, 0.9829, 0.9792, 0.9517, 0.9813, 0.9763, 0.9718, 0.9725, 0.9629, 0.9865, 0.9768, 0.9848, 0.9968, 0.9888, 0.9733, 0.9933, 0.9678, 0.955, 0.94, 0.9673, 0.9791, 0.9909, 0.9314, 0.9318, 0.9768, 0.9745, 0.9483, 0.9774, 0.9635, 0.9215, 0.9807, 0.9834, 0.9329, 0.9837, 0.9912, 0.9705, 0.9859, 0.9722, 0.9743, 0.9873, 0.9214], 'Recall@P=50': [0.9893, 0.968, 0.9909, 0.996, 0.98, 1.0, 0.988, 0.956, 0.9968, 0.9942, 0.984, 0.9928, 0.904, 0.992, 0.976, 0.996, 0.9976, 1.0, 0.992, 0.984, 0.988, 0.962, 0.984, 0.9952, 0.976, 0.9912, 0.984, 0.996, 0.9979, 0.9872, 0.948, 0.976, 0.988, 0.992, 0.9875, 0.968, 0.988, 0.9988, 0.991, 0.972, 1.0, 0.98, 0.992, 0.984, 0.988, 0.992, 0.9693, 0.984, 0.9547, 0.98, 0.956, 0.9874, 0.996, 0.9949, 0.998, 0.9947, 1.0, 0.984, 0.976, 0.972, 0.976, 0.992, 0.984, 0.988, 0.992, 0.962, 0.996, 0.9907, 0.99, 0.952, 0.976, 0.982, 0.992, 0.9888, 0.968, 0.982, 0.964, 0.9947, 0.9987, 1.0, 0.9911, 0.996, 0.9972, 0.956, 0.998, 0.994, 0.9991, 0.984, 0.987, 0.992, 0.998, 0.948, 0.988, 0.9832, 0.976, 0.9967, 0.996, 0.976, 0.9807, 0.988, 0.9897, 0.976, 0.976, 0.9893, 0.992, 0.9927, 0.998, 0.952, 0.9904, 0.992, 0.968, 1.0, 0.9994, 0.99, 0.932, 0.9853, 0.952, 0.9953, 0.992, 0.98, 0.996, 0.992, 0.992, 0.992, 0.9973, 0.976, 0.988, 0.992, 0.992, 0.98, 0.868, 0.992, 0.996, 0.988, 0.9953, 0.98, 0.9773, 0.984, 0.992, 0.988, 0.984, 0.972, 1.0, 0.989, 0.992, 1.0, 0.9997, 0.9893, 0.996, 0.974, 0.984, 0.976, 0.976, 0.98, 0.996, 0.952, 0.96, 0.992, 0.988, 0.98, 0.994, 0.984, 0.944, 0.9942, 0.988, 0.952, 0.9893, 0.992, 0.996, 1.0, 0.98, 0.984, 0.9996, 0.952], 'micro': 0.9777, 'macro': 0.9672, 'weighted': 0.9766}
2024-07-27 10:41:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:41:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:41:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 20128 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_33_iter_20128.pt
2024-07-27 10:41:04 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 20128 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_33_iter_20128.pt
[31m===========================================================================[0m
2024-07-27 10:41:06 - [32m[1mINFO   [0m - Training epoch 34
2024-07-27 10:41:07 - [34m[1mLOGS   [0m - Epoch:  34 [   20129/10000000], loss: {'classification': 5.3211, 'neural_augmentation': 8.7587, 'total_loss': 14.0798}, LR: [5e-06, 5e-06], Avg. batch load time: 0.743, Elapsed time:  0.83
2024-07-27 10:41:44 - [34m[1mLOGS   [0m - Epoch:  34 [   20629/10000000], loss: {'classification': 5.4267, 'neural_augmentation': 10.061, 'total_loss': 15.4878}, LR: [5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 38.30
2024-07-27 10:41:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'classification': 5.4443, 'neural_augmentation': 10.0707, 'total_loss': 15.515}
2024-07-27 10:42:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'classification': 2.5034, 'neural_augmentation': 0.0, 'total_loss': 2.5034} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9464, 0.9189, 0.9281, 0.9859, 0.9455, 0.99, 0.9228, 0.8866, 0.9496, 0.9143, 0.9243, 0.9303, 0.8121, 0.9556, 0.9206, 0.9571, 0.9727, 0.9839, 0.945, 0.945, 0.9631, 0.8784, 0.928, 0.9567, 0.9447, 0.9346, 0.9446, 0.9637, 0.9402, 0.9279, 0.8776, 0.8813, 0.9306, 0.9532, 0.9157, 0.9162, 0.9539, 0.9434, 0.9239, 0.899, 0.998, 0.8618, 0.9548, 0.9683, 0.9264, 0.9657, 0.8462, 0.9569, 0.8476, 0.9228, 0.9014, 0.9143, 0.9849, 0.9401, 0.9491, 0.9522, 0.9859, 0.9298, 0.9271, 0.8732, 0.8619, 0.9315, 0.9439, 0.9428, 0.9205, 0.8988, 0.9821, 0.9464, 0.9515, 0.8463, 0.917, 0.9145, 0.948, 0.938, 0.9148, 0.9051, 0.8867, 0.9434, 0.9619, 0.9723, 0.9258, 0.9841, 0.9352, 0.8944, 0.9652, 0.9641, 0.94, 0.9292, 0.9024, 0.9476, 0.9799, 0.806, 0.9417, 0.9125, 0.9433, 0.9371, 0.9841, 0.8876, 0.9126, 0.9137, 0.9392, 0.9287, 0.9381, 0.8971, 0.9683, 0.9371, 0.9717, 0.8948, 0.9554, 0.9535, 0.8863, 0.972, 0.9508, 0.9398, 0.7713, 0.9332, 0.8476, 0.9535, 0.9172, 0.9697, 0.9525, 0.9333, 0.9556, 0.9673, 0.9335, 0.8675, 0.9565, 0.947, 0.9347, 0.8944, 0.6831, 0.9549, 0.9822, 0.9565, 0.9441, 0.9699, 0.8956, 0.9676, 0.9315, 0.9194, 0.9284, 0.9087, 0.947, 0.9372, 0.9503, 0.9701, 0.9482, 0.9295, 0.9859, 0.9408, 0.9034, 0.8956, 0.9207, 0.9697, 0.968, 0.8834, 0.884, 0.9298, 0.9253, 0.8966, 0.933, 0.9317, 0.8815, 0.9378, 0.9556, 0.888, 0.9492, 0.9667, 0.9202, 0.9474, 0.9443, 0.9393, 0.9445, 0.8768], 'AP': [0.9814, 0.9547, 0.9744, 0.9908, 0.9734, 0.997, 0.97, 0.9307, 0.987, 0.9718, 0.965, 0.9772, 0.8846, 0.9874, 0.9623, 0.983, 0.9914, 0.9962, 0.9719, 0.9815, 0.9808, 0.9369, 0.9749, 0.9878, 0.9775, 0.9769, 0.9818, 0.987, 0.9843, 0.9702, 0.923, 0.9337, 0.9735, 0.9811, 0.9693, 0.9548, 0.9685, 0.9863, 0.9679, 0.9445, 1.0, 0.9207, 0.9875, 0.9884, 0.9705, 0.9877, 0.9236, 0.9798, 0.9165, 0.9659, 0.9521, 0.9683, 0.9923, 0.9808, 0.9819, 0.9863, 0.9966, 0.9713, 0.966, 0.9308, 0.9208, 0.9702, 0.9755, 0.9822, 0.9691, 0.9413, 0.9956, 0.9836, 0.9786, 0.9011, 0.9464, 0.9536, 0.9842, 0.9737, 0.9574, 0.9497, 0.9285, 0.981, 0.9925, 0.9932, 0.977, 0.9958, 0.9818, 0.95, 0.9915, 0.9913, 0.9844, 0.9751, 0.9623, 0.9868, 0.9938, 0.884, 0.9766, 0.9651, 0.9713, 0.9822, 0.9964, 0.9358, 0.9654, 0.9686, 0.9798, 0.9659, 0.9687, 0.9576, 0.9881, 0.977, 0.9943, 0.9343, 0.9858, 0.9816, 0.931, 0.9929, 0.989, 0.9771, 0.8267, 0.9743, 0.9024, 0.9878, 0.9706, 0.9875, 0.9877, 0.9758, 0.9828, 0.9882, 0.9818, 0.9298, 0.9864, 0.9841, 0.9742, 0.941, 0.7085, 0.9802, 0.9949, 0.9825, 0.9803, 0.9875, 0.9503, 0.9872, 0.9759, 0.9675, 0.9741, 0.9546, 0.9871, 0.9799, 0.9858, 0.9933, 0.989, 0.9748, 0.9903, 0.9734, 0.9546, 0.9386, 0.9632, 0.9876, 0.9919, 0.9314, 0.9294, 0.9764, 0.9703, 0.9452, 0.976, 0.9673, 0.9216, 0.9796, 0.9808, 0.9319, 0.9822, 0.9889, 0.9647, 0.9847, 0.9728, 0.9737, 0.9871, 0.9226], 'Recall@P=50': [0.9893, 0.976, 0.9891, 0.992, 0.976, 1.0, 0.9872, 0.96, 0.996, 0.9935, 0.986, 0.994, 0.912, 0.994, 0.978, 0.992, 0.9976, 1.0, 0.972, 0.992, 0.984, 0.966, 0.984, 0.9968, 0.9853, 0.9896, 0.992, 0.996, 0.9984, 0.984, 0.944, 0.956, 0.988, 0.992, 0.9895, 0.976, 0.988, 0.9993, 0.988, 0.968, 1.0, 0.968, 0.996, 0.988, 0.984, 0.992, 0.9707, 0.984, 0.956, 0.984, 0.964, 0.9863, 0.992, 0.9931, 0.992, 0.9947, 1.0, 0.984, 0.988, 0.964, 0.964, 0.996, 0.988, 0.992, 0.99, 0.962, 1.0, 0.9907, 0.984, 0.944, 0.972, 0.968, 0.992, 0.988, 0.98, 0.978, 0.96, 0.9973, 0.9987, 0.996, 0.9958, 0.996, 0.9978, 0.964, 0.998, 0.994, 0.9978, 0.984, 0.9861, 0.996, 0.996, 0.956, 0.988, 0.9848, 0.972, 0.9967, 0.996, 0.984, 0.9867, 0.984, 0.996, 0.978, 0.984, 0.9867, 0.992, 0.9917, 1.0, 0.952, 0.9944, 0.992, 0.956, 0.996, 0.9996, 0.99, 0.932, 0.9887, 0.96, 0.9953, 0.984, 0.988, 0.996, 0.9907, 0.996, 0.992, 0.998, 0.964, 0.992, 0.992, 0.992, 0.97, 0.876, 0.992, 0.996, 0.996, 0.9907, 0.988, 0.9787, 0.988, 0.9927, 0.992, 0.984, 0.964, 1.0, 0.99, 0.9944, 0.996, 0.9997, 0.988, 0.992, 0.982, 0.982, 0.96, 0.9827, 0.988, 0.996, 0.956, 0.952, 0.995, 0.984, 0.972, 0.991, 0.988, 0.944, 0.9952, 0.984, 0.952, 0.9907, 0.99, 0.98, 0.996, 0.98, 0.976, 0.9996, 0.948], 'micro': 0.9778, 'macro': 0.9673, 'weighted': 0.9766}
2024-07-27 10:42:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:42:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:42:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 20720 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_34_iter_20720.pt
2024-07-27 10:42:16 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 20720 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_34_iter_20720.pt
[31m===========================================================================[0m
2024-07-27 10:42:18 - [32m[1mINFO   [0m - Training epoch 35
2024-07-27 10:42:19 - [34m[1mLOGS   [0m - Epoch:  35 [   20721/10000000], loss: {'classification': 5.3347, 'neural_augmentation': 9.9073, 'total_loss': 15.242}, LR: [4e-06, 4e-06], Avg. batch load time: 0.323, Elapsed time:  0.42
2024-07-27 10:42:56 - [34m[1mLOGS   [0m - Epoch:  35 [   21221/10000000], loss: {'classification': 5.3347, 'neural_augmentation': 10.0633, 'total_loss': 15.398}, LR: [4e-06, 4e-06], Avg. batch load time: 0.002, Elapsed time: 38.20
2024-07-27 10:43:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'classification': 5.3341, 'neural_augmentation': 10.0897, 'total_loss': 15.4238}
2024-07-27 10:43:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'classification': 2.4045, 'neural_augmentation': 0.0, 'total_loss': 2.4045} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9489, 0.9148, 0.9295, 0.9798, 0.9452, 0.986, 0.9333, 0.8948, 0.9517, 0.9195, 0.9121, 0.9351, 0.8167, 0.9613, 0.9263, 0.9588, 0.9748, 0.9758, 0.9478, 0.9506, 0.9595, 0.877, 0.9339, 0.9606, 0.9465, 0.9365, 0.9506, 0.9637, 0.9439, 0.93, 0.8753, 0.8921, 0.9293, 0.9441, 0.9148, 0.9044, 0.9518, 0.9468, 0.9263, 0.9069, 0.998, 0.8719, 0.9533, 0.9657, 0.9419, 0.9676, 0.8434, 0.9633, 0.8611, 0.936, 0.888, 0.9136, 0.984, 0.9411, 0.9585, 0.9559, 0.9828, 0.9318, 0.9281, 0.8717, 0.8682, 0.9405, 0.9489, 0.9555, 0.9303, 0.8927, 0.9821, 0.9498, 0.959, 0.8521, 0.9202, 0.913, 0.9537, 0.9415, 0.9132, 0.914, 0.8916, 0.9519, 0.965, 0.9717, 0.9263, 0.978, 0.939, 0.8926, 0.9661, 0.9659, 0.9392, 0.9376, 0.8938, 0.9497, 0.9808, 0.8276, 0.9439, 0.9101, 0.945, 0.9402, 0.988, 0.8738, 0.9132, 0.9231, 0.9416, 0.9242, 0.9514, 0.894, 0.9665, 0.9411, 0.9695, 0.8925, 0.9561, 0.953, 0.8876, 0.9699, 0.9528, 0.949, 0.7635, 0.9352, 0.8419, 0.9557, 0.9303, 0.9676, 0.9602, 0.9303, 0.956, 0.9697, 0.9352, 0.8715, 0.9619, 0.9531, 0.9301, 0.8927, 0.6784, 0.9469, 0.978, 0.956, 0.9433, 0.9675, 0.9005, 0.9663, 0.9349, 0.9165, 0.9339, 0.8992, 0.9541, 0.9443, 0.9536, 0.9679, 0.9496, 0.9243, 0.9778, 0.9461, 0.911, 0.8985, 0.9257, 0.9703, 0.9651, 0.8839, 0.8898, 0.9296, 0.9405, 0.9014, 0.9348, 0.9281, 0.8778, 0.9394, 0.9556, 0.887, 0.9502, 0.9706, 0.9315, 0.9533, 0.9419, 0.9429, 0.9467, 0.8758], 'AP': [0.9831, 0.9516, 0.9761, 0.988, 0.9737, 0.9981, 0.9724, 0.9263, 0.9885, 0.974, 0.9651, 0.9792, 0.8793, 0.9888, 0.9654, 0.9844, 0.991, 0.9947, 0.9783, 0.9855, 0.984, 0.9421, 0.9753, 0.9891, 0.9786, 0.9796, 0.9854, 0.9877, 0.9855, 0.9728, 0.9315, 0.9458, 0.9755, 0.9806, 0.9698, 0.9553, 0.9749, 0.9881, 0.9698, 0.95, 0.9999, 0.9318, 0.9865, 0.9896, 0.975, 0.9878, 0.9213, 0.979, 0.9206, 0.9733, 0.9478, 0.9685, 0.9923, 0.9816, 0.9864, 0.9867, 0.9952, 0.9709, 0.9672, 0.9299, 0.9334, 0.9753, 0.9763, 0.9863, 0.975, 0.9444, 0.9957, 0.9863, 0.9841, 0.9117, 0.9528, 0.9583, 0.9843, 0.9768, 0.955, 0.9553, 0.9165, 0.9858, 0.9924, 0.9945, 0.9774, 0.9953, 0.9832, 0.946, 0.9912, 0.9911, 0.9844, 0.976, 0.961, 0.9865, 0.9958, 0.896, 0.9772, 0.9668, 0.9774, 0.9832, 0.9962, 0.9332, 0.9665, 0.9721, 0.9792, 0.9652, 0.975, 0.9585, 0.9896, 0.9803, 0.9939, 0.9413, 0.9852, 0.9816, 0.9234, 0.9935, 0.9891, 0.9793, 0.8331, 0.9762, 0.8994, 0.9866, 0.9748, 0.9884, 0.988, 0.9776, 0.9818, 0.9888, 0.9828, 0.9279, 0.9877, 0.9842, 0.9745, 0.9438, 0.6987, 0.9809, 0.9945, 0.983, 0.982, 0.9876, 0.9524, 0.9884, 0.9781, 0.965, 0.9735, 0.9582, 0.9895, 0.9829, 0.9856, 0.994, 0.9896, 0.9739, 0.9884, 0.9766, 0.9619, 0.944, 0.9701, 0.9886, 0.9921, 0.9331, 0.9328, 0.9753, 0.9754, 0.9484, 0.9771, 0.9682, 0.9306, 0.9823, 0.9827, 0.934, 0.9832, 0.9903, 0.9724, 0.9882, 0.9738, 0.9772, 0.9876, 0.9311], 'Recall@P=50': [0.992, 0.972, 0.9903, 0.988, 0.984, 1.0, 0.9872, 0.952, 0.9984, 0.9957, 0.99, 0.9932, 0.908, 0.996, 0.976, 0.992, 0.9984, 0.996, 0.984, 1.0, 0.992, 0.974, 0.988, 0.996, 0.984, 0.9912, 1.0, 0.996, 0.9979, 0.9864, 0.952, 0.972, 0.988, 0.988, 0.9875, 0.972, 0.984, 0.999, 0.985, 0.98, 1.0, 0.972, 0.988, 0.996, 0.988, 0.992, 0.9747, 0.98, 0.948, 0.98, 0.964, 0.9868, 0.99, 0.9931, 0.994, 0.9933, 0.998, 0.988, 0.984, 0.96, 0.976, 0.992, 0.984, 0.996, 0.99, 0.966, 0.996, 0.9947, 0.99, 0.944, 0.972, 0.98, 0.988, 0.9904, 0.972, 0.982, 0.956, 0.9947, 0.9987, 1.0, 0.9947, 0.996, 0.9984, 0.952, 0.996, 0.996, 0.9975, 0.988, 0.9913, 0.988, 0.998, 0.936, 0.984, 0.9832, 0.984, 0.996, 0.996, 0.976, 0.9853, 0.988, 0.9909, 0.98, 0.988, 0.988, 0.992, 0.992, 1.0, 0.956, 0.9928, 0.992, 0.956, 1.0, 0.999, 0.988, 0.936, 0.9893, 0.94, 0.9947, 0.992, 0.988, 0.994, 0.9933, 0.996, 0.992, 0.9977, 0.968, 0.992, 0.992, 0.992, 0.976, 0.004, 0.988, 0.996, 0.988, 0.992, 0.988, 0.9747, 0.988, 0.9937, 0.988, 0.984, 0.976, 0.996, 0.991, 0.9928, 1.0, 0.9997, 0.9893, 0.988, 0.986, 0.982, 0.974, 0.9827, 0.988, 0.996, 0.956, 0.96, 0.992, 0.984, 0.98, 0.994, 0.984, 0.948, 0.996, 0.988, 0.96, 0.992, 0.994, 0.988, 1.0, 0.984, 0.984, 0.9995, 0.952], 'micro': 0.9792, 'macro': 0.969, 'weighted': 0.978}
2024-07-27 10:43:27 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:43:27 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9647.pt
2024-07-27 10:43:27 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9656.pt', 'checkpoint_score_0.9660.pt', 'checkpoint_score_0.9672.pt', 'checkpoint_score_0.9676.pt', 'checkpoint_score_0.9690.pt']
2024-07-27 10:43:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:43:30 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:43:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:43:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 21312 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_35_iter_21312.pt
2024-07-27 10:43:31 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 21312 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_35_iter_21312.pt
[31m===========================================================================[0m
2024-07-27 10:43:33 - [32m[1mINFO   [0m - Training epoch 36
2024-07-27 10:43:34 - [34m[1mLOGS   [0m - Epoch:  36 [   21313/10000000], loss: {'classification': 6.3406, 'neural_augmentation': 9.7965, 'total_loss': 16.1371}, LR: [4e-06, 4e-06], Avg. batch load time: 0.388, Elapsed time:  0.48
2024-07-27 10:44:11 - [34m[1mLOGS   [0m - Epoch:  36 [   21813/10000000], loss: {'classification': 5.294, 'neural_augmentation': 10.1087, 'total_loss': 15.4027}, LR: [4e-06, 4e-06], Avg. batch load time: 0.001, Elapsed time: 38.04
2024-07-27 10:44:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'classification': 5.3017, 'neural_augmentation': 10.1034, 'total_loss': 15.4052}
2024-07-27 10:44:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'classification': 2.4115, 'neural_augmentation': 0.0, 'total_loss': 2.4115} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9497, 0.908, 0.9327, 0.9818, 0.94, 0.9859, 0.9268, 0.8943, 0.9537, 0.922, 0.9118, 0.9366, 0.8212, 0.96, 0.9276, 0.9533, 0.9759, 0.9818, 0.9485, 0.9435, 0.9652, 0.8829, 0.9405, 0.9571, 0.9543, 0.9398, 0.9491, 0.9634, 0.9451, 0.9339, 0.8816, 0.8893, 0.9381, 0.9499, 0.9157, 0.9182, 0.9597, 0.9469, 0.9298, 0.8872, 0.998, 0.8675, 0.9563, 0.9756, 0.9286, 0.9675, 0.8395, 0.9654, 0.8575, 0.9257, 0.8951, 0.9205, 0.984, 0.9446, 0.9593, 0.9527, 0.9828, 0.9371, 0.945, 0.8704, 0.8607, 0.9431, 0.9448, 0.9457, 0.9295, 0.8932, 0.9741, 0.9616, 0.957, 0.8672, 0.9246, 0.9149, 0.9547, 0.9408, 0.9133, 0.9115, 0.898, 0.9462, 0.966, 0.9697, 0.9318, 0.9705, 0.9372, 0.8977, 0.9625, 0.9652, 0.9392, 0.9424, 0.9009, 0.9512, 0.9808, 0.8251, 0.9508, 0.9145, 0.9465, 0.9401, 0.9839, 0.8802, 0.9161, 0.932, 0.9428, 0.9315, 0.9376, 0.8998, 0.9757, 0.9413, 0.9707, 0.888, 0.9597, 0.9452, 0.8907, 0.9719, 0.9558, 0.9439, 0.7681, 0.9387, 0.8628, 0.9562, 0.9283, 0.9758, 0.9609, 0.9291, 0.9555, 0.9662, 0.9366, 0.8742, 0.9618, 0.9486, 0.9414, 0.8982, 0.6836, 0.9448, 0.9745, 0.9509, 0.9468, 0.9736, 0.9067, 0.9737, 0.9364, 0.9262, 0.9383, 0.9206, 0.9567, 0.9489, 0.9561, 0.9695, 0.9511, 0.9282, 0.9817, 0.9512, 0.906, 0.8956, 0.9243, 0.9736, 0.9592, 0.8879, 0.8968, 0.9301, 0.9274, 0.8859, 0.9319, 0.9435, 0.8861, 0.9408, 0.9639, 0.898, 0.9477, 0.9696, 0.9446, 0.9489, 0.9402, 0.9478, 0.9468, 0.8833], 'AP': [0.9823, 0.955, 0.9748, 0.9904, 0.975, 0.9975, 0.9683, 0.9332, 0.9876, 0.9745, 0.9587, 0.9798, 0.8803, 0.9888, 0.9649, 0.9805, 0.9927, 0.9953, 0.9764, 0.9838, 0.9824, 0.9457, 0.9696, 0.9882, 0.9794, 0.9797, 0.9848, 0.9857, 0.9856, 0.9731, 0.9274, 0.9426, 0.9758, 0.98, 0.9693, 0.9465, 0.9774, 0.9878, 0.9718, 0.9459, 0.9999, 0.9262, 0.9888, 0.9906, 0.9694, 0.9884, 0.9246, 0.9816, 0.918, 0.9672, 0.9431, 0.9715, 0.9939, 0.9804, 0.9864, 0.9875, 0.9964, 0.9641, 0.9664, 0.9325, 0.9265, 0.9723, 0.9761, 0.9849, 0.9741, 0.9452, 0.9935, 0.9871, 0.9843, 0.9108, 0.9481, 0.9595, 0.9821, 0.9773, 0.9577, 0.955, 0.9273, 0.983, 0.9922, 0.9947, 0.9788, 0.9949, 0.9831, 0.9392, 0.9908, 0.9926, 0.9854, 0.9732, 0.9628, 0.988, 0.9954, 0.8938, 0.9773, 0.9686, 0.9757, 0.9826, 0.9951, 0.9321, 0.9691, 0.9762, 0.9816, 0.9694, 0.9716, 0.9606, 0.9906, 0.9807, 0.9932, 0.9441, 0.9859, 0.9802, 0.9341, 0.9935, 0.9898, 0.979, 0.8302, 0.9769, 0.9108, 0.9885, 0.9757, 0.9897, 0.9887, 0.9757, 0.9801, 0.9888, 0.9819, 0.9342, 0.9869, 0.9846, 0.975, 0.9456, 0.7142, 0.9802, 0.9937, 0.9849, 0.9832, 0.989, 0.9541, 0.9899, 0.9779, 0.9697, 0.9692, 0.9611, 0.9897, 0.984, 0.9858, 0.9952, 0.9897, 0.9742, 0.9904, 0.9776, 0.9598, 0.9421, 0.9665, 0.9892, 0.992, 0.9392, 0.9388, 0.9783, 0.9701, 0.9469, 0.977, 0.9693, 0.9284, 0.9825, 0.9854, 0.9391, 0.9825, 0.9903, 0.9737, 0.9849, 0.975, 0.9792, 0.988, 0.9276], 'Recall@P=50': [0.9893, 0.972, 0.9897, 0.988, 0.98, 1.0, 0.9848, 0.964, 0.9976, 0.9938, 0.984, 0.9924, 0.916, 0.996, 0.984, 0.984, 0.9944, 0.996, 0.984, 0.996, 0.992, 0.968, 0.988, 0.9952, 0.9853, 0.9904, 0.996, 0.996, 0.9988, 0.9864, 0.948, 0.964, 0.988, 0.988, 0.9885, 0.976, 0.988, 0.9992, 0.985, 0.98, 1.0, 0.968, 0.992, 0.996, 0.984, 0.992, 0.972, 0.988, 0.9533, 0.984, 0.96, 0.9863, 0.996, 0.992, 0.994, 0.9973, 0.998, 0.984, 0.988, 0.96, 0.972, 0.988, 0.98, 0.996, 0.9913, 0.966, 0.996, 0.9947, 0.99, 0.94, 0.968, 0.976, 0.984, 0.9904, 0.976, 0.98, 0.972, 0.9907, 0.9973, 1.0, 0.9926, 0.996, 0.9992, 0.952, 1.0, 0.998, 0.9993, 0.988, 0.987, 0.996, 0.998, 0.936, 0.984, 0.9864, 0.984, 0.9971, 0.996, 0.976, 0.9887, 0.988, 0.9937, 0.982, 0.98, 0.988, 0.992, 0.9917, 1.0, 0.96, 0.9928, 0.984, 0.972, 1.0, 0.999, 0.988, 0.94, 0.9887, 0.972, 0.996, 0.992, 0.992, 0.996, 0.9887, 0.992, 0.996, 0.998, 0.972, 0.992, 0.992, 0.992, 0.978, 0.88, 0.988, 0.996, 0.992, 0.9933, 0.992, 0.98, 0.992, 0.991, 0.984, 0.98, 0.968, 1.0, 0.991, 0.9944, 1.0, 0.9997, 0.988, 0.988, 0.98, 0.984, 0.974, 0.9827, 0.992, 0.998, 0.964, 0.968, 0.995, 0.98, 0.98, 0.99, 0.992, 0.948, 0.9962, 0.992, 0.964, 0.992, 0.994, 0.984, 0.996, 0.984, 0.988, 0.9999, 0.964], 'micro': 0.9796, 'macro': 0.9691, 'weighted': 0.9782}
2024-07-27 10:44:43 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:44:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9656.pt
2024-07-27 10:44:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9660.pt', 'checkpoint_score_0.9672.pt', 'checkpoint_score_0.9676.pt', 'checkpoint_score_0.9690.pt', 'checkpoint_score_0.9691.pt']
2024-07-27 10:44:46 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:44:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:44:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:44:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 21904 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_36_iter_21904.pt
2024-07-27 10:44:48 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 21904 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_36_iter_21904.pt
[31m===========================================================================[0m
2024-07-27 10:44:50 - [32m[1mINFO   [0m - Training epoch 37
2024-07-27 10:44:51 - [34m[1mLOGS   [0m - Epoch:  37 [   21905/10000000], loss: {'classification': 5.0718, 'neural_augmentation': 11.1961, 'total_loss': 16.2678}, LR: [4e-06, 4e-06], Avg. batch load time: 1.444, Elapsed time:  1.59
2024-07-27 10:45:31 - [34m[1mLOGS   [0m - Epoch:  37 [   22405/10000000], loss: {'classification': 5.1947, 'neural_augmentation': 10.0727, 'total_loss': 15.2674}, LR: [4e-06, 4e-06], Avg. batch load time: 0.004, Elapsed time: 40.90
2024-07-27 10:45:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'classification': 5.2109, 'neural_augmentation': 10.0613, 'total_loss': 15.2722}
2024-07-27 10:45:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'classification': 2.4247, 'neural_augmentation': 0.0, 'total_loss': 2.4247} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9485, 0.916, 0.9303, 0.9819, 0.9457, 0.9859, 0.9316, 0.8782, 0.9533, 0.9201, 0.9158, 0.9336, 0.8235, 0.9584, 0.924, 0.9516, 0.9739, 0.984, 0.9485, 0.9472, 0.9551, 0.8737, 0.9507, 0.9567, 0.9512, 0.9374, 0.9508, 0.9595, 0.9423, 0.9281, 0.8724, 0.8782, 0.9187, 0.9491, 0.9165, 0.9155, 0.9555, 0.9463, 0.9212, 0.8938, 0.998, 0.8683, 0.9488, 0.9739, 0.9389, 0.9652, 0.8467, 0.9574, 0.8543, 0.9275, 0.8971, 0.9154, 0.9849, 0.9425, 0.9571, 0.9543, 0.9859, 0.9467, 0.935, 0.8699, 0.8671, 0.9369, 0.9474, 0.9532, 0.9267, 0.8842, 0.9703, 0.9553, 0.956, 0.8543, 0.9127, 0.9157, 0.9452, 0.9369, 0.9149, 0.9078, 0.8908, 0.9512, 0.9689, 0.9737, 0.9279, 0.972, 0.936, 0.8994, 0.9626, 0.9636, 0.9404, 0.9541, 0.8933, 0.9447, 0.9819, 0.84, 0.9463, 0.9127, 0.951, 0.9392, 0.9839, 0.8897, 0.9103, 0.917, 0.9414, 0.9329, 0.9421, 0.8957, 0.9717, 0.9401, 0.9718, 0.8848, 0.9571, 0.9497, 0.8742, 0.9738, 0.9532, 0.9469, 0.7667, 0.936, 0.8436, 0.955, 0.9228, 0.972, 0.9534, 0.929, 0.9491, 0.9643, 0.9356, 0.875, 0.9581, 0.9526, 0.9184, 0.8953, 0.6806, 0.9465, 0.9698, 0.9484, 0.9471, 0.9738, 0.9058, 0.9736, 0.9331, 0.9234, 0.9503, 0.924, 0.9541, 0.9419, 0.9573, 0.9754, 0.949, 0.9284, 0.9798, 0.9449, 0.8986, 0.8907, 0.9303, 0.9719, 0.9557, 0.9023, 0.8944, 0.9348, 0.9331, 0.8884, 0.9372, 0.9353, 0.8815, 0.9408, 0.9602, 0.8945, 0.9515, 0.9717, 0.932, 0.9438, 0.9491, 0.9537, 0.9461, 0.8747], 'AP': [0.9823, 0.9546, 0.9755, 0.9918, 0.9745, 0.9961, 0.974, 0.9288, 0.9873, 0.9732, 0.9644, 0.9785, 0.8873, 0.9889, 0.9615, 0.9809, 0.992, 0.9957, 0.9778, 0.983, 0.9808, 0.9395, 0.9771, 0.9871, 0.9802, 0.9793, 0.9841, 0.9862, 0.9843, 0.9719, 0.9251, 0.9325, 0.97, 0.9807, 0.9709, 0.957, 0.9768, 0.9876, 0.9689, 0.9526, 1.0, 0.9277, 0.9882, 0.9903, 0.9792, 0.9882, 0.9265, 0.9806, 0.916, 0.9771, 0.9484, 0.9709, 0.9943, 0.9797, 0.986, 0.9875, 0.9963, 0.9715, 0.9693, 0.9282, 0.9291, 0.9722, 0.9768, 0.9849, 0.9748, 0.9473, 0.9952, 0.9869, 0.9855, 0.9065, 0.9498, 0.9619, 0.9825, 0.9752, 0.9577, 0.9537, 0.9229, 0.9862, 0.9939, 0.9966, 0.979, 0.9955, 0.9826, 0.9444, 0.9921, 0.9917, 0.9852, 0.9778, 0.9593, 0.9873, 0.9964, 0.8948, 0.9768, 0.9654, 0.976, 0.9829, 0.9955, 0.9358, 0.9656, 0.9737, 0.9807, 0.9689, 0.9712, 0.9619, 0.99, 0.9803, 0.9948, 0.94, 0.9865, 0.9809, 0.9294, 0.9962, 0.9898, 0.98, 0.8235, 0.977, 0.9028, 0.9884, 0.9753, 0.99, 0.9881, 0.9736, 0.98, 0.9878, 0.9817, 0.9294, 0.9872, 0.9847, 0.9683, 0.9444, 0.7026, 0.981, 0.9942, 0.9813, 0.9836, 0.9901, 0.9555, 0.9899, 0.9785, 0.9672, 0.9751, 0.958, 0.9897, 0.9808, 0.9865, 0.9966, 0.9889, 0.9748, 0.9918, 0.9756, 0.9523, 0.9409, 0.9676, 0.9899, 0.9913, 0.9337, 0.934, 0.978, 0.9786, 0.9507, 0.9772, 0.9723, 0.9251, 0.9826, 0.9845, 0.9346, 0.9833, 0.9901, 0.9738, 0.9868, 0.9742, 0.9773, 0.9881, 0.9227], 'Recall@P=50': [0.9913, 0.976, 0.9903, 0.996, 0.98, 1.0, 0.9904, 0.956, 0.9968, 0.9938, 0.99, 0.9924, 0.92, 0.996, 0.978, 0.996, 0.9968, 1.0, 0.98, 0.996, 0.992, 0.962, 0.984, 0.9944, 0.988, 0.992, 0.996, 0.996, 0.9984, 0.9896, 0.944, 0.96, 0.984, 0.988, 0.989, 0.972, 0.984, 0.9986, 0.982, 0.988, 1.0, 0.968, 0.996, 0.992, 0.988, 0.992, 0.9813, 0.988, 0.9533, 0.992, 0.968, 0.9874, 0.996, 0.9949, 0.994, 0.9967, 1.0, 0.984, 0.976, 0.948, 0.976, 0.996, 0.984, 0.996, 0.99, 0.968, 1.0, 0.9947, 0.992, 0.94, 0.972, 0.984, 0.996, 0.9896, 0.976, 0.982, 0.952, 0.9973, 1.0, 1.0, 0.9947, 1.0, 0.9984, 0.952, 0.998, 0.996, 0.9987, 0.984, 0.9817, 0.996, 0.998, 0.944, 0.98, 0.98, 0.976, 0.996, 0.996, 0.98, 0.9833, 0.992, 0.9943, 0.982, 0.972, 0.988, 0.992, 0.9933, 1.0, 0.968, 0.9936, 0.988, 0.964, 1.0, 0.9992, 0.994, 0.932, 0.9893, 0.952, 0.9953, 0.992, 0.992, 0.996, 0.9887, 0.996, 0.992, 0.997, 0.956, 0.992, 0.9933, 0.988, 0.978, 0.828, 0.988, 0.996, 0.988, 0.992, 0.992, 0.9773, 0.992, 0.9933, 0.984, 0.984, 0.968, 1.0, 0.991, 0.9936, 1.0, 0.9996, 0.9893, 0.992, 0.984, 0.972, 0.974, 0.9813, 0.992, 0.996, 0.956, 0.96, 0.992, 0.992, 0.988, 0.992, 0.98, 0.944, 0.9965, 0.988, 0.956, 0.994, 0.994, 0.988, 1.0, 0.98, 0.98, 0.9996, 0.944], 'micro': 0.9793, 'macro': 0.969, 'weighted': 0.9779}
2024-07-27 10:46:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:46:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:46:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 22496 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_37_iter_22496.pt
2024-07-27 10:46:04 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 22496 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_37_iter_22496.pt
[31m===========================================================================[0m
2024-07-27 10:46:06 - [32m[1mINFO   [0m - Training epoch 38
2024-07-27 10:46:07 - [34m[1mLOGS   [0m - Epoch:  38 [   22497/10000000], loss: {'classification': 6.1506, 'neural_augmentation': 11.3061, 'total_loss': 17.4567}, LR: [4e-06, 4e-06], Avg. batch load time: 0.608, Elapsed time:  0.69
2024-07-27 10:46:45 - [34m[1mLOGS   [0m - Epoch:  38 [   22997/10000000], loss: {'classification': 5.161, 'neural_augmentation': 10.0946, 'total_loss': 15.2556}, LR: [4e-06, 4e-06], Avg. batch load time: 0.002, Elapsed time: 38.25
2024-07-27 10:46:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'classification': 5.1913, 'neural_augmentation': 10.1049, 'total_loss': 15.2962}
2024-07-27 10:47:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'classification': 2.3692, 'neural_augmentation': 0.0, 'total_loss': 2.3692} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9482, 0.9118, 0.9262, 0.98, 0.9381, 0.9839, 0.9296, 0.8889, 0.9453, 0.9199, 0.9214, 0.9351, 0.8206, 0.9579, 0.9224, 0.9611, 0.9747, 0.9859, 0.9528, 0.9512, 0.9672, 0.8795, 0.9407, 0.9607, 0.9509, 0.938, 0.951, 0.9675, 0.9434, 0.9331, 0.8616, 0.8903, 0.9278, 0.9504, 0.9153, 0.9095, 0.9619, 0.9464, 0.9292, 0.8827, 0.998, 0.8596, 0.9556, 0.978, 0.9375, 0.9734, 0.8404, 0.9595, 0.8636, 0.935, 0.9032, 0.9182, 0.9839, 0.9442, 0.9546, 0.9583, 0.9879, 0.9426, 0.9366, 0.8705, 0.8612, 0.9325, 0.9457, 0.9516, 0.9301, 0.8887, 0.9781, 0.959, 0.9602, 0.8531, 0.9271, 0.9181, 0.9576, 0.9405, 0.9091, 0.9135, 0.8894, 0.9506, 0.9681, 0.9778, 0.9321, 0.978, 0.9409, 0.9038, 0.9659, 0.9665, 0.9412, 0.9395, 0.9043, 0.9495, 0.982, 0.8285, 0.9426, 0.912, 0.9504, 0.9416, 0.9839, 0.8889, 0.9187, 0.9187, 0.9437, 0.9277, 0.9385, 0.8977, 0.98, 0.9402, 0.9736, 0.8926, 0.9549, 0.9506, 0.8851, 0.9741, 0.9537, 0.9447, 0.7732, 0.9403, 0.8595, 0.9597, 0.9187, 0.9778, 0.9572, 0.9309, 0.9598, 0.9734, 0.9354, 0.8737, 0.9603, 0.9517, 0.9231, 0.8971, 0.6646, 0.9506, 0.978, 0.9507, 0.9476, 0.978, 0.9048, 0.978, 0.9332, 0.9315, 0.9421, 0.9087, 0.9621, 0.9424, 0.9538, 0.9736, 0.9511, 0.926, 0.9779, 0.9467, 0.9056, 0.8863, 0.9292, 0.9799, 0.963, 0.8865, 0.8944, 0.9361, 0.935, 0.8832, 0.9313, 0.9358, 0.8632, 0.9384, 0.9548, 0.8884, 0.9505, 0.9663, 0.939, 0.9549, 0.9435, 0.9491, 0.9462, 0.8614], 'AP': [0.9818, 0.9563, 0.9746, 0.9905, 0.9724, 0.9968, 0.9728, 0.9249, 0.9873, 0.9741, 0.9618, 0.9786, 0.8844, 0.9882, 0.9629, 0.9834, 0.9925, 0.9967, 0.9788, 0.9831, 0.9838, 0.9462, 0.9738, 0.9894, 0.9806, 0.9817, 0.9837, 0.9871, 0.9853, 0.973, 0.9256, 0.944, 0.9687, 0.9802, 0.9688, 0.9555, 0.9775, 0.9882, 0.9725, 0.9423, 0.9999, 0.9228, 0.9877, 0.9915, 0.9776, 0.9889, 0.9216, 0.9793, 0.9271, 0.9764, 0.9463, 0.971, 0.9937, 0.9808, 0.9885, 0.9892, 0.9971, 0.967, 0.9719, 0.9331, 0.9255, 0.9708, 0.9764, 0.984, 0.9748, 0.9415, 0.9955, 0.9886, 0.9855, 0.9135, 0.9509, 0.9626, 0.9873, 0.9778, 0.9593, 0.9512, 0.915, 0.9864, 0.9936, 0.9961, 0.9799, 0.9962, 0.984, 0.942, 0.9929, 0.9924, 0.9857, 0.9737, 0.9614, 0.9859, 0.9964, 0.8871, 0.9771, 0.9668, 0.9773, 0.9835, 0.9962, 0.9296, 0.9684, 0.9712, 0.9826, 0.9695, 0.9723, 0.9598, 0.9907, 0.9806, 0.9943, 0.9391, 0.9854, 0.9814, 0.9254, 0.9956, 0.9898, 0.9784, 0.8307, 0.9767, 0.9053, 0.9886, 0.9732, 0.9906, 0.9881, 0.975, 0.9876, 0.9895, 0.9831, 0.936, 0.986, 0.9851, 0.9676, 0.9452, 0.7013, 0.9814, 0.9944, 0.9821, 0.9851, 0.9901, 0.9575, 0.9906, 0.9779, 0.9671, 0.9725, 0.96, 0.9907, 0.9812, 0.9871, 0.9964, 0.9897, 0.9749, 0.9911, 0.9782, 0.9553, 0.9397, 0.9699, 0.9904, 0.9908, 0.9366, 0.9364, 0.9784, 0.9778, 0.9425, 0.9776, 0.973, 0.9242, 0.9822, 0.985, 0.9363, 0.9838, 0.9913, 0.9778, 0.9863, 0.9726, 0.9766, 0.9886, 0.9229], 'Recall@P=50': [0.99, 0.976, 0.9903, 0.988, 0.98, 1.0, 0.9872, 0.964, 0.9968, 0.9963, 0.984, 0.992, 0.916, 0.996, 0.974, 0.992, 0.9976, 1.0, 0.984, 0.992, 0.992, 0.968, 0.98, 0.9968, 0.9867, 0.9928, 0.996, 0.996, 0.9989, 0.9864, 0.956, 0.96, 0.988, 0.984, 0.9895, 0.972, 0.988, 0.9993, 0.987, 0.964, 1.0, 0.964, 0.992, 0.996, 0.984, 0.992, 0.9747, 0.98, 0.9613, 0.992, 0.96, 0.9889, 0.994, 0.992, 0.996, 0.9953, 1.0, 0.98, 0.988, 0.96, 0.972, 0.992, 0.988, 0.996, 0.9887, 0.96, 0.996, 0.996, 0.992, 0.944, 0.976, 0.978, 0.996, 0.988, 0.972, 0.982, 0.964, 0.9973, 0.9987, 1.0, 0.9942, 1.0, 0.9994, 0.952, 0.998, 0.996, 0.9987, 0.98, 0.9878, 0.996, 0.998, 0.928, 0.984, 0.9832, 0.988, 0.9967, 0.996, 0.968, 0.9827, 0.988, 0.9949, 0.984, 0.984, 0.988, 0.992, 0.9913, 0.998, 0.96, 0.9936, 0.988, 0.96, 1.0, 0.9994, 0.99, 0.936, 0.9907, 0.956, 0.994, 0.988, 0.992, 0.996, 0.9873, 1.0, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.992, 0.98, 0.884, 0.988, 0.996, 0.988, 0.996, 0.992, 0.984, 0.992, 0.9937, 0.976, 0.98, 0.972, 1.0, 0.992, 0.9944, 1.0, 0.9998, 0.9893, 0.988, 0.984, 0.978, 0.972, 0.9787, 0.992, 0.994, 0.96, 0.96, 0.995, 0.992, 0.976, 0.993, 0.988, 0.952, 0.9965, 0.988, 0.96, 0.9907, 0.994, 0.996, 1.0, 0.984, 0.976, 0.9998, 0.952], 'micro': 0.98, 'macro': 0.9692, 'weighted': 0.9784}
2024-07-27 10:47:16 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:47:16 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9660.pt
2024-07-27 10:47:16 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9672.pt', 'checkpoint_score_0.9676.pt', 'checkpoint_score_0.9690.pt', 'checkpoint_score_0.9691.pt', 'checkpoint_score_0.9692.pt']
2024-07-27 10:47:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:47:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:47:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:47:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 23088 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_38_iter_23088.pt
2024-07-27 10:47:20 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 23088 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_38_iter_23088.pt
[31m===========================================================================[0m
2024-07-27 10:47:22 - [32m[1mINFO   [0m - Training epoch 39
2024-07-27 10:47:23 - [34m[1mLOGS   [0m - Epoch:  39 [   23089/10000000], loss: {'classification': 5.1441, 'neural_augmentation': 11.0191, 'total_loss': 16.1632}, LR: [3e-06, 3e-06], Avg. batch load time: 0.723, Elapsed time:  0.81
2024-07-27 10:48:00 - [34m[1mLOGS   [0m - Epoch:  39 [   23589/10000000], loss: {'classification': 5.0094, 'neural_augmentation': 10.0358, 'total_loss': 15.0452}, LR: [3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 38.28
2024-07-27 10:48:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'classification': 5.0239, 'neural_augmentation': 10.0157, 'total_loss': 15.0396}
2024-07-27 10:48:25 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'classification': 2.4462, 'neural_augmentation': 0.0, 'total_loss': 2.4462} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.947, 0.916, 0.9293, 0.9798, 0.9385, 0.986, 0.929, 0.8907, 0.951, 0.9202, 0.9134, 0.931, 0.8121, 0.9575, 0.9218, 0.9611, 0.9717, 0.9781, 0.9545, 0.951, 0.9567, 0.8805, 0.9412, 0.9599, 0.9447, 0.9301, 0.9551, 0.9528, 0.9436, 0.9286, 0.8632, 0.888, 0.9265, 0.945, 0.9168, 0.9121, 0.9484, 0.9459, 0.9251, 0.8843, 0.998, 0.8631, 0.9458, 0.9738, 0.9426, 0.9695, 0.8403, 0.9592, 0.8587, 0.9452, 0.8848, 0.9182, 0.9839, 0.9426, 0.954, 0.9563, 0.9889, 0.9443, 0.9339, 0.8737, 0.8665, 0.9333, 0.9441, 0.951, 0.9255, 0.8842, 0.9761, 0.9474, 0.9563, 0.8503, 0.9148, 0.9186, 0.9472, 0.9373, 0.9179, 0.9179, 0.8875, 0.9521, 0.9718, 0.9757, 0.928, 0.976, 0.9377, 0.8915, 0.9612, 0.9584, 0.9406, 0.9443, 0.9012, 0.9383, 0.9819, 0.846, 0.9421, 0.9138, 0.9487, 0.9393, 0.9841, 0.874, 0.9129, 0.924, 0.9356, 0.9294, 0.9446, 0.9005, 0.9718, 0.9397, 0.9738, 0.8898, 0.9518, 0.9467, 0.8826, 0.9737, 0.9534, 0.9456, 0.7718, 0.9305, 0.8554, 0.958, 0.9275, 0.9717, 0.9552, 0.9303, 0.9512, 0.9695, 0.9351, 0.8776, 0.9589, 0.9505, 0.9296, 0.8842, 0.6703, 0.9467, 0.9782, 0.9478, 0.9446, 0.9718, 0.9026, 0.9718, 0.9347, 0.9243, 0.9358, 0.9116, 0.9513, 0.9387, 0.952, 0.9737, 0.9485, 0.9271, 0.9759, 0.9354, 0.9009, 0.8865, 0.9278, 0.9718, 0.9584, 0.8866, 0.8847, 0.9282, 0.9448, 0.8789, 0.9303, 0.9363, 0.8584, 0.9376, 0.9661, 0.8866, 0.9518, 0.9726, 0.9339, 0.9524, 0.9366, 0.9463, 0.9447, 0.8627], 'AP': [0.982, 0.9547, 0.9741, 0.9919, 0.9687, 0.9975, 0.9736, 0.9233, 0.9866, 0.9754, 0.9631, 0.9769, 0.8823, 0.9878, 0.964, 0.9832, 0.9923, 0.9969, 0.9777, 0.9832, 0.9815, 0.9426, 0.9725, 0.989, 0.9783, 0.9788, 0.9827, 0.985, 0.9852, 0.972, 0.9253, 0.9394, 0.9727, 0.9817, 0.9703, 0.9588, 0.9768, 0.9879, 0.9689, 0.9314, 1.0, 0.9225, 0.9843, 0.9919, 0.9783, 0.9892, 0.9207, 0.9798, 0.9249, 0.9765, 0.9448, 0.9718, 0.9941, 0.981, 0.9864, 0.9892, 0.9969, 0.9687, 0.9681, 0.9331, 0.9243, 0.9691, 0.9734, 0.9843, 0.9738, 0.944, 0.9942, 0.9854, 0.9839, 0.9021, 0.9527, 0.9614, 0.9861, 0.9767, 0.9568, 0.9533, 0.9134, 0.9847, 0.9937, 0.9945, 0.9787, 0.9949, 0.9837, 0.94, 0.9906, 0.9899, 0.9846, 0.9731, 0.9635, 0.9827, 0.9964, 0.9001, 0.9753, 0.9652, 0.9773, 0.9832, 0.9955, 0.9313, 0.9659, 0.9702, 0.9794, 0.9691, 0.9722, 0.9596, 0.9913, 0.9794, 0.9927, 0.9458, 0.9855, 0.981, 0.9218, 0.9938, 0.9896, 0.9781, 0.8258, 0.9739, 0.9036, 0.9874, 0.9718, 0.9916, 0.9872, 0.975, 0.9857, 0.9894, 0.9829, 0.9332, 0.9885, 0.9859, 0.9721, 0.9441, 0.712, 0.9812, 0.9932, 0.9823, 0.9835, 0.9909, 0.9552, 0.991, 0.9777, 0.9649, 0.9726, 0.9583, 0.9868, 0.9807, 0.9862, 0.9948, 0.9893, 0.9741, 0.9916, 0.9751, 0.953, 0.9392, 0.9682, 0.991, 0.9891, 0.9351, 0.9352, 0.9759, 0.9783, 0.9324, 0.9774, 0.97, 0.9238, 0.9811, 0.9856, 0.9356, 0.984, 0.9913, 0.9756, 0.9877, 0.9686, 0.9776, 0.9883, 0.9226], 'Recall@P=50': [0.9913, 0.976, 0.9903, 0.992, 0.968, 1.0, 0.9856, 0.964, 0.996, 0.9948, 0.984, 0.9924, 0.912, 0.994, 0.98, 0.992, 0.9976, 1.0, 0.984, 0.996, 0.992, 0.964, 0.98, 0.9968, 0.9867, 0.9928, 0.996, 0.996, 0.9989, 0.9856, 0.956, 0.96, 0.988, 0.992, 0.99, 0.968, 0.988, 0.9992, 0.982, 0.96, 1.0, 0.968, 0.996, 0.996, 0.984, 0.992, 0.9733, 0.984, 0.9627, 0.984, 0.964, 0.9884, 0.996, 0.9926, 0.992, 0.9953, 1.0, 0.98, 0.988, 0.952, 0.964, 0.988, 0.984, 0.996, 0.9887, 0.968, 0.996, 0.9933, 0.99, 0.928, 0.984, 0.982, 1.0, 0.9896, 0.972, 0.982, 0.964, 0.9933, 0.9973, 0.996, 0.9932, 1.0, 0.999, 0.956, 0.998, 0.994, 0.9991, 0.98, 0.9904, 0.996, 0.998, 0.944, 0.992, 0.9792, 0.98, 0.9964, 0.996, 0.976, 0.9847, 0.988, 0.9949, 0.982, 0.988, 0.988, 0.996, 0.991, 0.998, 0.964, 0.9944, 0.996, 0.968, 0.996, 0.9994, 0.99, 0.936, 0.9873, 0.956, 0.996, 0.988, 0.996, 0.994, 0.9887, 1.0, 0.992, 0.9987, 0.96, 0.996, 0.992, 0.988, 0.978, 0.876, 0.988, 0.992, 0.996, 0.994, 0.996, 0.9787, 0.996, 0.9943, 0.984, 0.98, 0.984, 0.992, 0.991, 0.9936, 0.996, 0.9998, 0.992, 0.992, 0.986, 0.976, 0.966, 0.98, 0.996, 0.996, 0.96, 0.964, 0.995, 0.988, 0.964, 0.994, 0.988, 0.952, 0.995, 0.992, 0.952, 0.9927, 0.994, 0.992, 1.0, 0.972, 0.988, 0.9996, 0.964], 'micro': 0.979, 'macro': 0.9685, 'weighted': 0.9778}
2024-07-27 10:48:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:48:31 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:48:32 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 23680 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_39_iter_23680.pt
2024-07-27 10:48:32 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 23680 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_39_iter_23680.pt
[31m===========================================================================[0m
2024-07-27 10:48:34 - [32m[1mINFO   [0m - Training epoch 40
2024-07-27 10:48:35 - [34m[1mLOGS   [0m - Epoch:  40 [   23681/10000000], loss: {'classification': 4.9482, 'neural_augmentation': 9.481, 'total_loss': 14.4293}, LR: [3e-06, 3e-06], Avg. batch load time: 0.722, Elapsed time:  0.80
2024-07-27 10:49:13 - [34m[1mLOGS   [0m - Epoch:  40 [   24181/10000000], loss: {'classification': 4.9682, 'neural_augmentation': 9.9691, 'total_loss': 14.9373}, LR: [3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 38.40
2024-07-27 10:49:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'classification': 4.9686, 'neural_augmentation': 9.9799, 'total_loss': 14.9485}
2024-07-27 10:49:39 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'classification': 2.3907, 'neural_augmentation': 0.0, 'total_loss': 2.3907} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.948, 0.9142, 0.9307, 0.982, 0.9429, 0.986, 0.9334, 0.8753, 0.9522, 0.9176, 0.9242, 0.9389, 0.817, 0.9585, 0.9263, 0.9574, 0.9709, 0.9734, 0.9522, 0.9508, 0.9593, 0.8893, 0.9388, 0.9608, 0.9481, 0.9361, 0.9526, 0.96, 0.942, 0.9328, 0.8769, 0.8848, 0.9278, 0.9504, 0.9158, 0.9091, 0.9576, 0.9462, 0.9245, 0.9039, 0.998, 0.8773, 0.9553, 0.9759, 0.9405, 0.9673, 0.8519, 0.9631, 0.8605, 0.9409, 0.8961, 0.9136, 0.984, 0.945, 0.9585, 0.9567, 0.9839, 0.9405, 0.9347, 0.8811, 0.8708, 0.9355, 0.9429, 0.9457, 0.9303, 0.8911, 0.9758, 0.9521, 0.9615, 0.8347, 0.9231, 0.9194, 0.9555, 0.9396, 0.9211, 0.9128, 0.8824, 0.9503, 0.9693, 0.9798, 0.9269, 0.978, 0.9389, 0.9025, 0.9677, 0.9658, 0.9403, 0.9423, 0.9038, 0.9539, 0.983, 0.8294, 0.9448, 0.91, 0.951, 0.9442, 0.988, 0.8834, 0.916, 0.9199, 0.9407, 0.9291, 0.9448, 0.9001, 0.9738, 0.9405, 0.9726, 0.892, 0.9552, 0.953, 0.8723, 0.9798, 0.9549, 0.9455, 0.7652, 0.9352, 0.8571, 0.9587, 0.9259, 0.9736, 0.9583, 0.9311, 0.96, 0.9652, 0.9351, 0.8833, 0.955, 0.9525, 0.9269, 0.8999, 0.6865, 0.9491, 0.9782, 0.9512, 0.9444, 0.9738, 0.9011, 0.9756, 0.9334, 0.9309, 0.9452, 0.9076, 0.9507, 0.9429, 0.9566, 0.9799, 0.9514, 0.933, 0.982, 0.9425, 0.9015, 0.8891, 0.9321, 0.976, 0.9625, 0.8853, 0.8875, 0.9359, 0.9409, 0.8982, 0.9308, 0.9414, 0.8763, 0.9388, 0.9657, 0.8845, 0.9523, 0.9748, 0.9371, 0.9522, 0.9412, 0.9512, 0.9462, 0.8761], 'AP': [0.9829, 0.9548, 0.9741, 0.9917, 0.9735, 0.9976, 0.9755, 0.9216, 0.988, 0.9749, 0.9637, 0.9792, 0.8867, 0.9879, 0.9641, 0.982, 0.9918, 0.9958, 0.9765, 0.9846, 0.9826, 0.9467, 0.9755, 0.9891, 0.979, 0.9793, 0.9846, 0.9865, 0.9854, 0.9736, 0.9269, 0.9385, 0.9735, 0.9814, 0.9702, 0.9547, 0.9747, 0.9884, 0.9709, 0.9434, 1.0, 0.9302, 0.9891, 0.9895, 0.9787, 0.9887, 0.9253, 0.9806, 0.9259, 0.9776, 0.9513, 0.9692, 0.994, 0.9812, 0.9872, 0.9886, 0.9955, 0.9727, 0.9669, 0.9425, 0.9311, 0.9736, 0.9731, 0.9852, 0.9737, 0.9414, 0.9948, 0.987, 0.9849, 0.8986, 0.9557, 0.9588, 0.9851, 0.9781, 0.956, 0.9562, 0.9127, 0.9862, 0.9941, 0.996, 0.9787, 0.9953, 0.9838, 0.9463, 0.9922, 0.9927, 0.9856, 0.9767, 0.9631, 0.9883, 0.9957, 0.8952, 0.9753, 0.9666, 0.9754, 0.984, 0.9947, 0.9345, 0.968, 0.9718, 0.9805, 0.9694, 0.9756, 0.9607, 0.9895, 0.9799, 0.9926, 0.9377, 0.9861, 0.9809, 0.9225, 0.9956, 0.9901, 0.9805, 0.837, 0.9749, 0.8992, 0.9881, 0.9726, 0.989, 0.9872, 0.976, 0.9831, 0.989, 0.9829, 0.9434, 0.9862, 0.9861, 0.9733, 0.945, 0.7176, 0.9821, 0.9939, 0.984, 0.9848, 0.9884, 0.9538, 0.989, 0.9782, 0.9676, 0.9741, 0.9616, 0.9887, 0.9809, 0.9869, 0.9963, 0.9899, 0.9769, 0.9926, 0.9761, 0.9545, 0.9371, 0.9708, 0.9888, 0.9917, 0.9365, 0.9349, 0.9773, 0.9778, 0.9426, 0.9784, 0.9692, 0.9276, 0.9824, 0.9852, 0.9368, 0.9847, 0.9912, 0.9757, 0.9878, 0.9732, 0.9747, 0.9883, 0.9261], 'Recall@P=50': [0.9907, 0.972, 0.9914, 0.992, 0.984, 1.0, 0.9864, 0.96, 0.996, 0.9963, 0.982, 0.9916, 0.92, 0.994, 0.976, 0.988, 0.9976, 0.996, 0.984, 0.996, 0.992, 0.972, 0.98, 0.9952, 0.9853, 0.992, 0.996, 0.996, 0.9986, 0.9888, 0.956, 0.968, 0.988, 0.988, 0.988, 0.976, 0.984, 0.9994, 0.986, 0.976, 1.0, 0.964, 0.996, 0.992, 0.988, 0.992, 0.972, 0.984, 0.9573, 0.988, 0.964, 0.9863, 0.996, 0.9931, 0.992, 0.9953, 0.996, 0.98, 0.98, 0.964, 0.972, 0.988, 0.988, 0.996, 0.9893, 0.962, 0.996, 0.996, 0.988, 0.932, 0.976, 0.98, 0.996, 0.9896, 0.972, 0.984, 0.964, 0.9947, 0.9987, 1.0, 0.9937, 0.996, 0.9986, 0.952, 0.998, 0.996, 0.9989, 0.984, 0.9887, 0.996, 0.998, 0.952, 0.988, 0.9848, 0.98, 0.996, 0.996, 0.972, 0.984, 0.988, 0.9931, 0.986, 0.988, 0.9867, 0.992, 0.9923, 1.0, 0.956, 0.9944, 0.98, 0.968, 1.0, 0.9993, 0.992, 0.936, 0.986, 0.956, 0.9947, 0.992, 0.992, 0.994, 0.9913, 0.996, 0.992, 0.9977, 0.972, 0.992, 0.992, 0.992, 0.968, 0.88, 0.988, 0.996, 0.992, 0.994, 0.992, 0.9827, 0.992, 0.9933, 0.988, 0.98, 0.98, 0.996, 0.992, 0.9928, 1.0, 0.9997, 0.9907, 0.992, 0.98, 0.978, 0.97, 0.9827, 0.992, 0.994, 0.956, 0.96, 0.994, 0.988, 0.972, 0.993, 0.984, 0.956, 0.9965, 0.988, 0.952, 0.9933, 0.994, 0.992, 1.0, 0.98, 0.98, 0.9996, 0.952], 'micro': 0.9799, 'macro': 0.9694, 'weighted': 0.9785}
2024-07-27 10:49:44 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:49:45 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9672.pt
2024-07-27 10:49:45 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9676.pt', 'checkpoint_score_0.9690.pt', 'checkpoint_score_0.9691.pt', 'checkpoint_score_0.9692.pt', 'checkpoint_score_0.9694.pt']
2024-07-27 10:49:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:49:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:49:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:49:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 24272 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_40_iter_24272.pt
2024-07-27 10:49:49 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 24272 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_40_iter_24272.pt
[31m===========================================================================[0m
2024-07-27 10:49:51 - [32m[1mINFO   [0m - Training epoch 41
2024-07-27 10:49:52 - [34m[1mLOGS   [0m - Epoch:  41 [   24273/10000000], loss: {'classification': 5.0055, 'neural_augmentation': 9.2038, 'total_loss': 14.2092}, LR: [3e-06, 3e-06], Avg. batch load time: 0.804, Elapsed time:  0.89
2024-07-27 10:50:29 - [34m[1mLOGS   [0m - Epoch:  41 [   24773/10000000], loss: {'classification': 4.9078, 'neural_augmentation': 9.9864, 'total_loss': 14.8942}, LR: [3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 38.43
2024-07-27 10:50:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'classification': 4.9042, 'neural_augmentation': 9.9985, 'total_loss': 14.9027}
2024-07-27 10:50:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'classification': 2.4729, 'neural_augmentation': 0.0, 'total_loss': 2.4729} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9503, 0.9144, 0.9262, 0.9839, 0.9426, 0.9839, 0.9271, 0.8803, 0.9512, 0.9151, 0.9138, 0.9339, 0.8108, 0.951, 0.9275, 0.9577, 0.9744, 0.9859, 0.9547, 0.959, 0.9618, 0.8903, 0.9433, 0.9623, 0.9399, 0.9338, 0.959, 0.9597, 0.9437, 0.9281, 0.8692, 0.883, 0.9347, 0.9487, 0.9178, 0.9098, 0.956, 0.9462, 0.9253, 0.9008, 0.998, 0.8629, 0.9323, 0.9696, 0.9322, 0.9652, 0.8473, 0.9613, 0.8694, 0.9287, 0.8987, 0.9207, 0.9829, 0.9426, 0.9628, 0.9554, 0.9839, 0.9419, 0.9461, 0.8717, 0.8676, 0.932, 0.9421, 0.959, 0.9255, 0.8927, 0.976, 0.9494, 0.9597, 0.8509, 0.9173, 0.9168, 0.9543, 0.9389, 0.9198, 0.9002, 0.8856, 0.9461, 0.9697, 0.9798, 0.9294, 0.9721, 0.9395, 0.9023, 0.9551, 0.9585, 0.9408, 0.9397, 0.9035, 0.9352, 0.983, 0.8207, 0.9443, 0.9116, 0.9526, 0.9387, 0.9899, 0.8772, 0.9139, 0.9194, 0.938, 0.9276, 0.9381, 0.8983, 0.9696, 0.9417, 0.9668, 0.8907, 0.9502, 0.9533, 0.8831, 0.9798, 0.9535, 0.9414, 0.764, 0.934, 0.8607, 0.9584, 0.9256, 0.9657, 0.9514, 0.934, 0.9581, 0.9673, 0.935, 0.8735, 0.9567, 0.9509, 0.9357, 0.8964, 0.6825, 0.9482, 0.9802, 0.9535, 0.9455, 0.9696, 0.9015, 0.9696, 0.9375, 0.928, 0.9429, 0.912, 0.9448, 0.9384, 0.9528, 0.978, 0.9498, 0.927, 0.9799, 0.9333, 0.911, 0.8873, 0.9304, 0.9676, 0.9538, 0.888, 0.8953, 0.9331, 0.9309, 0.8976, 0.9267, 0.9463, 0.8714, 0.9376, 0.9701, 0.8943, 0.9488, 0.9759, 0.9344, 0.948, 0.939, 0.9485, 0.9459, 0.8699], 'AP': [0.9821, 0.9553, 0.9743, 0.9922, 0.9729, 0.9959, 0.9738, 0.9292, 0.9864, 0.9737, 0.9639, 0.9773, 0.8798, 0.9864, 0.9638, 0.9833, 0.9928, 0.9962, 0.9742, 0.9812, 0.9822, 0.9474, 0.9759, 0.9884, 0.978, 0.9783, 0.9814, 0.9841, 0.9851, 0.9715, 0.9239, 0.9422, 0.9719, 0.9759, 0.9704, 0.9533, 0.9764, 0.9871, 0.9689, 0.9466, 1.0, 0.9273, 0.9777, 0.9903, 0.9761, 0.987, 0.9236, 0.981, 0.9282, 0.9739, 0.956, 0.9702, 0.9938, 0.9793, 0.9879, 0.988, 0.9966, 0.9705, 0.9686, 0.9313, 0.9291, 0.969, 0.9722, 0.9816, 0.9743, 0.946, 0.9944, 0.9856, 0.9856, 0.9037, 0.9517, 0.9591, 0.9839, 0.9769, 0.9567, 0.9494, 0.9225, 0.984, 0.9932, 0.9947, 0.9766, 0.9942, 0.9838, 0.9523, 0.986, 0.9887, 0.9849, 0.9754, 0.963, 0.977, 0.996, 0.8895, 0.9737, 0.9658, 0.9747, 0.9816, 0.9933, 0.9296, 0.9662, 0.9742, 0.979, 0.9688, 0.9716, 0.9607, 0.9897, 0.9808, 0.993, 0.9422, 0.9846, 0.977, 0.9281, 0.9945, 0.9896, 0.9771, 0.8292, 0.9753, 0.9004, 0.9865, 0.9749, 0.9898, 0.9862, 0.9758, 0.9823, 0.9882, 0.9827, 0.9326, 0.986, 0.9865, 0.9719, 0.9406, 0.6997, 0.9772, 0.9935, 0.9845, 0.9835, 0.9892, 0.9531, 0.9894, 0.978, 0.9698, 0.974, 0.9652, 0.9857, 0.9798, 0.9854, 0.995, 0.9893, 0.9736, 0.9915, 0.9757, 0.9596, 0.9412, 0.972, 0.9897, 0.9871, 0.9363, 0.9349, 0.976, 0.9757, 0.948, 0.9778, 0.9709, 0.9249, 0.9824, 0.9841, 0.9367, 0.9824, 0.9897, 0.9779, 0.9847, 0.9729, 0.9773, 0.9878, 0.9236], 'Recall@P=50': [0.99, 0.976, 0.9903, 0.996, 0.984, 0.996, 0.9888, 0.96, 0.9952, 0.9945, 0.986, 0.9932, 0.908, 0.994, 0.978, 0.988, 0.9976, 0.996, 0.976, 0.984, 0.992, 0.97, 0.984, 0.9952, 0.988, 0.9952, 0.988, 0.996, 0.9986, 0.9864, 0.96, 0.972, 0.988, 0.992, 0.9875, 0.968, 0.988, 0.9993, 0.983, 0.98, 1.0, 0.972, 0.996, 0.996, 0.984, 0.992, 0.9733, 0.988, 0.96, 0.984, 0.976, 0.9874, 0.996, 0.9926, 0.996, 0.996, 1.0, 0.98, 0.984, 0.952, 0.972, 0.988, 0.984, 0.988, 0.9893, 0.966, 0.996, 0.9987, 0.992, 0.932, 0.968, 0.978, 0.992, 0.9896, 0.976, 0.974, 0.96, 0.9933, 0.9987, 0.996, 0.9942, 0.996, 0.9982, 0.968, 0.998, 0.994, 0.9984, 0.984, 0.987, 0.996, 0.998, 0.932, 0.984, 0.9848, 0.976, 0.9949, 0.992, 0.976, 0.986, 0.992, 0.9943, 0.98, 0.988, 0.9853, 0.992, 0.992, 1.0, 0.96, 0.9928, 0.98, 0.968, 0.996, 0.9993, 0.992, 0.932, 0.9893, 0.948, 0.9947, 0.992, 0.996, 0.994, 0.9913, 0.996, 0.992, 0.9983, 0.964, 0.992, 0.9933, 0.988, 0.97, 0.872, 0.988, 0.996, 0.992, 0.9953, 0.992, 0.9773, 0.996, 0.9927, 0.988, 0.984, 0.976, 0.996, 0.991, 0.9936, 0.996, 0.9996, 0.9893, 0.996, 0.99, 0.982, 0.972, 0.9853, 0.992, 0.994, 0.96, 0.964, 0.99, 0.984, 0.976, 0.995, 0.984, 0.956, 0.9968, 0.988, 0.952, 0.992, 0.992, 0.992, 1.0, 0.976, 0.984, 0.9998, 0.96], 'micro': 0.9789, 'macro': 0.9685, 'weighted': 0.9777}
2024-07-27 10:51:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:51:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:51:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 24864 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_41_iter_24864.pt
2024-07-27 10:51:02 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 24864 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_41_iter_24864.pt
[31m===========================================================================[0m
2024-07-27 10:51:04 - [32m[1mINFO   [0m - Training epoch 42
2024-07-27 10:51:05 - [34m[1mLOGS   [0m - Epoch:  42 [   24865/10000000], loss: {'classification': 5.7216, 'neural_augmentation': 10.9107, 'total_loss': 16.6323}, LR: [3e-06, 3e-06], Avg. batch load time: 0.817, Elapsed time:  0.90
2024-07-27 10:51:42 - [34m[1mLOGS   [0m - Epoch:  42 [   25365/10000000], loss: {'classification': 4.8233, 'neural_augmentation': 9.9786, 'total_loss': 14.8019}, LR: [3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 38.35
2024-07-27 10:51:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'classification': 4.8255, 'neural_augmentation': 9.971, 'total_loss': 14.7965}
2024-07-27 10:52:08 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'classification': 2.3911, 'neural_augmentation': 0.0, 'total_loss': 2.3911} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9497, 0.9221, 0.9274, 0.984, 0.9407, 0.9841, 0.9335, 0.875, 0.9526, 0.9205, 0.9154, 0.936, 0.8235, 0.9565, 0.9237, 0.9565, 0.9728, 0.978, 0.9504, 0.9574, 0.9501, 0.8862, 0.9443, 0.9604, 0.9516, 0.9376, 0.9592, 0.9595, 0.9421, 0.9303, 0.873, 0.8849, 0.9306, 0.951, 0.9157, 0.9135, 0.9516, 0.9468, 0.9292, 0.8916, 0.998, 0.8665, 0.949, 0.9739, 0.9405, 0.9673, 0.8461, 0.9616, 0.8596, 0.9369, 0.9012, 0.9173, 0.9859, 0.9425, 0.96, 0.9517, 0.982, 0.9395, 0.9402, 0.8617, 0.8717, 0.9371, 0.9443, 0.9571, 0.9323, 0.9012, 0.972, 0.951, 0.9603, 0.8366, 0.9167, 0.9238, 0.9579, 0.9393, 0.9195, 0.9143, 0.8769, 0.9512, 0.97, 0.9742, 0.9223, 0.9723, 0.9412, 0.911, 0.9642, 0.9625, 0.9411, 0.9423, 0.8982, 0.947, 0.9829, 0.8441, 0.9469, 0.9126, 0.9487, 0.9399, 0.9879, 0.8785, 0.9179, 0.9247, 0.9432, 0.9304, 0.9398, 0.8972, 0.9714, 0.9418, 0.9737, 0.892, 0.9561, 0.9512, 0.8705, 0.9759, 0.9543, 0.9458, 0.778, 0.9354, 0.8543, 0.9554, 0.9208, 0.9739, 0.954, 0.934, 0.9581, 0.9672, 0.9354, 0.8623, 0.9549, 0.9487, 0.9317, 0.8956, 0.6884, 0.9487, 0.9744, 0.9461, 0.9457, 0.9739, 0.9005, 0.9758, 0.9351, 0.9224, 0.9429, 0.9138, 0.9526, 0.9416, 0.9534, 0.976, 0.9503, 0.933, 0.9839, 0.9455, 0.9054, 0.8943, 0.9342, 0.9721, 0.9591, 0.9, 0.8968, 0.9288, 0.9369, 0.8926, 0.9304, 0.9402, 0.8719, 0.9377, 0.964, 0.9011, 0.9526, 0.9739, 0.9398, 0.9495, 0.9395, 0.9421, 0.9468, 0.8687], 'AP': [0.9834, 0.9572, 0.9746, 0.9932, 0.973, 0.9982, 0.9732, 0.9231, 0.9877, 0.9746, 0.9639, 0.9798, 0.8851, 0.988, 0.9648, 0.9824, 0.9924, 0.9964, 0.9757, 0.9821, 0.9811, 0.9433, 0.9785, 0.9885, 0.9791, 0.9794, 0.9817, 0.9836, 0.9853, 0.97, 0.9248, 0.9395, 0.9704, 0.9777, 0.9712, 0.9529, 0.9752, 0.9881, 0.9711, 0.9316, 1.0, 0.9269, 0.9868, 0.9905, 0.9768, 0.9885, 0.9223, 0.9805, 0.9235, 0.9759, 0.9507, 0.9712, 0.9943, 0.9805, 0.9863, 0.9884, 0.9961, 0.9741, 0.9677, 0.9306, 0.9294, 0.9704, 0.9757, 0.9825, 0.974, 0.9442, 0.994, 0.9869, 0.986, 0.9083, 0.9531, 0.9634, 0.986, 0.9775, 0.9579, 0.9534, 0.9171, 0.9857, 0.994, 0.9962, 0.9776, 0.9942, 0.9837, 0.9462, 0.9919, 0.9921, 0.9858, 0.9793, 0.962, 0.9858, 0.9956, 0.9014, 0.9757, 0.9657, 0.9746, 0.9835, 0.9958, 0.9326, 0.9685, 0.9752, 0.9814, 0.97, 0.9746, 0.9617, 0.9904, 0.9797, 0.9935, 0.9378, 0.9863, 0.9768, 0.9228, 0.9964, 0.9899, 0.9788, 0.8352, 0.9739, 0.903, 0.9886, 0.9763, 0.9901, 0.9884, 0.9762, 0.985, 0.9889, 0.9825, 0.9311, 0.9873, 0.9849, 0.9708, 0.947, 0.7102, 0.9768, 0.9936, 0.9838, 0.9838, 0.9895, 0.9541, 0.9898, 0.9773, 0.9668, 0.9761, 0.963, 0.9892, 0.9815, 0.9859, 0.9963, 0.9896, 0.9754, 0.993, 0.9745, 0.9576, 0.9411, 0.9723, 0.9894, 0.9902, 0.939, 0.9378, 0.9793, 0.9772, 0.9322, 0.9787, 0.9718, 0.9267, 0.9828, 0.9844, 0.94, 0.9842, 0.991, 0.9741, 0.9863, 0.9722, 0.9767, 0.9884, 0.9251], 'Recall@P=50': [0.9893, 0.976, 0.9903, 0.996, 0.976, 1.0, 0.9872, 0.956, 0.9968, 0.9945, 0.988, 0.9948, 0.92, 0.994, 0.982, 0.992, 0.9984, 1.0, 0.988, 0.988, 0.992, 0.974, 0.988, 0.996, 0.984, 0.9936, 0.988, 0.992, 0.9982, 0.9848, 0.956, 0.964, 0.988, 0.98, 0.99, 0.964, 0.992, 0.9989, 0.985, 0.956, 1.0, 0.96, 0.992, 0.992, 0.984, 0.992, 0.968, 0.988, 0.96, 0.988, 0.968, 0.9879, 0.996, 0.9943, 0.994, 0.996, 1.0, 0.984, 0.988, 0.944, 0.96, 0.988, 0.992, 0.988, 0.9887, 0.97, 0.996, 0.9947, 0.99, 0.944, 0.976, 0.982, 0.996, 0.9912, 0.976, 0.98, 0.956, 0.9947, 0.9987, 1.0, 0.9947, 0.996, 0.9982, 0.956, 0.998, 0.996, 0.9985, 0.988, 0.9913, 0.992, 0.998, 0.948, 0.988, 0.9832, 0.98, 0.9967, 0.996, 0.976, 0.986, 0.992, 0.9937, 0.98, 0.984, 0.9867, 0.992, 0.9907, 1.0, 0.956, 0.9952, 0.98, 0.964, 1.0, 0.9992, 0.992, 0.936, 0.9867, 0.956, 0.996, 0.992, 0.988, 0.996, 0.994, 0.996, 0.992, 0.998, 0.972, 0.992, 0.992, 0.988, 0.976, 0.892, 0.98, 0.996, 0.996, 0.996, 0.992, 0.98, 0.992, 0.9933, 0.988, 0.988, 0.984, 1.0, 0.991, 0.9928, 1.0, 0.9997, 0.9907, 0.992, 0.984, 0.978, 0.972, 0.9893, 0.992, 0.994, 0.96, 0.96, 0.994, 0.988, 0.956, 0.994, 0.988, 0.96, 0.9965, 0.992, 0.96, 0.9933, 0.994, 0.988, 1.0, 0.976, 0.984, 0.9998, 0.964], 'micro': 0.9799, 'macro': 0.9692, 'weighted': 0.9783}
2024-07-27 10:52:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:52:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:52:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 25456 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_42_iter_25456.pt
2024-07-27 10:52:15 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 25456 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_42_iter_25456.pt
[31m===========================================================================[0m
2024-07-27 10:52:17 - [32m[1mINFO   [0m - Training epoch 43
2024-07-27 10:52:18 - [34m[1mLOGS   [0m - Epoch:  43 [   25457/10000000], loss: {'classification': 4.5661, 'neural_augmentation': 10.2501, 'total_loss': 14.8162}, LR: [3e-06, 3e-06], Avg. batch load time: 0.430, Elapsed time:  0.53
2024-07-27 10:52:58 - [34m[1mLOGS   [0m - Epoch:  43 [   25957/10000000], loss: {'classification': 4.7242, 'neural_augmentation': 9.9094, 'total_loss': 14.6336}, LR: [3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 40.75
2024-07-27 10:53:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'classification': 4.7407, 'neural_augmentation': 9.9161, 'total_loss': 14.6569}
2024-07-27 10:53:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'classification': 2.4089, 'neural_augmentation': 0.0, 'total_loss': 2.4089} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9533, 0.9102, 0.9321, 0.9839, 0.9493, 0.986, 0.9309, 0.878, 0.9532, 0.9194, 0.9133, 0.934, 0.822, 0.9606, 0.9266, 0.9518, 0.9746, 0.986, 0.9533, 0.9469, 0.9576, 0.8891, 0.9409, 0.961, 0.9401, 0.938, 0.9497, 0.9577, 0.9413, 0.9281, 0.8724, 0.8819, 0.9452, 0.9505, 0.9161, 0.9084, 0.9576, 0.9477, 0.934, 0.8961, 0.998, 0.8694, 0.9467, 0.9738, 0.9446, 0.9671, 0.8396, 0.9652, 0.8663, 0.9388, 0.8894, 0.9225, 0.9828, 0.9414, 0.9609, 0.9553, 0.9828, 0.9426, 0.9393, 0.8725, 0.8795, 0.9291, 0.9448, 0.9514, 0.931, 0.8982, 0.9741, 0.9619, 0.959, 0.8427, 0.9187, 0.9123, 0.9597, 0.9391, 0.9099, 0.9015, 0.883, 0.9549, 0.9669, 0.9698, 0.9316, 0.978, 0.9404, 0.8875, 0.9687, 0.9639, 0.9416, 0.9433, 0.901, 0.9472, 0.9801, 0.8376, 0.9409, 0.9179, 0.9555, 0.9421, 0.9879, 0.8635, 0.9195, 0.9214, 0.9477, 0.9193, 0.9374, 0.8978, 0.9737, 0.9417, 0.9741, 0.8947, 0.9582, 0.9506, 0.8735, 0.9719, 0.9538, 0.9432, 0.7698, 0.9382, 0.8434, 0.9561, 0.9212, 0.9718, 0.9607, 0.93, 0.9569, 0.9671, 0.9344, 0.8697, 0.9595, 0.9522, 0.9414, 0.8955, 0.6815, 0.9528, 0.9764, 0.9505, 0.9457, 0.9738, 0.9023, 0.9758, 0.9378, 0.9299, 0.9435, 0.9256, 0.9641, 0.9432, 0.9577, 0.9695, 0.95, 0.9307, 0.9819, 0.9403, 0.9065, 0.8893, 0.9234, 0.9737, 0.9636, 0.8852, 0.8861, 0.9283, 0.94, 0.8944, 0.9311, 0.9375, 0.8719, 0.9375, 0.9622, 0.8889, 0.9519, 0.9728, 0.9426, 0.9533, 0.9482, 0.9489, 0.9463, 0.8683], 'AP': [0.9826, 0.9543, 0.9746, 0.9925, 0.9759, 0.9973, 0.974, 0.9234, 0.9882, 0.9742, 0.9605, 0.9785, 0.8859, 0.9887, 0.9643, 0.9833, 0.9916, 0.9976, 0.9775, 0.9826, 0.9833, 0.9437, 0.9757, 0.9899, 0.9782, 0.9794, 0.9815, 0.9824, 0.9853, 0.9715, 0.9249, 0.9404, 0.973, 0.9833, 0.9709, 0.9517, 0.9764, 0.9878, 0.9712, 0.9503, 1.0, 0.9337, 0.9872, 0.9914, 0.979, 0.9892, 0.921, 0.9815, 0.9246, 0.9775, 0.9411, 0.9721, 0.994, 0.9798, 0.9869, 0.9896, 0.9968, 0.9736, 0.9679, 0.938, 0.9346, 0.971, 0.9751, 0.9835, 0.9744, 0.9451, 0.9956, 0.9878, 0.9866, 0.9091, 0.955, 0.9597, 0.9866, 0.9768, 0.9565, 0.953, 0.9153, 0.9867, 0.9931, 0.9956, 0.9792, 0.9958, 0.9843, 0.935, 0.9921, 0.992, 0.986, 0.9767, 0.963, 0.9872, 0.9965, 0.9002, 0.9753, 0.9678, 0.9759, 0.9831, 0.9961, 0.9282, 0.9677, 0.9754, 0.9819, 0.9668, 0.9695, 0.9604, 0.9908, 0.9813, 0.9919, 0.935, 0.9876, 0.9821, 0.9244, 0.9952, 0.9898, 0.9786, 0.8262, 0.9771, 0.899, 0.9878, 0.9758, 0.9906, 0.9887, 0.9777, 0.9859, 0.9893, 0.9828, 0.9381, 0.987, 0.9854, 0.972, 0.946, 0.7019, 0.9826, 0.9947, 0.9839, 0.9836, 0.9897, 0.955, 0.9905, 0.9785, 0.9688, 0.9755, 0.9664, 0.9911, 0.9825, 0.9867, 0.9949, 0.9894, 0.9777, 0.9918, 0.9768, 0.9582, 0.9403, 0.9651, 0.9899, 0.9921, 0.9349, 0.9328, 0.9765, 0.9782, 0.9513, 0.9765, 0.9694, 0.9259, 0.9821, 0.9842, 0.9341, 0.9834, 0.9914, 0.9768, 0.9853, 0.9757, 0.9775, 0.9886, 0.9251], 'Recall@P=50': [0.9907, 0.976, 0.9903, 0.992, 0.98, 1.0, 0.992, 0.96, 0.9976, 0.9942, 0.984, 0.9944, 0.92, 0.996, 0.98, 0.996, 0.996, 1.0, 0.984, 0.988, 0.992, 0.972, 0.984, 0.9984, 0.988, 0.992, 0.988, 0.992, 0.9984, 0.988, 0.948, 0.976, 0.984, 0.992, 0.9885, 0.972, 0.984, 0.9992, 0.987, 0.98, 1.0, 0.972, 0.992, 0.996, 0.992, 0.992, 0.9693, 0.984, 0.9627, 0.988, 0.96, 0.9868, 0.996, 0.9931, 0.992, 0.996, 1.0, 0.98, 0.984, 0.964, 0.976, 0.984, 0.98, 0.988, 0.99, 0.97, 0.996, 0.9933, 0.99, 0.928, 0.98, 0.98, 0.996, 0.988, 0.976, 0.98, 0.96, 0.9947, 0.9973, 1.0, 0.9937, 0.996, 0.9986, 0.952, 1.0, 0.996, 0.9989, 0.98, 0.9904, 0.996, 0.998, 0.952, 0.984, 0.9824, 0.98, 0.9967, 0.996, 0.972, 0.9813, 0.992, 0.9926, 0.982, 0.984, 0.984, 0.992, 0.9917, 0.998, 0.96, 0.9936, 0.988, 0.964, 1.0, 0.9992, 0.992, 0.928, 0.988, 0.964, 0.9953, 0.992, 0.996, 0.996, 0.994, 0.996, 0.992, 0.9977, 0.968, 0.992, 0.992, 0.98, 0.982, 0.892, 0.992, 0.996, 0.996, 0.9933, 0.992, 0.9787, 0.992, 0.993, 0.98, 0.98, 0.976, 1.0, 0.99, 0.9944, 1.0, 0.9997, 0.9933, 0.992, 0.988, 0.98, 0.974, 0.9787, 0.992, 0.998, 0.964, 0.96, 0.994, 0.988, 0.984, 0.993, 0.988, 0.948, 0.9975, 0.992, 0.956, 0.992, 0.994, 0.988, 1.0, 0.98, 0.984, 0.9998, 0.952], 'micro': 0.9798, 'macro': 0.9694, 'weighted': 0.9784}
2024-07-27 10:53:30 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:53:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:53:31 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:53:32 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 26048 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_43_iter_26048.pt
2024-07-27 10:53:32 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 26048 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_43_iter_26048.pt
[31m===========================================================================[0m
2024-07-27 10:53:34 - [32m[1mINFO   [0m - Training epoch 44
2024-07-27 10:53:35 - [34m[1mLOGS   [0m - Epoch:  44 [   26049/10000000], loss: {'classification': 5.6875, 'neural_augmentation': 9.4624, 'total_loss': 15.15}, LR: [2e-06, 2e-06], Avg. batch load time: 0.833, Elapsed time:  0.92
2024-07-27 10:54:12 - [34m[1mLOGS   [0m - Epoch:  44 [   26549/10000000], loss: {'classification': 4.7505, 'neural_augmentation': 9.9859, 'total_loss': 14.7364}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 38.38
2024-07-27 10:54:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'classification': 4.7367, 'neural_augmentation': 9.9714, 'total_loss': 14.7081}
2024-07-27 10:54:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'classification': 2.4306, 'neural_augmentation': 0.0, 'total_loss': 2.4306} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9526, 0.917, 0.9318, 0.9819, 0.9474, 0.986, 0.9282, 0.8842, 0.9515, 0.9208, 0.9137, 0.9357, 0.8235, 0.9564, 0.9296, 0.9533, 0.9746, 0.9839, 0.953, 0.9611, 0.9514, 0.8812, 0.9441, 0.9607, 0.9526, 0.9364, 0.9611, 0.9616, 0.945, 0.9323, 0.8742, 0.8885, 0.935, 0.9532, 0.9196, 0.9117, 0.9535, 0.9476, 0.9314, 0.8957, 0.998, 0.874, 0.9539, 0.9719, 0.9361, 0.9693, 0.8425, 0.9627, 0.8538, 0.932, 0.8874, 0.9204, 0.984, 0.9415, 0.9577, 0.9571, 0.9839, 0.9469, 0.9317, 0.8821, 0.8724, 0.9315, 0.9441, 0.9633, 0.9304, 0.895, 0.9762, 0.9568, 0.9615, 0.8311, 0.9215, 0.9242, 0.9572, 0.9399, 0.917, 0.9061, 0.8917, 0.9492, 0.9668, 0.972, 0.9339, 0.976, 0.9405, 0.8861, 0.9668, 0.9663, 0.9415, 0.9551, 0.9027, 0.9522, 0.9809, 0.8302, 0.9463, 0.9116, 0.9553, 0.9404, 0.988, 0.8755, 0.9177, 0.9209, 0.9443, 0.9253, 0.9431, 0.904, 0.9697, 0.9395, 0.9716, 0.9032, 0.9544, 0.9518, 0.8857, 0.9737, 0.9546, 0.939, 0.7811, 0.9348, 0.8387, 0.954, 0.9231, 0.9717, 0.9496, 0.9337, 0.9553, 0.9652, 0.9367, 0.877, 0.9528, 0.95, 0.939, 0.8933, 0.6811, 0.9553, 0.9801, 0.9482, 0.9507, 0.9719, 0.9058, 0.9717, 0.9359, 0.9328, 0.9455, 0.9199, 0.9583, 0.9421, 0.9551, 0.9715, 0.949, 0.9289, 0.978, 0.9417, 0.9052, 0.8909, 0.9281, 0.9699, 0.9632, 0.8879, 0.8894, 0.932, 0.9366, 0.8898, 0.9367, 0.9347, 0.8784, 0.9368, 0.9624, 0.8948, 0.9531, 0.9729, 0.9416, 0.9539, 0.9495, 0.9433, 0.9463, 0.8727], 'AP': [0.982, 0.9607, 0.9753, 0.9912, 0.9721, 0.9972, 0.9746, 0.9273, 0.9869, 0.9742, 0.9599, 0.9792, 0.8927, 0.9834, 0.9649, 0.9829, 0.9924, 0.9958, 0.9775, 0.9826, 0.9789, 0.9415, 0.9737, 0.9902, 0.9796, 0.9775, 0.9815, 0.9836, 0.9855, 0.9737, 0.9243, 0.9372, 0.9716, 0.9824, 0.9713, 0.9585, 0.9783, 0.9879, 0.9699, 0.9434, 1.0, 0.9307, 0.9881, 0.9893, 0.9777, 0.9886, 0.9235, 0.9792, 0.9213, 0.9762, 0.9498, 0.9702, 0.9931, 0.9805, 0.985, 0.9886, 0.9959, 0.9697, 0.9663, 0.9369, 0.9326, 0.9728, 0.9766, 0.9828, 0.9763, 0.9452, 0.9951, 0.9849, 0.9864, 0.8995, 0.9552, 0.9585, 0.9852, 0.9779, 0.9605, 0.9549, 0.915, 0.9857, 0.9936, 0.9955, 0.9797, 0.9953, 0.9836, 0.944, 0.9924, 0.9922, 0.9856, 0.975, 0.964, 0.9876, 0.9965, 0.8931, 0.9766, 0.9622, 0.9759, 0.9834, 0.9955, 0.9331, 0.967, 0.9763, 0.9811, 0.9655, 0.9728, 0.9619, 0.9891, 0.9803, 0.9926, 0.9416, 0.9846, 0.9826, 0.9261, 0.9949, 0.9901, 0.9786, 0.8438, 0.9748, 0.8957, 0.9875, 0.9781, 0.9893, 0.9828, 0.9783, 0.9847, 0.9892, 0.9828, 0.936, 0.9811, 0.9843, 0.9719, 0.9409, 0.7076, 0.9825, 0.9944, 0.9847, 0.9841, 0.9887, 0.9576, 0.9886, 0.9786, 0.9698, 0.9732, 0.9618, 0.99, 0.9818, 0.9859, 0.9942, 0.9893, 0.9758, 0.9906, 0.9772, 0.9593, 0.9392, 0.9676, 0.9888, 0.9912, 0.931, 0.9293, 0.9772, 0.9777, 0.9455, 0.9786, 0.9686, 0.9243, 0.9811, 0.9854, 0.9335, 0.9834, 0.9915, 0.973, 0.987, 0.9727, 0.9788, 0.9882, 0.9237], 'Recall@P=50': [0.99, 0.98, 0.9909, 0.992, 0.976, 1.0, 0.9904, 0.968, 0.996, 0.9935, 0.99, 0.994, 0.928, 0.996, 0.98, 0.996, 0.9968, 1.0, 0.98, 0.992, 0.992, 0.966, 0.988, 0.9992, 0.984, 0.9888, 0.992, 0.992, 0.9979, 0.9888, 0.952, 0.968, 0.988, 0.988, 0.989, 0.976, 0.988, 0.999, 0.983, 0.964, 1.0, 0.968, 0.996, 0.992, 0.988, 0.992, 0.9693, 0.98, 0.9667, 0.988, 0.972, 0.9842, 0.994, 0.9931, 0.992, 0.9953, 0.998, 0.98, 0.984, 0.968, 0.968, 0.988, 0.988, 0.988, 0.992, 0.964, 0.996, 0.9933, 0.992, 0.932, 0.984, 0.978, 0.996, 0.9896, 0.976, 0.976, 0.964, 0.9933, 0.9987, 1.0, 0.9926, 0.996, 0.9978, 0.968, 1.0, 0.996, 0.9987, 0.98, 0.9913, 0.996, 0.998, 0.956, 0.992, 0.9784, 0.976, 0.9967, 0.996, 0.984, 0.984, 0.992, 0.9943, 0.978, 0.976, 0.9867, 0.992, 0.99, 1.0, 0.968, 0.9912, 0.992, 0.968, 0.996, 0.9993, 0.99, 0.948, 0.9887, 0.952, 0.9953, 0.992, 0.992, 0.996, 0.992, 0.992, 0.992, 0.9977, 0.968, 0.984, 0.992, 0.992, 0.98, 0.88, 0.996, 0.996, 0.996, 0.9927, 0.992, 0.9747, 0.992, 0.9937, 0.988, 0.98, 0.968, 1.0, 0.991, 0.9936, 0.996, 0.9999, 0.9907, 0.992, 0.986, 0.98, 0.974, 0.984, 0.992, 0.996, 0.952, 0.948, 0.99, 0.988, 0.976, 0.994, 0.988, 0.948, 0.9968, 0.992, 0.952, 0.992, 0.994, 0.988, 1.0, 0.984, 0.984, 0.9994, 0.952], 'micro': 0.9797, 'macro': 0.9691, 'weighted': 0.9782}
2024-07-27 10:54:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:54:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:54:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 26640 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_44_iter_26640.pt
2024-07-27 10:54:45 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 26640 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_44_iter_26640.pt
[31m===========================================================================[0m
2024-07-27 10:54:47 - [32m[1mINFO   [0m - Training epoch 45
2024-07-27 10:54:48 - [34m[1mLOGS   [0m - Epoch:  45 [   26641/10000000], loss: {'classification': 5.3781, 'neural_augmentation': 8.9149, 'total_loss': 14.293}, LR: [2e-06, 2e-06], Avg. batch load time: 0.689, Elapsed time:  0.77
2024-07-27 10:55:25 - [34m[1mLOGS   [0m - Epoch:  45 [   27141/10000000], loss: {'classification': 4.6825, 'neural_augmentation': 10.0135, 'total_loss': 14.696}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 38.22
2024-07-27 10:55:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'classification': 4.6653, 'neural_augmentation': 10.0027, 'total_loss': 14.6679}
2024-07-27 10:55:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'classification': 2.3738, 'neural_augmentation': 0.0, 'total_loss': 2.3738} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.953, 0.9158, 0.9277, 0.9837, 0.9452, 0.986, 0.9297, 0.8856, 0.9519, 0.922, 0.9188, 0.9403, 0.8214, 0.9574, 0.9249, 0.9549, 0.9746, 0.9801, 0.9526, 0.9516, 0.9608, 0.8803, 0.94, 0.9613, 0.9489, 0.941, 0.9553, 0.9556, 0.9452, 0.928, 0.8682, 0.8926, 0.9341, 0.9506, 0.9178, 0.9125, 0.9543, 0.9508, 0.9333, 0.893, 0.998, 0.8763, 0.9577, 0.9758, 0.945, 0.9673, 0.8421, 0.9654, 0.8573, 0.9395, 0.899, 0.9192, 0.984, 0.9442, 0.9598, 0.9557, 0.9849, 0.9371, 0.9356, 0.8734, 0.8798, 0.9301, 0.9528, 0.9508, 0.9318, 0.8947, 0.9744, 0.9586, 0.9607, 0.8493, 0.9262, 0.9232, 0.9556, 0.9398, 0.914, 0.9093, 0.8968, 0.9523, 0.9692, 0.9779, 0.9372, 0.9743, 0.9418, 0.9027, 0.9699, 0.9659, 0.9404, 0.9465, 0.9092, 0.9539, 0.982, 0.834, 0.9482, 0.9151, 0.9512, 0.9425, 0.9879, 0.8827, 0.9218, 0.9212, 0.9447, 0.9255, 0.9447, 0.9035, 0.9757, 0.944, 0.9726, 0.8933, 0.9545, 0.9569, 0.8935, 0.9757, 0.9552, 0.9477, 0.7649, 0.9357, 0.8536, 0.9575, 0.9189, 0.9757, 0.9539, 0.9365, 0.9548, 0.9698, 0.9362, 0.8721, 0.9565, 0.9504, 0.935, 0.9005, 0.6832, 0.9535, 0.9762, 0.9537, 0.95, 0.9738, 0.9083, 0.9757, 0.9381, 0.9259, 0.9489, 0.9124, 0.957, 0.9471, 0.9572, 0.9778, 0.9514, 0.9308, 0.98, 0.9447, 0.9142, 0.891, 0.9352, 0.9737, 0.9624, 0.8844, 0.888, 0.9325, 0.9424, 0.8903, 0.936, 0.9378, 0.8735, 0.9384, 0.964, 0.8782, 0.9568, 0.9711, 0.9452, 0.9443, 0.9446, 0.9493, 0.9458, 0.8696], 'AP': [0.9817, 0.9597, 0.9756, 0.9912, 0.9751, 0.9976, 0.9738, 0.9263, 0.9878, 0.9752, 0.9644, 0.9803, 0.8902, 0.9873, 0.9655, 0.9837, 0.9925, 0.9973, 0.975, 0.9836, 0.9823, 0.943, 0.9716, 0.9894, 0.9788, 0.9799, 0.9829, 0.9848, 0.9861, 0.9724, 0.9255, 0.9424, 0.9721, 0.9859, 0.972, 0.9559, 0.9761, 0.9888, 0.972, 0.944, 1.0, 0.9366, 0.9881, 0.9887, 0.9785, 0.9882, 0.9273, 0.9822, 0.9254, 0.978, 0.9545, 0.9719, 0.9931, 0.9817, 0.986, 0.9893, 0.9961, 0.9686, 0.9672, 0.9326, 0.9383, 0.9694, 0.9771, 0.9834, 0.9755, 0.9465, 0.9962, 0.9857, 0.9848, 0.9161, 0.9563, 0.9627, 0.9855, 0.9785, 0.9602, 0.9508, 0.9186, 0.9859, 0.9949, 0.9968, 0.9811, 0.9962, 0.9842, 0.9506, 0.9917, 0.9921, 0.9864, 0.9741, 0.9645, 0.9873, 0.9951, 0.8973, 0.9783, 0.9671, 0.9745, 0.9839, 0.9957, 0.9348, 0.9682, 0.9741, 0.9822, 0.9656, 0.9737, 0.9619, 0.9887, 0.9817, 0.9925, 0.9454, 0.9854, 0.986, 0.9264, 0.9966, 0.9904, 0.9792, 0.8304, 0.9759, 0.9011, 0.9886, 0.975, 0.9873, 0.9876, 0.9792, 0.9846, 0.9895, 0.9835, 0.9321, 0.9845, 0.987, 0.9716, 0.9465, 0.7174, 0.9855, 0.9949, 0.9863, 0.9852, 0.9867, 0.958, 0.988, 0.9791, 0.9713, 0.9716, 0.9625, 0.9891, 0.9827, 0.987, 0.9967, 0.9902, 0.9781, 0.9917, 0.9763, 0.9611, 0.9414, 0.9716, 0.9869, 0.9921, 0.9318, 0.9294, 0.9792, 0.9787, 0.9429, 0.978, 0.9709, 0.928, 0.9829, 0.9841, 0.931, 0.9852, 0.9904, 0.9744, 0.9858, 0.9742, 0.979, 0.9888, 0.9266], 'Recall@P=50': [0.9907, 0.98, 0.9914, 0.992, 0.976, 1.0, 0.988, 0.96, 0.9968, 0.9957, 0.992, 0.9948, 0.932, 0.996, 0.98, 0.996, 0.996, 1.0, 0.98, 0.992, 0.992, 0.968, 0.984, 0.9968, 0.984, 0.992, 0.992, 0.996, 0.9986, 0.9872, 0.952, 0.976, 0.988, 0.996, 0.9905, 0.972, 0.98, 0.9989, 0.983, 0.964, 1.0, 0.972, 1.0, 0.988, 0.988, 0.992, 0.976, 0.984, 0.9627, 0.988, 0.968, 0.9879, 0.994, 0.9949, 0.99, 0.9953, 0.998, 0.98, 0.988, 0.96, 0.976, 0.992, 0.988, 0.988, 0.992, 0.966, 1.0, 0.9907, 0.988, 0.956, 0.976, 0.978, 0.996, 0.9888, 0.976, 0.978, 0.96, 0.992, 0.9987, 1.0, 0.9942, 1.0, 0.998, 0.968, 1.0, 0.996, 0.9985, 0.98, 0.9904, 1.0, 0.998, 0.936, 0.988, 0.9808, 0.98, 0.9975, 0.996, 0.98, 0.9873, 0.984, 0.9949, 0.974, 0.984, 0.9853, 0.992, 0.9917, 0.998, 0.964, 0.9936, 0.996, 0.964, 1.0, 0.9993, 0.99, 0.936, 0.988, 0.956, 0.9967, 0.992, 0.988, 0.992, 0.9947, 0.996, 0.992, 0.9983, 0.964, 0.988, 0.992, 0.984, 0.974, 0.896, 0.992, 0.996, 0.996, 0.9953, 0.988, 0.9813, 0.988, 0.9933, 0.996, 0.98, 0.972, 1.0, 0.991, 0.9936, 1.0, 0.9999, 0.9947, 0.992, 0.982, 0.982, 0.974, 0.9827, 0.988, 0.998, 0.952, 0.948, 0.995, 0.992, 0.976, 0.992, 0.988, 0.96, 0.996, 0.992, 0.948, 0.9927, 0.994, 0.984, 1.0, 0.976, 0.984, 0.9996, 0.96], 'micro': 0.9806, 'macro': 0.97, 'weighted': 0.9791}
2024-07-27 10:55:58 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:55:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9676.pt
2024-07-27 10:55:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9690.pt', 'checkpoint_score_0.9691.pt', 'checkpoint_score_0.9692.pt', 'checkpoint_score_0.9694.pt', 'checkpoint_score_0.9700.pt']
2024-07-27 10:56:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:56:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:56:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:56:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 27232 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_45_iter_27232.pt
2024-07-27 10:56:03 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 27232 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_45_iter_27232.pt
[31m===========================================================================[0m
2024-07-27 10:56:05 - [32m[1mINFO   [0m - Training epoch 46
2024-07-27 10:56:05 - [34m[1mLOGS   [0m - Epoch:  46 [   27233/10000000], loss: {'classification': 5.1001, 'neural_augmentation': 10.5444, 'total_loss': 15.6444}, LR: [2e-06, 2e-06], Avg. batch load time: 0.556, Elapsed time:  0.64
2024-07-27 10:56:43 - [34m[1mLOGS   [0m - Epoch:  46 [   27733/10000000], loss: {'classification': 4.5865, 'neural_augmentation': 9.8476, 'total_loss': 14.4341}, LR: [2e-06, 2e-06], Avg. batch load time: 0.001, Elapsed time: 38.19
2024-07-27 10:56:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'classification': 4.6019, 'neural_augmentation': 9.8572, 'total_loss': 14.4591}
2024-07-27 10:57:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'classification': 2.3713, 'neural_augmentation': 0.0, 'total_loss': 2.3713} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9522, 0.9158, 0.9339, 0.9818, 0.9489, 0.986, 0.9326, 0.899, 0.9547, 0.9198, 0.9172, 0.9417, 0.8294, 0.959, 0.9222, 0.9551, 0.9718, 0.9899, 0.9508, 0.9528, 0.9616, 0.8816, 0.9457, 0.9623, 0.9519, 0.9389, 0.951, 0.9641, 0.9476, 0.9319, 0.8661, 0.8948, 0.9284, 0.9495, 0.9192, 0.9124, 0.9501, 0.9483, 0.9285, 0.8973, 0.998, 0.8732, 0.9474, 0.9757, 0.9441, 0.9672, 0.8424, 0.9628, 0.8662, 0.9363, 0.9027, 0.9212, 0.9819, 0.946, 0.9565, 0.9569, 0.9869, 0.9419, 0.9405, 0.8696, 0.8678, 0.9405, 0.9441, 0.9508, 0.9329, 0.8965, 0.9781, 0.9543, 0.9576, 0.8528, 0.9261, 0.9235, 0.9576, 0.9421, 0.9195, 0.91, 0.905, 0.9568, 0.9688, 0.9721, 0.9376, 0.978, 0.9411, 0.9068, 0.9672, 0.9658, 0.9445, 0.9476, 0.9086, 0.9459, 0.981, 0.8252, 0.9419, 0.9124, 0.9506, 0.9424, 0.99, 0.8828, 0.9199, 0.9202, 0.9462, 0.9283, 0.9518, 0.9003, 0.9738, 0.9398, 0.9736, 0.8938, 0.9591, 0.9535, 0.9031, 0.9718, 0.9562, 0.9494, 0.7654, 0.9407, 0.8571, 0.9568, 0.9241, 0.9757, 0.9545, 0.9354, 0.9574, 0.9661, 0.9364, 0.8683, 0.9511, 0.9518, 0.93, 0.8994, 0.6784, 0.9555, 0.9801, 0.9541, 0.944, 0.9737, 0.9079, 0.9778, 0.9408, 0.9283, 0.9512, 0.9216, 0.9531, 0.9487, 0.9574, 0.9738, 0.9526, 0.9325, 0.978, 0.9463, 0.915, 0.8977, 0.9377, 0.9738, 0.9572, 0.8889, 0.8884, 0.9328, 0.9409, 0.8943, 0.9353, 0.9426, 0.8673, 0.9381, 0.9624, 0.8944, 0.9528, 0.9721, 0.9357, 0.952, 0.9443, 0.9467, 0.9454, 0.8706], 'AP': [0.9828, 0.9563, 0.9766, 0.9918, 0.9737, 0.9981, 0.9754, 0.9274, 0.9884, 0.9753, 0.9656, 0.9806, 0.886, 0.989, 0.966, 0.9821, 0.9917, 0.9967, 0.9767, 0.9833, 0.9834, 0.9419, 0.9743, 0.9894, 0.982, 0.9798, 0.9834, 0.9856, 0.9863, 0.9722, 0.9255, 0.9465, 0.9715, 0.9829, 0.9717, 0.9571, 0.9764, 0.9888, 0.9697, 0.9363, 1.0, 0.9359, 0.9878, 0.9925, 0.9788, 0.9882, 0.9244, 0.9813, 0.9253, 0.9783, 0.952, 0.9718, 0.9942, 0.9816, 0.9844, 0.989, 0.9967, 0.9719, 0.9656, 0.9344, 0.9368, 0.9761, 0.9747, 0.9845, 0.9755, 0.9456, 0.9958, 0.9862, 0.9843, 0.9183, 0.9561, 0.9641, 0.9831, 0.977, 0.9578, 0.9575, 0.917, 0.9873, 0.9936, 0.9959, 0.9812, 0.9962, 0.9843, 0.9477, 0.9919, 0.9923, 0.9863, 0.9756, 0.9648, 0.9869, 0.9958, 0.8987, 0.9754, 0.9652, 0.9761, 0.9835, 0.996, 0.9335, 0.9694, 0.9724, 0.9827, 0.9679, 0.9731, 0.9603, 0.9921, 0.9801, 0.9923, 0.9435, 0.9879, 0.9823, 0.9262, 0.9959, 0.9902, 0.9798, 0.8341, 0.9748, 0.9014, 0.9889, 0.9727, 0.992, 0.9884, 0.9798, 0.9808, 0.9889, 0.9835, 0.9337, 0.9874, 0.9862, 0.9702, 0.9491, 0.7103, 0.9835, 0.9945, 0.9843, 0.9815, 0.9916, 0.9605, 0.9916, 0.9786, 0.9736, 0.9738, 0.9624, 0.9893, 0.9835, 0.9862, 0.9955, 0.9903, 0.978, 0.9925, 0.9794, 0.9649, 0.9449, 0.9687, 0.9914, 0.9917, 0.9346, 0.9327, 0.9778, 0.9792, 0.9372, 0.9777, 0.9689, 0.9279, 0.9822, 0.985, 0.9342, 0.9845, 0.9914, 0.9705, 0.9861, 0.9748, 0.9782, 0.9885, 0.9268], 'Recall@P=50': [0.9907, 0.976, 0.9903, 0.992, 0.984, 1.0, 0.9904, 0.964, 0.9968, 0.9948, 0.99, 0.9944, 0.912, 0.994, 0.976, 0.992, 0.996, 1.0, 0.984, 0.992, 0.992, 0.968, 0.984, 0.9984, 0.9893, 0.9912, 0.992, 0.992, 0.9986, 0.9848, 0.944, 0.972, 0.984, 0.996, 0.9905, 0.972, 0.988, 0.9988, 0.98, 0.964, 1.0, 0.976, 0.996, 0.996, 0.988, 0.992, 0.9707, 0.984, 0.956, 0.988, 0.964, 0.9889, 0.998, 0.996, 0.99, 0.9953, 1.0, 0.98, 0.988, 0.96, 0.98, 0.992, 0.984, 0.996, 0.99, 0.966, 1.0, 0.992, 0.99, 0.952, 0.976, 0.982, 0.996, 0.9856, 0.976, 0.982, 0.96, 0.9947, 0.996, 1.0, 0.9942, 1.0, 0.9982, 0.96, 1.0, 0.996, 0.9987, 0.98, 0.9896, 1.0, 0.998, 0.952, 0.984, 0.9872, 0.984, 0.9975, 0.996, 0.984, 0.9873, 0.988, 0.9931, 0.976, 0.98, 0.9853, 0.996, 0.991, 0.998, 0.968, 0.9952, 0.992, 0.96, 1.0, 0.9993, 0.992, 0.948, 0.9867, 0.964, 0.9967, 0.988, 0.996, 0.994, 0.992, 0.992, 0.992, 0.9977, 0.964, 0.992, 0.992, 0.984, 0.98, 0.872, 0.988, 0.996, 0.992, 0.992, 0.996, 0.9813, 0.996, 0.9933, 0.992, 0.98, 0.976, 0.996, 0.99, 0.9928, 1.0, 0.9998, 0.9933, 0.996, 0.986, 0.984, 0.974, 0.988, 0.996, 0.998, 0.952, 0.956, 0.994, 0.988, 0.96, 0.994, 0.988, 0.956, 0.9965, 0.992, 0.956, 0.9913, 0.994, 0.98, 0.996, 0.984, 0.98, 0.9996, 0.952], 'micro': 0.9805, 'macro': 0.9701, 'weighted': 0.979}
2024-07-27 10:57:15 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:57:15 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9690.pt
2024-07-27 10:57:15 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9691.pt', 'checkpoint_score_0.9692.pt', 'checkpoint_score_0.9694.pt', 'checkpoint_score_0.9700.pt', 'checkpoint_score_0.9701.pt']
2024-07-27 10:57:17 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:57:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:57:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:57:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 27824 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_46_iter_27824.pt
2024-07-27 10:57:19 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 27824 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_46_iter_27824.pt
[31m===========================================================================[0m
2024-07-27 10:57:21 - [32m[1mINFO   [0m - Training epoch 47
2024-07-27 10:57:22 - [34m[1mLOGS   [0m - Epoch:  47 [   27825/10000000], loss: {'classification': 4.9199, 'neural_augmentation': 8.8868, 'total_loss': 13.8067}, LR: [2e-06, 2e-06], Avg. batch load time: 0.726, Elapsed time:  0.81
2024-07-27 10:58:00 - [34m[1mLOGS   [0m - Epoch:  47 [   28325/10000000], loss: {'classification': 4.5904, 'neural_augmentation': 9.9225, 'total_loss': 14.5129}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 38.39
2024-07-27 10:58:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'classification': 4.5818, 'neural_augmentation': 9.9231, 'total_loss': 14.5048}
2024-07-27 10:58:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'classification': 2.3374, 'neural_augmentation': 0.0, 'total_loss': 2.3374} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9518, 0.9202, 0.9349, 0.9879, 0.9463, 0.988, 0.934, 0.8815, 0.9507, 0.9236, 0.9238, 0.94, 0.8258, 0.9581, 0.9235, 0.963, 0.975, 0.9819, 0.9448, 0.9547, 0.9613, 0.89, 0.9433, 0.9611, 0.9524, 0.9381, 0.9549, 0.9616, 0.9482, 0.9325, 0.8692, 0.898, 0.9347, 0.9506, 0.9191, 0.9199, 0.9493, 0.9501, 0.9298, 0.8968, 0.998, 0.872, 0.9549, 0.9778, 0.9378, 0.9714, 0.8478, 0.9628, 0.8662, 0.9347, 0.8946, 0.923, 0.984, 0.9445, 0.9602, 0.9576, 0.9849, 0.9457, 0.9424, 0.8721, 0.8712, 0.9409, 0.9465, 0.9553, 0.9302, 0.8902, 0.978, 0.9586, 0.9593, 0.8595, 0.9163, 0.9223, 0.9532, 0.9403, 0.9188, 0.9068, 0.8889, 0.9555, 0.9707, 0.9777, 0.9362, 0.9741, 0.9422, 0.8992, 0.9719, 0.9637, 0.9436, 0.9465, 0.9088, 0.9616, 0.9839, 0.832, 0.9455, 0.9124, 0.9446, 0.9443, 0.992, 0.8902, 0.9199, 0.9228, 0.9459, 0.93, 0.9428, 0.8978, 0.9758, 0.9437, 0.9726, 0.8992, 0.9588, 0.9547, 0.8879, 0.9736, 0.9557, 0.9487, 0.7841, 0.9387, 0.8588, 0.9591, 0.925, 0.9778, 0.958, 0.9375, 0.9551, 0.9681, 0.9384, 0.878, 0.9581, 0.9472, 0.9363, 0.9019, 0.6893, 0.9504, 0.9742, 0.9512, 0.9486, 0.9757, 0.9096, 0.9778, 0.9395, 0.9283, 0.9493, 0.9317, 0.9563, 0.9492, 0.9594, 0.9757, 0.9529, 0.9338, 0.9859, 0.9479, 0.9216, 0.8941, 0.9335, 0.9778, 0.9645, 0.8903, 0.8945, 0.9308, 0.9375, 0.8987, 0.9331, 0.9441, 0.8705, 0.94, 0.9641, 0.8981, 0.9547, 0.975, 0.9366, 0.9495, 0.9412, 0.9526, 0.9484, 0.8694], 'AP': [0.9834, 0.9579, 0.9765, 0.9904, 0.9737, 0.997, 0.9736, 0.928, 0.9885, 0.9753, 0.9636, 0.9802, 0.8916, 0.9883, 0.9667, 0.9834, 0.9934, 0.9968, 0.977, 0.9842, 0.9844, 0.9446, 0.9743, 0.9891, 0.9809, 0.98, 0.9839, 0.987, 0.9863, 0.9736, 0.928, 0.9472, 0.9711, 0.9819, 0.9725, 0.9588, 0.9765, 0.9891, 0.9726, 0.9432, 1.0, 0.9342, 0.9871, 0.9899, 0.9769, 0.9884, 0.927, 0.9812, 0.9254, 0.9766, 0.9471, 0.9721, 0.9927, 0.9816, 0.9872, 0.9891, 0.9972, 0.971, 0.9673, 0.9386, 0.9357, 0.9758, 0.9764, 0.9848, 0.9762, 0.9452, 0.9947, 0.9875, 0.9854, 0.9156, 0.9506, 0.9634, 0.9848, 0.9771, 0.959, 0.9561, 0.9189, 0.987, 0.9949, 0.9953, 0.9802, 0.9953, 0.9849, 0.9432, 0.9926, 0.9917, 0.987, 0.9757, 0.9646, 0.9873, 0.9956, 0.8952, 0.9764, 0.967, 0.9752, 0.9847, 0.9953, 0.9314, 0.9701, 0.9764, 0.9834, 0.9694, 0.9729, 0.9613, 0.9901, 0.9808, 0.9937, 0.94, 0.9869, 0.982, 0.9276, 0.9953, 0.9901, 0.9805, 0.8421, 0.9762, 0.9064, 0.9887, 0.976, 0.9894, 0.9885, 0.98, 0.9839, 0.9893, 0.9835, 0.9379, 0.9871, 0.9853, 0.9725, 0.9473, 0.7155, 0.9823, 0.9939, 0.985, 0.9849, 0.9894, 0.9595, 0.9897, 0.9788, 0.9705, 0.9737, 0.9674, 0.9892, 0.9832, 0.9861, 0.9947, 0.9904, 0.9762, 0.9915, 0.9782, 0.9668, 0.9464, 0.9698, 0.9892, 0.991, 0.9383, 0.9371, 0.9788, 0.9775, 0.9436, 0.9782, 0.9709, 0.9286, 0.9829, 0.9863, 0.9376, 0.9845, 0.9915, 0.9754, 0.9865, 0.9728, 0.9796, 0.989, 0.9286], 'Recall@P=50': [0.9927, 0.976, 0.9926, 0.992, 0.984, 1.0, 0.9864, 0.964, 0.9968, 0.9957, 0.992, 0.9936, 0.928, 0.994, 0.978, 0.992, 0.9976, 1.0, 0.984, 0.996, 0.992, 0.97, 0.984, 0.9968, 0.988, 0.9936, 0.996, 0.996, 0.9984, 0.9872, 0.956, 0.968, 0.988, 0.992, 0.9905, 0.976, 0.984, 0.9992, 0.985, 0.968, 1.0, 0.972, 0.992, 0.992, 0.988, 0.992, 0.9747, 0.984, 0.9573, 0.988, 0.964, 0.9879, 0.994, 0.9931, 0.994, 0.9947, 1.0, 0.98, 0.98, 0.976, 0.976, 0.992, 0.988, 0.996, 0.9893, 0.968, 0.996, 0.992, 0.99, 0.952, 0.976, 0.98, 0.992, 0.9888, 0.976, 0.976, 0.96, 0.9947, 1.0, 1.0, 0.9963, 0.996, 0.9988, 0.956, 1.0, 0.996, 0.9985, 0.98, 0.9904, 0.992, 0.998, 0.944, 0.992, 0.9832, 0.984, 0.9982, 0.996, 0.984, 0.9873, 0.992, 0.9937, 0.98, 0.984, 0.9853, 0.992, 0.9907, 1.0, 0.968, 0.9944, 0.992, 0.96, 1.0, 0.9994, 0.992, 0.944, 0.9907, 0.96, 0.996, 0.992, 0.988, 0.996, 0.994, 0.992, 0.992, 0.998, 0.976, 0.992, 0.992, 0.988, 0.976, 0.912, 0.992, 0.996, 0.996, 0.996, 0.992, 0.98, 0.988, 0.9953, 0.984, 0.98, 0.984, 1.0, 0.99, 0.992, 1.0, 0.9998, 0.9907, 0.992, 0.984, 0.988, 0.976, 0.9813, 0.988, 0.996, 0.964, 0.964, 0.995, 0.988, 0.968, 0.993, 0.988, 0.956, 0.9958, 0.992, 0.96, 0.992, 0.994, 0.988, 1.0, 0.984, 0.988, 0.9995, 0.96], 'micro': 0.9809, 'macro': 0.9705, 'weighted': 0.9794}
2024-07-27 10:58:30 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 10:58:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9691.pt
2024-07-27 10:58:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9692.pt', 'checkpoint_score_0.9694.pt', 'checkpoint_score_0.9700.pt', 'checkpoint_score_0.9701.pt', 'checkpoint_score_0.9705.pt']
2024-07-27 10:58:32 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 10:58:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:58:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:58:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 28416 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_47_iter_28416.pt
2024-07-27 10:58:34 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 28416 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_47_iter_28416.pt
[31m===========================================================================[0m
2024-07-27 10:58:36 - [32m[1mINFO   [0m - Training epoch 48
2024-07-27 10:58:37 - [34m[1mLOGS   [0m - Epoch:  48 [   28417/10000000], loss: {'classification': 3.6952, 'neural_augmentation': 9.1959, 'total_loss': 12.8911}, LR: [2e-06, 2e-06], Avg. batch load time: 0.616, Elapsed time:  0.70
2024-07-27 10:59:14 - [34m[1mLOGS   [0m - Epoch:  48 [   28917/10000000], loss: {'classification': 4.4286, 'neural_augmentation': 9.8843, 'total_loss': 14.3129}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 38.27
2024-07-27 10:59:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'classification': 4.4346, 'neural_augmentation': 9.8974, 'total_loss': 14.332}
2024-07-27 10:59:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'classification': 2.3679, 'neural_augmentation': 0.0, 'total_loss': 2.3679} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.95, 0.9148, 0.9333, 0.9839, 0.9421, 0.984, 0.9334, 0.8824, 0.9511, 0.9223, 0.9218, 0.939, 0.819, 0.9597, 0.9281, 0.9572, 0.9762, 0.9818, 0.9569, 0.9487, 0.9572, 0.8866, 0.9315, 0.9615, 0.9492, 0.9407, 0.9526, 0.9581, 0.9462, 0.9318, 0.8689, 0.897, 0.9402, 0.9524, 0.9219, 0.908, 0.9555, 0.95, 0.9356, 0.9015, 0.998, 0.8683, 0.9495, 0.9695, 0.9429, 0.9673, 0.8496, 0.9628, 0.8669, 0.94, 0.9016, 0.9239, 0.985, 0.9466, 0.9657, 0.9547, 0.9848, 0.9339, 0.9378, 0.8776, 0.876, 0.936, 0.9459, 0.9526, 0.9311, 0.8944, 0.9762, 0.9565, 0.9592, 0.859, 0.9187, 0.9223, 0.9577, 0.9402, 0.9198, 0.9078, 0.8926, 0.9544, 0.9705, 0.9778, 0.9353, 0.9761, 0.9416, 0.9064, 0.9688, 0.9659, 0.9437, 0.9363, 0.9062, 0.9522, 0.981, 0.832, 0.9487, 0.9193, 0.9549, 0.9441, 0.99, 0.884, 0.9206, 0.9243, 0.9494, 0.9286, 0.9433, 0.9003, 0.9713, 0.9435, 0.9737, 0.8926, 0.9556, 0.9592, 0.8838, 0.9801, 0.9564, 0.9491, 0.7733, 0.9394, 0.856, 0.9563, 0.9259, 0.9736, 0.9586, 0.937, 0.9618, 0.9652, 0.9358, 0.8795, 0.9563, 0.9502, 0.9416, 0.901, 0.6875, 0.9549, 0.976, 0.9535, 0.9503, 0.972, 0.9057, 0.9715, 0.9391, 0.9289, 0.9358, 0.9249, 0.9581, 0.9478, 0.9568, 0.9779, 0.9534, 0.9298, 0.98, 0.9436, 0.9212, 0.9041, 0.9325, 0.9697, 0.9598, 0.8852, 0.8856, 0.9339, 0.9405, 0.9039, 0.9345, 0.9378, 0.8719, 0.9413, 0.9639, 0.8846, 0.9548, 0.9738, 0.9438, 0.9595, 0.9457, 0.9493, 0.9482, 0.8784], 'AP': [0.9833, 0.9561, 0.9764, 0.9904, 0.9719, 0.9979, 0.9754, 0.9272, 0.9882, 0.9766, 0.967, 0.9803, 0.8856, 0.9875, 0.9655, 0.9826, 0.993, 0.9966, 0.9772, 0.9823, 0.9846, 0.943, 0.9695, 0.9893, 0.9793, 0.9804, 0.9817, 0.9866, 0.9865, 0.973, 0.9275, 0.9512, 0.9715, 0.982, 0.973, 0.9564, 0.9778, 0.989, 0.9716, 0.9402, 1.0, 0.9353, 0.9869, 0.9897, 0.9792, 0.9875, 0.9257, 0.9816, 0.9247, 0.9789, 0.9506, 0.9735, 0.9939, 0.9825, 0.9868, 0.9889, 0.9965, 0.9671, 0.9665, 0.9346, 0.9365, 0.9761, 0.9788, 0.9828, 0.9763, 0.9457, 0.9941, 0.9874, 0.9872, 0.9168, 0.9534, 0.9627, 0.9847, 0.9768, 0.9577, 0.9555, 0.9158, 0.9873, 0.9944, 0.9956, 0.9807, 0.9944, 0.9844, 0.9472, 0.9925, 0.9917, 0.9865, 0.9719, 0.9648, 0.9869, 0.9958, 0.8981, 0.9789, 0.9675, 0.9755, 0.9839, 0.9961, 0.9385, 0.9705, 0.9738, 0.983, 0.97, 0.9704, 0.9623, 0.9901, 0.9811, 0.9928, 0.9429, 0.9865, 0.9818, 0.9242, 0.9951, 0.9905, 0.9809, 0.8425, 0.9761, 0.9042, 0.9886, 0.9733, 0.9896, 0.9871, 0.9804, 0.9837, 0.9883, 0.9832, 0.9328, 0.9858, 0.9856, 0.9707, 0.9473, 0.7124, 0.9821, 0.9932, 0.9858, 0.9845, 0.9892, 0.9594, 0.9892, 0.9795, 0.9703, 0.9701, 0.9648, 0.989, 0.9827, 0.9866, 0.9951, 0.9902, 0.9763, 0.9913, 0.9771, 0.9684, 0.9447, 0.9707, 0.9888, 0.9905, 0.9384, 0.9371, 0.9789, 0.9795, 0.9412, 0.9779, 0.9691, 0.9287, 0.9828, 0.9855, 0.9395, 0.9849, 0.9917, 0.9753, 0.9872, 0.973, 0.9806, 0.9888, 0.9285], 'Recall@P=50': [0.9907, 0.976, 0.9909, 0.992, 0.98, 1.0, 0.9896, 0.956, 0.996, 0.9954, 0.988, 0.9952, 0.928, 0.994, 0.976, 0.992, 0.9976, 1.0, 0.98, 0.992, 0.992, 0.966, 0.984, 0.9976, 0.9813, 0.9928, 0.988, 0.996, 0.9986, 0.988, 0.948, 0.984, 0.984, 0.992, 0.9905, 0.972, 0.984, 0.999, 0.98, 0.964, 1.0, 0.976, 0.992, 0.992, 0.988, 0.992, 0.9707, 0.988, 0.9587, 0.992, 0.96, 0.9874, 0.996, 0.9954, 0.99, 0.996, 0.998, 0.98, 0.988, 0.972, 0.976, 0.996, 0.988, 0.988, 0.99, 0.97, 0.996, 0.9933, 0.994, 0.94, 0.976, 0.974, 0.992, 0.9896, 0.968, 0.984, 0.956, 0.996, 0.9973, 1.0, 0.9942, 0.996, 0.9988, 0.96, 1.0, 0.996, 0.9985, 0.984, 0.9896, 0.996, 0.998, 0.944, 0.992, 0.9864, 0.976, 0.9975, 0.996, 0.98, 0.9887, 0.992, 0.9937, 0.978, 0.98, 0.9907, 0.992, 0.9917, 1.0, 0.972, 0.9936, 0.992, 0.964, 0.996, 0.9993, 0.992, 0.944, 0.9887, 0.964, 0.996, 0.996, 0.992, 0.996, 0.9927, 0.992, 0.992, 0.998, 0.972, 0.992, 0.992, 0.984, 0.972, 0.004, 0.992, 0.996, 0.996, 0.9947, 0.992, 0.98, 0.992, 0.993, 0.984, 0.98, 0.968, 0.996, 0.988, 0.9936, 1.0, 0.9999, 0.9893, 0.992, 0.984, 0.986, 0.966, 0.9827, 0.992, 0.998, 0.956, 0.956, 0.995, 0.992, 0.964, 0.993, 0.988, 0.956, 0.9965, 0.992, 0.952, 0.9933, 0.994, 0.988, 1.0, 0.976, 0.992, 0.9996, 0.952], 'micro': 0.9807, 'macro': 0.9702, 'weighted': 0.9793}
2024-07-27 10:59:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 10:59:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 10:59:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 29008 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_48_iter_29008.pt
2024-07-27 10:59:48 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 29008 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_48_iter_29008.pt
[31m===========================================================================[0m
2024-07-27 10:59:50 - [32m[1mINFO   [0m - Training epoch 49
2024-07-27 10:59:51 - [34m[1mLOGS   [0m - Epoch:  49 [   29009/10000000], loss: {'classification': 5.1191, 'neural_augmentation': 11.8157, 'total_loss': 16.9348}, LR: [2e-06, 2e-06], Avg. batch load time: 0.831, Elapsed time:  0.92
2024-07-27 11:00:31 - [34m[1mLOGS   [0m - Epoch:  49 [   29509/10000000], loss: {'classification': 4.5116, 'neural_augmentation': 9.985, 'total_loss': 14.4966}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 40.69
2024-07-27 11:00:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'classification': 4.4933, 'neural_augmentation': 9.9575, 'total_loss': 14.4508}
2024-07-27 11:00:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'classification': 2.3905, 'neural_augmentation': 0.0, 'total_loss': 2.3905} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9515, 0.9158, 0.9322, 0.98, 0.9467, 0.984, 0.9321, 0.8824, 0.9531, 0.9188, 0.927, 0.9368, 0.8168, 0.9646, 0.9239, 0.9574, 0.9756, 0.9859, 0.9528, 0.953, 0.9634, 0.888, 0.94, 0.9643, 0.9472, 0.9395, 0.9535, 0.9556, 0.9452, 0.931, 0.8672, 0.9024, 0.9374, 0.951, 0.921, 0.9098, 0.9577, 0.9495, 0.9286, 0.8996, 0.998, 0.8715, 0.9442, 0.9758, 0.945, 0.9677, 0.8466, 0.9608, 0.8652, 0.9424, 0.8942, 0.9222, 0.983, 0.9457, 0.9618, 0.9561, 0.9828, 0.9393, 0.9443, 0.875, 0.8685, 0.9315, 0.9421, 0.9551, 0.929, 0.8932, 0.978, 0.956, 0.9633, 0.8577, 0.9299, 0.9209, 0.9593, 0.9428, 0.9142, 0.91, 0.887, 0.9532, 0.9659, 0.9757, 0.9323, 0.978, 0.942, 0.8957, 0.9639, 0.9628, 0.9424, 0.943, 0.9105, 0.9431, 0.9829, 0.8403, 0.9417, 0.9169, 0.9504, 0.9432, 0.9899, 0.8948, 0.9191, 0.9231, 0.9448, 0.9281, 0.9414, 0.8996, 0.9718, 0.9437, 0.9718, 0.8981, 0.959, 0.9549, 0.8847, 0.9759, 0.9554, 0.9417, 0.7793, 0.9377, 0.8468, 0.9558, 0.9244, 0.9758, 0.9607, 0.9372, 0.9563, 0.9696, 0.9361, 0.873, 0.9606, 0.9515, 0.9398, 0.9013, 0.6823, 0.9553, 0.978, 0.9463, 0.9477, 0.9759, 0.9038, 0.9737, 0.9369, 0.932, 0.9482, 0.9286, 0.9569, 0.9455, 0.9591, 0.9736, 0.952, 0.9348, 0.9762, 0.9455, 0.9191, 0.8989, 0.9255, 0.9741, 0.9602, 0.8851, 0.8879, 0.9315, 0.945, 0.8945, 0.9332, 0.9443, 0.8703, 0.9414, 0.964, 0.8912, 0.9559, 0.9768, 0.9455, 0.9551, 0.9426, 0.9524, 0.9472, 0.8619], 'AP': [0.9829, 0.9575, 0.9773, 0.9907, 0.9723, 0.997, 0.9749, 0.9249, 0.9885, 0.9753, 0.9643, 0.9797, 0.8836, 0.9879, 0.9648, 0.9816, 0.9926, 0.996, 0.9784, 0.9843, 0.9823, 0.9443, 0.973, 0.9897, 0.9781, 0.9796, 0.9836, 0.9858, 0.9864, 0.9742, 0.9247, 0.9466, 0.9678, 0.983, 0.9734, 0.9575, 0.9765, 0.9889, 0.9721, 0.9476, 1.0, 0.9339, 0.9845, 0.9903, 0.9772, 0.9878, 0.9253, 0.9808, 0.9307, 0.9773, 0.949, 0.9725, 0.9936, 0.9821, 0.9853, 0.9887, 0.9971, 0.9708, 0.9715, 0.9334, 0.934, 0.9747, 0.9764, 0.9847, 0.9759, 0.9462, 0.9951, 0.9863, 0.9851, 0.9167, 0.955, 0.9617, 0.985, 0.9776, 0.959, 0.9564, 0.9173, 0.9862, 0.9942, 0.9966, 0.9795, 0.9954, 0.9846, 0.944, 0.9908, 0.9908, 0.9867, 0.9754, 0.9642, 0.9832, 0.9968, 0.9005, 0.9771, 0.9669, 0.975, 0.9831, 0.9967, 0.9381, 0.969, 0.9746, 0.9825, 0.9663, 0.9658, 0.9607, 0.9903, 0.9814, 0.9917, 0.944, 0.9876, 0.9834, 0.9246, 0.9967, 0.9907, 0.9797, 0.8416, 0.9767, 0.8982, 0.9881, 0.9744, 0.9907, 0.9878, 0.9787, 0.9838, 0.9889, 0.9825, 0.9309, 0.9874, 0.9857, 0.9666, 0.9483, 0.7134, 0.9838, 0.9938, 0.9844, 0.9837, 0.9902, 0.9581, 0.99, 0.9787, 0.9705, 0.9735, 0.9661, 0.9896, 0.981, 0.9866, 0.9961, 0.99, 0.9771, 0.9919, 0.9764, 0.9655, 0.9456, 0.9655, 0.9901, 0.9892, 0.9318, 0.9304, 0.9778, 0.9785, 0.9494, 0.9781, 0.9732, 0.9259, 0.9831, 0.9845, 0.9321, 0.9841, 0.9911, 0.9738, 0.9859, 0.9736, 0.9768, 0.9887, 0.9266], 'Recall@P=50': [0.9913, 0.976, 0.992, 0.988, 0.98, 1.0, 0.9896, 0.96, 0.9976, 0.9954, 0.984, 0.9952, 0.916, 0.992, 0.978, 0.988, 0.996, 1.0, 0.988, 0.992, 0.988, 0.97, 0.98, 0.9976, 0.984, 0.9888, 0.992, 0.996, 0.9988, 0.9872, 0.948, 0.972, 0.98, 0.992, 0.9915, 0.972, 0.98, 0.9989, 0.985, 0.968, 1.0, 0.968, 0.992, 0.992, 0.988, 0.992, 0.976, 0.98, 0.9667, 0.988, 0.968, 0.9874, 0.994, 0.996, 0.988, 0.9953, 1.0, 0.98, 0.984, 0.968, 0.972, 0.992, 0.984, 0.996, 0.9907, 0.966, 0.996, 0.992, 0.99, 0.948, 0.976, 0.974, 0.992, 0.988, 0.976, 0.982, 0.96, 0.9933, 1.0, 1.0, 0.9953, 0.996, 0.9986, 0.956, 0.998, 0.994, 0.9989, 0.98, 0.9887, 0.992, 0.998, 0.948, 0.992, 0.984, 0.98, 0.9967, 0.996, 0.984, 0.9873, 0.992, 0.9949, 0.978, 0.976, 0.9907, 0.992, 0.9917, 0.998, 0.968, 0.9952, 0.992, 0.964, 1.0, 0.9996, 0.99, 0.952, 0.99, 0.96, 0.9973, 0.996, 0.992, 0.994, 0.992, 0.992, 0.992, 0.9983, 0.976, 0.992, 0.9933, 0.98, 0.974, 0.86, 0.992, 0.996, 0.996, 0.9933, 0.992, 0.9773, 0.992, 0.993, 0.988, 0.98, 0.972, 1.0, 0.989, 0.9912, 1.0, 0.9996, 0.992, 0.992, 0.986, 0.988, 0.976, 0.9773, 0.992, 0.992, 0.956, 0.956, 0.994, 0.984, 0.976, 0.993, 0.984, 0.952, 0.9972, 0.988, 0.956, 0.9907, 0.994, 0.984, 1.0, 0.976, 0.976, 0.9995, 0.956], 'micro': 0.9804, 'macro': 0.9699, 'weighted': 0.9791}
2024-07-27 11:01:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:01:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:01:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 29600 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_49_iter_29600.pt
2024-07-27 11:01:03 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 29600 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_49_iter_29600.pt
[31m===========================================================================[0m
2024-07-27 11:01:05 - [32m[1mINFO   [0m - Training epoch 50
2024-07-27 11:01:06 - [34m[1mLOGS   [0m - Epoch:  50 [   29601/10000000], loss: {'classification': 4.7229, 'neural_augmentation': 10.1185, 'total_loss': 14.8414}, LR: [2e-06, 2e-06], Avg. batch load time: 0.731, Elapsed time:  0.81
2024-07-27 11:01:43 - [34m[1mLOGS   [0m - Epoch:  50 [   30101/10000000], loss: {'classification': 4.3861, 'neural_augmentation': 9.824, 'total_loss': 14.2101}, LR: [2e-06, 2e-06], Avg. batch load time: 0.002, Elapsed time: 38.34
2024-07-27 11:01:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 50
	 loss={'classification': 4.3906, 'neural_augmentation': 9.8258, 'total_loss': 14.2164}
2024-07-27 11:02:08 - [34m[1mLOGS   [0m - *** Validation summary for epoch 50
	 loss={'classification': 2.3535, 'neural_augmentation': 0.0, 'total_loss': 2.3535} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9517, 0.9221, 0.9316, 0.984, 0.9383, 0.986, 0.9296, 0.8857, 0.9503, 0.9209, 0.9276, 0.9393, 0.817, 0.9595, 0.9249, 0.9593, 0.9757, 0.986, 0.948, 0.9528, 0.9602, 0.8851, 0.9405, 0.9621, 0.9518, 0.9394, 0.9533, 0.9595, 0.9469, 0.9328, 0.8662, 0.8907, 0.935, 0.9485, 0.9188, 0.9109, 0.9565, 0.9501, 0.9285, 0.888, 0.998, 0.8768, 0.9518, 0.9741, 0.9407, 0.9675, 0.8412, 0.9631, 0.8591, 0.9421, 0.9027, 0.9253, 0.986, 0.9449, 0.9583, 0.9578, 0.9828, 0.9384, 0.9414, 0.8776, 0.8737, 0.9405, 0.9461, 0.9508, 0.9339, 0.8936, 0.9743, 0.9575, 0.9604, 0.8537, 0.9144, 0.922, 0.96, 0.9392, 0.9174, 0.9126, 0.8898, 0.9536, 0.9675, 0.9798, 0.9334, 0.9761, 0.9402, 0.9079, 0.9669, 0.9624, 0.9435, 0.9426, 0.908, 0.9499, 0.9829, 0.841, 0.9439, 0.9151, 0.9478, 0.9449, 0.986, 0.8994, 0.9208, 0.9263, 0.9476, 0.9295, 0.9433, 0.8955, 0.9715, 0.942, 0.9747, 0.888, 0.9588, 0.9556, 0.8814, 0.9738, 0.9566, 0.9477, 0.7811, 0.9376, 0.8595, 0.9591, 0.9234, 0.976, 0.9588, 0.9398, 0.9577, 0.9702, 0.937, 0.8758, 0.959, 0.9508, 0.9381, 0.8999, 0.6898, 0.9553, 0.9761, 0.9522, 0.9502, 0.9721, 0.9053, 0.9736, 0.9372, 0.929, 0.9412, 0.9295, 0.9597, 0.9468, 0.9563, 0.9757, 0.9526, 0.9324, 0.984, 0.9478, 0.9125, 0.8971, 0.9369, 0.972, 0.9578, 0.888, 0.8912, 0.9331, 0.9407, 0.8889, 0.93, 0.9435, 0.8681, 0.9399, 0.9655, 0.8908, 0.9567, 0.9697, 0.9358, 0.9537, 0.9342, 0.9487, 0.9479, 0.8758], 'AP': [0.9835, 0.9573, 0.977, 0.9911, 0.9689, 0.9964, 0.9745, 0.9232, 0.9882, 0.9755, 0.9655, 0.9808, 0.8855, 0.989, 0.9648, 0.9829, 0.9933, 0.9966, 0.9778, 0.9849, 0.984, 0.9417, 0.9742, 0.9891, 0.9801, 0.9794, 0.9848, 0.9888, 0.9866, 0.9731, 0.9231, 0.9507, 0.971, 0.9833, 0.9724, 0.9543, 0.9763, 0.9888, 0.9702, 0.9399, 1.0, 0.934, 0.9844, 0.9906, 0.98, 0.9899, 0.9241, 0.9809, 0.924, 0.9794, 0.952, 0.9728, 0.9937, 0.9822, 0.9852, 0.9886, 0.9971, 0.971, 0.969, 0.938, 0.9362, 0.9732, 0.9774, 0.9857, 0.9776, 0.9457, 0.9964, 0.9853, 0.9862, 0.917, 0.9531, 0.9622, 0.9838, 0.977, 0.9585, 0.9549, 0.918, 0.9872, 0.9941, 0.9948, 0.9806, 0.9962, 0.9846, 0.9482, 0.9915, 0.9911, 0.9867, 0.9759, 0.9658, 0.9833, 0.9963, 0.9001, 0.978, 0.966, 0.976, 0.9835, 0.9963, 0.9364, 0.9677, 0.9742, 0.9828, 0.9686, 0.9706, 0.9609, 0.9908, 0.9808, 0.9921, 0.9411, 0.9873, 0.9833, 0.9247, 0.9946, 0.9908, 0.9781, 0.8396, 0.9752, 0.9007, 0.9885, 0.974, 0.9902, 0.9887, 0.9803, 0.982, 0.9904, 0.9836, 0.9371, 0.988, 0.986, 0.9707, 0.9485, 0.7133, 0.9834, 0.9949, 0.9845, 0.9833, 0.9901, 0.9593, 0.9899, 0.9786, 0.9719, 0.9738, 0.9693, 0.99, 0.9827, 0.9864, 0.9943, 0.9904, 0.9768, 0.9924, 0.9772, 0.9668, 0.9444, 0.9671, 0.99, 0.9893, 0.9363, 0.9349, 0.9778, 0.9803, 0.9414, 0.9779, 0.9711, 0.923, 0.983, 0.9864, 0.937, 0.985, 0.991, 0.9704, 0.9853, 0.9701, 0.9794, 0.9891, 0.9234], 'Recall@P=50': [0.99, 0.98, 0.9909, 0.992, 0.972, 1.0, 0.9896, 0.952, 0.9976, 0.9951, 0.986, 0.9948, 0.928, 0.994, 0.982, 0.992, 0.9984, 1.0, 0.984, 0.992, 0.992, 0.966, 0.98, 0.9968, 0.9867, 0.9904, 0.996, 0.996, 0.9989, 0.9864, 0.952, 0.976, 0.988, 0.992, 0.9895, 0.968, 0.988, 0.999, 0.983, 0.948, 1.0, 0.976, 0.988, 0.992, 0.988, 0.992, 0.968, 0.984, 0.9613, 0.988, 0.964, 0.9879, 0.996, 0.9954, 0.988, 0.9953, 1.0, 0.98, 0.984, 0.972, 0.972, 0.992, 0.992, 0.992, 0.9913, 0.964, 1.0, 0.9933, 0.992, 0.944, 0.972, 0.978, 0.992, 0.9888, 0.972, 0.984, 0.956, 0.996, 0.9987, 1.0, 0.9958, 1.0, 0.999, 0.964, 0.998, 0.994, 0.9984, 0.984, 0.9913, 0.988, 0.998, 0.948, 0.992, 0.9816, 0.984, 0.9971, 0.996, 0.976, 0.9873, 0.988, 0.9943, 0.978, 0.98, 0.988, 0.992, 0.991, 0.998, 0.968, 0.9952, 0.992, 0.956, 1.0, 0.9994, 0.988, 0.952, 0.9867, 0.952, 0.9967, 0.992, 0.992, 0.994, 0.9927, 0.992, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.988, 0.978, 0.864, 0.992, 0.996, 0.996, 0.9933, 0.992, 0.98, 0.992, 0.9943, 0.992, 0.98, 0.976, 1.0, 0.99, 0.992, 1.0, 0.9999, 0.9907, 0.992, 0.986, 0.988, 0.976, 0.9827, 0.992, 0.994, 0.956, 0.96, 0.996, 0.992, 0.964, 0.992, 0.988, 0.944, 0.9962, 0.992, 0.952, 0.994, 0.994, 0.98, 1.0, 0.972, 0.988, 0.9996, 0.944], 'micro': 0.9808, 'macro': 0.9701, 'weighted': 0.9792}
2024-07-27 11:02:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:02:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:02:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 50/iteration 30192 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_50_iter_30192.pt
2024-07-27 11:02:16 - [34m[1mLOGS   [0m - Model state for epoch 50/iteration 30192 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_50_iter_30192.pt
[31m===========================================================================[0m
2024-07-27 11:02:18 - [32m[1mINFO   [0m - Training epoch 51
2024-07-27 11:02:19 - [34m[1mLOGS   [0m - Epoch:  51 [   30193/10000000], loss: {'classification': 3.3515, 'neural_augmentation': 11.0968, 'total_loss': 14.4483}, LR: [1e-06, 1e-06], Avg. batch load time: 0.538, Elapsed time:  0.62
2024-07-27 11:02:57 - [34m[1mLOGS   [0m - Epoch:  51 [   30693/10000000], loss: {'classification': 4.3625, 'neural_augmentation': 9.849, 'total_loss': 14.2116}, LR: [1e-06, 1e-06], Avg. batch load time: 0.001, Elapsed time: 38.24
2024-07-27 11:03:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 51
	 loss={'classification': 4.3762, 'neural_augmentation': 9.8623, 'total_loss': 14.2384}
2024-07-27 11:03:23 - [34m[1mLOGS   [0m - *** Validation summary for epoch 51
	 loss={'classification': 2.3635, 'neural_augmentation': 0.0, 'total_loss': 2.3635} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9546, 0.9218, 0.9356, 0.9798, 0.9414, 0.9879, 0.9277, 0.8831, 0.9547, 0.9206, 0.9248, 0.9395, 0.8238, 0.9609, 0.9212, 0.9539, 0.9762, 0.986, 0.9535, 0.9547, 0.96, 0.8948, 0.9439, 0.9637, 0.9531, 0.9406, 0.9553, 0.9562, 0.9481, 0.932, 0.8697, 0.8893, 0.9357, 0.953, 0.9201, 0.9095, 0.9556, 0.9488, 0.9318, 0.8916, 0.998, 0.8768, 0.9499, 0.9721, 0.9402, 0.9654, 0.8462, 0.9608, 0.8654, 0.9347, 0.9032, 0.9255, 0.9829, 0.9445, 0.9606, 0.9574, 0.9829, 0.9421, 0.9402, 0.8721, 0.8814, 0.9296, 0.9491, 0.9569, 0.9351, 0.898, 0.9762, 0.9593, 0.958, 0.8589, 0.9243, 0.9216, 0.9581, 0.9412, 0.9191, 0.9059, 0.8861, 0.9494, 0.9693, 0.9778, 0.9354, 0.9739, 0.9426, 0.9068, 0.9698, 0.9657, 0.9437, 0.9439, 0.9127, 0.9524, 0.9849, 0.8454, 0.9516, 0.9168, 0.9499, 0.9424, 0.992, 0.8871, 0.9222, 0.9179, 0.9474, 0.936, 0.9424, 0.8965, 0.9721, 0.9448, 0.9758, 0.898, 0.9569, 0.9537, 0.8739, 0.9757, 0.9567, 0.9417, 0.7784, 0.9397, 0.8496, 0.9574, 0.9133, 0.9721, 0.9606, 0.9381, 0.9597, 0.9666, 0.9389, 0.8748, 0.9556, 0.9508, 0.9398, 0.9021, 0.6877, 0.9533, 0.9743, 0.9505, 0.9493, 0.972, 0.9059, 0.9737, 0.9366, 0.9296, 0.9443, 0.9306, 0.9639, 0.9468, 0.9566, 0.9756, 0.9538, 0.9295, 0.9758, 0.9458, 0.9143, 0.8939, 0.9314, 0.9723, 0.9602, 0.8983, 0.8996, 0.9355, 0.9369, 0.895, 0.9325, 0.9385, 0.8713, 0.943, 0.9661, 0.9004, 0.9532, 0.9718, 0.9366, 0.952, 0.9357, 0.9465, 0.9474, 0.868], 'AP': [0.9837, 0.9567, 0.9775, 0.9912, 0.9701, 0.9971, 0.9737, 0.9211, 0.989, 0.9756, 0.9658, 0.9803, 0.8844, 0.9879, 0.9646, 0.9829, 0.9933, 0.9976, 0.9767, 0.9833, 0.9831, 0.9438, 0.9752, 0.9895, 0.9795, 0.981, 0.9833, 0.9884, 0.9865, 0.9736, 0.9227, 0.9502, 0.9713, 0.9838, 0.9726, 0.9577, 0.9783, 0.9889, 0.9727, 0.9439, 1.0, 0.937, 0.9869, 0.991, 0.9768, 0.9891, 0.9268, 0.9808, 0.9274, 0.9756, 0.9475, 0.9733, 0.9934, 0.9822, 0.9871, 0.9894, 0.9971, 0.9722, 0.9705, 0.9396, 0.9394, 0.9727, 0.978, 0.9842, 0.9766, 0.944, 0.9956, 0.9871, 0.9845, 0.917, 0.9527, 0.9638, 0.986, 0.9772, 0.9596, 0.9528, 0.9141, 0.9861, 0.9949, 0.9963, 0.9811, 0.9948, 0.9848, 0.9435, 0.992, 0.9922, 0.9865, 0.9768, 0.9664, 0.9864, 0.9962, 0.9015, 0.9778, 0.9667, 0.9751, 0.9836, 0.9958, 0.9371, 0.9685, 0.972, 0.9829, 0.9683, 0.9687, 0.9608, 0.9908, 0.9812, 0.9907, 0.9393, 0.9873, 0.9834, 0.9218, 0.9959, 0.9906, 0.9784, 0.8396, 0.9761, 0.9026, 0.9885, 0.9723, 0.9908, 0.9879, 0.9807, 0.9838, 0.9899, 0.9837, 0.9384, 0.987, 0.9867, 0.9708, 0.9477, 0.7297, 0.9838, 0.9941, 0.9848, 0.9842, 0.9904, 0.9586, 0.9904, 0.9785, 0.9714, 0.9747, 0.9681, 0.9908, 0.9819, 0.9867, 0.996, 0.9903, 0.9771, 0.9914, 0.9762, 0.9654, 0.9434, 0.9691, 0.9902, 0.9902, 0.9363, 0.9335, 0.9791, 0.9769, 0.9453, 0.9776, 0.9724, 0.9244, 0.9833, 0.9866, 0.9366, 0.985, 0.9915, 0.9741, 0.9865, 0.9711, 0.9773, 0.9888, 0.9237], 'Recall@P=50': [0.9913, 0.98, 0.9909, 0.992, 0.976, 1.0, 0.9888, 0.952, 0.996, 0.9951, 0.988, 0.9932, 0.924, 0.994, 0.98, 0.992, 0.9976, 1.0, 0.98, 0.988, 0.992, 0.966, 0.98, 0.9968, 0.988, 0.9928, 0.988, 0.996, 0.9988, 0.9888, 0.94, 0.972, 0.988, 0.996, 0.9905, 0.972, 0.984, 0.999, 0.985, 0.972, 1.0, 0.968, 0.992, 0.996, 0.988, 0.992, 0.976, 0.984, 0.9613, 0.988, 0.964, 0.99, 0.996, 0.9943, 0.99, 0.996, 1.0, 0.98, 0.988, 0.972, 0.972, 0.992, 0.992, 0.988, 0.99, 0.97, 1.0, 0.9947, 0.986, 0.944, 0.976, 0.976, 0.996, 0.988, 0.98, 0.974, 0.96, 0.9947, 0.9987, 1.0, 0.9947, 1.0, 0.9986, 0.96, 0.998, 0.994, 0.9991, 0.984, 0.9887, 0.992, 0.998, 0.96, 0.992, 0.9832, 0.984, 0.9971, 0.996, 0.976, 0.9873, 0.992, 0.9943, 0.976, 0.976, 0.984, 0.992, 0.9913, 0.994, 0.968, 0.9928, 0.992, 0.956, 1.0, 0.9996, 0.992, 0.936, 0.988, 0.964, 0.9967, 0.992, 0.996, 0.994, 0.9953, 0.992, 0.992, 0.9983, 0.98, 0.992, 0.992, 0.988, 0.976, 0.9, 0.996, 0.996, 0.996, 0.994, 0.992, 0.9773, 0.992, 0.993, 0.992, 0.98, 0.976, 0.996, 0.99, 0.9944, 1.0, 0.9997, 0.992, 0.992, 0.984, 0.986, 0.974, 0.9827, 0.992, 0.996, 0.956, 0.956, 0.995, 0.988, 0.976, 0.993, 0.988, 0.948, 0.996, 0.992, 0.948, 0.9913, 0.994, 0.984, 0.996, 0.976, 0.984, 0.9996, 0.944], 'micro': 0.9808, 'macro': 0.9703, 'weighted': 0.9794}
2024-07-27 11:03:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:03:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:03:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 51/iteration 30784 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_51_iter_30784.pt
2024-07-27 11:03:31 - [34m[1mLOGS   [0m - Model state for epoch 51/iteration 30784 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_51_iter_30784.pt
[31m===========================================================================[0m
2024-07-27 11:03:33 - [32m[1mINFO   [0m - Training epoch 52
2024-07-27 11:03:34 - [34m[1mLOGS   [0m - Epoch:  52 [   30785/10000000], loss: {'classification': 4.6807, 'neural_augmentation': 8.9574, 'total_loss': 13.6382}, LR: [1e-06, 1e-06], Avg. batch load time: 0.533, Elapsed time:  0.62
2024-07-27 11:04:11 - [34m[1mLOGS   [0m - Epoch:  52 [   31285/10000000], loss: {'classification': 4.3722, 'neural_augmentation': 9.8362, 'total_loss': 14.2084}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 38.42
2024-07-27 11:04:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 52
	 loss={'classification': 4.367, 'neural_augmentation': 9.8474, 'total_loss': 14.2144}
2024-07-27 11:04:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 52
	 loss={'classification': 2.3912, 'neural_augmentation': 0.0, 'total_loss': 2.3912} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9522, 0.9221, 0.9359, 0.9838, 0.9419, 0.986, 0.9329, 0.8787, 0.954, 0.9218, 0.9249, 0.9385, 0.8155, 0.9593, 0.9212, 0.9574, 0.9763, 0.986, 0.9516, 0.951, 0.9597, 0.8903, 0.9474, 0.961, 0.9552, 0.94, 0.9565, 0.9637, 0.9474, 0.9318, 0.8617, 0.894, 0.9371, 0.9549, 0.9185, 0.9106, 0.9565, 0.95, 0.9249, 0.8898, 0.998, 0.8752, 0.9501, 0.972, 0.9429, 0.9695, 0.845, 0.9592, 0.8647, 0.9397, 0.8972, 0.9206, 0.9859, 0.9461, 0.9635, 0.9566, 0.9839, 0.9484, 0.937, 0.8735, 0.8685, 0.9374, 0.9465, 0.9508, 0.9337, 0.8939, 0.9801, 0.9587, 0.9599, 0.8527, 0.9141, 0.9228, 0.9602, 0.9376, 0.9211, 0.9059, 0.8898, 0.955, 0.9671, 0.9777, 0.9339, 0.978, 0.9401, 0.8961, 0.9674, 0.9648, 0.9432, 0.9487, 0.9061, 0.952, 0.9839, 0.8386, 0.9487, 0.912, 0.9514, 0.9443, 0.99, 0.8934, 0.9182, 0.925, 0.9475, 0.9276, 0.9433, 0.8934, 0.9719, 0.9411, 0.9747, 0.8955, 0.9567, 0.9549, 0.8833, 0.9778, 0.9557, 0.9469, 0.7854, 0.9363, 0.8445, 0.9587, 0.9249, 0.9739, 0.9593, 0.9384, 0.9634, 0.9696, 0.9384, 0.8784, 0.9593, 0.9508, 0.9336, 0.9054, 0.6859, 0.9547, 0.9801, 0.9514, 0.9465, 0.9741, 0.9063, 0.9721, 0.9354, 0.9246, 0.9476, 0.9309, 0.9576, 0.9483, 0.9561, 0.9756, 0.953, 0.9329, 0.9818, 0.9477, 0.9167, 0.8963, 0.9299, 0.9739, 0.9639, 0.8831, 0.8843, 0.9316, 0.9426, 0.8898, 0.9326, 0.9372, 0.8653, 0.9404, 0.9654, 0.8838, 0.9552, 0.975, 0.9385, 0.952, 0.9358, 0.9456, 0.9465, 0.8606], 'AP': [0.9833, 0.9576, 0.9778, 0.9908, 0.9701, 0.9977, 0.9751, 0.9262, 0.9883, 0.9755, 0.9616, 0.9807, 0.8858, 0.9886, 0.9653, 0.9822, 0.9937, 0.9976, 0.9742, 0.9835, 0.9838, 0.9397, 0.9759, 0.9894, 0.9812, 0.9803, 0.9832, 0.9878, 0.9866, 0.9745, 0.9238, 0.946, 0.9688, 0.9823, 0.9719, 0.9588, 0.98, 0.9889, 0.9695, 0.9461, 1.0, 0.9374, 0.9867, 0.9903, 0.9775, 0.9891, 0.9254, 0.9807, 0.9249, 0.9769, 0.953, 0.9718, 0.9929, 0.9816, 0.9865, 0.989, 0.9971, 0.973, 0.9658, 0.9358, 0.9382, 0.9763, 0.9772, 0.9847, 0.9769, 0.9445, 0.997, 0.986, 0.9845, 0.9152, 0.9514, 0.9644, 0.985, 0.9781, 0.9593, 0.954, 0.9216, 0.9876, 0.9944, 0.996, 0.9804, 0.9966, 0.9843, 0.9488, 0.9919, 0.992, 0.9865, 0.9771, 0.9635, 0.9867, 0.9959, 0.8959, 0.9775, 0.9652, 0.9728, 0.9833, 0.9966, 0.9349, 0.9682, 0.9762, 0.9835, 0.9681, 0.9697, 0.9598, 0.9905, 0.9805, 0.9924, 0.938, 0.9872, 0.9828, 0.9274, 0.9957, 0.9905, 0.9794, 0.8366, 0.9756, 0.9021, 0.9881, 0.9763, 0.9902, 0.9889, 0.9792, 0.9832, 0.9898, 0.984, 0.9352, 0.9878, 0.9859, 0.9689, 0.9504, 0.7225, 0.982, 0.9955, 0.9848, 0.9833, 0.9899, 0.9576, 0.9895, 0.9783, 0.9696, 0.9757, 0.9686, 0.9892, 0.9825, 0.9867, 0.9959, 0.9902, 0.9768, 0.9917, 0.9781, 0.9656, 0.946, 0.9687, 0.9897, 0.9911, 0.9352, 0.9325, 0.9778, 0.9779, 0.9469, 0.9784, 0.9695, 0.9253, 0.9832, 0.986, 0.9357, 0.986, 0.9919, 0.9731, 0.9857, 0.9709, 0.9766, 0.9887, 0.9247], 'Recall@P=50': [0.9907, 0.976, 0.9914, 0.992, 0.972, 1.0, 0.9904, 0.96, 0.996, 0.9957, 0.99, 0.9948, 0.924, 0.992, 0.982, 0.992, 0.9984, 1.0, 0.98, 0.996, 0.992, 0.964, 0.98, 0.9952, 0.9867, 0.9936, 0.992, 0.996, 0.9984, 0.9896, 0.956, 0.972, 0.988, 0.992, 0.9895, 0.972, 0.988, 0.999, 0.982, 0.972, 1.0, 0.968, 0.992, 0.992, 0.988, 0.992, 0.9707, 0.984, 0.9587, 0.988, 0.964, 0.9889, 0.992, 0.996, 0.988, 0.9947, 0.998, 0.98, 0.988, 0.964, 0.972, 0.996, 0.992, 0.996, 0.99, 0.968, 1.0, 0.992, 0.988, 0.94, 0.972, 0.978, 0.992, 0.9888, 0.972, 0.978, 0.96, 0.9947, 0.9987, 1.0, 0.9942, 1.0, 0.9984, 0.96, 0.998, 0.996, 0.9984, 0.98, 0.9913, 0.992, 0.998, 0.952, 0.988, 0.9832, 0.976, 0.9967, 0.996, 0.976, 0.9853, 0.988, 0.9937, 0.982, 0.98, 0.9867, 0.992, 0.992, 0.996, 0.964, 0.9952, 0.988, 0.964, 1.0, 0.9989, 0.992, 0.952, 0.9887, 0.96, 0.9967, 0.988, 0.992, 0.994, 0.994, 0.992, 0.992, 0.9983, 0.968, 0.992, 0.992, 0.988, 0.978, 0.892, 0.988, 1.0, 0.996, 0.9933, 0.992, 0.9787, 0.992, 0.993, 0.992, 0.98, 0.98, 0.996, 0.989, 0.9944, 1.0, 0.9996, 0.9907, 0.992, 0.986, 0.99, 0.976, 0.984, 0.992, 0.996, 0.948, 0.952, 0.995, 0.988, 0.976, 0.994, 0.988, 0.944, 0.996, 0.992, 0.944, 0.9933, 0.994, 0.98, 0.996, 0.976, 0.98, 0.9998, 0.956], 'micro': 0.9807, 'macro': 0.9702, 'weighted': 0.9792}
2024-07-27 11:04:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:04:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:04:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 52/iteration 31376 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_52_iter_31376.pt
2024-07-27 11:04:44 - [34m[1mLOGS   [0m - Model state for epoch 52/iteration 31376 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_52_iter_31376.pt
[31m===========================================================================[0m
2024-07-27 11:04:46 - [32m[1mINFO   [0m - Training epoch 53
2024-07-27 11:04:47 - [34m[1mLOGS   [0m - Epoch:  53 [   31377/10000000], loss: {'classification': 3.4391, 'neural_augmentation': 10.5237, 'total_loss': 13.9628}, LR: [1e-06, 1e-06], Avg. batch load time: 0.561, Elapsed time:  0.65
2024-07-27 11:05:25 - [34m[1mLOGS   [0m - Epoch:  53 [   31877/10000000], loss: {'classification': 4.331, 'neural_augmentation': 9.8166, 'total_loss': 14.1475}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 38.22
2024-07-27 11:05:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 53
	 loss={'classification': 4.3335, 'neural_augmentation': 9.8102, 'total_loss': 14.1437}
2024-07-27 11:05:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 53
	 loss={'classification': 2.3421, 'neural_augmentation': 0.0, 'total_loss': 2.3421} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9535, 0.9163, 0.9338, 0.9837, 0.9333, 0.984, 0.9332, 0.8857, 0.955, 0.9226, 0.9253, 0.9387, 0.8161, 0.9584, 0.9246, 0.9576, 0.9767, 0.986, 0.9533, 0.9571, 0.9595, 0.8933, 0.9421, 0.9643, 0.9532, 0.9406, 0.9572, 0.9577, 0.9473, 0.9297, 0.8655, 0.9018, 0.9421, 0.9547, 0.9189, 0.9156, 0.96, 0.9505, 0.9294, 0.8957, 0.998, 0.8755, 0.9486, 0.9739, 0.9435, 0.9673, 0.844, 0.9611, 0.864, 0.9414, 0.9028, 0.9204, 0.9869, 0.9436, 0.9657, 0.9555, 0.9839, 0.9448, 0.938, 0.8745, 0.8765, 0.9309, 0.9465, 0.9537, 0.9318, 0.8962, 0.982, 0.9612, 0.9624, 0.85, 0.9212, 0.9215, 0.9602, 0.9415, 0.9174, 0.9062, 0.8944, 0.9569, 0.9691, 0.9798, 0.9353, 0.9801, 0.9407, 0.9075, 0.968, 0.9687, 0.9432, 0.9436, 0.9109, 0.9484, 0.9849, 0.8398, 0.9446, 0.9172, 0.9474, 0.9438, 0.992, 0.8889, 0.9219, 0.924, 0.9456, 0.9331, 0.9421, 0.8983, 0.9759, 0.9436, 0.9726, 0.9006, 0.9584, 0.953, 0.8917, 0.98, 0.9558, 0.9458, 0.7846, 0.9379, 0.8484, 0.9571, 0.9237, 0.9762, 0.955, 0.9415, 0.964, 0.968, 0.9375, 0.8787, 0.9571, 0.9499, 0.9421, 0.9055, 0.68, 0.9547, 0.9801, 0.9453, 0.9489, 0.976, 0.9112, 0.976, 0.9387, 0.9281, 0.9438, 0.9303, 0.9555, 0.946, 0.9582, 0.9777, 0.9526, 0.9323, 0.982, 0.9459, 0.9157, 0.8957, 0.9357, 0.978, 0.9643, 0.888, 0.8903, 0.931, 0.9431, 0.8898, 0.9347, 0.938, 0.8714, 0.9417, 0.9679, 0.8971, 0.9566, 0.9749, 0.9366, 0.9491, 0.9339, 0.9461, 0.9474, 0.8672], 'AP': [0.9833, 0.9568, 0.9774, 0.9913, 0.9705, 0.9977, 0.9756, 0.9261, 0.9885, 0.9763, 0.9634, 0.9805, 0.8865, 0.989, 0.9651, 0.9823, 0.9938, 0.9972, 0.9745, 0.9832, 0.9833, 0.9433, 0.9752, 0.9897, 0.9789, 0.9814, 0.9836, 0.9901, 0.9867, 0.9736, 0.9236, 0.9508, 0.9722, 0.9833, 0.9726, 0.9591, 0.9782, 0.9891, 0.9727, 0.9429, 1.0, 0.934, 0.9859, 0.9905, 0.9796, 0.9894, 0.9269, 0.9821, 0.9261, 0.9791, 0.9552, 0.9726, 0.9934, 0.9817, 0.9872, 0.9892, 0.9973, 0.9722, 0.9679, 0.9391, 0.9353, 0.9735, 0.9745, 0.9844, 0.9772, 0.9455, 0.997, 0.9865, 0.9861, 0.9154, 0.953, 0.9632, 0.9849, 0.9787, 0.9577, 0.9543, 0.9246, 0.987, 0.9948, 0.9967, 0.9802, 0.9968, 0.9846, 0.9512, 0.9921, 0.9921, 0.9868, 0.9765, 0.9661, 0.9851, 0.9962, 0.8982, 0.9748, 0.9667, 0.9742, 0.9841, 0.9966, 0.9378, 0.9683, 0.9776, 0.9829, 0.9678, 0.9738, 0.9612, 0.9906, 0.9815, 0.9924, 0.9391, 0.9877, 0.9826, 0.9282, 0.9968, 0.9907, 0.9801, 0.8449, 0.9759, 0.9019, 0.9889, 0.9784, 0.9904, 0.9889, 0.98, 0.9814, 0.9898, 0.9843, 0.9364, 0.9878, 0.9868, 0.9716, 0.9464, 0.7202, 0.9833, 0.9953, 0.9847, 0.9856, 0.9902, 0.9599, 0.9898, 0.9786, 0.9707, 0.9742, 0.9662, 0.9904, 0.9807, 0.9869, 0.9968, 0.9904, 0.9775, 0.9923, 0.9741, 0.9649, 0.9444, 0.9724, 0.9896, 0.9906, 0.9346, 0.9327, 0.9789, 0.9799, 0.9444, 0.9791, 0.9702, 0.9246, 0.9839, 0.9863, 0.9347, 0.986, 0.992, 0.9759, 0.987, 0.9721, 0.9775, 0.989, 0.9253], 'Recall@P=50': [0.9913, 0.976, 0.9909, 0.992, 0.976, 1.0, 0.9912, 0.952, 0.9968, 0.9951, 0.988, 0.9948, 0.928, 0.996, 0.982, 0.988, 0.9976, 1.0, 0.976, 0.992, 0.992, 0.962, 0.984, 0.9976, 0.9867, 0.9944, 0.992, 1.0, 0.9988, 0.9872, 0.948, 0.968, 0.988, 0.996, 0.992, 0.98, 0.988, 0.9993, 0.983, 0.968, 1.0, 0.972, 0.992, 0.992, 0.988, 0.992, 0.9747, 0.988, 0.9627, 0.988, 0.968, 0.9889, 0.994, 0.996, 0.992, 0.996, 1.0, 0.98, 0.984, 0.972, 0.968, 0.992, 0.984, 0.992, 0.9913, 0.966, 1.0, 0.992, 0.988, 0.94, 0.976, 0.98, 0.992, 0.9904, 0.976, 0.98, 0.956, 0.9947, 0.9987, 1.0, 0.9947, 1.0, 0.9988, 0.96, 0.998, 0.994, 0.9985, 0.984, 0.9913, 0.992, 0.998, 0.948, 0.988, 0.9816, 0.984, 0.9975, 0.996, 0.98, 0.9867, 0.992, 0.9937, 0.978, 0.98, 0.988, 0.992, 0.992, 0.998, 0.968, 0.9944, 0.988, 0.968, 1.0, 0.9992, 0.992, 0.948, 0.9893, 0.96, 0.9967, 0.996, 0.996, 0.996, 0.992, 0.992, 0.992, 0.9987, 0.968, 0.992, 0.9933, 0.988, 0.972, 0.908, 0.996, 0.996, 0.996, 0.9953, 0.992, 0.9787, 0.992, 0.9933, 0.992, 0.98, 0.976, 1.0, 0.99, 0.9936, 1.0, 0.9996, 0.992, 0.992, 0.982, 0.982, 0.978, 0.9853, 0.992, 0.996, 0.952, 0.952, 0.996, 0.992, 0.972, 0.995, 0.984, 0.948, 0.996, 0.992, 0.952, 0.9947, 0.994, 0.984, 1.0, 0.976, 0.984, 0.9996, 0.956], 'micro': 0.981, 'macro': 0.9706, 'weighted': 0.9796}
2024-07-27 11:05:56 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 11:05:57 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9692.pt
2024-07-27 11:05:57 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9694.pt', 'checkpoint_score_0.9700.pt', 'checkpoint_score_0.9701.pt', 'checkpoint_score_0.9705.pt', 'checkpoint_score_0.9706.pt']
2024-07-27 11:05:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 11:06:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:06:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:06:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 53/iteration 31968 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_53_iter_31968.pt
2024-07-27 11:06:02 - [34m[1mLOGS   [0m - Model state for epoch 53/iteration 31968 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_53_iter_31968.pt
[31m===========================================================================[0m
2024-07-27 11:06:04 - [32m[1mINFO   [0m - Training epoch 54
2024-07-27 11:06:05 - [34m[1mLOGS   [0m - Epoch:  54 [   31969/10000000], loss: {'classification': 3.8205, 'neural_augmentation': 9.7562, 'total_loss': 13.5767}, LR: [1e-06, 1e-06], Avg. batch load time: 0.484, Elapsed time:  0.57
2024-07-27 11:06:42 - [34m[1mLOGS   [0m - Epoch:  54 [   32469/10000000], loss: {'classification': 4.2919, 'neural_augmentation': 9.858, 'total_loss': 14.15}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 38.32
2024-07-27 11:06:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 54
	 loss={'classification': 4.2922, 'neural_augmentation': 9.8452, 'total_loss': 14.1375}
2024-07-27 11:07:08 - [34m[1mLOGS   [0m - *** Validation summary for epoch 54
	 loss={'classification': 2.3449, 'neural_augmentation': 0.0, 'total_loss': 2.3449} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9548, 0.9174, 0.9353, 0.9838, 0.9412, 0.9859, 0.9306, 0.8866, 0.9551, 0.9205, 0.9323, 0.9407, 0.8082, 0.9598, 0.9262, 0.959, 0.9767, 0.986, 0.9512, 0.959, 0.9621, 0.8828, 0.9455, 0.9618, 0.9516, 0.9379, 0.9572, 0.9637, 0.9476, 0.9326, 0.8694, 0.9006, 0.939, 0.9595, 0.9211, 0.9184, 0.9532, 0.9512, 0.9274, 0.8964, 0.998, 0.8806, 0.9533, 0.982, 0.9407, 0.9655, 0.8474, 0.9672, 0.8675, 0.9385, 0.8942, 0.9223, 0.985, 0.9477, 0.9594, 0.9583, 0.9821, 0.9467, 0.9369, 0.8808, 0.8797, 0.935, 0.9489, 0.9588, 0.9317, 0.8922, 0.9762, 0.9623, 0.961, 0.8552, 0.9212, 0.926, 0.9618, 0.9377, 0.9193, 0.9077, 0.8917, 0.9562, 0.9694, 0.978, 0.9351, 0.9743, 0.9405, 0.9, 0.9698, 0.965, 0.9443, 0.9457, 0.9081, 0.952, 0.9819, 0.8373, 0.9506, 0.9178, 0.9491, 0.9462, 0.99, 0.8978, 0.9244, 0.9218, 0.9468, 0.9311, 0.9463, 0.8974, 0.98, 0.9414, 0.9738, 0.8898, 0.961, 0.9576, 0.8908, 0.98, 0.9564, 0.9479, 0.7821, 0.9396, 0.8531, 0.959, 0.9218, 0.9839, 0.9577, 0.9417, 0.9597, 0.9657, 0.9365, 0.8844, 0.9588, 0.9498, 0.9398, 0.8977, 0.6835, 0.9572, 0.9781, 0.9497, 0.9466, 0.982, 0.908, 0.98, 0.9372, 0.9218, 0.9416, 0.9212, 0.9602, 0.9503, 0.9555, 0.9739, 0.9528, 0.9321, 0.9818, 0.9476, 0.9204, 0.9013, 0.9314, 0.9839, 0.9636, 0.8819, 0.8908, 0.9338, 0.9402, 0.8963, 0.9342, 0.9385, 0.8734, 0.9415, 0.9698, 0.8912, 0.9545, 0.9751, 0.9369, 0.948, 0.9398, 0.9457, 0.9469, 0.8723], 'AP': [0.9838, 0.9578, 0.9778, 0.9899, 0.9716, 0.9966, 0.9759, 0.9291, 0.9886, 0.9758, 0.9666, 0.9807, 0.8848, 0.9892, 0.9671, 0.9826, 0.994, 0.9975, 0.9757, 0.9854, 0.9837, 0.9444, 0.9754, 0.9894, 0.9804, 0.9807, 0.9852, 0.9862, 0.9868, 0.9744, 0.9278, 0.9475, 0.9714, 0.9807, 0.9731, 0.9599, 0.9796, 0.9893, 0.9704, 0.945, 1.0, 0.9374, 0.9878, 0.9902, 0.9792, 0.9876, 0.9267, 0.9815, 0.9278, 0.9781, 0.9533, 0.9738, 0.9925, 0.9824, 0.9853, 0.9894, 0.9975, 0.9727, 0.9676, 0.9394, 0.9383, 0.9733, 0.9753, 0.9864, 0.9772, 0.9474, 0.9963, 0.9866, 0.9854, 0.9171, 0.9517, 0.9645, 0.985, 0.977, 0.9597, 0.9566, 0.9224, 0.9874, 0.9946, 0.9954, 0.9814, 0.9963, 0.9846, 0.9484, 0.992, 0.9918, 0.9871, 0.976, 0.9648, 0.9872, 0.9947, 0.8981, 0.9755, 0.9684, 0.975, 0.9841, 0.9969, 0.9421, 0.9698, 0.9752, 0.9832, 0.9679, 0.9719, 0.9602, 0.9905, 0.981, 0.9932, 0.9412, 0.9883, 0.9809, 0.9305, 0.9952, 0.9906, 0.9794, 0.8369, 0.9759, 0.9008, 0.9883, 0.9758, 0.9901, 0.9894, 0.9799, 0.9825, 0.9885, 0.9843, 0.9397, 0.988, 0.986, 0.9704, 0.9482, 0.7187, 0.9814, 0.995, 0.9854, 0.9847, 0.9891, 0.9587, 0.9896, 0.9795, 0.9702, 0.9747, 0.9633, 0.9913, 0.9829, 0.9862, 0.9952, 0.9903, 0.9769, 0.9908, 0.9772, 0.966, 0.9466, 0.9712, 0.9891, 0.9918, 0.9357, 0.9327, 0.9784, 0.9794, 0.946, 0.9785, 0.9709, 0.9293, 0.9834, 0.9855, 0.9358, 0.9858, 0.9919, 0.9738, 0.9849, 0.9733, 0.9787, 0.9892, 0.9301], 'Recall@P=50': [0.99, 0.98, 0.992, 0.992, 0.976, 1.0, 0.9896, 0.968, 0.9976, 0.9954, 0.99, 0.9944, 0.92, 0.996, 0.984, 0.988, 0.9968, 1.0, 0.976, 0.996, 0.992, 0.964, 0.98, 0.996, 0.9853, 0.9912, 0.992, 0.992, 0.9988, 0.9888, 0.948, 0.972, 0.984, 0.988, 0.9905, 0.976, 0.992, 0.9992, 0.983, 0.968, 1.0, 0.976, 0.992, 0.992, 0.988, 0.992, 0.9747, 0.984, 0.9613, 0.988, 0.968, 0.9911, 0.996, 0.9966, 0.99, 0.9947, 1.0, 0.98, 0.984, 0.964, 0.976, 0.992, 0.98, 0.996, 0.99, 0.97, 1.0, 0.9907, 0.99, 0.944, 0.976, 0.978, 0.992, 0.9904, 0.98, 0.982, 0.964, 0.9947, 0.9987, 1.0, 0.9942, 1.0, 0.9986, 0.956, 1.0, 0.996, 0.9989, 0.98, 0.9896, 0.992, 0.998, 0.952, 0.984, 0.9848, 0.98, 0.9975, 0.996, 0.988, 0.988, 0.992, 0.9926, 0.984, 0.98, 0.9853, 0.992, 0.9917, 1.0, 0.964, 0.9952, 0.984, 0.968, 1.0, 0.9993, 0.99, 0.956, 0.9887, 0.96, 0.996, 0.996, 0.988, 0.996, 0.9913, 0.992, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.988, 0.976, 0.892, 0.988, 0.996, 0.996, 0.9947, 0.992, 0.9813, 0.992, 0.993, 0.992, 0.98, 0.972, 1.0, 0.99, 0.9936, 1.0, 1.0, 0.9907, 0.992, 0.984, 0.984, 0.974, 0.984, 0.992, 0.996, 0.956, 0.952, 0.994, 0.988, 0.976, 0.992, 0.988, 0.952, 0.9962, 0.992, 0.956, 0.9933, 0.994, 0.98, 0.996, 0.98, 0.984, 0.9998, 0.96], 'micro': 0.9811, 'macro': 0.9707, 'weighted': 0.9797}
2024-07-27 11:07:14 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 11:07:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9694.pt
2024-07-27 11:07:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9700.pt', 'checkpoint_score_0.9701.pt', 'checkpoint_score_0.9705.pt', 'checkpoint_score_0.9706.pt', 'checkpoint_score_0.9707.pt']
2024-07-27 11:07:17 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 11:07:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:07:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:07:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 54/iteration 32560 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_54_iter_32560.pt
2024-07-27 11:07:20 - [34m[1mLOGS   [0m - Model state for epoch 54/iteration 32560 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_54_iter_32560.pt
[31m===========================================================================[0m
2024-07-27 11:07:22 - [32m[1mINFO   [0m - Training epoch 55
2024-07-27 11:07:22 - [34m[1mLOGS   [0m - Epoch:  55 [   32561/10000000], loss: {'classification': 3.9007, 'neural_augmentation': 9.3551, 'total_loss': 13.2558}, LR: [1e-06, 1e-06], Avg. batch load time: 0.560, Elapsed time:  0.65
2024-07-27 11:08:02 - [34m[1mLOGS   [0m - Epoch:  55 [   33061/10000000], loss: {'classification': 4.2645, 'neural_augmentation': 9.8389, 'total_loss': 14.1034}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 40.57
2024-07-27 11:08:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 55
	 loss={'classification': 4.2753, 'neural_augmentation': 9.8413, 'total_loss': 14.1165}
2024-07-27 11:08:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 55
	 loss={'classification': 2.3513, 'neural_augmentation': 0.0, 'total_loss': 2.3513} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9547, 0.9189, 0.9353, 0.9879, 0.9424, 0.9839, 0.9339, 0.8866, 0.9565, 0.9242, 0.9319, 0.9403, 0.8114, 0.9584, 0.9236, 0.9615, 0.9779, 0.9821, 0.9547, 0.9563, 0.964, 0.8875, 0.9457, 0.9637, 0.9495, 0.9419, 0.9571, 0.9598, 0.9479, 0.9337, 0.865, 0.8893, 0.9393, 0.9549, 0.9209, 0.9137, 0.9556, 0.9506, 0.9304, 0.8983, 0.998, 0.876, 0.9503, 0.9719, 0.9433, 0.9659, 0.8499, 0.9607, 0.8664, 0.9414, 0.9036, 0.9221, 0.985, 0.9477, 0.9657, 0.9574, 0.983, 0.9493, 0.9393, 0.8776, 0.876, 0.9371, 0.9485, 0.9565, 0.9342, 0.8961, 0.978, 0.963, 0.961, 0.8526, 0.924, 0.9273, 0.9597, 0.9411, 0.917, 0.9106, 0.8884, 0.9588, 0.9684, 0.9778, 0.9361, 0.9761, 0.943, 0.9117, 0.969, 0.9661, 0.9446, 0.9476, 0.9089, 0.9526, 0.983, 0.8396, 0.9463, 0.9152, 0.9491, 0.9463, 0.9901, 0.8956, 0.9252, 0.9199, 0.9459, 0.9298, 0.9424, 0.8964, 0.9715, 0.9442, 0.9738, 0.8911, 0.9566, 0.9574, 0.8861, 0.976, 0.9563, 0.9469, 0.7756, 0.9394, 0.8537, 0.9598, 0.9244, 0.9738, 0.9549, 0.9373, 0.9555, 0.9673, 0.9358, 0.8824, 0.9558, 0.95, 0.9363, 0.9044, 0.6977, 0.9553, 0.9761, 0.9495, 0.9486, 0.9718, 0.9051, 0.9717, 0.9377, 0.9264, 0.9474, 0.9303, 0.9625, 0.9467, 0.9586, 0.9757, 0.9526, 0.9318, 0.9818, 0.9422, 0.9167, 0.9004, 0.9331, 0.9719, 0.9608, 0.8842, 0.8879, 0.9319, 0.9433, 0.8948, 0.9347, 0.9388, 0.869, 0.9403, 0.968, 0.8912, 0.9543, 0.9739, 0.9405, 0.9535, 0.9431, 0.9455, 0.9487, 0.8643], 'AP': [0.9839, 0.9581, 0.9772, 0.9898, 0.9727, 0.9967, 0.9757, 0.9288, 0.9895, 0.9765, 0.9665, 0.9805, 0.8837, 0.9881, 0.9662, 0.9829, 0.9938, 0.9974, 0.976, 0.9844, 0.9845, 0.9428, 0.9754, 0.9894, 0.9795, 0.9818, 0.9842, 0.9884, 0.9869, 0.9737, 0.9268, 0.9455, 0.9731, 0.9802, 0.9737, 0.9578, 0.98, 0.9894, 0.974, 0.9444, 1.0, 0.9383, 0.9864, 0.9916, 0.9792, 0.9885, 0.927, 0.9819, 0.9268, 0.9787, 0.9549, 0.9735, 0.9927, 0.9824, 0.9882, 0.989, 0.9974, 0.9723, 0.9661, 0.9366, 0.9397, 0.9733, 0.9751, 0.985, 0.977, 0.9462, 0.9955, 0.9877, 0.9851, 0.9165, 0.9541, 0.9641, 0.9841, 0.978, 0.9589, 0.9534, 0.9252, 0.9871, 0.9939, 0.9955, 0.9814, 0.9955, 0.9849, 0.9507, 0.9914, 0.9913, 0.9872, 0.976, 0.9655, 0.9857, 0.9959, 0.8988, 0.9755, 0.9664, 0.9751, 0.9842, 0.9968, 0.9391, 0.9692, 0.9755, 0.9835, 0.9688, 0.9709, 0.9593, 0.9914, 0.9816, 0.9927, 0.9414, 0.9873, 0.9798, 0.9307, 0.9954, 0.9907, 0.9798, 0.8408, 0.9767, 0.9025, 0.9884, 0.9764, 0.9913, 0.9882, 0.9792, 0.9821, 0.989, 0.9841, 0.9357, 0.9866, 0.986, 0.9728, 0.9503, 0.7209, 0.9796, 0.9944, 0.9851, 0.9851, 0.9911, 0.9583, 0.9908, 0.9789, 0.9702, 0.9743, 0.9662, 0.9921, 0.9824, 0.9862, 0.9956, 0.9904, 0.9775, 0.991, 0.976, 0.9651, 0.9441, 0.9705, 0.9903, 0.991, 0.9361, 0.9342, 0.9789, 0.9794, 0.9454, 0.9782, 0.9697, 0.9286, 0.9837, 0.987, 0.9365, 0.9859, 0.9923, 0.9767, 0.9854, 0.974, 0.9801, 0.9892, 0.9281], 'Recall@P=50': [0.9913, 0.976, 0.9903, 0.988, 0.98, 1.0, 0.9928, 0.96, 0.9976, 0.996, 0.986, 0.9936, 0.928, 0.996, 0.98, 0.992, 0.9976, 1.0, 0.98, 0.992, 0.992, 0.962, 0.98, 0.996, 0.988, 0.9928, 0.992, 0.996, 0.9988, 0.9864, 0.94, 0.976, 0.988, 0.988, 0.99, 0.972, 0.984, 0.9992, 0.985, 0.968, 1.0, 0.972, 0.992, 0.996, 0.988, 0.992, 0.972, 0.988, 0.9613, 0.988, 0.964, 0.9884, 0.994, 0.9971, 0.992, 0.9947, 1.0, 0.98, 0.984, 0.964, 0.976, 0.992, 0.984, 0.988, 0.99, 0.97, 0.996, 0.9933, 0.99, 0.94, 0.976, 0.98, 0.992, 0.9904, 0.976, 0.982, 0.964, 0.9947, 0.9973, 1.0, 0.9942, 1.0, 0.999, 0.964, 0.998, 0.994, 0.9991, 0.98, 0.9904, 0.992, 0.998, 0.952, 0.984, 0.9808, 0.976, 0.9967, 0.996, 0.98, 0.9873, 0.992, 0.9931, 0.98, 0.98, 0.9893, 0.996, 0.9923, 1.0, 0.964, 0.9944, 0.984, 0.964, 1.0, 0.9994, 0.992, 0.956, 0.9887, 0.96, 0.996, 0.992, 0.996, 0.996, 0.992, 0.992, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.984, 0.976, 0.896, 0.988, 0.996, 0.996, 0.994, 0.996, 0.98, 0.996, 0.9933, 0.992, 0.98, 0.976, 1.0, 0.991, 0.992, 1.0, 0.9998, 0.992, 0.992, 0.984, 0.984, 0.972, 0.9813, 0.992, 0.996, 0.956, 0.96, 0.993, 0.988, 0.972, 0.992, 0.988, 0.944, 0.9968, 0.992, 0.956, 0.9933, 0.994, 0.98, 0.996, 0.98, 0.988, 0.9998, 0.96], 'micro': 0.9811, 'macro': 0.9708, 'weighted': 0.9797}
2024-07-27 11:08:35 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 11:08:35 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9700.pt
2024-07-27 11:08:35 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9701.pt', 'checkpoint_score_0.9705.pt', 'checkpoint_score_0.9706.pt', 'checkpoint_score_0.9707.pt', 'checkpoint_score_0.9708.pt']
2024-07-27 11:08:38 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 11:08:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:08:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:08:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 55/iteration 33152 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_55_iter_33152.pt
2024-07-27 11:08:40 - [34m[1mLOGS   [0m - Model state for epoch 55/iteration 33152 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_55_iter_33152.pt
[31m===========================================================================[0m
2024-07-27 11:08:42 - [32m[1mINFO   [0m - Training epoch 56
2024-07-27 11:08:43 - [34m[1mLOGS   [0m - Epoch:  56 [   33153/10000000], loss: {'classification': 3.5254, 'neural_augmentation': 10.7852, 'total_loss': 14.3106}, LR: [1e-06, 1e-06], Avg. batch load time: 0.789, Elapsed time:  0.95
2024-07-27 11:10:17 - [34m[1mLOGS   [0m - Epoch:  56 [   33653/10000000], loss: {'classification': 4.2621, 'neural_augmentation': 9.8724, 'total_loss': 14.1345}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 94.37
2024-07-27 11:10:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 56
	 loss={'classification': 4.2477, 'neural_augmentation': 9.8586, 'total_loss': 14.1063}
2024-07-27 11:11:05 - [34m[1mLOGS   [0m - *** Validation summary for epoch 56
	 loss={'classification': 2.3684, 'neural_augmentation': 0.0, 'total_loss': 2.3684} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9539, 0.917, 0.9374, 0.9859, 0.939, 0.986, 0.9329, 0.8857, 0.9562, 0.9212, 0.9336, 0.9406, 0.8206, 0.9637, 0.9212, 0.959, 0.9771, 0.984, 0.9526, 0.9572, 0.9618, 0.8898, 0.9446, 0.9611, 0.9524, 0.9393, 0.9631, 0.9598, 0.9476, 0.9346, 0.8634, 0.9016, 0.9379, 0.9551, 0.9232, 0.9102, 0.9581, 0.951, 0.9327, 0.8975, 0.998, 0.8745, 0.9562, 0.9741, 0.9424, 0.9652, 0.8461, 0.961, 0.8658, 0.9405, 0.9028, 0.9211, 0.986, 0.9487, 0.9666, 0.9563, 0.984, 0.9457, 0.9366, 0.8798, 0.8752, 0.9322, 0.9485, 0.9569, 0.9334, 0.8972, 0.976, 0.9565, 0.9654, 0.8589, 0.9215, 0.9274, 0.9637, 0.9431, 0.9172, 0.9115, 0.8861, 0.9537, 0.9684, 0.9758, 0.9333, 0.976, 0.9421, 0.9038, 0.9687, 0.9677, 0.942, 0.9472, 0.9042, 0.9522, 0.9839, 0.8451, 0.9487, 0.9187, 0.9489, 0.9466, 0.99, 0.8957, 0.9211, 0.9162, 0.9428, 0.9314, 0.9396, 0.8972, 0.9741, 0.943, 0.9728, 0.8944, 0.9589, 0.9593, 0.8795, 0.978, 0.956, 0.9434, 0.7771, 0.9398, 0.8548, 0.9586, 0.9182, 0.9737, 0.9594, 0.9397, 0.9637, 0.9652, 0.9365, 0.8853, 0.9587, 0.9497, 0.9355, 0.9031, 0.694, 0.9555, 0.976, 0.9478, 0.9476, 0.9759, 0.903, 0.9721, 0.938, 0.9237, 0.9441, 0.9253, 0.9615, 0.9455, 0.9547, 0.9777, 0.9533, 0.9311, 0.98, 0.9443, 0.9198, 0.9007, 0.9307, 0.9757, 0.9638, 0.8898, 0.8922, 0.9351, 0.9448, 0.8948, 0.9364, 0.9385, 0.8721, 0.9421, 0.9676, 0.8917, 0.9548, 0.977, 0.9447, 0.9574, 0.9381, 0.9461, 0.9475, 0.8685], 'AP': [0.9841, 0.9566, 0.9781, 0.9901, 0.9717, 0.9972, 0.9748, 0.9292, 0.9888, 0.9761, 0.9668, 0.9807, 0.8854, 0.9888, 0.9653, 0.9822, 0.9935, 0.9969, 0.9771, 0.9845, 0.9812, 0.9445, 0.9765, 0.9892, 0.9806, 0.9814, 0.9843, 0.9867, 0.9869, 0.9739, 0.9243, 0.9498, 0.9705, 0.9828, 0.9737, 0.9585, 0.98, 0.9894, 0.9729, 0.9409, 1.0, 0.9394, 0.9878, 0.9913, 0.9786, 0.9884, 0.9267, 0.9807, 0.9271, 0.9771, 0.9519, 0.9728, 0.9927, 0.9829, 0.9876, 0.9891, 0.9973, 0.9733, 0.9675, 0.9378, 0.9393, 0.9728, 0.9775, 0.9851, 0.9766, 0.9482, 0.9954, 0.9866, 0.9858, 0.9174, 0.9519, 0.9648, 0.985, 0.9785, 0.9584, 0.956, 0.9209, 0.9871, 0.9949, 0.9965, 0.9804, 0.9956, 0.985, 0.9475, 0.9921, 0.9921, 0.9871, 0.9775, 0.9646, 0.9872, 0.996, 0.8983, 0.977, 0.9673, 0.9758, 0.9841, 0.9969, 0.9417, 0.969, 0.974, 0.9823, 0.9687, 0.9701, 0.9602, 0.9912, 0.9808, 0.9934, 0.942, 0.988, 0.9821, 0.9294, 0.9965, 0.9907, 0.9785, 0.8403, 0.976, 0.9047, 0.9889, 0.9753, 0.9913, 0.989, 0.9795, 0.9808, 0.989, 0.9836, 0.9361, 0.9877, 0.9856, 0.9691, 0.9478, 0.7205, 0.9819, 0.9943, 0.9836, 0.985, 0.9905, 0.9591, 0.9907, 0.9786, 0.9688, 0.9749, 0.9671, 0.9911, 0.9819, 0.9858, 0.9965, 0.9904, 0.9763, 0.991, 0.977, 0.9655, 0.9432, 0.971, 0.9903, 0.9909, 0.9345, 0.934, 0.9799, 0.9792, 0.9426, 0.978, 0.9701, 0.9255, 0.9837, 0.9865, 0.9355, 0.9861, 0.9925, 0.9755, 0.9861, 0.973, 0.9781, 0.989, 0.925], 'Recall@P=50': [0.992, 0.972, 0.9897, 0.992, 0.976, 1.0, 0.9912, 0.964, 0.9976, 0.9957, 0.99, 0.994, 0.924, 0.994, 0.98, 0.992, 0.9968, 1.0, 0.98, 0.992, 0.992, 0.966, 0.984, 0.996, 0.988, 0.9936, 0.992, 0.992, 0.9988, 0.9856, 0.948, 0.976, 0.984, 0.992, 0.991, 0.972, 0.988, 0.999, 0.986, 0.968, 1.0, 0.972, 0.996, 0.996, 0.988, 0.992, 0.9707, 0.984, 0.96, 0.988, 0.964, 0.9895, 0.996, 0.996, 0.992, 0.9953, 1.0, 0.98, 0.988, 0.968, 0.972, 0.992, 0.988, 0.988, 0.9907, 0.97, 1.0, 0.9947, 0.99, 0.944, 0.976, 0.978, 0.992, 0.9904, 0.976, 0.976, 0.96, 0.9933, 0.9973, 1.0, 0.9947, 1.0, 0.999, 0.96, 0.998, 0.994, 0.9985, 0.984, 0.9896, 0.996, 0.998, 0.956, 0.992, 0.984, 0.98, 0.9975, 0.996, 0.984, 0.988, 0.988, 0.9926, 0.98, 0.976, 0.9907, 0.996, 0.9907, 0.998, 0.968, 0.9952, 0.988, 0.968, 1.0, 0.9993, 0.988, 0.956, 0.988, 0.956, 0.9967, 0.992, 0.996, 0.996, 0.994, 0.996, 0.992, 0.9987, 0.968, 0.992, 0.992, 0.984, 0.976, 0.9, 0.988, 0.996, 0.996, 0.994, 0.992, 0.9787, 0.996, 0.9927, 0.992, 0.98, 0.976, 1.0, 0.99, 0.9936, 1.0, 0.9998, 0.9907, 0.992, 0.986, 0.984, 0.968, 0.9827, 0.992, 0.996, 0.956, 0.96, 0.996, 0.988, 0.968, 0.992, 0.988, 0.944, 0.9968, 0.992, 0.952, 0.9927, 0.994, 0.98, 1.0, 0.976, 0.984, 0.9998, 0.964], 'micro': 0.9811, 'macro': 0.9707, 'weighted': 0.9796}
2024-07-27 11:11:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:11:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:11:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 56/iteration 33744 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_56_iter_33744.pt
2024-07-27 11:11:13 - [34m[1mLOGS   [0m - Model state for epoch 56/iteration 33744 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_56_iter_33744.pt
[31m===========================================================================[0m
2024-07-27 11:11:15 - [32m[1mINFO   [0m - Training epoch 57
2024-07-27 11:11:15 - [34m[1mLOGS   [0m - Epoch:  57 [   33745/10000000], loss: {'classification': 4.5157, 'neural_augmentation': 8.8551, 'total_loss': 13.3709}, LR: [1e-06, 1e-06], Avg. batch load time: 0.303, Elapsed time:  0.57
2024-07-27 11:13:06 - [34m[1mLOGS   [0m - Epoch:  57 [   34245/10000000], loss: {'classification': 4.2342, 'neural_augmentation': 9.8151, 'total_loss': 14.0493}, LR: [1e-06, 1e-06], Avg. batch load time: 0.001, Elapsed time: 111.44
2024-07-27 11:13:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 57
	 loss={'classification': 4.243, 'neural_augmentation': 9.8071, 'total_loss': 14.0501}
2024-07-27 11:13:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 57
	 loss={'classification': 2.3834, 'neural_augmentation': 0.0, 'total_loss': 2.3834} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9534, 0.9167, 0.9347, 0.9818, 0.9407, 0.984, 0.9301, 0.8857, 0.9546, 0.9231, 0.9214, 0.9376, 0.8196, 0.9603, 0.9174, 0.9633, 0.9762, 0.984, 0.953, 0.9565, 0.9613, 0.8898, 0.9431, 0.9616, 0.9494, 0.9407, 0.9569, 0.9637, 0.9466, 0.936, 0.8608, 0.896, 0.9395, 0.9551, 0.9232, 0.9076, 0.956, 0.95, 0.9272, 0.898, 0.998, 0.873, 0.9461, 0.9721, 0.938, 0.9655, 0.849, 0.9579, 0.8704, 0.9383, 0.9032, 0.9204, 0.984, 0.9458, 0.9618, 0.9563, 0.9839, 0.9465, 0.9393, 0.8778, 0.8694, 0.936, 0.9485, 0.9587, 0.9346, 0.8968, 0.978, 0.9547, 0.9613, 0.854, 0.9173, 0.9253, 0.9657, 0.9415, 0.9142, 0.9136, 0.8861, 0.9551, 0.967, 0.9798, 0.9332, 0.978, 0.9417, 0.9076, 0.9645, 0.9657, 0.9419, 0.9419, 0.9093, 0.9433, 0.983, 0.8469, 0.9485, 0.9178, 0.9474, 0.9447, 0.988, 0.8924, 0.922, 0.9184, 0.9444, 0.9295, 0.9423, 0.8981, 0.9721, 0.9427, 0.9727, 0.8957, 0.9601, 0.9615, 0.8822, 0.978, 0.9555, 0.944, 0.7767, 0.9383, 0.8497, 0.9579, 0.9249, 0.9715, 0.9623, 0.9394, 0.9658, 0.9679, 0.9367, 0.874, 0.9598, 0.9511, 0.936, 0.8969, 0.6904, 0.9595, 0.9801, 0.9518, 0.9472, 0.972, 0.9064, 0.9714, 0.9363, 0.9256, 0.9451, 0.9234, 0.9619, 0.9459, 0.9562, 0.9756, 0.9533, 0.9305, 0.9798, 0.9451, 0.9229, 0.9014, 0.9335, 0.9737, 0.9598, 0.8903, 0.8889, 0.9332, 0.9378, 0.8926, 0.9348, 0.9405, 0.8665, 0.9422, 0.9639, 0.887, 0.9527, 0.9739, 0.9428, 0.9541, 0.9379, 0.9452, 0.9477, 0.8654], 'AP': [0.9836, 0.9567, 0.9777, 0.9913, 0.9692, 0.9974, 0.974, 0.9321, 0.9887, 0.9763, 0.9654, 0.9797, 0.8854, 0.9887, 0.9636, 0.9817, 0.9933, 0.9959, 0.9748, 0.986, 0.9833, 0.9428, 0.977, 0.9892, 0.9803, 0.9806, 0.9855, 0.9871, 0.9868, 0.9746, 0.9216, 0.9512, 0.9697, 0.9839, 0.9733, 0.9586, 0.9782, 0.989, 0.9717, 0.9451, 1.0, 0.9385, 0.9855, 0.9903, 0.9787, 0.9883, 0.9258, 0.9807, 0.9264, 0.9773, 0.9514, 0.9733, 0.9938, 0.9825, 0.9864, 0.9888, 0.9965, 0.9742, 0.9661, 0.9374, 0.9379, 0.9728, 0.9774, 0.9865, 0.9763, 0.9476, 0.9947, 0.9857, 0.9859, 0.9188, 0.9516, 0.9657, 0.9837, 0.9773, 0.9583, 0.9574, 0.9235, 0.9862, 0.9938, 0.9958, 0.9806, 0.9948, 0.9845, 0.946, 0.9902, 0.9906, 0.9868, 0.9775, 0.9657, 0.9843, 0.9958, 0.9005, 0.9776, 0.9656, 0.9738, 0.983, 0.9964, 0.9386, 0.9683, 0.9756, 0.9822, 0.9674, 0.9705, 0.9592, 0.9903, 0.9806, 0.993, 0.941, 0.988, 0.9833, 0.9311, 0.9956, 0.9905, 0.9779, 0.8358, 0.9755, 0.8996, 0.9876, 0.9767, 0.9907, 0.9884, 0.9804, 0.9811, 0.989, 0.9842, 0.9363, 0.9868, 0.9857, 0.9681, 0.9472, 0.7188, 0.9833, 0.9937, 0.9857, 0.9843, 0.9898, 0.9593, 0.9898, 0.9783, 0.9708, 0.9759, 0.9635, 0.9905, 0.9813, 0.9859, 0.9955, 0.9902, 0.9769, 0.9919, 0.9774, 0.9678, 0.9413, 0.9707, 0.9895, 0.9898, 0.9328, 0.9325, 0.9779, 0.9786, 0.9467, 0.9783, 0.969, 0.9227, 0.9831, 0.9869, 0.9342, 0.9854, 0.9922, 0.9738, 0.9864, 0.9704, 0.978, 0.9893, 0.9218], 'Recall@P=50': [0.9913, 0.976, 0.9897, 0.992, 0.976, 1.0, 0.9896, 0.972, 0.9968, 0.9957, 0.986, 0.9936, 0.928, 0.994, 0.978, 0.992, 0.9968, 0.996, 0.976, 0.992, 0.988, 0.962, 0.98, 0.9952, 0.9867, 0.9928, 0.992, 0.996, 0.9989, 0.9872, 0.944, 0.972, 0.984, 0.996, 0.9915, 0.98, 0.984, 0.9989, 0.983, 0.972, 1.0, 0.972, 0.992, 0.992, 0.988, 0.992, 0.972, 0.984, 0.9573, 0.988, 0.964, 0.9895, 0.998, 0.9943, 0.99, 0.9953, 0.998, 0.98, 0.984, 0.968, 0.972, 0.992, 0.988, 0.996, 0.9887, 0.972, 0.996, 0.992, 0.99, 0.952, 0.972, 0.98, 0.992, 0.9896, 0.98, 0.978, 0.964, 0.9947, 0.9973, 1.0, 0.9937, 0.996, 0.9982, 0.96, 0.998, 0.994, 0.9985, 0.984, 0.9922, 0.992, 0.998, 0.956, 0.988, 0.9832, 0.98, 0.9967, 0.996, 0.98, 0.9873, 0.992, 0.9926, 0.98, 0.976, 0.9867, 0.992, 0.9907, 1.0, 0.964, 0.9952, 0.992, 0.968, 1.0, 0.9992, 0.988, 0.944, 0.988, 0.952, 0.9947, 0.992, 0.996, 0.994, 0.9947, 0.992, 0.992, 0.9983, 0.968, 0.992, 0.992, 0.988, 0.976, 0.892, 0.996, 0.996, 0.996, 0.994, 0.992, 0.98, 0.992, 0.9923, 0.992, 0.98, 0.968, 1.0, 0.99, 0.9936, 1.0, 0.9997, 0.9933, 0.992, 0.986, 0.988, 0.968, 0.98, 0.992, 0.994, 0.956, 0.96, 0.992, 0.988, 0.972, 0.994, 0.988, 0.944, 0.997, 0.992, 0.952, 0.9927, 0.994, 0.98, 1.0, 0.98, 0.988, 0.9995, 0.952], 'micro': 0.9807, 'macro': 0.9703, 'weighted': 0.9793}
2024-07-27 11:14:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:14:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:14:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 57/iteration 34336 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_57_iter_34336.pt
2024-07-27 11:14:01 - [34m[1mLOGS   [0m - Model state for epoch 57/iteration 34336 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_57_iter_34336.pt
[31m===========================================================================[0m
2024-07-27 11:14:03 - [32m[1mINFO   [0m - Training epoch 58
2024-07-27 11:14:04 - [34m[1mLOGS   [0m - Epoch:  58 [   34337/10000000], loss: {'classification': 4.9806, 'neural_augmentation': 10.5902, 'total_loss': 15.5708}, LR: [1e-06, 1e-06], Avg. batch load time: 0.410, Elapsed time:  0.65
2024-07-27 11:15:49 - [34m[1mLOGS   [0m - Epoch:  58 [   34837/10000000], loss: {'classification': 4.1864, 'neural_augmentation': 9.8501, 'total_loss': 14.0365}, LR: [1e-06, 1e-06], Avg. batch load time: 0.002, Elapsed time: 105.70
2024-07-27 11:16:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 58
	 loss={'classification': 4.2107, 'neural_augmentation': 9.8238, 'total_loss': 14.0346}
2024-07-27 11:16:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 58
	 loss={'classification': 2.3627, 'neural_augmentation': 0.0, 'total_loss': 2.3627} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9531, 0.9155, 0.9374, 0.9838, 0.939, 0.9841, 0.9345, 0.8935, 0.9543, 0.9232, 0.9257, 0.9402, 0.816, 0.9657, 0.9202, 0.9571, 0.9747, 0.984, 0.9547, 0.959, 0.9615, 0.8877, 0.9419, 0.9645, 0.9496, 0.9384, 0.9571, 0.9602, 0.9487, 0.9342, 0.856, 0.898, 0.9393, 0.9569, 0.9214, 0.911, 0.9535, 0.9502, 0.9246, 0.8926, 0.998, 0.8755, 0.952, 0.9739, 0.9424, 0.9672, 0.8475, 0.9607, 0.8681, 0.9405, 0.8927, 0.9216, 0.9869, 0.9466, 0.9616, 0.9567, 0.9849, 0.9442, 0.9357, 0.874, 0.8778, 0.9376, 0.951, 0.9547, 0.934, 0.8996, 0.976, 0.9558, 0.9571, 0.8467, 0.9271, 0.9229, 0.9657, 0.9426, 0.9191, 0.9104, 0.8908, 0.9569, 0.9683, 0.9798, 0.9348, 0.976, 0.9413, 0.8951, 0.9681, 0.9643, 0.9434, 0.9431, 0.9039, 0.948, 0.9839, 0.8413, 0.9506, 0.9175, 0.9506, 0.9457, 0.99, 0.8941, 0.9209, 0.9131, 0.9471, 0.9289, 0.9369, 0.8955, 0.9719, 0.9422, 0.9737, 0.9073, 0.9613, 0.9572, 0.8884, 0.9799, 0.9555, 0.9499, 0.7784, 0.9366, 0.853, 0.9585, 0.9184, 0.9719, 0.963, 0.9391, 0.9657, 0.9671, 0.9368, 0.881, 0.9605, 0.9539, 0.9379, 0.8965, 0.6899, 0.9595, 0.9743, 0.9535, 0.9469, 0.972, 0.9065, 0.972, 0.9376, 0.9256, 0.945, 0.9317, 0.9621, 0.9497, 0.9564, 0.9777, 0.9525, 0.9326, 0.9798, 0.9473, 0.9185, 0.9028, 0.9304, 0.9739, 0.9618, 0.8817, 0.887, 0.9329, 0.9446, 0.894, 0.9366, 0.94, 0.865, 0.9403, 0.9696, 0.8866, 0.9549, 0.975, 0.9371, 0.9543, 0.938, 0.9455, 0.9481, 0.8614], 'AP': [0.9835, 0.9558, 0.9786, 0.9902, 0.9694, 0.9971, 0.9755, 0.9285, 0.9892, 0.9767, 0.9662, 0.9801, 0.8842, 0.9891, 0.9642, 0.9813, 0.9931, 0.9967, 0.977, 0.9851, 0.9823, 0.9409, 0.9764, 0.9895, 0.9779, 0.9803, 0.9846, 0.9877, 0.9867, 0.9741, 0.9228, 0.9514, 0.9723, 0.9853, 0.9736, 0.9595, 0.9805, 0.9891, 0.971, 0.9392, 1.0, 0.9388, 0.9873, 0.9898, 0.9794, 0.9884, 0.9275, 0.9797, 0.9255, 0.9776, 0.948, 0.9733, 0.9931, 0.9831, 0.9858, 0.989, 0.997, 0.9734, 0.964, 0.9353, 0.9386, 0.9742, 0.9788, 0.9855, 0.976, 0.9484, 0.9955, 0.9857, 0.9856, 0.9171, 0.9537, 0.9646, 0.9862, 0.9774, 0.9571, 0.9569, 0.9216, 0.9881, 0.9941, 0.9963, 0.9811, 0.9954, 0.9846, 0.9421, 0.991, 0.9915, 0.9869, 0.9767, 0.9655, 0.9861, 0.9958, 0.8988, 0.9783, 0.9659, 0.9757, 0.9836, 0.9968, 0.9409, 0.9679, 0.9738, 0.983, 0.9679, 0.9698, 0.9585, 0.9896, 0.9803, 0.9929, 0.9439, 0.9879, 0.9849, 0.929, 0.9959, 0.9905, 0.9793, 0.8392, 0.9752, 0.9057, 0.9887, 0.9747, 0.9902, 0.9891, 0.9806, 0.9847, 0.9889, 0.9843, 0.9357, 0.9872, 0.986, 0.9722, 0.9495, 0.722, 0.9851, 0.9941, 0.9845, 0.9843, 0.9891, 0.9599, 0.989, 0.9792, 0.9707, 0.9754, 0.9675, 0.9916, 0.9815, 0.9865, 0.9962, 0.9903, 0.9776, 0.9912, 0.9741, 0.9663, 0.9445, 0.9694, 0.989, 0.9907, 0.9335, 0.9324, 0.9793, 0.9793, 0.94, 0.9787, 0.9672, 0.9249, 0.983, 0.9862, 0.9345, 0.986, 0.992, 0.9732, 0.9873, 0.9711, 0.9776, 0.9892, 0.9231], 'Recall@P=50': [0.9913, 0.976, 0.9914, 0.992, 0.98, 1.0, 0.988, 0.964, 0.9976, 0.9957, 0.986, 0.9952, 0.908, 0.994, 0.982, 0.988, 0.996, 1.0, 0.976, 0.992, 0.992, 0.962, 0.98, 0.9944, 0.988, 0.992, 0.992, 0.996, 0.9991, 0.9864, 0.948, 0.972, 0.988, 1.0, 0.991, 0.976, 0.992, 0.999, 0.984, 0.964, 1.0, 0.976, 0.996, 0.992, 0.988, 0.992, 0.9707, 0.984, 0.9573, 0.988, 0.964, 0.9884, 0.992, 0.9949, 0.988, 0.9947, 1.0, 0.98, 0.988, 0.972, 0.976, 0.992, 0.992, 0.996, 0.99, 0.974, 0.996, 0.992, 0.99, 0.948, 0.972, 0.982, 0.992, 0.9888, 0.972, 0.98, 0.964, 0.9947, 0.9973, 1.0, 0.9937, 1.0, 0.9982, 0.952, 0.998, 0.994, 0.9985, 0.984, 0.9896, 0.996, 0.998, 0.952, 0.992, 0.9824, 0.98, 0.9967, 0.996, 0.98, 0.9853, 0.988, 0.9931, 0.98, 0.98, 0.988, 0.992, 0.991, 1.0, 0.968, 0.9936, 0.996, 0.972, 1.0, 0.9992, 0.99, 0.936, 0.9887, 0.956, 0.9967, 0.992, 0.992, 0.996, 0.994, 0.996, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.992, 0.978, 0.896, 0.992, 0.996, 0.996, 0.9933, 0.992, 0.984, 0.992, 0.9933, 0.992, 0.98, 0.972, 1.0, 0.991, 0.9944, 1.0, 0.9997, 0.9947, 0.992, 0.986, 0.982, 0.97, 0.984, 0.992, 0.994, 0.956, 0.96, 0.996, 0.988, 0.964, 0.993, 0.988, 0.948, 0.9968, 0.992, 0.956, 0.994, 0.994, 0.98, 1.0, 0.98, 0.984, 0.9996, 0.96], 'micro': 0.9809, 'macro': 0.9704, 'weighted': 0.9795}
2024-07-27 11:16:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:16:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:16:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 58/iteration 34928 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_58_iter_34928.pt
2024-07-27 11:16:44 - [34m[1mLOGS   [0m - Model state for epoch 58/iteration 34928 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_58_iter_34928.pt
[31m===========================================================================[0m
2024-07-27 11:16:46 - [32m[1mINFO   [0m - Training epoch 59
2024-07-27 11:16:46 - [34m[1mLOGS   [0m - Epoch:  59 [   34929/10000000], loss: {'classification': 3.319, 'neural_augmentation': 7.0895, 'total_loss': 10.4085}, LR: [1e-06, 1e-06], Avg. batch load time: 0.324, Elapsed time:  0.50
2024-07-27 11:18:38 - [34m[1mLOGS   [0m - Epoch:  59 [   35429/10000000], loss: {'classification': 4.165, 'neural_augmentation': 9.7975, 'total_loss': 13.9625}, LR: [1e-06, 1e-06], Avg. batch load time: 0.001, Elapsed time: 112.56
2024-07-27 11:18:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 59
	 loss={'classification': 4.1705, 'neural_augmentation': 9.7698, 'total_loss': 13.9404}
2024-07-27 11:19:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 59
	 loss={'classification': 2.3467, 'neural_augmentation': 0.0, 'total_loss': 2.3467} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.9543, 0.9106, 0.9379, 0.9838, 0.9366, 0.9839, 0.9333, 0.8832, 0.9559, 0.9227, 0.9273, 0.9419, 0.8143, 0.963, 0.9217, 0.9576, 0.976, 0.9839, 0.9508, 0.9571, 0.9571, 0.8898, 0.9412, 0.9612, 0.9514, 0.9417, 0.9588, 0.9655, 0.948, 0.9359, 0.8627, 0.8975, 0.9369, 0.9549, 0.9214, 0.9121, 0.9522, 0.952, 0.9284, 0.8984, 0.998, 0.8803, 0.9533, 0.9759, 0.9443, 0.9695, 0.8506, 0.9607, 0.8661, 0.9407, 0.8988, 0.9208, 0.9859, 0.9479, 0.9648, 0.9584, 0.9849, 0.9423, 0.9398, 0.8782, 0.88, 0.9402, 0.9463, 0.9565, 0.9345, 0.9026, 0.976, 0.9606, 0.9626, 0.8623, 0.9228, 0.9243, 0.9637, 0.9427, 0.9145, 0.9116, 0.8856, 0.9592, 0.9678, 0.9778, 0.9347, 0.9739, 0.9419, 0.9043, 0.9679, 0.9665, 0.9445, 0.9426, 0.9064, 0.9537, 0.9839, 0.8374, 0.9463, 0.9159, 0.9506, 0.946, 0.99, 0.903, 0.922, 0.9196, 0.948, 0.9342, 0.9402, 0.8999, 0.9759, 0.9428, 0.9737, 0.8971, 0.959, 0.9576, 0.8765, 0.9779, 0.9569, 0.9473, 0.7808, 0.9417, 0.8641, 0.9596, 0.9212, 0.9737, 0.9599, 0.9392, 0.9621, 0.9673, 0.9367, 0.8837, 0.9583, 0.953, 0.9376, 0.9038, 0.6894, 0.9574, 0.9723, 0.9533, 0.9471, 0.9739, 0.9075, 0.9739, 0.937, 0.9283, 0.9488, 0.9295, 0.9637, 0.9491, 0.9559, 0.9777, 0.9532, 0.9312, 0.9798, 0.948, 0.9198, 0.9007, 0.933, 0.9759, 0.961, 0.8922, 0.896, 0.9337, 0.9407, 0.8966, 0.9339, 0.9395, 0.8688, 0.9424, 0.9652, 0.8908, 0.9548, 0.973, 0.945, 0.9543, 0.9385, 0.9452, 0.9488, 0.8584], 'AP': [0.9838, 0.9562, 0.9787, 0.9912, 0.97, 0.9971, 0.9756, 0.9297, 0.989, 0.9759, 0.9661, 0.981, 0.8848, 0.9883, 0.9659, 0.9814, 0.9938, 0.9964, 0.9778, 0.9844, 0.983, 0.9435, 0.9764, 0.9894, 0.9803, 0.9808, 0.9841, 0.9863, 0.9865, 0.9744, 0.9247, 0.9513, 0.9729, 0.9846, 0.973, 0.9605, 0.9793, 0.9894, 0.9717, 0.9403, 1.0, 0.9426, 0.9874, 0.9901, 0.9788, 0.9891, 0.9273, 0.9797, 0.9279, 0.9773, 0.9488, 0.9729, 0.9932, 0.9832, 0.9864, 0.9894, 0.9968, 0.9729, 0.9662, 0.9399, 0.9433, 0.9759, 0.9788, 0.9852, 0.9773, 0.9473, 0.9959, 0.9864, 0.9859, 0.9197, 0.9564, 0.9658, 0.9851, 0.9773, 0.9579, 0.957, 0.9229, 0.9874, 0.9941, 0.9963, 0.9804, 0.9955, 0.9846, 0.9428, 0.9916, 0.9917, 0.9874, 0.9768, 0.9644, 0.986, 0.9955, 0.8984, 0.9788, 0.9657, 0.9765, 0.9837, 0.9966, 0.9421, 0.9686, 0.9755, 0.9837, 0.9685, 0.9705, 0.9598, 0.9901, 0.9805, 0.9941, 0.9409, 0.9875, 0.9845, 0.9298, 0.9956, 0.9905, 0.9792, 0.8438, 0.9757, 0.9033, 0.9884, 0.9754, 0.99, 0.988, 0.9809, 0.9834, 0.9892, 0.9839, 0.9378, 0.986, 0.9866, 0.9723, 0.9514, 0.7248, 0.9841, 0.9943, 0.9857, 0.9846, 0.989, 0.9605, 0.9892, 0.979, 0.9711, 0.975, 0.9662, 0.9908, 0.9829, 0.9868, 0.9957, 0.9905, 0.9784, 0.9917, 0.9771, 0.9676, 0.9435, 0.9705, 0.9889, 0.9909, 0.936, 0.9344, 0.9785, 0.9789, 0.9414, 0.9778, 0.9691, 0.9266, 0.9837, 0.9866, 0.9369, 0.9858, 0.992, 0.9746, 0.9866, 0.9714, 0.9784, 0.9891, 0.9257], 'Recall@P=50': [0.992, 0.968, 0.9914, 0.992, 0.976, 1.0, 0.9896, 0.964, 0.9976, 0.9951, 0.99, 0.994, 0.92, 0.994, 0.982, 0.988, 0.9968, 1.0, 0.984, 0.996, 0.992, 0.966, 0.98, 0.9968, 0.9867, 0.9936, 0.996, 0.992, 0.9984, 0.9864, 0.944, 0.968, 0.988, 0.992, 0.9915, 0.976, 0.988, 0.9989, 0.984, 0.956, 1.0, 0.976, 0.992, 0.992, 0.988, 0.992, 0.968, 0.984, 0.9613, 0.984, 0.968, 0.9879, 0.992, 0.9954, 0.99, 0.996, 1.0, 0.98, 0.988, 0.968, 0.972, 0.992, 0.992, 0.992, 0.99, 0.966, 1.0, 0.9907, 0.994, 0.948, 0.976, 0.98, 0.992, 0.9888, 0.972, 0.976, 0.964, 0.996, 0.9973, 1.0, 0.9958, 1.0, 0.9984, 0.96, 0.998, 0.994, 0.9985, 0.98, 0.9896, 0.992, 0.998, 0.948, 0.996, 0.9784, 0.98, 0.9967, 0.996, 0.984, 0.9867, 0.988, 0.9937, 0.98, 0.98, 0.9867, 0.992, 0.9917, 1.0, 0.96, 0.9936, 0.992, 0.968, 1.0, 0.9994, 0.99, 0.952, 0.988, 0.952, 0.9967, 0.988, 0.992, 0.994, 0.994, 0.992, 0.992, 0.9987, 0.972, 0.992, 0.992, 0.992, 0.98, 0.904, 0.992, 0.996, 0.996, 0.9933, 0.992, 0.98, 0.988, 0.993, 0.992, 0.98, 0.976, 1.0, 0.99, 0.9936, 1.0, 0.9998, 0.9933, 0.992, 0.984, 0.984, 0.966, 0.984, 0.992, 0.996, 0.96, 0.96, 0.996, 0.992, 0.964, 0.992, 0.988, 0.944, 0.9962, 0.992, 0.96, 0.9933, 0.994, 0.98, 1.0, 0.976, 0.992, 0.9996, 0.948], 'micro': 0.9812, 'macro': 0.9709, 'weighted': 0.9797}
2024-07-27 11:19:34 - [34m[1mLOGS   [0m - Best checkpoint with score 0.97 saved at /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_best.pt
2024-07-27 11:19:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_score_0.9701.pt
2024-07-27 11:19:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_0.9705.pt', 'checkpoint_score_0.9706.pt', 'checkpoint_score_0.9707.pt', 'checkpoint_score_0.9708.pt', 'checkpoint_score_0.9709.pt']
2024-07-27 11:19:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_avg.pt
2024-07-27 11:19:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_last.pt
2024-07-27 11:19:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_last.pt
2024-07-27 11:19:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 59/iteration 35520 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/training_checkpoint_epoch_59_iter_35520.pt
2024-07-27 11:19:38 - [34m[1mLOGS   [0m - Model state for epoch 59/iteration 35520 is saved at: /ML-A100/team/mm/models/catlip_data/open_vit_base/ingredient_101/train/checkpoint_epoch_59_iter_35520.pt
2024-07-27 11:19:38 - [34m[1mLOGS   [0m - Training took 01:50:11.25
