nohup: ignoring input
2024-07-22 11:30:10 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-07-22 11:30:12 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/vit_base.pt
2024-07-22 11:30:12 - [32m[1mINFO   [0m - Trainable parameters: ['cls_token', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-07-22 11:30:12 - [34m[1mLOGS   [0m - [36mModel[0m
VisionTransformer(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_emb): Sequential(
    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
    (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
    (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
  )
  (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
  (transformer): Sequential(
    (0): FlashTransformerEncoder
    (1): FlashTransformerEncoder
    (2): FlashTransformerEncoder
    (3): FlashTransformerEncoder
    (4): FlashTransformerEncoder
    (5): FlashTransformerEncoder
    (6): FlashTransformerEncoder
    (7): FlashTransformerEncoder
    (8): FlashTransformerEncoder
    (9): FlashTransformerEncoder
    (10): FlashTransformerEncoder
    (11): FlashTransformerEncoder
  )
  (classifier): LinearLayer(in_features=768, out_features=172, bias=True, channel_first=False)
  (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
  (emb_dropout): Dropout(p=0.0, inplace=False)
)
[31m=================================================================[0m
                  VisionTransformer Summary
[31m=================================================================[0m
Total parameters     =   86.088 M
Total trainable parameters =   86.088 M

2024-07-22 11:30:12 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-22 11:30:12 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 86.088M                | 17.013G    |
|  cls_token                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_emb                           |  0.748M                |  0.262G    |
|   patch_emb.0.block                  |   9.6K                 |   30.106M  |
|    patch_emb.0.block.conv            |    9.216K              |    28.901M |
|    patch_emb.0.block.norm            |    0.384K              |    1.204M  |
|   patch_emb.1.block                  |   0.148M               |   0.116G   |
|    patch_emb.1.block.conv            |    0.147M              |    0.116G  |
|    patch_emb.1.block.norm            |    0.384K              |    0.301M  |
|   patch_emb.2.block.conv             |   0.591M               |   0.116G   |
|    patch_emb.2.block.conv.weight     |    (768, 192, 2, 2)    |            |
|    patch_emb.2.block.conv.bias       |    (768,)              |            |
|  post_transformer_norm               |  1.536K                |  0.756M    |
|   post_transformer_norm.weight       |   (768,)               |            |
|   post_transformer_norm.bias         |   (768,)               |            |
|  transformer                         |  85.054M               |  16.75G    |
|   transformer.0                      |   7.088M               |   1.396G   |
|    transformer.0.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.0.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.1                      |   7.088M               |   1.396G   |
|    transformer.1.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.1.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.2                      |   7.088M               |   1.396G   |
|    transformer.2.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.2.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.3                      |   7.088M               |   1.396G   |
|    transformer.3.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.3.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.4                      |   7.088M               |   1.396G   |
|    transformer.4.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.4.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.5                      |   7.088M               |   1.396G   |
|    transformer.5.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.5.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.6                      |   7.088M               |   1.396G   |
|    transformer.6.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.6.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.7                      |   7.088M               |   1.396G   |
|    transformer.7.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.7.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.8                      |   7.088M               |   1.396G   |
|    transformer.8.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.8.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.9                      |   7.088M               |   1.396G   |
|    transformer.9.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.9.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.10                     |   7.088M               |   1.396G   |
|    transformer.10.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.10.pre_norm_ffn       |    4.724M              |    0.93G   |
|   transformer.11                     |   7.088M               |   1.396G   |
|    transformer.11.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.11.pre_norm_ffn       |    4.724M              |    0.93G   |
|  classifier                          |  0.132M                |  0.132M    |
|   classifier.weight                  |   (172, 768)           |            |
|   classifier.bias                    |   (172,)               |            |
|  pos_embed.pos_embed                 |  0.151M                |  0         |
|   pos_embed.pos_embed.pos_embed      |   (1, 1, 196, 768)     |            |
2024-07-22 11:30:13 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-22 11:30:13 - [33m[1mWARNING[0m - Uncalled Modules:
{'transformer.0.drop_path', 'transformer.9.drop_path', 'neural_augmentor', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.contrast.min_fn', 'neural_augmentor.noise.max_fn', 'neural_augmentor.contrast.max_fn', 'neural_augmentor.noise', 'transformer.4.drop_path', 'transformer.1.drop_path', 'transformer.6.drop_path', 'neural_augmentor.contrast', 'transformer.8.drop_path', 'neural_augmentor.noise.min_fn', 'transformer.3.drop_path', 'transformer.10.drop_path', 'neural_augmentor.brightness.max_fn', 'transformer.5.drop_path', 'transformer.7.drop_path', 'transformer.2.drop_path', 'neural_augmentor.brightness', 'transformer.11.drop_path'}
2024-07-22 11:30:13 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 14, 'aten::scaled_dot_product_attention': 12, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-22 11:30:13 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train
2024-07-22 11:30:19 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:30001
2024-07-22 11:30:23 - [34m[1mLOGS   [0m - Number of categories: 172
2024-07-22 11:30:23 - [34m[1mLOGS   [0m - Total number of samples: 66071
2024-07-22 11:30:23 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-22 11:30:23 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food172/food_172/train_images 
	is_training=True 
	num_samples=66071
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=172
)
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Number of categories: 172
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Total number of samples: 44170
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food172/food_172/test_images 
	is_training=False 
	num_samples=44170
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=172
)
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=256
	 scales=[(128, 128, 784), (160, 160, 501), (192, 192, 348), (224, 224, 256), (256, 256, 196), (288, 288, 154), (320, 320, 125)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(224, 224, 100)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-22 11:30:24 - [34m[1mLOGS   [0m - Number of data workers: 64
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/vit_base.pt
2024-07-22 11:30:27 - [32m[1mINFO   [0m - Trainable parameters: ['cls_token', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - [36mModel[0m
VisionTransformer(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_emb): Sequential(
    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
    (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
    (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
  )
  (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
  (transformer): Sequential(
    (0): FlashTransformerEncoder
    (1): FlashTransformerEncoder
    (2): FlashTransformerEncoder
    (3): FlashTransformerEncoder
    (4): FlashTransformerEncoder
    (5): FlashTransformerEncoder
    (6): FlashTransformerEncoder
    (7): FlashTransformerEncoder
    (8): FlashTransformerEncoder
    (9): FlashTransformerEncoder
    (10): FlashTransformerEncoder
    (11): FlashTransformerEncoder
  )
  (classifier): LinearLayer(in_features=768, out_features=172, bias=True, channel_first=False)
  (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
  (emb_dropout): Dropout(p=0.0, inplace=False)
)
[31m=================================================================[0m
                  VisionTransformer Summary
[31m=================================================================[0m
Total parameters     =   86.088 M
Total trainable parameters =   86.088 M

2024-07-22 11:30:27 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 86.088M                | 17.013G    |
|  cls_token                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_emb                           |  0.748M                |  0.262G    |
|   patch_emb.0.block                  |   9.6K                 |   30.106M  |
|    patch_emb.0.block.conv            |    9.216K              |    28.901M |
|    patch_emb.0.block.norm            |    0.384K              |    1.204M  |
|   patch_emb.1.block                  |   0.148M               |   0.116G   |
|    patch_emb.1.block.conv            |    0.147M              |    0.116G  |
|    patch_emb.1.block.norm            |    0.384K              |    0.301M  |
|   patch_emb.2.block.conv             |   0.591M               |   0.116G   |
|    patch_emb.2.block.conv.weight     |    (768, 192, 2, 2)    |            |
|    patch_emb.2.block.conv.bias       |    (768,)              |            |
|  post_transformer_norm               |  1.536K                |  0.756M    |
|   post_transformer_norm.weight       |   (768,)               |            |
|   post_transformer_norm.bias         |   (768,)               |            |
|  transformer                         |  85.054M               |  16.75G    |
|   transformer.0                      |   7.088M               |   1.396G   |
|    transformer.0.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.0.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.1                      |   7.088M               |   1.396G   |
|    transformer.1.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.1.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.2                      |   7.088M               |   1.396G   |
|    transformer.2.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.2.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.3                      |   7.088M               |   1.396G   |
|    transformer.3.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.3.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.4                      |   7.088M               |   1.396G   |
|    transformer.4.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.4.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.5                      |   7.088M               |   1.396G   |
|    transformer.5.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.5.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.6                      |   7.088M               |   1.396G   |
|    transformer.6.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.6.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.7                      |   7.088M               |   1.396G   |
|    transformer.7.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.7.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.8                      |   7.088M               |   1.396G   |
|    transformer.8.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.8.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.9                      |   7.088M               |   1.396G   |
|    transformer.9.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.9.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.10                     |   7.088M               |   1.396G   |
|    transformer.10.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.10.pre_norm_ffn       |    4.724M              |    0.93G   |
|   transformer.11                     |   7.088M               |   1.396G   |
|    transformer.11.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.11.pre_norm_ffn       |    4.724M              |    0.93G   |
|  classifier                          |  0.132M                |  0.132M    |
|   classifier.weight                  |   (172, 768)           |            |
|   classifier.bias                    |   (172,)               |            |
|  pos_embed.pos_embed                 |  0.151M                |  0         |
|   pos_embed.pos_embed.pos_embed      |   (1, 1, 196, 768)     |            |
2024-07-22 11:30:27 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-22 11:30:27 - [33m[1mWARNING[0m - Uncalled Modules:
{'transformer.7.drop_path', 'transformer.3.drop_path', 'neural_augmentor.contrast.max_fn', 'transformer.1.drop_path', 'transformer.8.drop_path', 'neural_augmentor.brightness', 'neural_augmentor.contrast', 'neural_augmentor', 'transformer.10.drop_path', 'transformer.2.drop_path', 'neural_augmentor.noise', 'transformer.5.drop_path', 'transformer.0.drop_path', 'neural_augmentor.noise.min_fn', 'neural_augmentor.noise.max_fn', 'neural_augmentor.contrast.min_fn', 'transformer.11.drop_path', 'transformer.6.drop_path', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.brightness.max_fn', 'transformer.4.drop_path', 'transformer.9.drop_path'}
2024-07-22 11:30:27 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 14, 'aten::scaled_dot_product_attention': 12, 'aten::sub': 1})
[31m=================================================================[0m
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - Max. epochs for training: 60
2024-07-22 11:30:27 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=60
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-22 11:30:28 - [34m[1mLOGS   [0m - Loaded checkpoint from /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:30:28 - [34m[1mLOGS   [0m - Resuming training for epoch 16
2024-07-22 11:30:28 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-22 11:30:30 - [32m[1mINFO   [0m - Training epoch 16
2024-07-22 11:30:19 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:30001
2024-07-22 11:30:19 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:30001
2024-07-22 11:30:19 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:30001
2024-07-22 11:33:31 - [34m[1mLOGS   [0m - Epoch:  16 [    1605/10000000], loss: {'classification': 1.1105, 'neural_augmentation': 0.2599, 'total_loss': 1.3703}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 174.888, Elapsed time: 180.18
2024-07-22 11:33:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 1.089, 'neural_augmentation': 0.2523, 'total_loss': 1.3413}
2024-07-22 11:37:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 0.4486, 'neural_augmentation': 0.0, 'total_loss': 0.4486} || top1={'logits': 90.964} || top5={'logits': 98.4707}
2024-07-22 11:37:10 - [34m[1mLOGS   [0m - Best checkpoint with score 90.96 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:37:10 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_89.9009.pt
2024-07-22 11:37:10 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.0788.pt', 'checkpoint_score_90.3626.pt', 'checkpoint_score_90.4032.pt', 'checkpoint_score_90.6014.pt', 'checkpoint_score_90.9640.pt']
2024-07-22 11:37:12 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:37:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:37:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:37:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 1654 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_16_iter_1654.pt
2024-07-22 11:37:16 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 1654 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_16_iter_1654.pt
[31m===========================================================================[0m
2024-07-22 11:37:18 - [32m[1mINFO   [0m - Training epoch 17
2024-07-22 11:37:20 - [34m[1mLOGS   [0m - Epoch:  17 [    1655/10000000], loss: {'classification': 1.0183, 'neural_augmentation': 0.254, 'total_loss': 1.2723}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 1.666, Elapsed time:  2.11
2024-07-22 11:37:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 1.0881, 'neural_augmentation': 0.2553, 'total_loss': 1.3433}
2024-07-22 11:37:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 0.4267, 'neural_augmentation': 0.0, 'total_loss': 0.4267} || top1={'logits': 91.4279} || top5={'logits': 98.5653}
2024-07-22 11:37:51 - [34m[1mLOGS   [0m - Best checkpoint with score 91.43 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:37:51 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_90.0788.pt
2024-07-22 11:37:51 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.3626.pt', 'checkpoint_score_90.4032.pt', 'checkpoint_score_90.6014.pt', 'checkpoint_score_90.9640.pt', 'checkpoint_score_91.4279.pt']
2024-07-22 11:37:54 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:37:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:37:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:37:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 1693 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_17_iter_1693.pt
2024-07-22 11:37:57 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 1693 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_17_iter_1693.pt
[31m===========================================================================[0m
2024-07-22 11:37:59 - [32m[1mINFO   [0m - Training epoch 18
2024-07-22 11:38:02 - [34m[1mLOGS   [0m - Epoch:  18 [    1694/10000000], loss: {'classification': 1.0038, 'neural_augmentation': 0.252, 'total_loss': 1.2557}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.432, Elapsed time:  2.96
2024-07-22 11:38:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 1.0588, 'neural_augmentation': 0.2557, 'total_loss': 1.3145}
2024-07-22 11:38:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 0.4301, 'neural_augmentation': 0.0, 'total_loss': 0.4301} || top1={'logits': 91.4977} || top5={'logits': 98.5676}
2024-07-22 11:38:36 - [34m[1mLOGS   [0m - Best checkpoint with score 91.50 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:38:37 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_90.3626.pt
2024-07-22 11:38:37 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.4032.pt', 'checkpoint_score_90.6014.pt', 'checkpoint_score_90.9640.pt', 'checkpoint_score_91.4279.pt', 'checkpoint_score_91.4977.pt']
2024-07-22 11:38:39 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:38:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:38:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:38:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 1743 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_18_iter_1743.pt
2024-07-22 11:38:42 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 1743 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_18_iter_1743.pt
[31m===========================================================================[0m
2024-07-22 11:38:44 - [32m[1mINFO   [0m - Training epoch 19
2024-07-22 11:38:47 - [34m[1mLOGS   [0m - Epoch:  19 [    1744/10000000], loss: {'classification': 1.0445, 'neural_augmentation': 0.2697, 'total_loss': 1.3142}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 2.210, Elapsed time:  2.76
2024-07-22 11:39:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 1.0606, 'neural_augmentation': 0.2586, 'total_loss': 1.3192}
2024-07-22 11:39:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 0.4298, 'neural_augmentation': 0.0, 'total_loss': 0.4298} || top1={'logits': 91.3041} || top5={'logits': 98.509}
2024-07-22 11:39:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:39:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:39:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 1795 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_19_iter_1795.pt
2024-07-22 11:39:23 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 1795 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_19_iter_1795.pt
[31m===========================================================================[0m
2024-07-22 11:39:25 - [32m[1mINFO   [0m - Training epoch 20
2024-07-22 11:39:31 - [34m[1mLOGS   [0m - Epoch:  20 [    1796/10000000], loss: {'classification': 0.9994, 'neural_augmentation': 0.262, 'total_loss': 1.2614}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 5.386, Elapsed time:  5.84
2024-07-22 11:39:52 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 1.0533, 'neural_augmentation': 0.263, 'total_loss': 1.3163}
2024-07-22 11:40:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 0.4308, 'neural_augmentation': 0.0, 'total_loss': 0.4308} || top1={'logits': 91.5586} || top5={'logits': 98.5473}
2024-07-22 11:40:04 - [34m[1mLOGS   [0m - Best checkpoint with score 91.56 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:40:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_90.4032.pt
2024-07-22 11:40:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.6014.pt', 'checkpoint_score_90.9640.pt', 'checkpoint_score_91.4279.pt', 'checkpoint_score_91.4977.pt', 'checkpoint_score_91.5586.pt']
2024-07-22 11:40:07 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:40:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:40:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:40:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 1845 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_20_iter_1845.pt
2024-07-22 11:40:11 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 1845 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_20_iter_1845.pt
[31m===========================================================================[0m
2024-07-22 11:40:13 - [32m[1mINFO   [0m - Training epoch 21
2024-07-22 11:40:14 - [34m[1mLOGS   [0m - Epoch:  21 [    1846/10000000], loss: {'classification': 1.0195, 'neural_augmentation': 0.2508, 'total_loss': 1.2703}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 1.403, Elapsed time:  1.87
2024-07-22 11:40:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 1.044, 'neural_augmentation': 0.2672, 'total_loss': 1.3112}
2024-07-22 11:40:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 0.4254, 'neural_augmentation': 0.0, 'total_loss': 0.4254} || top1={'logits': 91.5811} || top5={'logits': 98.5495}
2024-07-22 11:40:49 - [34m[1mLOGS   [0m - Best checkpoint with score 91.58 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:40:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_90.6014.pt
2024-07-22 11:40:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_90.9640.pt', 'checkpoint_score_91.4279.pt', 'checkpoint_score_91.4977.pt', 'checkpoint_score_91.5586.pt', 'checkpoint_score_91.5811.pt']
2024-07-22 11:40:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:40:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:40:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:40:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 1895 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_21_iter_1895.pt
2024-07-22 11:40:55 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 1895 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_21_iter_1895.pt
[31m===========================================================================[0m
2024-07-22 11:40:57 - [32m[1mINFO   [0m - Training epoch 22
2024-07-22 11:41:01 - [34m[1mLOGS   [0m - Epoch:  22 [    1896/10000000], loss: {'classification': 1.0593, 'neural_augmentation': 0.2768, 'total_loss': 1.3361}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 3.848, Elapsed time:  4.30
2024-07-22 11:41:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 1.0347, 'neural_augmentation': 0.2724, 'total_loss': 1.3072}
2024-07-22 11:41:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 0.4285, 'neural_augmentation': 0.0, 'total_loss': 0.4285} || top1={'logits': 91.527} || top5={'logits': 98.5}
2024-07-22 11:41:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:41:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:41:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 1944 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_22_iter_1944.pt
2024-07-22 11:41:36 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 1944 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_22_iter_1944.pt
[31m===========================================================================[0m
2024-07-22 11:41:38 - [32m[1mINFO   [0m - Training epoch 23
2024-07-22 11:41:40 - [34m[1mLOGS   [0m - Epoch:  23 [    1945/10000000], loss: {'classification': 0.9755, 'neural_augmentation': 0.2767, 'total_loss': 1.2522}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 1.977, Elapsed time:  2.43
2024-07-22 11:42:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 1.0317, 'neural_augmentation': 0.2779, 'total_loss': 1.3096}
2024-07-22 11:42:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 0.4268, 'neural_augmentation': 0.0, 'total_loss': 0.4268} || top1={'logits': 91.5586} || top5={'logits': 98.5495}
2024-07-22 11:42:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:42:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:42:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 1991 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_23_iter_1991.pt
2024-07-22 11:42:17 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 1991 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_23_iter_1991.pt
[31m===========================================================================[0m
2024-07-22 11:42:19 - [32m[1mINFO   [0m - Training epoch 24
2024-07-22 11:42:23 - [34m[1mLOGS   [0m - Epoch:  24 [    1992/10000000], loss: {'classification': 0.9925, 'neural_augmentation': 0.2839, 'total_loss': 1.2764}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 3.524, Elapsed time:  3.98
2024-07-22 11:42:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 1.0259, 'neural_augmentation': 0.2868, 'total_loss': 1.3127}
2024-07-22 11:42:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 0.4313, 'neural_augmentation': 0.0, 'total_loss': 0.4313} || top1={'logits': 91.5473} || top5={'logits': 98.5315}
2024-07-22 11:42:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:42:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:42:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 2044 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_24_iter_2044.pt
2024-07-22 11:42:59 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 2044 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_24_iter_2044.pt
[31m===========================================================================[0m
2024-07-22 11:43:01 - [32m[1mINFO   [0m - Training epoch 25
2024-07-22 11:43:04 - [34m[1mLOGS   [0m - Epoch:  25 [    2045/10000000], loss: {'classification': 0.9719, 'neural_augmentation': 0.2972, 'total_loss': 1.2691}, LR: [2e-05, 2e-05], Avg. batch load time: 2.031, Elapsed time:  2.47
2024-07-22 11:43:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 1.0233, 'neural_augmentation': 0.2947, 'total_loss': 1.318}
2024-07-22 11:43:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 0.4372, 'neural_augmentation': 0.0, 'total_loss': 0.4372} || top1={'logits': 91.6261} || top5={'logits': 98.5653}
2024-07-22 11:43:41 - [34m[1mLOGS   [0m - Best checkpoint with score 91.63 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:43:41 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_90.9640.pt
2024-07-22 11:43:41 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.4279.pt', 'checkpoint_score_91.4977.pt', 'checkpoint_score_91.5586.pt', 'checkpoint_score_91.5811.pt', 'checkpoint_score_91.6261.pt']
2024-07-22 11:43:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:43:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:43:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:43:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 2096 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_25_iter_2096.pt
2024-07-22 11:43:47 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 2096 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_25_iter_2096.pt
[31m===========================================================================[0m
2024-07-22 11:43:49 - [32m[1mINFO   [0m - Training epoch 26
2024-07-22 11:43:51 - [34m[1mLOGS   [0m - Epoch:  26 [    2097/10000000], loss: {'classification': 0.9999, 'neural_augmentation': 0.2982, 'total_loss': 1.2982}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 2.041, Elapsed time:  2.59
2024-07-22 11:44:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 1.0083, 'neural_augmentation': 0.3052, 'total_loss': 1.3135}
2024-07-22 11:44:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 0.4392, 'neural_augmentation': 0.0, 'total_loss': 0.4392} || top1={'logits': 91.6374} || top5={'logits': 98.518}
2024-07-22 11:44:27 - [34m[1mLOGS   [0m - Best checkpoint with score 91.64 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:44:27 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.4279.pt
2024-07-22 11:44:27 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.4977.pt', 'checkpoint_score_91.5586.pt', 'checkpoint_score_91.5811.pt', 'checkpoint_score_91.6261.pt', 'checkpoint_score_91.6374.pt']
2024-07-22 11:44:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:44:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:44:31 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:44:32 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 2151 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_26_iter_2151.pt
2024-07-22 11:44:33 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 2151 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_26_iter_2151.pt
[31m===========================================================================[0m
2024-07-22 11:44:35 - [32m[1mINFO   [0m - Training epoch 27
2024-07-22 11:44:39 - [34m[1mLOGS   [0m - Epoch:  27 [    2152/10000000], loss: {'classification': 1.0465, 'neural_augmentation': 0.3189, 'total_loss': 1.3653}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 3.678, Elapsed time:  4.13
2024-07-22 11:45:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 1.0162, 'neural_augmentation': 0.3152, 'total_loss': 1.3315}
2024-07-22 11:45:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 0.4282, 'neural_augmentation': 0.0, 'total_loss': 0.4282} || top1={'logits': 91.8198} || top5={'logits': 98.4932}
2024-07-22 11:45:12 - [34m[1mLOGS   [0m - Best checkpoint with score 91.82 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:45:13 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.4977.pt
2024-07-22 11:45:13 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.5586.pt', 'checkpoint_score_91.5811.pt', 'checkpoint_score_91.6261.pt', 'checkpoint_score_91.6374.pt', 'checkpoint_score_91.8198.pt']
2024-07-22 11:45:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:45:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:45:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:45:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 2201 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_27_iter_2201.pt
2024-07-22 11:45:18 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 2201 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_27_iter_2201.pt
[31m===========================================================================[0m
2024-07-22 11:45:20 - [32m[1mINFO   [0m - Training epoch 28
2024-07-22 11:45:23 - [34m[1mLOGS   [0m - Epoch:  28 [    2202/10000000], loss: {'classification': 1.0006, 'neural_augmentation': 0.3253, 'total_loss': 1.3259}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 1.747, Elapsed time:  2.30
2024-07-22 11:45:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 0.999, 'neural_augmentation': 0.3263, 'total_loss': 1.3253}
2024-07-22 11:45:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 0.4281, 'neural_augmentation': 0.0, 'total_loss': 0.4281} || top1={'logits': 91.8288} || top5={'logits': 98.5428}
2024-07-22 11:45:59 - [34m[1mLOGS   [0m - Best checkpoint with score 91.83 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:45:59 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.5586.pt
2024-07-22 11:45:59 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.5811.pt', 'checkpoint_score_91.6261.pt', 'checkpoint_score_91.6374.pt', 'checkpoint_score_91.8198.pt', 'checkpoint_score_91.8288.pt']
2024-07-22 11:46:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:46:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:46:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:46:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_28_iter_2256.pt
2024-07-22 11:46:05 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_28_iter_2256.pt
[31m===========================================================================[0m
2024-07-22 11:46:07 - [32m[1mINFO   [0m - Training epoch 29
2024-07-22 11:46:10 - [34m[1mLOGS   [0m - Epoch:  29 [    2257/10000000], loss: {'classification': 0.9928, 'neural_augmentation': 0.3463, 'total_loss': 1.3391}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 2.676, Elapsed time:  3.12
2024-07-22 11:46:30 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 1.0014, 'neural_augmentation': 0.34, 'total_loss': 1.3413}
2024-07-22 11:46:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 0.4442, 'neural_augmentation': 0.0, 'total_loss': 0.4442} || top1={'logits': 91.491} || top5={'logits': 98.4797}
2024-07-22 11:46:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:46:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:46:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 2306 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_29_iter_2306.pt
2024-07-22 11:46:47 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 2306 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_29_iter_2306.pt
[31m===========================================================================[0m
2024-07-22 11:46:49 - [32m[1mINFO   [0m - Training epoch 30
2024-07-22 11:46:52 - [34m[1mLOGS   [0m - Epoch:  30 [    2307/10000000], loss: {'classification': 0.9368, 'neural_augmentation': 0.3536, 'total_loss': 1.2904}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 3.097, Elapsed time:  3.51
2024-07-22 11:47:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'classification': 0.9942, 'neural_augmentation': 0.3537, 'total_loss': 1.3479}
2024-07-22 11:47:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'classification': 0.4313, 'neural_augmentation': 0.0, 'total_loss': 0.4313} || top1={'logits': 91.6239} || top5={'logits': 98.4437}
2024-07-22 11:47:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:47:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:47:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 2359 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_30_iter_2359.pt
2024-07-22 11:47:30 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 2359 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_30_iter_2359.pt
[31m===========================================================================[0m
2024-07-22 11:47:32 - [32m[1mINFO   [0m - Training epoch 31
2024-07-22 11:47:35 - [34m[1mLOGS   [0m - Epoch:  31 [    2360/10000000], loss: {'classification': 0.9483, 'neural_augmentation': 0.3689, 'total_loss': 1.3172}, LR: [1.6e-05, 1.6e-05], Avg. batch load time: 1.865, Elapsed time:  2.29
2024-07-22 11:47:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'classification': 1.0011, 'neural_augmentation': 0.3693, 'total_loss': 1.3704}
2024-07-22 11:48:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'classification': 0.4307, 'neural_augmentation': 0.0, 'total_loss': 0.4307} || top1={'logits': 91.8018} || top5={'logits': 98.5068}
2024-07-22 11:48:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:48:08 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:48:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 2406 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_31_iter_2406.pt
2024-07-22 11:48:09 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 2406 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_31_iter_2406.pt
[31m===========================================================================[0m
2024-07-22 11:48:11 - [32m[1mINFO   [0m - Training epoch 32
2024-07-22 11:48:13 - [34m[1mLOGS   [0m - Epoch:  32 [    2407/10000000], loss: {'classification': 0.9651, 'neural_augmentation': 0.3893, 'total_loss': 1.3544}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 2.281, Elapsed time:  2.71
2024-07-22 11:48:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'classification': 0.9929, 'neural_augmentation': 0.3832, 'total_loss': 1.3761}
2024-07-22 11:48:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'classification': 0.4388, 'neural_augmentation': 0.0, 'total_loss': 0.4388} || top1={'logits': 91.8333} || top5={'logits': 98.491}
2024-07-22 11:48:47 - [34m[1mLOGS   [0m - Best checkpoint with score 91.83 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:48:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.5811.pt
2024-07-22 11:48:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.6261.pt', 'checkpoint_score_91.6374.pt', 'checkpoint_score_91.8198.pt', 'checkpoint_score_91.8288.pt', 'checkpoint_score_91.8333.pt']
2024-07-22 11:48:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:48:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:48:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:48:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 2460 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_32_iter_2460.pt
2024-07-22 11:48:54 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 2460 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_32_iter_2460.pt
[31m===========================================================================[0m
2024-07-22 11:48:56 - [32m[1mINFO   [0m - Training epoch 33
2024-07-22 11:48:57 - [34m[1mLOGS   [0m - Epoch:  33 [    2461/10000000], loss: {'classification': 0.9377, 'neural_augmentation': 0.4068, 'total_loss': 1.3445}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 0.930, Elapsed time:  1.36
2024-07-22 11:49:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'classification': 0.9937, 'neural_augmentation': 0.4001, 'total_loss': 1.3938}
2024-07-22 11:49:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'classification': 0.428, 'neural_augmentation': 0.0, 'total_loss': 0.428} || top1={'logits': 91.9685} || top5={'logits': 98.5135}
2024-07-22 11:49:31 - [34m[1mLOGS   [0m - Best checkpoint with score 91.97 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:49:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.6261.pt
2024-07-22 11:49:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.6374.pt', 'checkpoint_score_91.8198.pt', 'checkpoint_score_91.8288.pt', 'checkpoint_score_91.8333.pt', 'checkpoint_score_91.9685.pt']
2024-07-22 11:49:34 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:49:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:49:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:49:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 2512 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_33_iter_2512.pt
2024-07-22 11:49:37 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 2512 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_33_iter_2512.pt
[31m===========================================================================[0m
2024-07-22 11:49:39 - [32m[1mINFO   [0m - Training epoch 34
2024-07-22 11:49:43 - [34m[1mLOGS   [0m - Epoch:  34 [    2513/10000000], loss: {'classification': 1.0218, 'neural_augmentation': 0.4149, 'total_loss': 1.4367}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 3.382, Elapsed time:  3.81
2024-07-22 11:50:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'classification': 0.9797, 'neural_augmentation': 0.4161, 'total_loss': 1.3958}
2024-07-22 11:50:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'classification': 0.434, 'neural_augmentation': 0.0, 'total_loss': 0.434} || top1={'logits': 92.0} || top5={'logits': 98.5293}
2024-07-22 11:50:14 - [34m[1mLOGS   [0m - Best checkpoint with score 92.00 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:50:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.6374.pt
2024-07-22 11:50:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.8198.pt', 'checkpoint_score_91.8288.pt', 'checkpoint_score_91.8333.pt', 'checkpoint_score_91.9685.pt', 'checkpoint_score_92.0000.pt']
2024-07-22 11:50:16 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:50:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:50:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:50:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 2559 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_34_iter_2559.pt
2024-07-22 11:50:20 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 2559 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_34_iter_2559.pt
[31m===========================================================================[0m
2024-07-22 11:50:22 - [32m[1mINFO   [0m - Training epoch 35
2024-07-22 11:50:24 - [34m[1mLOGS   [0m - Epoch:  35 [    2560/10000000], loss: {'classification': 0.9533, 'neural_augmentation': 0.4356, 'total_loss': 1.3889}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 1.664, Elapsed time:  2.09
2024-07-22 11:50:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'classification': 0.9875, 'neural_augmentation': 0.4323, 'total_loss': 1.4197}
2024-07-22 11:50:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'classification': 0.4267, 'neural_augmentation': 0.0, 'total_loss': 0.4267} || top1={'logits': 92.1667} || top5={'logits': 98.5901}
2024-07-22 11:50:52 - [34m[1mLOGS   [0m - Best checkpoint with score 92.17 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:50:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.8198.pt
2024-07-22 11:50:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.8288.pt', 'checkpoint_score_91.8333.pt', 'checkpoint_score_91.9685.pt', 'checkpoint_score_92.0000.pt', 'checkpoint_score_92.1667.pt']
2024-07-22 11:50:55 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:50:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:50:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:50:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 2600 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_35_iter_2600.pt
2024-07-22 11:50:59 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 2600 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_35_iter_2600.pt
[31m===========================================================================[0m
2024-07-22 11:51:01 - [32m[1mINFO   [0m - Training epoch 36
2024-07-22 11:51:02 - [34m[1mLOGS   [0m - Epoch:  36 [    2601/10000000], loss: {'classification': 0.9385, 'neural_augmentation': 0.4422, 'total_loss': 1.3807}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 1.401, Elapsed time:  1.83
2024-07-22 11:51:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'classification': 0.9747, 'neural_augmentation': 0.4486, 'total_loss': 1.4234}
2024-07-22 11:51:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'classification': 0.4344, 'neural_augmentation': 0.0, 'total_loss': 0.4344} || top1={'logits': 91.9144} || top5={'logits': 98.5}
2024-07-22 11:51:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:51:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:51:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 2653 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_36_iter_2653.pt
2024-07-22 11:51:38 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 2653 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_36_iter_2653.pt
[31m===========================================================================[0m
2024-07-22 11:51:40 - [32m[1mINFO   [0m - Training epoch 37
2024-07-22 11:51:43 - [34m[1mLOGS   [0m - Epoch:  37 [    2654/10000000], loss: {'classification': 0.9635, 'neural_augmentation': 0.4653, 'total_loss': 1.4288}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 3.220, Elapsed time:  3.63
2024-07-22 11:52:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'classification': 0.9774, 'neural_augmentation': 0.4663, 'total_loss': 1.4436}
2024-07-22 11:52:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'classification': 0.4311, 'neural_augmentation': 0.0, 'total_loss': 0.4311} || top1={'logits': 92.1059} || top5={'logits': 98.482}
2024-07-22 11:52:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:52:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:52:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 2694 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_37_iter_2694.pt
2024-07-22 11:52:13 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 2694 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_37_iter_2694.pt
[31m===========================================================================[0m
2024-07-22 11:52:15 - [32m[1mINFO   [0m - Training epoch 38
2024-07-22 11:52:18 - [34m[1mLOGS   [0m - Epoch:  38 [    2695/10000000], loss: {'classification': 0.9457, 'neural_augmentation': 0.4806, 'total_loss': 1.4263}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 2.494, Elapsed time:  2.91
2024-07-22 11:52:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'classification': 0.97, 'neural_augmentation': 0.4842, 'total_loss': 1.4542}
2024-07-22 11:52:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'classification': 0.4195, 'neural_augmentation': 0.0, 'total_loss': 0.4195} || top1={'logits': 92.2297} || top5={'logits': 98.5811}
2024-07-22 11:52:48 - [34m[1mLOGS   [0m - Best checkpoint with score 92.23 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:52:49 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.8288.pt
2024-07-22 11:52:49 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.8333.pt', 'checkpoint_score_91.9685.pt', 'checkpoint_score_92.0000.pt', 'checkpoint_score_92.1667.pt', 'checkpoint_score_92.2297.pt']
2024-07-22 11:52:53 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:52:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:52:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:52:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 2741 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_38_iter_2741.pt
2024-07-22 11:52:56 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 2741 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_38_iter_2741.pt
[31m===========================================================================[0m
2024-07-22 11:52:58 - [32m[1mINFO   [0m - Training epoch 39
2024-07-22 11:53:01 - [34m[1mLOGS   [0m - Epoch:  39 [    2742/10000000], loss: {'classification': 0.9658, 'neural_augmentation': 0.5117, 'total_loss': 1.4775}, LR: [1e-05, 1e-05], Avg. batch load time: 2.248, Elapsed time:  2.69
2024-07-22 11:53:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'classification': 0.9663, 'neural_augmentation': 0.5033, 'total_loss': 1.4696}
2024-07-22 11:53:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'classification': 0.4308, 'neural_augmentation': 0.0, 'total_loss': 0.4308} || top1={'logits': 92.1284} || top5={'logits': 98.4977}
2024-07-22 11:53:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:53:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:53:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 2790 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_39_iter_2790.pt
2024-07-22 11:53:35 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 2790 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_39_iter_2790.pt
[31m===========================================================================[0m
2024-07-22 11:53:37 - [32m[1mINFO   [0m - Training epoch 40
2024-07-22 11:53:42 - [34m[1mLOGS   [0m - Epoch:  40 [    2791/10000000], loss: {'classification': 0.9917, 'neural_augmentation': 0.5223, 'total_loss': 1.5139}, LR: [1e-05, 1e-05], Avg. batch load time: 4.238, Elapsed time:  4.69
2024-07-22 11:54:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'classification': 0.9621, 'neural_augmentation': 0.5209, 'total_loss': 1.4829}
2024-07-22 11:54:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'classification': 0.4406, 'neural_augmentation': 0.0, 'total_loss': 0.4406} || top1={'logits': 91.964} || top5={'logits': 98.4887}
2024-07-22 11:54:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:54:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:54:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 2843 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_40_iter_2843.pt
2024-07-22 11:54:17 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 2843 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_40_iter_2843.pt
[31m===========================================================================[0m
2024-07-22 11:54:19 - [32m[1mINFO   [0m - Training epoch 41
2024-07-22 11:54:24 - [34m[1mLOGS   [0m - Epoch:  41 [    2844/10000000], loss: {'classification': 0.9496, 'neural_augmentation': 0.53, 'total_loss': 1.4795}, LR: [9e-06, 9e-06], Avg. batch load time: 3.876, Elapsed time:  4.29
2024-07-22 11:54:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'classification': 0.959, 'neural_augmentation': 0.5379, 'total_loss': 1.4969}
2024-07-22 11:54:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'classification': 0.4345, 'neural_augmentation': 0.0, 'total_loss': 0.4345} || top1={'logits': 92.1329} || top5={'logits': 98.5608}
2024-07-22 11:54:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:54:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:54:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 2893 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_41_iter_2893.pt
2024-07-22 11:55:00 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 2893 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_41_iter_2893.pt
[31m===========================================================================[0m
2024-07-22 11:55:02 - [32m[1mINFO   [0m - Training epoch 42
2024-07-22 11:55:05 - [34m[1mLOGS   [0m - Epoch:  42 [    2894/10000000], loss: {'classification': 0.9963, 'neural_augmentation': 0.5555, 'total_loss': 1.5518}, LR: [9e-06, 9e-06], Avg. batch load time: 3.056, Elapsed time:  3.49
2024-07-22 11:55:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'classification': 0.967, 'neural_augmentation': 0.5564, 'total_loss': 1.5234}
2024-07-22 11:55:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'classification': 0.4232, 'neural_augmentation': 0.0, 'total_loss': 0.4232} || top1={'logits': 92.1261} || top5={'logits': 98.5766}
2024-07-22 11:55:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:55:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:55:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 2936 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_42_iter_2936.pt
2024-07-22 11:55:39 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 2936 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_42_iter_2936.pt
[31m===========================================================================[0m
2024-07-22 11:55:41 - [32m[1mINFO   [0m - Training epoch 43
2024-07-22 11:55:42 - [34m[1mLOGS   [0m - Epoch:  43 [    2937/10000000], loss: {'classification': 0.9326, 'neural_augmentation': 0.5847, 'total_loss': 1.5173}, LR: [8e-06, 8e-06], Avg. batch load time: 0.904, Elapsed time:  1.35
2024-07-22 11:56:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'classification': 0.9583, 'neural_augmentation': 0.5732, 'total_loss': 1.5315}
2024-07-22 11:56:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'classification': 0.4384, 'neural_augmentation': 0.0, 'total_loss': 0.4384} || top1={'logits': 92.1239} || top5={'logits': 98.491}
2024-07-22 11:56:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:56:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:56:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 2983 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_43_iter_2983.pt
2024-07-22 11:56:20 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 2983 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_43_iter_2983.pt
[31m===========================================================================[0m
2024-07-22 11:56:22 - [32m[1mINFO   [0m - Training epoch 44
2024-07-22 11:56:25 - [34m[1mLOGS   [0m - Epoch:  44 [    2984/10000000], loss: {'classification': 0.9466, 'neural_augmentation': 0.5864, 'total_loss': 1.533}, LR: [7e-06, 7e-06], Avg. batch load time: 2.665, Elapsed time:  3.09
2024-07-22 11:56:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'classification': 0.9572, 'neural_augmentation': 0.5886, 'total_loss': 1.5459}
2024-07-22 11:56:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'classification': 0.4252, 'neural_augmentation': 0.0, 'total_loss': 0.4252} || top1={'logits': 92.3041} || top5={'logits': 98.5833}
2024-07-22 11:56:58 - [34m[1mLOGS   [0m - Best checkpoint with score 92.30 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:56:59 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.8333.pt
2024-07-22 11:56:59 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_91.9685.pt', 'checkpoint_score_92.0000.pt', 'checkpoint_score_92.1667.pt', 'checkpoint_score_92.2297.pt', 'checkpoint_score_92.3041.pt']
2024-07-22 11:57:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:57:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:57:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:57:07 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 3036 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_44_iter_3036.pt
2024-07-22 11:57:07 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 3036 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_44_iter_3036.pt
[31m===========================================================================[0m
2024-07-22 11:57:09 - [32m[1mINFO   [0m - Training epoch 45
2024-07-22 11:57:14 - [34m[1mLOGS   [0m - Epoch:  45 [    3037/10000000], loss: {'classification': 0.982, 'neural_augmentation': 0.611, 'total_loss': 1.593}, LR: [7e-06, 7e-06], Avg. batch load time: 3.838, Elapsed time:  4.26
2024-07-22 11:57:35 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'classification': 0.956, 'neural_augmentation': 0.6065, 'total_loss': 1.5625}
2024-07-22 11:57:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'classification': 0.4222, 'neural_augmentation': 0.0, 'total_loss': 0.4222} || top1={'logits': 92.3311} || top5={'logits': 98.6149}
2024-07-22 11:57:47 - [34m[1mLOGS   [0m - Best checkpoint with score 92.33 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:57:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_91.9685.pt
2024-07-22 11:57:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.0000.pt', 'checkpoint_score_92.1667.pt', 'checkpoint_score_92.2297.pt', 'checkpoint_score_92.3041.pt', 'checkpoint_score_92.3311.pt']
2024-07-22 11:57:51 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 11:57:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:57:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:57:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 3089 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_45_iter_3089.pt
2024-07-22 11:57:56 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 3089 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_45_iter_3089.pt
[31m===========================================================================[0m
2024-07-22 11:57:58 - [32m[1mINFO   [0m - Training epoch 46
2024-07-22 11:58:00 - [34m[1mLOGS   [0m - Epoch:  46 [    3090/10000000], loss: {'classification': 0.9248, 'neural_augmentation': 0.6135, 'total_loss': 1.5383}, LR: [6e-06, 6e-06], Avg. batch load time: 2.002, Elapsed time:  2.45
2024-07-22 11:58:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'classification': 0.9545, 'neural_augmentation': 0.6206, 'total_loss': 1.5751}
2024-07-22 11:58:30 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'classification': 0.4302, 'neural_augmentation': 0.0, 'total_loss': 0.4302} || top1={'logits': 92.3131} || top5={'logits': 98.5518}
2024-07-22 11:58:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:58:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:58:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 3135 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_46_iter_3135.pt
2024-07-22 11:58:36 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 3135 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_46_iter_3135.pt
[31m===========================================================================[0m
2024-07-22 11:58:38 - [32m[1mINFO   [0m - Training epoch 47
2024-07-22 11:58:40 - [34m[1mLOGS   [0m - Epoch:  47 [    3136/10000000], loss: {'classification': 0.8989, 'neural_augmentation': 0.6357, 'total_loss': 1.5346}, LR: [6e-06, 6e-06], Avg. batch load time: 0.981, Elapsed time:  1.42
2024-07-22 11:58:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'classification': 0.9555, 'neural_augmentation': 0.635, 'total_loss': 1.5905}
2024-07-22 11:59:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'classification': 0.427, 'neural_augmentation': 0.0, 'total_loss': 0.427} || top1={'logits': 92.3041} || top5={'logits': 98.5968}
2024-07-22 11:59:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 11:59:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 11:59:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 3181 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_47_iter_3181.pt
2024-07-22 11:59:16 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 3181 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_47_iter_3181.pt
[31m===========================================================================[0m
2024-07-22 11:59:18 - [32m[1mINFO   [0m - Training epoch 48
2024-07-22 11:59:21 - [34m[1mLOGS   [0m - Epoch:  48 [    3182/10000000], loss: {'classification': 0.9165, 'neural_augmentation': 0.6487, 'total_loss': 1.5652}, LR: [6e-06, 6e-06], Avg. batch load time: 2.690, Elapsed time:  3.11
2024-07-22 11:59:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'classification': 0.9503, 'neural_augmentation': 0.6505, 'total_loss': 1.6008}
2024-07-22 11:59:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'classification': 0.422, 'neural_augmentation': 0.0, 'total_loss': 0.422} || top1={'logits': 92.3559} || top5={'logits': 98.5946}
2024-07-22 11:59:54 - [34m[1mLOGS   [0m - Best checkpoint with score 92.36 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 11:59:54 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_92.0000.pt
2024-07-22 11:59:54 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.1667.pt', 'checkpoint_score_92.2297.pt', 'checkpoint_score_92.3041.pt', 'checkpoint_score_92.3311.pt', 'checkpoint_score_92.3559.pt']
2024-07-22 11:59:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 12:00:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:00:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:00:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 3232 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_48_iter_3232.pt
2024-07-22 12:00:03 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 3232 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_48_iter_3232.pt
[31m===========================================================================[0m
2024-07-22 12:00:05 - [32m[1mINFO   [0m - Training epoch 49
2024-07-22 12:00:09 - [34m[1mLOGS   [0m - Epoch:  49 [    3233/10000000], loss: {'classification': 0.9779, 'neural_augmentation': 0.6695, 'total_loss': 1.6474}, LR: [5e-06, 5e-06], Avg. batch load time: 3.844, Elapsed time:  4.27
2024-07-22 12:00:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'classification': 0.9472, 'neural_augmentation': 0.665, 'total_loss': 1.6122}
2024-07-22 12:00:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'classification': 0.4265, 'neural_augmentation': 0.0, 'total_loss': 0.4265} || top1={'logits': 92.3649} || top5={'logits': 98.5856}
2024-07-22 12:00:42 - [34m[1mLOGS   [0m - Best checkpoint with score 92.36 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 12:00:43 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_92.1667.pt
2024-07-22 12:00:43 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.2297.pt', 'checkpoint_score_92.3041.pt', 'checkpoint_score_92.3311.pt', 'checkpoint_score_92.3559.pt', 'checkpoint_score_92.3649.pt']
2024-07-22 12:00:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 12:00:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:00:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:00:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 3285 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_49_iter_3285.pt
2024-07-22 12:00:51 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 3285 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_49_iter_3285.pt
[31m===========================================================================[0m
2024-07-22 12:00:53 - [32m[1mINFO   [0m - Training epoch 50
2024-07-22 12:00:56 - [34m[1mLOGS   [0m - Epoch:  50 [    3286/10000000], loss: {'classification': 0.9579, 'neural_augmentation': 0.6847, 'total_loss': 1.6426}, LR: [5e-06, 5e-06], Avg. batch load time: 2.598, Elapsed time:  3.02
2024-07-22 12:01:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 50
	 loss={'classification': 0.9475, 'neural_augmentation': 0.6772, 'total_loss': 1.6247}
2024-07-22 12:01:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 50
	 loss={'classification': 0.426, 'neural_augmentation': 0.0, 'total_loss': 0.426} || top1={'logits': 92.4054} || top5={'logits': 98.5541}
2024-07-22 12:01:30 - [34m[1mLOGS   [0m - Best checkpoint with score 92.41 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 12:01:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_92.2297.pt
2024-07-22 12:01:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.3041.pt', 'checkpoint_score_92.3311.pt', 'checkpoint_score_92.3559.pt', 'checkpoint_score_92.3649.pt', 'checkpoint_score_92.4054.pt']
2024-07-22 12:01:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 12:01:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:01:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:01:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 50/iteration 3338 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_50_iter_3338.pt
2024-07-22 12:01:40 - [34m[1mLOGS   [0m - Model state for epoch 50/iteration 3338 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_50_iter_3338.pt
[31m===========================================================================[0m
2024-07-22 12:01:42 - [32m[1mINFO   [0m - Training epoch 51
2024-07-22 12:01:43 - [34m[1mLOGS   [0m - Epoch:  51 [    3339/10000000], loss: {'classification': 0.9015, 'neural_augmentation': 0.6848, 'total_loss': 1.5863}, LR: [4e-06, 4e-06], Avg. batch load time: 1.022, Elapsed time:  1.48
2024-07-22 12:02:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 51
	 loss={'classification': 0.9454, 'neural_augmentation': 0.6855, 'total_loss': 1.6309}
2024-07-22 12:02:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 51
	 loss={'classification': 0.4302, 'neural_augmentation': 0.0, 'total_loss': 0.4302} || top1={'logits': 92.3604} || top5={'logits': 98.5766}
2024-07-22 12:02:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:02:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:02:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 51/iteration 3391 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_51_iter_3391.pt
2024-07-22 12:02:21 - [34m[1mLOGS   [0m - Model state for epoch 51/iteration 3391 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_51_iter_3391.pt
[31m===========================================================================[0m
2024-07-22 12:02:23 - [32m[1mINFO   [0m - Training epoch 52
2024-07-22 12:02:26 - [34m[1mLOGS   [0m - Epoch:  52 [    3392/10000000], loss: {'classification': 0.9339, 'neural_augmentation': 0.6947, 'total_loss': 1.6286}, LR: [4e-06, 4e-06], Avg. batch load time: 2.505, Elapsed time:  2.93
2024-07-22 12:02:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 52
	 loss={'classification': 0.9518, 'neural_augmentation': 0.6994, 'total_loss': 1.6512}
2024-07-22 12:02:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 52
	 loss={'classification': 0.4308, 'neural_augmentation': 0.0, 'total_loss': 0.4308} || top1={'logits': 92.3288} || top5={'logits': 98.5495}
2024-07-22 12:02:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:02:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:02:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 52/iteration 3431 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_52_iter_3431.pt
2024-07-22 12:02:55 - [34m[1mLOGS   [0m - Model state for epoch 52/iteration 3431 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_52_iter_3431.pt
[31m===========================================================================[0m
2024-07-22 12:02:57 - [32m[1mINFO   [0m - Training epoch 53
2024-07-22 12:03:01 - [34m[1mLOGS   [0m - Epoch:  53 [    3432/10000000], loss: {'classification': 0.9238, 'neural_augmentation': 0.7125, 'total_loss': 1.6364}, LR: [4e-06, 4e-06], Avg. batch load time: 3.675, Elapsed time:  4.11
2024-07-22 12:03:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 53
	 loss={'classification': 0.9381, 'neural_augmentation': 0.7086, 'total_loss': 1.6467}
2024-07-22 12:03:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 53
	 loss={'classification': 0.43, 'neural_augmentation': 0.0, 'total_loss': 0.43} || top1={'logits': 92.3851} || top5={'logits': 98.5405}
2024-07-22 12:03:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:03:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:03:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 53/iteration 3485 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_53_iter_3485.pt
2024-07-22 12:03:36 - [34m[1mLOGS   [0m - Model state for epoch 53/iteration 3485 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_53_iter_3485.pt
[31m===========================================================================[0m
2024-07-22 12:03:38 - [32m[1mINFO   [0m - Training epoch 54
2024-07-22 12:03:42 - [34m[1mLOGS   [0m - Epoch:  54 [    3486/10000000], loss: {'classification': 0.9119, 'neural_augmentation': 0.7093, 'total_loss': 1.6213}, LR: [4e-06, 4e-06], Avg. batch load time: 3.374, Elapsed time:  3.79
2024-07-22 12:04:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 54
	 loss={'classification': 0.9435, 'neural_augmentation': 0.7176, 'total_loss': 1.6611}
2024-07-22 12:04:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 54
	 loss={'classification': 0.4295, 'neural_augmentation': 0.0, 'total_loss': 0.4295} || top1={'logits': 92.3356} || top5={'logits': 98.5518}
2024-07-22 12:04:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:04:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:04:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 54/iteration 3537 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_54_iter_3537.pt
2024-07-22 12:04:17 - [34m[1mLOGS   [0m - Model state for epoch 54/iteration 3537 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_54_iter_3537.pt
[31m===========================================================================[0m
2024-07-22 12:04:19 - [32m[1mINFO   [0m - Training epoch 55
2024-07-22 12:04:23 - [34m[1mLOGS   [0m - Epoch:  55 [    3538/10000000], loss: {'classification': 0.9753, 'neural_augmentation': 0.7226, 'total_loss': 1.698}, LR: [3e-06, 3e-06], Avg. batch load time: 3.631, Elapsed time:  4.05
2024-07-22 12:04:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 55
	 loss={'classification': 0.9497, 'neural_augmentation': 0.7238, 'total_loss': 1.6735}
2024-07-22 12:04:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 55
	 loss={'classification': 0.4276, 'neural_augmentation': 0.0, 'total_loss': 0.4276} || top1={'logits': 92.5135} || top5={'logits': 98.5811}
2024-07-22 12:04:53 - [34m[1mLOGS   [0m - Best checkpoint with score 92.51 saved at /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_best.pt
2024-07-22 12:04:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_score_92.3041.pt
2024-07-22 12:04:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_92.3311.pt', 'checkpoint_score_92.3559.pt', 'checkpoint_score_92.3649.pt', 'checkpoint_score_92.4054.pt', 'checkpoint_score_92.5135.pt']
2024-07-22 12:04:56 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_avg.pt
2024-07-22 12:04:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:04:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:04:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 55/iteration 3582 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_55_iter_3582.pt
2024-07-22 12:04:59 - [34m[1mLOGS   [0m - Model state for epoch 55/iteration 3582 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_55_iter_3582.pt
[31m===========================================================================[0m
2024-07-22 12:05:01 - [32m[1mINFO   [0m - Training epoch 56
2024-07-22 12:05:05 - [34m[1mLOGS   [0m - Epoch:  56 [    3583/10000000], loss: {'classification': 0.9473, 'neural_augmentation': 0.7269, 'total_loss': 1.6742}, LR: [3e-06, 3e-06], Avg. batch load time: 3.594, Elapsed time:  4.01
2024-07-22 12:05:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 56
	 loss={'classification': 0.9367, 'neural_augmentation': 0.731, 'total_loss': 1.6677}
2024-07-22 12:05:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 56
	 loss={'classification': 0.4269, 'neural_augmentation': 0.0, 'total_loss': 0.4269} || top1={'logits': 92.4122} || top5={'logits': 98.6149}
2024-07-22 12:05:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:05:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:05:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 56/iteration 3634 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_56_iter_3634.pt
2024-07-22 12:05:41 - [34m[1mLOGS   [0m - Model state for epoch 56/iteration 3634 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_56_iter_3634.pt
[31m===========================================================================[0m
2024-07-22 12:05:43 - [32m[1mINFO   [0m - Training epoch 57
2024-07-22 12:05:46 - [34m[1mLOGS   [0m - Epoch:  57 [    3635/10000000], loss: {'classification': 0.9264, 'neural_augmentation': 0.7284, 'total_loss': 1.6548}, LR: [3e-06, 3e-06], Avg. batch load time: 2.881, Elapsed time:  3.31
2024-07-22 12:06:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 57
	 loss={'classification': 0.9415, 'neural_augmentation': 0.7365, 'total_loss': 1.6779}
2024-07-22 12:06:17 - [34m[1mLOGS   [0m - *** Validation summary for epoch 57
	 loss={'classification': 0.4291, 'neural_augmentation': 0.0, 'total_loss': 0.4291} || top1={'logits': 92.4189} || top5={'logits': 98.5721}
2024-07-22 12:06:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:06:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:06:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 57/iteration 3682 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_57_iter_3682.pt
2024-07-22 12:06:20 - [34m[1mLOGS   [0m - Model state for epoch 57/iteration 3682 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_57_iter_3682.pt
[31m===========================================================================[0m
2024-07-22 12:06:22 - [32m[1mINFO   [0m - Training epoch 58
2024-07-22 12:06:24 - [34m[1mLOGS   [0m - Epoch:  58 [    3683/10000000], loss: {'classification': 0.8956, 'neural_augmentation': 0.7355, 'total_loss': 1.6311}, LR: [3e-06, 3e-06], Avg. batch load time: 1.736, Elapsed time:  2.18
2024-07-22 12:06:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 58
	 loss={'classification': 0.9422, 'neural_augmentation': 0.7401, 'total_loss': 1.6823}
2024-07-22 12:06:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 58
	 loss={'classification': 0.429, 'neural_augmentation': 0.0, 'total_loss': 0.429} || top1={'logits': 92.3604} || top5={'logits': 98.5721}
2024-07-22 12:06:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:06:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:07:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 58/iteration 3736 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_58_iter_3736.pt
2024-07-22 12:07:00 - [34m[1mLOGS   [0m - Model state for epoch 58/iteration 3736 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_58_iter_3736.pt
[31m===========================================================================[0m
2024-07-22 12:07:02 - [32m[1mINFO   [0m - Training epoch 59
2024-07-22 12:07:05 - [34m[1mLOGS   [0m - Epoch:  59 [    3737/10000000], loss: {'classification': 0.9222, 'neural_augmentation': 0.7377, 'total_loss': 1.6599}, LR: [3e-06, 3e-06], Avg. batch load time: 2.519, Elapsed time:  2.94
2024-07-22 12:07:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 59
	 loss={'classification': 0.944, 'neural_augmentation': 0.7433, 'total_loss': 1.6873}
2024-07-22 12:07:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 59
	 loss={'classification': 0.4284, 'neural_augmentation': 0.0, 'total_loss': 0.4284} || top1={'logits': 92.4842} || top5={'logits': 98.5811}
2024-07-22 12:07:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_last.pt
2024-07-22 12:07:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_last.pt
2024-07-22 12:07:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 59/iteration 3782 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/training_checkpoint_epoch_59_iter_3782.pt
2024-07-22 12:07:40 - [34m[1mLOGS   [0m - Model state for epoch 59/iteration 3782 is saved at: /ML-A100/team/mm/models/catlip_data/single_vit_base/food172/train/checkpoint_epoch_59_iter_3782.pt
2024-07-22 12:07:40 - [34m[1mLOGS   [0m - Training took 00:37:11.15
