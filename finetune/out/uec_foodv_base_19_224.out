nohup: ignoring input
2024-07-28 03:43:53 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_19_iter_162435.pt
2024-07-28 03:43:54 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-28 03:43:54 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-28 03:43:54 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): ViTamin(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 103, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-07-28 03:43:54 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.109G                 | 13.31G     |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  6.929M                |  0.349G    |
|   seg_head.aspp.aspp_layer                |   6.905M               |   0.327G   |
|    seg_head.aspp.aspp_layer.convs         |    6.654M              |    0.315G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    12.315M |
|   seg_head.classifier.block.conv          |   23.175K              |   1.131M   |
|    seg_head.classifier.block.conv.weight  |    (103, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (103,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.673M  |
2024-07-28 03:43:54 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-28 03:43:54 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.blocks.2.ls1', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.blocks1.6.attn.q_norm', 'encoder.blocks1.2.attn.attn_drop', 'encoder.blocks.6.drop_path2', 'encoder.blocks.1.attn.attn_drop', 'encoder.blocks.2.drop_path1', 'encoder.blocks1.0.ls1', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.blocks.4.drop_path1', 'encoder.blocks.4.drop_path2', 'encoder.blocks1.3.drop_path1', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.blocks1.5.attn.q_norm', 'encoder.neural_augmentor.noise.max_fn', 'encoder.blocks.0.attn.attn_drop', 'encoder.blocks1.1.ls1', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.blocks1.0.attn.attn_drop', 'encoder.patch_embed.proj', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.blocks.4.ls2', 'encoder.blocks.5.ls2', 'encoder.mlp.1', 'encoder.blocks1.4.attn.k_norm', 'encoder.neural_augmentor', 'encoder.blocks1.0.attn.k_norm', 'encoder.blocks1.2.attn.q_norm', 'encoder.blocks1.1.drop_path2', 'encoder.blocks1.5.ls2', 'encoder.blocks1.3.ls2', 'encoder.blocks.5.attn.k_norm', 'encoder.blocks.3.attn.attn_drop', 'encoder.blocks.3.ls2', 'encoder.blocks.6.attn.attn_drop', 'encoder.patch_drop', 'encoder.blocks.6.drop_path1', 'encoder.mlp.2', 'encoder.blocks.3.ls1', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.blocks.3.attn.q_norm', 'encoder.blocks.1.attn.q_norm', 'encoder.mlp.0', 'encoder.blocks.4.ls1', 'encoder.blocks1.2.ls2', 'encoder.blocks1.4.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.blocks.2.ls2', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop', 'encoder.blocks1.6.drop_path1', 'encoder.blocks.0.ls2', 'encoder.blocks.3.drop_path2', 'encoder.blocks.0.attn.k_norm', 'encoder.blocks.0.drop_path1', 'encoder.blocks1.5.drop_path2', 'encoder.blocks.1.ls2', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.blocks.5.drop_path1', 'encoder.blocks.0.drop_path2', 'encoder.classifier_drop', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.blocks1.3.attn.attn_drop', 'encoder.mlp', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.neural_augmentor.contrast', 'encoder.neural_augmentor.noise', 'encoder.blocks.2.attn.k_norm', 'encoder.blocks.1.drop_path1', 'encoder.blocks1.5.drop_path1', 'encoder.blocks.4.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.blocks1.4.ls2', 'encoder.blocks.3.drop_path1', 'encoder.blocks1.6.drop_path2', 'encoder.blocks1.3.drop_path2', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.blocks1.2.drop_path2', 'encoder.blocks1.5.ls1', 'encoder.neural_augmentor.noise.min_fn', 'encoder.blocks1.2.drop_path1', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.fc_norm', 'encoder.blocks.6.attn.k_norm', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.blocks1.1.attn.attn_drop', 'encoder.blocks.0.attn.q_norm', 'encoder.blocks1.0.drop_path2', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.blocks1.6.attn.k_norm', 'encoder.blocks.6.attn.q_norm', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.blocks1.1.drop_path1', 'encoder.blocks1.3.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.blocks.5.ls1', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.blocks.5.attn.attn_drop', 'encoder.blocks.1.attn.k_norm', 'encoder.blocks1.3.ls1', 'encoder.norm_pre', 'encoder.blocks1.4.drop_path2', 'encoder.blocks.1.drop_path2', 'encoder.blocks1.2.attn.k_norm', 'encoder.blocks1.0.drop_path1', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks.3.attn.k_norm', 'encoder.blocks.5.drop_path2', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.blocks1.4.ls1', 'encoder.blocks.1.ls1', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks1.6.ls1', 'encoder.blocks.0.ls1', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.blocks1.1.ls2', 'encoder.blocks1.6.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.blocks1.6.ls2', 'encoder.blocks1.2.ls1', 'encoder.blocks.2.drop_path2', 'encoder.blocks1.0.ls2', 'encoder.neural_augmentor.brightness', 'encoder.blocks1.5.attn.k_norm', 'encoder.blocks.6.ls1', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks.4.attn.q_norm', 'encoder.norm', 'encoder.blocks1.4.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.blocks1.1.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.blocks.2.attn.attn_drop', 'encoder.blocks1.3.attn.k_norm', 'encoder.blocks.4.attn.attn_drop', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.blocks.6.ls2', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.blocks1.4.drop_path1', 'encoder.blocks.2.attn.q_norm'}
2024-07-28 03:43:54 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-07-28 03:43:54 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train
2024-07-28 03:43:58 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40010
base
dci
2024-07-28 03:43:58 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40010
base
dci
2024-07-28 03:43:57 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40010
2024-07-28 03:44:00 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=True 
	num_samples=9000
	transforms=Compose(
			RandomShortSizeResize(short_side_min=128, short_side_max=320, interpolation=bicubic), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=224, w=224), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-28 03:44:00 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/UECFOODPIXCOMPLETE/data 
	is_training=False 
	num_samples=1000
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-07-28 03:44:00 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-07-28 03:44:00 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=4
)
2024-07-28 03:44:00 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-07-28 03:44:02 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_19_iter_162435.pt
2024-07-28 03:44:02 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-28 03:44:02 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-07-28 03:44:02 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-07-28 03:44:02 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): ViTamin(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 103, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-07-28 03:44:02 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-28 03:44:02 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                                    | #parameters or shape   | #flops     |
|:------------------------------------------|:-----------------------|:-----------|
| model                                     | 0.109G                 | 13.31G     |
|  encoder                                  |  0.102G                |  12.961G   |
|   encoder.pos_embed                       |   (1, 1, 512)          |            |
|   encoder.neural_augmentor                |   6                    |            |
|    encoder.neural_augmentor.brightness    |    2                   |            |
|    encoder.neural_augmentor.contrast      |    2                   |            |
|    encoder.neural_augmentor.noise         |    2                   |            |
|   encoder.patch_embed.backbone            |   3.653M               |   5.52G    |
|    encoder.patch_embed.backbone.stem      |    0.151M              |    1.901G  |
|    encoder.patch_embed.backbone.stages    |    2.321M              |    3.387G  |
|    encoder.patch_embed.backbone.pool      |    1.181M              |    0.232G  |
|   encoder.blocks                          |   18.404M              |   3.607G   |
|    encoder.blocks.0                       |    2.629M              |    0.515G  |
|    encoder.blocks.1                       |    2.629M              |    0.515G  |
|    encoder.blocks.2                       |    2.629M              |    0.515G  |
|    encoder.blocks.3                       |    2.629M              |    0.515G  |
|    encoder.blocks.4                       |    2.629M              |    0.515G  |
|    encoder.blocks.5                       |    2.629M              |    0.515G  |
|    encoder.blocks.6                       |    2.629M              |    0.515G  |
|   encoder.pool                            |   4.721M               |   0.232G   |
|    encoder.pool.proj                      |    4.72M               |    0.231G  |
|    encoder.pool.norm                      |    1.024K              |    0.502M  |
|   encoder.blocks1                         |   73.508M              |   3.602G   |
|    encoder.blocks1.0                      |    10.501M             |    0.515G  |
|    encoder.blocks1.1                      |    10.501M             |    0.515G  |
|    encoder.blocks1.2                      |    10.501M             |    0.515G  |
|    encoder.blocks1.3                      |    10.501M             |    0.515G  |
|    encoder.blocks1.4                      |    10.501M             |    0.515G  |
|    encoder.blocks1.5                      |    10.501M             |    0.515G  |
|    encoder.blocks1.6                      |    10.501M             |    0.515G  |
|   encoder.mlp                             |   2.099M               |            |
|    encoder.mlp.0                          |    1.05M               |            |
|    encoder.mlp.2                          |    1.05M               |            |
|   encoder.fc_norm                         |   2.048K               |            |
|    encoder.fc_norm.weight                 |    (1024,)             |            |
|    encoder.fc_norm.bias                   |    (1024,)             |            |
|  seg_head                                 |  6.929M                |  0.349G    |
|   seg_head.aspp.aspp_layer                |   6.905M               |   0.327G   |
|    seg_head.aspp.aspp_layer.convs         |    6.654M              |    0.315G  |
|    seg_head.aspp.aspp_layer.project.block |    0.251M              |    12.315M |
|   seg_head.classifier.block.conv          |   23.175K              |   1.131M   |
|    seg_head.classifier.block.conv.weight  |    (103, 224, 1, 1)    |            |
|    seg_head.classifier.block.conv.bias    |    (103,)              |            |
|   seg_head.upsample_seg_out               |                        |   20.673M  |
2024-07-28 03:44:02 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-28 03:44:02 - [33m[1mWARNING[0m - Uncalled Modules:
{'encoder.patch_embed.backbone.stages.1.2.pre_norm.act', 'encoder.blocks1.2.ls1', 'encoder.blocks.1.drop_path2', 'encoder.blocks.6.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.3.down', 'encoder.blocks.6.ls1', 'encoder.blocks.6.drop_path2', 'encoder.blocks1.2.drop_path2', 'encoder.blocks1.0.attn.q_norm', 'encoder.blocks.3.ls1', 'encoder.blocks.5.drop_path2', 'encoder.patch_embed.backbone.stages.1.3.drop_path', 'encoder.blocks.0.drop_path1', 'encoder.patch_embed.backbone.stages.0.0.drop_path', 'encoder.blocks.0.ls1', 'encoder.blocks1.6.ls1', 'encoder.blocks.6.drop_path1', 'encoder.blocks.0.ls2', 'encoder.blocks1.1.drop_path1', 'encoder.blocks1.1.attn.q_norm', 'encoder.blocks.1.attn.attn_drop', 'encoder.neural_augmentor.brightness', 'encoder.patch_embed.backbone.stages.1.2.drop_path', 'encoder.neural_augmentor.noise.max_fn', 'encoder.patch_embed.backbone.stages.1.3.shortcut', 'encoder.blocks1.3.drop_path1', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.act', 'encoder.blocks1.6.drop_path1', 'encoder.blocks.6.ls2', 'encoder.patch_embed.backbone.stages.1.2.shortcut', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.drop', 'encoder.blocks1.5.attn.q_norm', 'encoder.blocks.5.attn.attn_drop', 'encoder.norm', 'encoder.patch_embed.backbone.stages.1.1.drop_path', 'encoder.blocks.3.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.act', 'encoder.blocks.1.ls2', 'encoder.blocks1.3.ls2', 'encoder.patch_embed.backbone.stages.0.1.shortcut', 'encoder.blocks.5.ls1', 'encoder.blocks1.0.attn.k_norm', 'encoder.blocks1.4.drop_path2', 'encoder.blocks.2.ls1', 'encoder.blocks.1.ls1', 'encoder.blocks.1.drop_path1', 'encoder.blocks1.5.drop_path1', 'encoder.patch_embed.proj', 'encoder.blocks1.1.attn.k_norm', 'encoder.fc_norm', 'encoder.blocks1.2.attn.q_norm', 'encoder.blocks1.0.ls1', 'encoder.blocks1.1.ls2', 'encoder.neural_augmentor.noise.min_fn', 'encoder.blocks1.3.attn.attn_drop', 'encoder.blocks.5.attn.k_norm', 'encoder.patch_embed.backbone.stages.1.1.shortcut', 'encoder.neural_augmentor.contrast.min_fn', 'encoder.patch_embed.backbone.stages.1.0.down', 'encoder.blocks1.4.ls1', 'encoder.blocks.2.drop_path2', 'encoder.blocks.0.attn.k_norm', 'encoder.neural_augmentor.noise', 'encoder.blocks1.2.ls2', 'encoder.blocks.3.attn.q_norm', 'encoder.blocks.4.ls2', 'encoder.neural_augmentor.brightness.max_fn', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.drop', 'encoder.blocks1.2.attn.k_norm', 'encoder.blocks.3.drop_path1', 'encoder.blocks1.0.ls2', 'encoder.blocks1.1.ls1', 'encoder.blocks1.5.attn.attn_drop', 'encoder.blocks1.1.drop_path2', 'encoder.blocks.0.drop_path2', 'encoder.blocks.2.ls2', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.act', 'encoder.patch_embed.backbone.stages.1.1.down', 'encoder.blocks.2.attn.k_norm', 'encoder.blocks1.6.attn.k_norm', 'encoder.blocks1.2.attn.attn_drop', 'encoder.mlp.0', 'encoder.blocks1.4.attn.k_norm', 'encoder.patch_embed.backbone.stem.norm1.drop', 'encoder.blocks1.1.attn.attn_drop', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.drop', 'encoder.blocks.3.attn.k_norm', 'encoder.blocks1.6.drop_path2', 'encoder.blocks1.4.attn.q_norm', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.act', 'encoder.blocks.4.attn.q_norm', 'encoder.neural_augmentor', 'encoder.blocks.5.drop_path1', 'encoder.blocks.0.attn.attn_drop', 'encoder.blocks1.5.attn.k_norm', 'encoder.blocks1.6.ls2', 'encoder.blocks1.0.drop_path1', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.drop', 'encoder.patch_embed.backbone.stages.1.0.drop_path', 'encoder.blocks1.4.ls2', 'encoder.blocks1.2.drop_path1', 'encoder.blocks1.3.drop_path2', 'encoder.blocks.4.attn.attn_drop', 'encoder.norm_pre', 'encoder.blocks.2.attn.q_norm', 'encoder.patch_embed.backbone.stages.0.0.shortcut.expand', 'encoder.blocks1.3.attn.q_norm', 'encoder.neural_augmentor.brightness.min_fn', 'encoder.blocks.4.ls1', 'encoder.blocks.4.drop_path2', 'encoder.patch_drop', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.drop', 'encoder.blocks1.5.drop_path2', 'encoder.blocks.3.ls2', 'encoder.blocks.6.attn.q_norm', 'encoder.blocks.1.attn.k_norm', 'encoder.blocks.1.attn.q_norm', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.act', 'encoder.blocks1.4.drop_path1', 'encoder.blocks.4.drop_path1', 'encoder.patch_embed.backbone.stages.1.2.down', 'encoder.blocks1.3.ls1', 'encoder.blocks.5.attn.q_norm', 'encoder.blocks.2.attn.attn_drop', 'encoder.blocks.3.drop_path2', 'encoder.blocks1.6.attn.q_norm', 'encoder.patch_embed.backbone.stages.0.1.down', 'encoder.blocks1.0.drop_path2', 'encoder.mlp', 'encoder.blocks1.4.attn.attn_drop', 'encoder.classifier_drop', 'encoder.neural_augmentor.contrast.max_fn', 'encoder.blocks1.5.ls2', 'encoder.blocks.2.drop_path1', 'encoder.blocks.4.attn.k_norm', 'encoder.blocks1.3.attn.k_norm', 'encoder.blocks1.0.attn.attn_drop', 'encoder.mlp.1', 'encoder.neural_augmentor.contrast', 'encoder.patch_embed.backbone.stages.0.0.down', 'encoder.blocks1.6.attn.attn_drop', 'encoder.blocks.0.attn.q_norm', 'encoder.blocks.5.ls2', 'encoder.mlp.2', 'encoder.blocks.6.attn.attn_drop', 'encoder.patch_embed.backbone.stages.0.1.drop_path', 'encoder.blocks1.5.ls1', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.drop'}
2024-07-28 03:44:02 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 33, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::feature_dropout': 1})
[31m=================================================================[0m
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - Max. epochs for training: 50
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=50
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-28 03:44:03 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt'
2024-07-28 03:44:03 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-28 03:44:05 - [32m[1mINFO   [0m - Training epoch 0
2024-07-28 03:43:58 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40010
base
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [224, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-28 03:46:59 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'segmentation': 4.6862, 'neural_augmentation': 0.4543, 'total_loss': 5.1405}, LR: [1e-06, 1e-06, 1e-06, 1e-06], Avg. batch load time: 169.294, Elapsed time: 174.45
2024-07-28 03:47:11 - [34m[1mLOGS   [0m - Epoch:   0 [     101/10000000], loss: {'segmentation': 4.4431, 'neural_augmentation': 0.3725, 'total_loss': 4.8156}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 1.676, Elapsed time: 186.32
2024-07-28 03:47:22 - [34m[1mLOGS   [0m - Epoch:   0 [     201/10000000], loss: {'segmentation': 3.9791, 'neural_augmentation': 0.3717, 'total_loss': 4.3508}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.843, Elapsed time: 197.54
2024-07-28 03:47:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'segmentation': 3.6768, 'neural_augmentation': 0.3731, 'total_loss': 4.0499}
2024-07-28 03:50:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'segmentation': 2.6053, 'neural_augmentation': 0.0, 'total_loss': 2.6053} || iou=30.4675
2024-07-28 03:50:27 - [34m[1mLOGS   [0m - Best checkpoint with score 30.47 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:50:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:50:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:50:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_0_iter_282.pt
2024-07-28 03:50:32 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 282 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_0_iter_282.pt
[31m===========================================================================[0m
2024-07-28 03:50:34 - [32m[1mINFO   [0m - Training epoch 1
2024-07-28 03:50:34 - [34m[1mLOGS   [0m - Epoch:   1 [     283/10000000], loss: {'segmentation': 2.7112, 'neural_augmentation': 0.3985, 'total_loss': 3.1097}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.117, Elapsed time:  0.28
2024-07-28 03:50:46 - [34m[1mLOGS   [0m - Epoch:   1 [     383/10000000], loss: {'segmentation': 2.4701, 'neural_augmentation': 0.3716, 'total_loss': 2.8417}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.003, Elapsed time: 11.98
2024-07-28 03:50:57 - [34m[1mLOGS   [0m - Epoch:   1 [     483/10000000], loss: {'segmentation': 2.2917, 'neural_augmentation': 0.3696, 'total_loss': 2.6613}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.002, Elapsed time: 23.09
2024-07-28 03:51:06 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'segmentation': 2.1652, 'neural_augmentation': 0.3687, 'total_loss': 2.5339}
2024-07-28 03:51:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'segmentation': 1.7442, 'neural_augmentation': 0.0, 'total_loss': 1.7442} || iou=59.347
2024-07-28 03:51:09 - [34m[1mLOGS   [0m - Best checkpoint with score 59.35 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:51:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:51:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:51:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_1_iter_564.pt
2024-07-28 03:51:13 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 564 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_1_iter_564.pt
[31m===========================================================================[0m
2024-07-28 03:51:15 - [32m[1mINFO   [0m - Training epoch 2
2024-07-28 03:51:15 - [34m[1mLOGS   [0m - Epoch:   2 [     565/10000000], loss: {'segmentation': 1.7416, 'neural_augmentation': 0.3753, 'total_loss': 2.1169}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.371, Elapsed time:  0.51
2024-07-28 03:51:27 - [34m[1mLOGS   [0m - Epoch:   2 [     665/10000000], loss: {'segmentation': 1.646, 'neural_augmentation': 0.3707, 'total_loss': 2.0167}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.004, Elapsed time: 11.98
2024-07-28 03:51:38 - [34m[1mLOGS   [0m - Epoch:   2 [     765/10000000], loss: {'segmentation': 1.5731, 'neural_augmentation': 0.369, 'total_loss': 1.9421}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 23.13
2024-07-28 03:51:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'segmentation': 1.523, 'neural_augmentation': 0.3698, 'total_loss': 1.8928}
2024-07-28 03:51:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'segmentation': 1.2792, 'neural_augmentation': 0.0, 'total_loss': 1.2792} || iou=63.8079
2024-07-28 03:51:51 - [34m[1mLOGS   [0m - Best checkpoint with score 63.81 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:51:53 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:51:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:51:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_2_iter_846.pt
2024-07-28 03:51:55 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 846 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_2_iter_846.pt
[31m===========================================================================[0m
2024-07-28 03:51:57 - [32m[1mINFO   [0m - Training epoch 3
2024-07-28 03:51:57 - [34m[1mLOGS   [0m - Epoch:   3 [     847/10000000], loss: {'segmentation': 1.2883, 'neural_augmentation': 0.3737, 'total_loss': 1.662}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.404, Elapsed time:  0.54
2024-07-28 03:52:09 - [34m[1mLOGS   [0m - Epoch:   3 [     947/10000000], loss: {'segmentation': 1.2628, 'neural_augmentation': 0.3573, 'total_loss': 1.6201}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.004, Elapsed time: 11.82
2024-07-28 03:52:20 - [34m[1mLOGS   [0m - Epoch:   3 [    1047/10000000], loss: {'segmentation': 1.2242, 'neural_augmentation': 0.3576, 'total_loss': 1.5818}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 23.33
2024-07-28 03:52:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'segmentation': 1.1934, 'neural_augmentation': 0.3569, 'total_loss': 1.5503}
2024-07-28 03:52:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'segmentation': 1.1211, 'neural_augmentation': 0.0, 'total_loss': 1.1211} || iou=66.3065
2024-07-28 03:52:33 - [34m[1mLOGS   [0m - Best checkpoint with score 66.31 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:52:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:52:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:52:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_3_iter_1128.pt
2024-07-28 03:52:36 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 1128 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_3_iter_1128.pt
[31m===========================================================================[0m
2024-07-28 03:52:38 - [32m[1mINFO   [0m - Training epoch 4
2024-07-28 03:52:39 - [34m[1mLOGS   [0m - Epoch:   4 [    1129/10000000], loss: {'segmentation': 1.0714, 'neural_augmentation': 0.2707, 'total_loss': 1.3421}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.108, Elapsed time:  0.27
2024-07-28 03:52:50 - [34m[1mLOGS   [0m - Epoch:   4 [    1229/10000000], loss: {'segmentation': 1.0238, 'neural_augmentation': 0.3476, 'total_loss': 1.3713}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.002, Elapsed time: 12.22
2024-07-28 03:53:02 - [34m[1mLOGS   [0m - Epoch:   4 [    1329/10000000], loss: {'segmentation': 0.9988, 'neural_augmentation': 0.3466, 'total_loss': 1.3454}, LR: [3e-05, 3e-05, 3e-05, 3e-05], Avg. batch load time: 0.001, Elapsed time: 23.61
2024-07-28 03:53:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'segmentation': 0.9786, 'neural_augmentation': 0.3473, 'total_loss': 1.326}
2024-07-28 03:53:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'segmentation': 0.8944, 'neural_augmentation': 0.0, 'total_loss': 0.8944} || iou=66.4022
2024-07-28 03:53:14 - [34m[1mLOGS   [0m - Best checkpoint with score 66.40 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:53:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:53:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:53:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_4_iter_1410.pt
2024-07-28 03:53:18 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 1410 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_4_iter_1410.pt
[31m===========================================================================[0m
2024-07-28 03:53:20 - [32m[1mINFO   [0m - Training epoch 5
2024-07-28 03:53:20 - [34m[1mLOGS   [0m - Epoch:   5 [    1411/10000000], loss: {'segmentation': 0.929, 'neural_augmentation': 0.3753, 'total_loss': 1.3043}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.220, Elapsed time:  0.38
2024-07-28 03:53:32 - [34m[1mLOGS   [0m - Epoch:   5 [    1511/10000000], loss: {'segmentation': 0.8563, 'neural_augmentation': 0.363, 'total_loss': 1.2194}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.003, Elapsed time: 12.26
2024-07-28 03:53:43 - [34m[1mLOGS   [0m - Epoch:   5 [    1611/10000000], loss: {'segmentation': 0.8226, 'neural_augmentation': 0.3615, 'total_loss': 1.184}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.001, Elapsed time: 23.50
2024-07-28 03:53:52 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'segmentation': 0.8022, 'neural_augmentation': 0.3594, 'total_loss': 1.1616}
2024-07-28 03:53:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'segmentation': 0.794, 'neural_augmentation': 0.0, 'total_loss': 0.794} || iou=67.8186
2024-07-28 03:53:56 - [34m[1mLOGS   [0m - Best checkpoint with score 67.82 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:53:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_30.4675.pt
2024-07-28 03:53:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_59.3470.pt', 'checkpoint_score_63.8079.pt', 'checkpoint_score_66.3065.pt', 'checkpoint_score_66.4022.pt', 'checkpoint_score_67.8186.pt']
2024-07-28 03:54:00 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 03:54:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:54:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:54:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_5_iter_1692.pt
2024-07-28 03:54:03 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_5_iter_1692.pt
[31m===========================================================================[0m
2024-07-28 03:54:05 - [32m[1mINFO   [0m - Training epoch 6
2024-07-28 03:54:05 - [34m[1mLOGS   [0m - Epoch:   6 [    1693/10000000], loss: {'segmentation': 0.6563, 'neural_augmentation': 0.3464, 'total_loss': 1.0028}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.375, Elapsed time:  0.51
2024-07-28 03:54:17 - [34m[1mLOGS   [0m - Epoch:   6 [    1793/10000000], loss: {'segmentation': 0.6854, 'neural_augmentation': 0.3567, 'total_loss': 1.0421}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.004, Elapsed time: 11.95
2024-07-28 03:54:28 - [34m[1mLOGS   [0m - Epoch:   6 [    1893/10000000], loss: {'segmentation': 0.6619, 'neural_augmentation': 0.3584, 'total_loss': 1.0203}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.002, Elapsed time: 22.99
2024-07-28 03:54:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'segmentation': 0.6451, 'neural_augmentation': 0.3609, 'total_loss': 1.006}
2024-07-28 03:54:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'segmentation': 0.6899, 'neural_augmentation': 0.0, 'total_loss': 0.6899} || iou=70.0538
2024-07-28 03:54:41 - [34m[1mLOGS   [0m - Best checkpoint with score 70.05 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:54:41 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_59.3470.pt
2024-07-28 03:54:41 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_63.8079.pt', 'checkpoint_score_66.3065.pt', 'checkpoint_score_66.4022.pt', 'checkpoint_score_67.8186.pt', 'checkpoint_score_70.0538.pt']
2024-07-28 03:54:44 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 03:54:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:54:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:54:46 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_6_iter_1974.pt
2024-07-28 03:54:46 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 1974 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_6_iter_1974.pt
[31m===========================================================================[0m
2024-07-28 03:54:48 - [32m[1mINFO   [0m - Training epoch 7
2024-07-28 03:54:49 - [34m[1mLOGS   [0m - Epoch:   7 [    1975/10000000], loss: {'segmentation': 0.4573, 'neural_augmentation': 0.1942, 'total_loss': 0.6515}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.383, Elapsed time:  0.52
2024-07-28 03:55:00 - [34m[1mLOGS   [0m - Epoch:   7 [    2075/10000000], loss: {'segmentation': 0.5406, 'neural_augmentation': 0.3307, 'total_loss': 0.8713}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.004, Elapsed time: 11.76
2024-07-28 03:55:12 - [34m[1mLOGS   [0m - Epoch:   7 [    2175/10000000], loss: {'segmentation': 0.5358, 'neural_augmentation': 0.3336, 'total_loss': 0.8694}, LR: [2.9e-05, 2.9e-05, 2.9e-05, 2.9e-05], Avg. batch load time: 0.002, Elapsed time: 23.33
2024-07-28 03:55:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'segmentation': 0.5274, 'neural_augmentation': 0.3373, 'total_loss': 0.8647}
2024-07-28 03:55:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'segmentation': 0.5818, 'neural_augmentation': 0.0, 'total_loss': 0.5818} || iou=69.2652
2024-07-28 03:55:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:55:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:55:26 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_7_iter_2256.pt
2024-07-28 03:55:27 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 2256 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_7_iter_2256.pt
[31m===========================================================================[0m
2024-07-28 03:55:29 - [32m[1mINFO   [0m - Training epoch 8
2024-07-28 03:55:29 - [34m[1mLOGS   [0m - Epoch:   8 [    2257/10000000], loss: {'segmentation': 0.3831, 'neural_augmentation': 0.3772, 'total_loss': 0.7603}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.294, Elapsed time:  0.44
2024-07-28 03:55:41 - [34m[1mLOGS   [0m - Epoch:   8 [    2357/10000000], loss: {'segmentation': 0.4497, 'neural_augmentation': 0.3224, 'total_loss': 0.7721}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.003, Elapsed time: 11.72
2024-07-28 03:55:52 - [34m[1mLOGS   [0m - Epoch:   8 [    2457/10000000], loss: {'segmentation': 0.4453, 'neural_augmentation': 0.3277, 'total_loss': 0.773}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.002, Elapsed time: 23.38
2024-07-28 03:56:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'segmentation': 0.4391, 'neural_augmentation': 0.3284, 'total_loss': 0.7675}
2024-07-28 03:56:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'segmentation': 0.5197, 'neural_augmentation': 0.0, 'total_loss': 0.5197} || iou=70.5807
2024-07-28 03:56:05 - [34m[1mLOGS   [0m - Best checkpoint with score 70.58 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:56:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_63.8079.pt
2024-07-28 03:56:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_66.3065.pt', 'checkpoint_score_66.4022.pt', 'checkpoint_score_67.8186.pt', 'checkpoint_score_70.0538.pt', 'checkpoint_score_70.5807.pt']
2024-07-28 03:56:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 03:56:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:56:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:56:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_8_iter_2538.pt
2024-07-28 03:56:10 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 2538 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_8_iter_2538.pt
[31m===========================================================================[0m
2024-07-28 03:56:12 - [32m[1mINFO   [0m - Training epoch 9
2024-07-28 03:56:13 - [34m[1mLOGS   [0m - Epoch:   9 [    2539/10000000], loss: {'segmentation': 0.3261, 'neural_augmentation': 0.2831, 'total_loss': 0.6093}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.215, Elapsed time:  0.37
2024-07-28 03:56:24 - [34m[1mLOGS   [0m - Epoch:   9 [    2639/10000000], loss: {'segmentation': 0.3828, 'neural_augmentation': 0.34, 'total_loss': 0.7228}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.003, Elapsed time: 12.14
2024-07-28 03:56:36 - [34m[1mLOGS   [0m - Epoch:   9 [    2739/10000000], loss: {'segmentation': 0.3787, 'neural_augmentation': 0.3344, 'total_loss': 0.7131}, LR: [2.8e-05, 2.8e-05, 2.8e-05, 2.8e-05], Avg. batch load time: 0.002, Elapsed time: 23.32
2024-07-28 03:56:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'segmentation': 0.3715, 'neural_augmentation': 0.3391, 'total_loss': 0.7107}
2024-07-28 03:56:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'segmentation': 0.5369, 'neural_augmentation': 0.0, 'total_loss': 0.5369} || iou=68.5045
2024-07-28 03:56:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:56:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:56:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_9_iter_2820.pt
2024-07-28 03:56:51 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 2820 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_9_iter_2820.pt
[31m===========================================================================[0m
2024-07-28 03:56:53 - [32m[1mINFO   [0m - Training epoch 10
2024-07-28 03:56:54 - [34m[1mLOGS   [0m - Epoch:  10 [    2821/10000000], loss: {'segmentation': 0.3276, 'neural_augmentation': 0.3565, 'total_loss': 0.6841}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.449, Elapsed time:  0.59
2024-07-28 03:57:05 - [34m[1mLOGS   [0m - Epoch:  10 [    2921/10000000], loss: {'segmentation': 0.3307, 'neural_augmentation': 0.3366, 'total_loss': 0.6673}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.005, Elapsed time: 12.14
2024-07-28 03:57:17 - [34m[1mLOGS   [0m - Epoch:  10 [    3021/10000000], loss: {'segmentation': 0.3275, 'neural_augmentation': 0.3348, 'total_loss': 0.6623}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.002, Elapsed time: 23.23
2024-07-28 03:57:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'segmentation': 0.323, 'neural_augmentation': 0.3305, 'total_loss': 0.6535}
2024-07-28 03:57:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'segmentation': 0.4476, 'neural_augmentation': 0.0, 'total_loss': 0.4476} || iou=72.0272
2024-07-28 03:57:29 - [34m[1mLOGS   [0m - Best checkpoint with score 72.03 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:57:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_66.3065.pt
2024-07-28 03:57:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_66.4022.pt', 'checkpoint_score_67.8186.pt', 'checkpoint_score_70.0538.pt', 'checkpoint_score_70.5807.pt', 'checkpoint_score_72.0272.pt']
2024-07-28 03:57:33 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 03:57:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:57:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:57:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_10_iter_3102.pt
2024-07-28 03:57:35 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 3102 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_10_iter_3102.pt
[31m===========================================================================[0m
2024-07-28 03:57:37 - [32m[1mINFO   [0m - Training epoch 11
2024-07-28 03:57:38 - [34m[1mLOGS   [0m - Epoch:  11 [    3103/10000000], loss: {'segmentation': 0.2554, 'neural_augmentation': 0.428, 'total_loss': 0.6834}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.385, Elapsed time:  0.53
2024-07-28 03:57:49 - [34m[1mLOGS   [0m - Epoch:  11 [    3203/10000000], loss: {'segmentation': 0.2919, 'neural_augmentation': 0.3283, 'total_loss': 0.6202}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.004, Elapsed time: 11.79
2024-07-28 03:58:01 - [34m[1mLOGS   [0m - Epoch:  11 [    3303/10000000], loss: {'segmentation': 0.2768, 'neural_augmentation': 0.3275, 'total_loss': 0.6042}, LR: [2.7e-05, 2.7e-05, 2.7e-05, 2.7e-05], Avg. batch load time: 0.002, Elapsed time: 23.34
2024-07-28 03:58:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'segmentation': 0.2763, 'neural_augmentation': 0.3291, 'total_loss': 0.6054}
2024-07-28 03:58:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'segmentation': 0.454, 'neural_augmentation': 0.0, 'total_loss': 0.454} || iou=71.1828
2024-07-28 03:58:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:58:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:58:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_11_iter_3384.pt
2024-07-28 03:58:16 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 3384 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_11_iter_3384.pt
[31m===========================================================================[0m
2024-07-28 03:58:18 - [32m[1mINFO   [0m - Training epoch 12
2024-07-28 03:58:19 - [34m[1mLOGS   [0m - Epoch:  12 [    3385/10000000], loss: {'segmentation': 0.3358, 'neural_augmentation': 0.3423, 'total_loss': 0.6781}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.430, Elapsed time:  0.56
2024-07-28 03:58:30 - [34m[1mLOGS   [0m - Epoch:  12 [    3485/10000000], loss: {'segmentation': 0.257, 'neural_augmentation': 0.3169, 'total_loss': 0.574}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.005, Elapsed time: 11.84
2024-07-28 03:58:42 - [34m[1mLOGS   [0m - Epoch:  12 [    3585/10000000], loss: {'segmentation': 0.2579, 'neural_augmentation': 0.3172, 'total_loss': 0.5751}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.002, Elapsed time: 23.44
2024-07-28 03:58:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'segmentation': 0.2555, 'neural_augmentation': 0.3203, 'total_loss': 0.5758}
2024-07-28 03:58:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'segmentation': 0.4347, 'neural_augmentation': 0.0, 'total_loss': 0.4347} || iou=72.3151
2024-07-28 03:58:54 - [34m[1mLOGS   [0m - Best checkpoint with score 72.32 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 03:58:55 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_66.4022.pt
2024-07-28 03:58:55 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_67.8186.pt', 'checkpoint_score_70.0538.pt', 'checkpoint_score_70.5807.pt', 'checkpoint_score_72.0272.pt', 'checkpoint_score_72.3151.pt']
2024-07-28 03:58:57 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 03:58:58 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:58:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:59:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_12_iter_3666.pt
2024-07-28 03:59:00 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 3666 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_12_iter_3666.pt
[31m===========================================================================[0m
2024-07-28 03:59:02 - [32m[1mINFO   [0m - Training epoch 13
2024-07-28 03:59:03 - [34m[1mLOGS   [0m - Epoch:  13 [    3667/10000000], loss: {'segmentation': 0.2603, 'neural_augmentation': 0.3539, 'total_loss': 0.6142}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.427, Elapsed time:  0.56
2024-07-28 03:59:14 - [34m[1mLOGS   [0m - Epoch:  13 [    3767/10000000], loss: {'segmentation': 0.2356, 'neural_augmentation': 0.3161, 'total_loss': 0.5516}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.005, Elapsed time: 12.38
2024-07-28 03:59:26 - [34m[1mLOGS   [0m - Epoch:  13 [    3867/10000000], loss: {'segmentation': 0.2395, 'neural_augmentation': 0.3207, 'total_loss': 0.5602}, LR: [2.6e-05, 2.6e-05, 2.6e-05, 2.6e-05], Avg. batch load time: 0.002, Elapsed time: 23.80
2024-07-28 03:59:35 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'segmentation': 0.2389, 'neural_augmentation': 0.3196, 'total_loss': 0.5585}
2024-07-28 03:59:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'segmentation': 0.4394, 'neural_augmentation': 0.0, 'total_loss': 0.4394} || iou=71.8782
2024-07-28 03:59:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 03:59:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 03:59:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_13_iter_3948.pt
2024-07-28 03:59:41 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 3948 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_13_iter_3948.pt
[31m===========================================================================[0m
2024-07-28 03:59:43 - [32m[1mINFO   [0m - Training epoch 14
2024-07-28 03:59:43 - [34m[1mLOGS   [0m - Epoch:  14 [    3949/10000000], loss: {'segmentation': 0.1845, 'neural_augmentation': 0.2616, 'total_loss': 0.4461}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.178, Elapsed time:  0.33
2024-07-28 03:59:55 - [34m[1mLOGS   [0m - Epoch:  14 [    4049/10000000], loss: {'segmentation': 0.2323, 'neural_augmentation': 0.3263, 'total_loss': 0.5585}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.003, Elapsed time: 11.93
2024-07-28 04:00:06 - [34m[1mLOGS   [0m - Epoch:  14 [    4149/10000000], loss: {'segmentation': 0.2308, 'neural_augmentation': 0.3202, 'total_loss': 0.551}, LR: [2.5e-05, 2.5e-05, 2.5e-05, 2.5e-05], Avg. batch load time: 0.002, Elapsed time: 23.06
2024-07-28 04:00:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'segmentation': 0.2354, 'neural_augmentation': 0.3162, 'total_loss': 0.5516}
2024-07-28 04:00:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'segmentation': 0.4335, 'neural_augmentation': 0.0, 'total_loss': 0.4335} || iou=71.3884
2024-07-28 04:00:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:00:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:00:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_14_iter_4230.pt
2024-07-28 04:00:21 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 4230 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_14_iter_4230.pt
[31m===========================================================================[0m
2024-07-28 04:00:23 - [32m[1mINFO   [0m - Training epoch 15
2024-07-28 04:00:24 - [34m[1mLOGS   [0m - Epoch:  15 [    4231/10000000], loss: {'segmentation': 0.3276, 'neural_augmentation': 0.3467, 'total_loss': 0.6743}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.401, Elapsed time:  0.54
2024-07-28 04:00:35 - [34m[1mLOGS   [0m - Epoch:  15 [    4331/10000000], loss: {'segmentation': 0.2195, 'neural_augmentation': 0.3109, 'total_loss': 0.5304}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.004, Elapsed time: 11.91
2024-07-28 04:00:47 - [34m[1mLOGS   [0m - Epoch:  15 [    4431/10000000], loss: {'segmentation': 0.2186, 'neural_augmentation': 0.3136, 'total_loss': 0.5321}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.002, Elapsed time: 23.08
2024-07-28 04:00:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'segmentation': 0.2235, 'neural_augmentation': 0.3145, 'total_loss': 0.538}
2024-07-28 04:00:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'segmentation': 0.4654, 'neural_augmentation': 0.0, 'total_loss': 0.4654} || iou=69.3463
2024-07-28 04:01:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:01:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:01:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_15_iter_4512.pt
2024-07-28 04:01:02 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 4512 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_15_iter_4512.pt
[31m===========================================================================[0m
2024-07-28 04:01:04 - [32m[1mINFO   [0m - Training epoch 16
2024-07-28 04:01:05 - [34m[1mLOGS   [0m - Epoch:  16 [    4513/10000000], loss: {'segmentation': 0.1942, 'neural_augmentation': 0.2715, 'total_loss': 0.4657}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.284, Elapsed time:  0.43
2024-07-28 04:01:16 - [34m[1mLOGS   [0m - Epoch:  16 [    4613/10000000], loss: {'segmentation': 0.2091, 'neural_augmentation': 0.3153, 'total_loss': 0.5244}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.003, Elapsed time: 11.68
2024-07-28 04:01:27 - [34m[1mLOGS   [0m - Epoch:  16 [    4713/10000000], loss: {'segmentation': 0.2116, 'neural_augmentation': 0.317, 'total_loss': 0.5286}, LR: [2.4e-05, 2.4e-05, 2.4e-05, 2.4e-05], Avg. batch load time: 0.002, Elapsed time: 23.26
2024-07-28 04:01:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'segmentation': 0.2079, 'neural_augmentation': 0.3183, 'total_loss': 0.5262}
2024-07-28 04:01:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'segmentation': 0.4365, 'neural_augmentation': 0.0, 'total_loss': 0.4365} || iou=72.0917
2024-07-28 04:01:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:01:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:01:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_16_iter_4794.pt
2024-07-28 04:01:43 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 4794 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_16_iter_4794.pt
[31m===========================================================================[0m
2024-07-28 04:01:45 - [32m[1mINFO   [0m - Training epoch 17
2024-07-28 04:01:46 - [34m[1mLOGS   [0m - Epoch:  17 [    4795/10000000], loss: {'segmentation': 0.2393, 'neural_augmentation': 0.3707, 'total_loss': 0.61}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.325, Elapsed time:  0.47
2024-07-28 04:01:57 - [34m[1mLOGS   [0m - Epoch:  17 [    4895/10000000], loss: {'segmentation': 0.1953, 'neural_augmentation': 0.3243, 'total_loss': 0.5196}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.003, Elapsed time: 11.81
2024-07-28 04:02:09 - [34m[1mLOGS   [0m - Epoch:  17 [    4995/10000000], loss: {'segmentation': 0.1953, 'neural_augmentation': 0.3224, 'total_loss': 0.5176}, LR: [2.3e-05, 2.3e-05, 2.3e-05, 2.3e-05], Avg. batch load time: 0.002, Elapsed time: 23.51
2024-07-28 04:02:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'segmentation': 0.1943, 'neural_augmentation': 0.3236, 'total_loss': 0.5179}
2024-07-28 04:02:21 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'segmentation': 0.4529, 'neural_augmentation': 0.0, 'total_loss': 0.4529} || iou=70.2794
2024-07-28 04:02:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:02:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:02:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_17_iter_5076.pt
2024-07-28 04:02:24 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 5076 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_17_iter_5076.pt
[31m===========================================================================[0m
2024-07-28 04:02:26 - [32m[1mINFO   [0m - Training epoch 18
2024-07-28 04:02:26 - [34m[1mLOGS   [0m - Epoch:  18 [    5077/10000000], loss: {'segmentation': 0.1767, 'neural_augmentation': 0.3045, 'total_loss': 0.4812}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.391, Elapsed time:  0.52
2024-07-28 04:02:38 - [34m[1mLOGS   [0m - Epoch:  18 [    5177/10000000], loss: {'segmentation': 0.1809, 'neural_augmentation': 0.3314, 'total_loss': 0.5124}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.004, Elapsed time: 12.23
2024-07-28 04:02:49 - [34m[1mLOGS   [0m - Epoch:  18 [    5277/10000000], loss: {'segmentation': 0.1797, 'neural_augmentation': 0.3241, 'total_loss': 0.5038}, LR: [2.2e-05, 2.2e-05, 2.2e-05, 2.2e-05], Avg. batch load time: 0.002, Elapsed time: 23.51
2024-07-28 04:02:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'segmentation': 0.1804, 'neural_augmentation': 0.3235, 'total_loss': 0.5039}
2024-07-28 04:03:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'segmentation': 0.4049, 'neural_augmentation': 0.0, 'total_loss': 0.4049} || iou=73.224
2024-07-28 04:03:02 - [34m[1mLOGS   [0m - Best checkpoint with score 73.22 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 04:03:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_67.8186.pt
2024-07-28 04:03:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_70.0538.pt', 'checkpoint_score_70.5807.pt', 'checkpoint_score_72.0272.pt', 'checkpoint_score_72.3151.pt', 'checkpoint_score_73.2240.pt']
2024-07-28 04:03:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 04:03:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:03:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:03:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_18_iter_5358.pt
2024-07-28 04:03:09 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 5358 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_18_iter_5358.pt
[31m===========================================================================[0m
2024-07-28 04:03:11 - [32m[1mINFO   [0m - Training epoch 19
2024-07-28 04:03:11 - [34m[1mLOGS   [0m - Epoch:  19 [    5359/10000000], loss: {'segmentation': 0.1372, 'neural_augmentation': 0.3686, 'total_loss': 0.5058}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.248, Elapsed time:  0.40
2024-07-28 04:03:22 - [34m[1mLOGS   [0m - Epoch:  19 [    5459/10000000], loss: {'segmentation': 0.1775, 'neural_augmentation': 0.319, 'total_loss': 0.4965}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.003, Elapsed time: 11.84
2024-07-28 04:03:34 - [34m[1mLOGS   [0m - Epoch:  19 [    5559/10000000], loss: {'segmentation': 0.1731, 'neural_augmentation': 0.3173, 'total_loss': 0.4904}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.001, Elapsed time: 22.95
2024-07-28 04:03:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'segmentation': 0.1732, 'neural_augmentation': 0.3202, 'total_loss': 0.4934}
2024-07-28 04:03:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'segmentation': 0.4421, 'neural_augmentation': 0.0, 'total_loss': 0.4421} || iou=71.9525
2024-07-28 04:03:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:03:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:03:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_19_iter_5640.pt
2024-07-28 04:03:49 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 5640 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_19_iter_5640.pt
[31m===========================================================================[0m
2024-07-28 04:03:51 - [32m[1mINFO   [0m - Training epoch 20
2024-07-28 04:03:52 - [34m[1mLOGS   [0m - Epoch:  20 [    5641/10000000], loss: {'segmentation': 0.142, 'neural_augmentation': 0.2787, 'total_loss': 0.4207}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.410, Elapsed time:  0.54
2024-07-28 04:04:03 - [34m[1mLOGS   [0m - Epoch:  20 [    5741/10000000], loss: {'segmentation': 0.1676, 'neural_augmentation': 0.3332, 'total_loss': 0.5008}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.004, Elapsed time: 11.85
2024-07-28 04:04:14 - [34m[1mLOGS   [0m - Epoch:  20 [    5841/10000000], loss: {'segmentation': 0.1654, 'neural_augmentation': 0.3325, 'total_loss': 0.4978}, LR: [2.1e-05, 2.1e-05, 2.1e-05, 2.1e-05], Avg. batch load time: 0.002, Elapsed time: 22.87
2024-07-28 04:04:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'segmentation': 0.1658, 'neural_augmentation': 0.3339, 'total_loss': 0.4997}
2024-07-28 04:04:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'segmentation': 0.4378, 'neural_augmentation': 0.0, 'total_loss': 0.4378} || iou=71.9592
2024-07-28 04:04:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:04:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:04:29 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_20_iter_5922.pt
2024-07-28 04:04:30 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 5922 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_20_iter_5922.pt
[31m===========================================================================[0m
2024-07-28 04:04:32 - [32m[1mINFO   [0m - Training epoch 21
2024-07-28 04:04:32 - [34m[1mLOGS   [0m - Epoch:  21 [    5923/10000000], loss: {'segmentation': 0.1911, 'neural_augmentation': 0.3764, 'total_loss': 0.5675}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.441, Elapsed time:  0.57
2024-07-28 04:04:43 - [34m[1mLOGS   [0m - Epoch:  21 [    6023/10000000], loss: {'segmentation': 0.1643, 'neural_augmentation': 0.3411, 'total_loss': 0.5055}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.005, Elapsed time: 11.77
2024-07-28 04:04:55 - [34m[1mLOGS   [0m - Epoch:  21 [    6123/10000000], loss: {'segmentation': 0.1769, 'neural_augmentation': 0.3392, 'total_loss': 0.5161}, LR: [2e-05, 2e-05, 2e-05, 2e-05], Avg. batch load time: 0.002, Elapsed time: 23.33
2024-07-28 04:05:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'segmentation': 0.1828, 'neural_augmentation': 0.3387, 'total_loss': 0.5215}
2024-07-28 04:05:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'segmentation': 0.4423, 'neural_augmentation': 0.0, 'total_loss': 0.4423} || iou=70.9609
2024-07-28 04:05:08 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:05:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:05:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_21_iter_6204.pt
2024-07-28 04:05:10 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 6204 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_21_iter_6204.pt
[31m===========================================================================[0m
2024-07-28 04:05:12 - [32m[1mINFO   [0m - Training epoch 22
2024-07-28 04:05:13 - [34m[1mLOGS   [0m - Epoch:  22 [    6205/10000000], loss: {'segmentation': 0.1674, 'neural_augmentation': 0.3916, 'total_loss': 0.559}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.357, Elapsed time:  0.49
2024-07-28 04:05:25 - [34m[1mLOGS   [0m - Epoch:  22 [    6305/10000000], loss: {'segmentation': 0.1796, 'neural_augmentation': 0.3517, 'total_loss': 0.5312}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.004, Elapsed time: 12.12
2024-07-28 04:05:36 - [34m[1mLOGS   [0m - Epoch:  22 [    6405/10000000], loss: {'segmentation': 0.1725, 'neural_augmentation': 0.3499, 'total_loss': 0.5223}, LR: [1.9e-05, 1.9e-05, 1.9e-05, 1.9e-05], Avg. batch load time: 0.002, Elapsed time: 23.48
2024-07-28 04:05:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'segmentation': 0.17, 'neural_augmentation': 0.3481, 'total_loss': 0.5181}
2024-07-28 04:05:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'segmentation': 0.4171, 'neural_augmentation': 0.0, 'total_loss': 0.4171} || iou=71.7509
2024-07-28 04:05:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:05:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:05:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_22_iter_6486.pt
2024-07-28 04:05:51 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 6486 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_22_iter_6486.pt
[31m===========================================================================[0m
2024-07-28 04:05:53 - [32m[1mINFO   [0m - Training epoch 23
2024-07-28 04:05:54 - [34m[1mLOGS   [0m - Epoch:  23 [    6487/10000000], loss: {'segmentation': 0.1632, 'neural_augmentation': 0.3716, 'total_loss': 0.5347}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.333, Elapsed time:  0.47
2024-07-28 04:06:05 - [34m[1mLOGS   [0m - Epoch:  23 [    6587/10000000], loss: {'segmentation': 0.1654, 'neural_augmentation': 0.355, 'total_loss': 0.5204}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.004, Elapsed time: 12.22
2024-07-28 04:06:17 - [34m[1mLOGS   [0m - Epoch:  23 [    6687/10000000], loss: {'segmentation': 0.1605, 'neural_augmentation': 0.3578, 'total_loss': 0.5183}, LR: [1.8e-05, 1.8e-05, 1.8e-05, 1.8e-05], Avg. batch load time: 0.002, Elapsed time: 23.53
2024-07-28 04:06:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'segmentation': 0.1582, 'neural_augmentation': 0.357, 'total_loss': 0.5152}
2024-07-28 04:06:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'segmentation': 0.4007, 'neural_augmentation': 0.0, 'total_loss': 0.4007} || iou=73.0731
2024-07-28 04:06:30 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:06:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:06:32 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 6768 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_23_iter_6768.pt
2024-07-28 04:06:33 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 6768 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_23_iter_6768.pt
[31m===========================================================================[0m
2024-07-28 04:06:35 - [32m[1mINFO   [0m - Training epoch 24
2024-07-28 04:06:35 - [34m[1mLOGS   [0m - Epoch:  24 [    6769/10000000], loss: {'segmentation': 0.1372, 'neural_augmentation': 0.3571, 'total_loss': 0.4943}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.189, Elapsed time:  0.34
2024-07-28 04:06:47 - [34m[1mLOGS   [0m - Epoch:  24 [    6869/10000000], loss: {'segmentation': 0.1594, 'neural_augmentation': 0.361, 'total_loss': 0.5204}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.003, Elapsed time: 11.81
2024-07-28 04:06:58 - [34m[1mLOGS   [0m - Epoch:  24 [    6969/10000000], loss: {'segmentation': 0.1601, 'neural_augmentation': 0.3652, 'total_loss': 0.5253}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.002, Elapsed time: 22.87
2024-07-28 04:07:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'segmentation': 0.1575, 'neural_augmentation': 0.367, 'total_loss': 0.5245}
2024-07-28 04:07:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'segmentation': 0.4137, 'neural_augmentation': 0.0, 'total_loss': 0.4137} || iou=72.9326
2024-07-28 04:07:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:07:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:07:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 7050 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_24_iter_7050.pt
2024-07-28 04:07:13 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 7050 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_24_iter_7050.pt
[31m===========================================================================[0m
2024-07-28 04:07:15 - [32m[1mINFO   [0m - Training epoch 25
2024-07-28 04:07:16 - [34m[1mLOGS   [0m - Epoch:  25 [    7051/10000000], loss: {'segmentation': 0.1553, 'neural_augmentation': 0.3455, 'total_loss': 0.5008}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.371, Elapsed time:  0.50
2024-07-28 04:07:27 - [34m[1mLOGS   [0m - Epoch:  25 [    7151/10000000], loss: {'segmentation': 0.1507, 'neural_augmentation': 0.3823, 'total_loss': 0.533}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.004, Elapsed time: 11.75
2024-07-28 04:07:38 - [34m[1mLOGS   [0m - Epoch:  25 [    7251/10000000], loss: {'segmentation': 0.1542, 'neural_augmentation': 0.3823, 'total_loss': 0.5365}, LR: [1.7e-05, 1.7e-05, 1.7e-05, 1.7e-05], Avg. batch load time: 0.002, Elapsed time: 22.82
2024-07-28 04:07:47 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'segmentation': 0.1538, 'neural_augmentation': 0.382, 'total_loss': 0.5358}
2024-07-28 04:07:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'segmentation': 0.4011, 'neural_augmentation': 0.0, 'total_loss': 0.4011} || iou=73.2704
2024-07-28 04:07:51 - [34m[1mLOGS   [0m - Best checkpoint with score 73.27 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 04:07:51 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_70.0538.pt
2024-07-28 04:07:51 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_70.5807.pt', 'checkpoint_score_72.0272.pt', 'checkpoint_score_72.3151.pt', 'checkpoint_score_73.2240.pt', 'checkpoint_score_73.2704.pt']
2024-07-28 04:07:54 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 04:07:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:07:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:07:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 7332 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_25_iter_7332.pt
2024-07-28 04:07:56 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 7332 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_25_iter_7332.pt
[31m===========================================================================[0m
2024-07-28 04:07:58 - [32m[1mINFO   [0m - Training epoch 26
2024-07-28 04:07:59 - [34m[1mLOGS   [0m - Epoch:  26 [    7333/10000000], loss: {'segmentation': 0.1311, 'neural_augmentation': 0.3298, 'total_loss': 0.4609}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.243, Elapsed time:  0.39
2024-07-28 04:08:10 - [34m[1mLOGS   [0m - Epoch:  26 [    7433/10000000], loss: {'segmentation': 0.1441, 'neural_augmentation': 0.404, 'total_loss': 0.5481}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.003, Elapsed time: 11.65
2024-07-28 04:08:21 - [34m[1mLOGS   [0m - Epoch:  26 [    7533/10000000], loss: {'segmentation': 0.1428, 'neural_augmentation': 0.3963, 'total_loss': 0.539}, LR: [1.6e-05, 1.6e-05, 1.6e-05, 1.6e-05], Avg. batch load time: 0.002, Elapsed time: 23.22
2024-07-28 04:08:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'segmentation': 0.145, 'neural_augmentation': 0.3951, 'total_loss': 0.5401}
2024-07-28 04:08:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'segmentation': 0.4028, 'neural_augmentation': 0.0, 'total_loss': 0.4028} || iou=73.3001
2024-07-28 04:08:34 - [34m[1mLOGS   [0m - Best checkpoint with score 73.30 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 04:08:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_70.5807.pt
2024-07-28 04:08:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_72.0272.pt', 'checkpoint_score_72.3151.pt', 'checkpoint_score_73.2240.pt', 'checkpoint_score_73.2704.pt', 'checkpoint_score_73.3001.pt']
2024-07-28 04:08:38 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 04:08:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:08:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:08:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 7614 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_26_iter_7614.pt
2024-07-28 04:08:40 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 7614 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_26_iter_7614.pt
[31m===========================================================================[0m
2024-07-28 04:08:42 - [32m[1mINFO   [0m - Training epoch 27
2024-07-28 04:08:42 - [34m[1mLOGS   [0m - Epoch:  27 [    7615/10000000], loss: {'segmentation': 0.1307, 'neural_augmentation': 0.3901, 'total_loss': 0.5208}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.345, Elapsed time:  0.48
2024-07-28 04:08:54 - [34m[1mLOGS   [0m - Epoch:  27 [    7715/10000000], loss: {'segmentation': 0.1424, 'neural_augmentation': 0.4164, 'total_loss': 0.5588}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.004, Elapsed time: 12.17
2024-07-28 04:09:05 - [34m[1mLOGS   [0m - Epoch:  27 [    7815/10000000], loss: {'segmentation': 0.1406, 'neural_augmentation': 0.4128, 'total_loss': 0.5534}, LR: [1.5e-05, 1.5e-05, 1.5e-05, 1.5e-05], Avg. batch load time: 0.002, Elapsed time: 23.48
2024-07-28 04:09:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'segmentation': 0.1416, 'neural_augmentation': 0.412, 'total_loss': 0.5536}
2024-07-28 04:09:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'segmentation': 0.3991, 'neural_augmentation': 0.0, 'total_loss': 0.3991} || iou=72.9616
2024-07-28 04:09:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:09:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:09:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 7896 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_27_iter_7896.pt
2024-07-28 04:09:21 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 7896 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_27_iter_7896.pt
[31m===========================================================================[0m
2024-07-28 04:09:23 - [32m[1mINFO   [0m - Training epoch 28
2024-07-28 04:09:23 - [34m[1mLOGS   [0m - Epoch:  28 [    7897/10000000], loss: {'segmentation': 0.1411, 'neural_augmentation': 0.3924, 'total_loss': 0.5334}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.241, Elapsed time:  0.38
2024-07-28 04:09:35 - [34m[1mLOGS   [0m - Epoch:  28 [    7997/10000000], loss: {'segmentation': 0.1395, 'neural_augmentation': 0.4222, 'total_loss': 0.5617}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.003, Elapsed time: 12.19
2024-07-28 04:09:46 - [34m[1mLOGS   [0m - Epoch:  28 [    8097/10000000], loss: {'segmentation': 0.14, 'neural_augmentation': 0.4251, 'total_loss': 0.5651}, LR: [1.4e-05, 1.4e-05, 1.4e-05, 1.4e-05], Avg. batch load time: 0.002, Elapsed time: 23.50
2024-07-28 04:09:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'segmentation': 0.139, 'neural_augmentation': 0.4253, 'total_loss': 0.5643}
2024-07-28 04:09:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'segmentation': 0.4089, 'neural_augmentation': 0.0, 'total_loss': 0.4089} || iou=73.0528
2024-07-28 04:10:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:10:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:10:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_28_iter_8178.pt
2024-07-28 04:10:03 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_28_iter_8178.pt
[31m===========================================================================[0m
2024-07-28 04:10:05 - [32m[1mINFO   [0m - Training epoch 29
2024-07-28 04:10:05 - [34m[1mLOGS   [0m - Epoch:  29 [    8179/10000000], loss: {'segmentation': 0.1158, 'neural_augmentation': 0.4312, 'total_loss': 0.547}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.425, Elapsed time:  0.56
2024-07-28 04:10:16 - [34m[1mLOGS   [0m - Epoch:  29 [    8279/10000000], loss: {'segmentation': 0.1369, 'neural_augmentation': 0.4501, 'total_loss': 0.5871}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.004, Elapsed time: 11.82
2024-07-28 04:10:28 - [34m[1mLOGS   [0m - Epoch:  29 [    8379/10000000], loss: {'segmentation': 0.1344, 'neural_augmentation': 0.4433, 'total_loss': 0.5777}, LR: [1.3e-05, 1.3e-05, 1.3e-05, 1.3e-05], Avg. batch load time: 0.002, Elapsed time: 22.92
2024-07-28 04:10:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'segmentation': 0.1342, 'neural_augmentation': 0.4426, 'total_loss': 0.5768}
2024-07-28 04:10:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'segmentation': 0.4076, 'neural_augmentation': 0.0, 'total_loss': 0.4076} || iou=73.1573
2024-07-28 04:10:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:10:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:10:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 8460 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_29_iter_8460.pt
2024-07-28 04:10:43 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 8460 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_29_iter_8460.pt
[31m===========================================================================[0m
2024-07-28 04:10:45 - [32m[1mINFO   [0m - Training epoch 30
2024-07-28 04:10:46 - [34m[1mLOGS   [0m - Epoch:  30 [    8461/10000000], loss: {'segmentation': 0.1153, 'neural_augmentation': 0.4849, 'total_loss': 0.6002}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.408, Elapsed time:  0.54
2024-07-28 04:10:57 - [34m[1mLOGS   [0m - Epoch:  30 [    8561/10000000], loss: {'segmentation': 0.1335, 'neural_augmentation': 0.4661, 'total_loss': 0.5996}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.004, Elapsed time: 11.75
2024-07-28 04:11:08 - [34m[1mLOGS   [0m - Epoch:  30 [    8661/10000000], loss: {'segmentation': 0.1316, 'neural_augmentation': 0.4664, 'total_loss': 0.5981}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.002, Elapsed time: 23.12
2024-07-28 04:11:17 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'segmentation': 0.1316, 'neural_augmentation': 0.4636, 'total_loss': 0.5951}
2024-07-28 04:11:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'segmentation': 0.4258, 'neural_augmentation': 0.0, 'total_loss': 0.4258} || iou=73.0252
2024-07-28 04:11:22 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:11:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:11:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 8742 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_30_iter_8742.pt
2024-07-28 04:11:24 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 8742 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_30_iter_8742.pt
[31m===========================================================================[0m
2024-07-28 04:11:26 - [32m[1mINFO   [0m - Training epoch 31
2024-07-28 04:11:26 - [34m[1mLOGS   [0m - Epoch:  31 [    8743/10000000], loss: {'segmentation': 0.1429, 'neural_augmentation': 0.4163, 'total_loss': 0.5591}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.193, Elapsed time:  0.34
2024-07-28 04:11:38 - [34m[1mLOGS   [0m - Epoch:  31 [    8843/10000000], loss: {'segmentation': 0.1354, 'neural_augmentation': 0.4793, 'total_loss': 0.6146}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.003, Elapsed time: 11.66
2024-07-28 04:11:49 - [34m[1mLOGS   [0m - Epoch:  31 [    8943/10000000], loss: {'segmentation': 0.1329, 'neural_augmentation': 0.48, 'total_loss': 0.6129}, LR: [1.2e-05, 1.2e-05, 1.2e-05, 1.2e-05], Avg. batch load time: 0.002, Elapsed time: 23.25
2024-07-28 04:11:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'segmentation': 0.1316, 'neural_augmentation': 0.4777, 'total_loss': 0.6093}
2024-07-28 04:12:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'segmentation': 0.4095, 'neural_augmentation': 0.0, 'total_loss': 0.4095} || iou=73.5827
2024-07-28 04:12:02 - [34m[1mLOGS   [0m - Best checkpoint with score 73.58 saved at /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_best.pt
2024-07-28 04:12:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_score_72.0272.pt
2024-07-28 04:12:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_72.3151.pt', 'checkpoint_score_73.2240.pt', 'checkpoint_score_73.2704.pt', 'checkpoint_score_73.3001.pt', 'checkpoint_score_73.5827.pt']
2024-07-28 04:12:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_avg.pt
2024-07-28 04:12:06 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:12:07 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:12:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 9024 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_31_iter_9024.pt
2024-07-28 04:12:08 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 9024 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_31_iter_9024.pt
[31m===========================================================================[0m
2024-07-28 04:12:10 - [32m[1mINFO   [0m - Training epoch 32
2024-07-28 04:12:11 - [34m[1mLOGS   [0m - Epoch:  32 [    9025/10000000], loss: {'segmentation': 0.1176, 'neural_augmentation': 0.4146, 'total_loss': 0.5322}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.304, Elapsed time:  0.45
2024-07-28 04:12:22 - [34m[1mLOGS   [0m - Epoch:  32 [    9125/10000000], loss: {'segmentation': 0.131, 'neural_augmentation': 0.4959, 'total_loss': 0.6269}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.003, Elapsed time: 12.34
2024-07-28 04:12:34 - [34m[1mLOGS   [0m - Epoch:  32 [    9225/10000000], loss: {'segmentation': 0.1282, 'neural_augmentation': 0.4918, 'total_loss': 0.62}, LR: [1.1e-05, 1.1e-05, 1.1e-05, 1.1e-05], Avg. batch load time: 0.002, Elapsed time: 23.48
2024-07-28 04:12:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'segmentation': 0.1278, 'neural_augmentation': 0.4917, 'total_loss': 0.6195}
2024-07-28 04:12:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'segmentation': 0.4194, 'neural_augmentation': 0.0, 'total_loss': 0.4194} || iou=73.0793
2024-07-28 04:12:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:12:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:12:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 9306 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_32_iter_9306.pt
2024-07-28 04:12:50 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 9306 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_32_iter_9306.pt
[31m===========================================================================[0m
2024-07-28 04:12:52 - [32m[1mINFO   [0m - Training epoch 33
2024-07-28 04:12:52 - [34m[1mLOGS   [0m - Epoch:  33 [    9307/10000000], loss: {'segmentation': 0.1249, 'neural_augmentation': 0.5021, 'total_loss': 0.627}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.226, Elapsed time:  0.38
2024-07-28 04:13:03 - [34m[1mLOGS   [0m - Epoch:  33 [    9407/10000000], loss: {'segmentation': 0.1225, 'neural_augmentation': 0.5115, 'total_loss': 0.634}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.003, Elapsed time: 11.79
2024-07-28 04:13:14 - [34m[1mLOGS   [0m - Epoch:  33 [    9507/10000000], loss: {'segmentation': 0.1248, 'neural_augmentation': 0.5143, 'total_loss': 0.6391}, LR: [1e-05, 1e-05, 1e-05, 1e-05], Avg. batch load time: 0.001, Elapsed time: 22.82
2024-07-28 04:13:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'segmentation': 0.1261, 'neural_augmentation': 0.5139, 'total_loss': 0.64}
2024-07-28 04:13:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'segmentation': 0.444, 'neural_augmentation': 0.0, 'total_loss': 0.444} || iou=72.1603
2024-07-28 04:13:28 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:13:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:13:30 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 9588 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_33_iter_9588.pt
2024-07-28 04:13:30 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 9588 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_33_iter_9588.pt
[31m===========================================================================[0m
2024-07-28 04:13:32 - [32m[1mINFO   [0m - Training epoch 34
2024-07-28 04:13:32 - [34m[1mLOGS   [0m - Epoch:  34 [    9589/10000000], loss: {'segmentation': 0.1092, 'neural_augmentation': 0.5427, 'total_loss': 0.6519}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.151, Elapsed time:  0.30
2024-07-28 04:13:44 - [34m[1mLOGS   [0m - Epoch:  34 [    9689/10000000], loss: {'segmentation': 0.1227, 'neural_augmentation': 0.5316, 'total_loss': 0.6543}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 11.68
2024-07-28 04:13:55 - [34m[1mLOGS   [0m - Epoch:  34 [    9789/10000000], loss: {'segmentation': 0.1222, 'neural_augmentation': 0.5332, 'total_loss': 0.6554}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.001, Elapsed time: 22.77
2024-07-28 04:14:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'segmentation': 0.1237, 'neural_augmentation': 0.5335, 'total_loss': 0.6572}
2024-07-28 04:14:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'segmentation': 0.4369, 'neural_augmentation': 0.0, 'total_loss': 0.4369} || iou=72.2933
2024-07-28 04:14:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:14:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:14:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 9870 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_34_iter_9870.pt
2024-07-28 04:14:11 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 9870 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_34_iter_9870.pt
[31m===========================================================================[0m
2024-07-28 04:14:13 - [32m[1mINFO   [0m - Training epoch 35
2024-07-28 04:14:13 - [34m[1mLOGS   [0m - Epoch:  35 [    9871/10000000], loss: {'segmentation': 0.096, 'neural_augmentation': 0.5125, 'total_loss': 0.6086}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.431, Elapsed time:  0.56
2024-07-28 04:14:24 - [34m[1mLOGS   [0m - Epoch:  35 [    9971/10000000], loss: {'segmentation': 0.1234, 'neural_augmentation': 0.5522, 'total_loss': 0.6756}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.005, Elapsed time: 11.65
2024-07-28 04:14:35 - [34m[1mLOGS   [0m - Epoch:  35 [   10071/10000000], loss: {'segmentation': 0.1236, 'neural_augmentation': 0.5547, 'total_loss': 0.6783}, LR: [9e-06, 9e-06, 9e-06, 9e-06], Avg. batch load time: 0.002, Elapsed time: 22.70
2024-07-28 04:14:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'segmentation': 0.1236, 'neural_augmentation': 0.5547, 'total_loss': 0.6783}
2024-07-28 04:14:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'segmentation': 0.4642, 'neural_augmentation': 0.0, 'total_loss': 0.4642} || iou=71.4503
2024-07-28 04:14:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:14:49 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:14:51 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 10152 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_35_iter_10152.pt
2024-07-28 04:14:51 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 10152 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_35_iter_10152.pt
[31m===========================================================================[0m
2024-07-28 04:14:53 - [32m[1mINFO   [0m - Training epoch 36
2024-07-28 04:14:54 - [34m[1mLOGS   [0m - Epoch:  36 [   10153/10000000], loss: {'segmentation': 0.1513, 'neural_augmentation': 0.5396, 'total_loss': 0.6909}, LR: [8e-06, 8e-06, 8e-06, 8e-06], Avg. batch load time: 0.229, Elapsed time:  0.37
2024-07-28 04:15:05 - [34m[1mLOGS   [0m - Epoch:  36 [   10253/10000000], loss: {'segmentation': 0.1215, 'neural_augmentation': 0.5638, 'total_loss': 0.6853}, LR: [8e-06, 8e-06, 8e-06, 8e-06], Avg. batch load time: 0.003, Elapsed time: 11.64
2024-07-28 04:15:16 - [34m[1mLOGS   [0m - Epoch:  36 [   10353/10000000], loss: {'segmentation': 0.1208, 'neural_augmentation': 0.5677, 'total_loss': 0.6885}, LR: [8e-06, 8e-06, 8e-06, 8e-06], Avg. batch load time: 0.001, Elapsed time: 22.82
2024-07-28 04:15:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'segmentation': 0.1212, 'neural_augmentation': 0.5678, 'total_loss': 0.689}
2024-07-28 04:15:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'segmentation': 0.4395, 'neural_augmentation': 0.0, 'total_loss': 0.4395} || iou=72.86
2024-07-28 04:15:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:15:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:15:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 10434 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_36_iter_10434.pt
2024-07-28 04:15:31 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 10434 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_36_iter_10434.pt
[31m===========================================================================[0m
2024-07-28 04:15:33 - [32m[1mINFO   [0m - Training epoch 37
2024-07-28 04:15:34 - [34m[1mLOGS   [0m - Epoch:  37 [   10435/10000000], loss: {'segmentation': 0.1352, 'neural_augmentation': 0.5737, 'total_loss': 0.7089}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.302, Elapsed time:  0.43
2024-07-28 04:15:46 - [34m[1mLOGS   [0m - Epoch:  37 [   10535/10000000], loss: {'segmentation': 0.1197, 'neural_augmentation': 0.5815, 'total_loss': 0.7012}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.003, Elapsed time: 12.94
2024-07-28 04:15:58 - [34m[1mLOGS   [0m - Epoch:  37 [   10635/10000000], loss: {'segmentation': 0.1191, 'neural_augmentation': 0.5868, 'total_loss': 0.7058}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.002, Elapsed time: 24.57
2024-07-28 04:16:07 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'segmentation': 0.1194, 'neural_augmentation': 0.5856, 'total_loss': 0.7051}
2024-07-28 04:16:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'segmentation': 0.4446, 'neural_augmentation': 0.0, 'total_loss': 0.4446} || iou=72.3349
2024-07-28 04:16:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:16:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:16:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 10716 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_37_iter_10716.pt
2024-07-28 04:16:13 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 10716 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_37_iter_10716.pt
[31m===========================================================================[0m
2024-07-28 04:16:15 - [32m[1mINFO   [0m - Training epoch 38
2024-07-28 04:16:16 - [34m[1mLOGS   [0m - Epoch:  38 [   10717/10000000], loss: {'segmentation': 0.1397, 'neural_augmentation': 0.6711, 'total_loss': 0.8108}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.445, Elapsed time:  0.58
2024-07-28 04:16:28 - [34m[1mLOGS   [0m - Epoch:  38 [   10817/10000000], loss: {'segmentation': 0.1185, 'neural_augmentation': 0.6003, 'total_loss': 0.7188}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.005, Elapsed time: 12.40
2024-07-28 04:16:39 - [34m[1mLOGS   [0m - Epoch:  38 [   10917/10000000], loss: {'segmentation': 0.1188, 'neural_augmentation': 0.6003, 'total_loss': 0.7191}, LR: [7e-06, 7e-06, 7e-06, 7e-06], Avg. batch load time: 0.003, Elapsed time: 23.67
2024-07-28 04:16:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'segmentation': 0.1184, 'neural_augmentation': 0.5992, 'total_loss': 0.7176}
2024-07-28 04:16:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'segmentation': 0.4629, 'neural_augmentation': 0.0, 'total_loss': 0.4629} || iou=71.9484
2024-07-28 04:16:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:16:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:16:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 10998 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_38_iter_10998.pt
2024-07-28 04:16:54 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 10998 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_38_iter_10998.pt
[31m===========================================================================[0m
2024-07-28 04:16:56 - [32m[1mINFO   [0m - Training epoch 39
2024-07-28 04:16:57 - [34m[1mLOGS   [0m - Epoch:  39 [   10999/10000000], loss: {'segmentation': 0.1583, 'neural_augmentation': 0.5172, 'total_loss': 0.6755}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.465, Elapsed time:  0.60
2024-07-28 04:17:08 - [34m[1mLOGS   [0m - Epoch:  39 [   11099/10000000], loss: {'segmentation': 0.118, 'neural_augmentation': 0.6133, 'total_loss': 0.7312}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.005, Elapsed time: 12.01
2024-07-28 04:17:20 - [34m[1mLOGS   [0m - Epoch:  39 [   11199/10000000], loss: {'segmentation': 0.1166, 'neural_augmentation': 0.6159, 'total_loss': 0.7325}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.003, Elapsed time: 23.51
2024-07-28 04:17:28 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'segmentation': 0.1171, 'neural_augmentation': 0.6172, 'total_loss': 0.7343}
2024-07-28 04:17:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'segmentation': 0.4605, 'neural_augmentation': 0.0, 'total_loss': 0.4605} || iou=71.7003
2024-07-28 04:17:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:17:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:17:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 11280 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_39_iter_11280.pt
2024-07-28 04:17:35 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 11280 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_39_iter_11280.pt
[31m===========================================================================[0m
2024-07-28 04:17:37 - [32m[1mINFO   [0m - Training epoch 40
2024-07-28 04:17:37 - [34m[1mLOGS   [0m - Epoch:  40 [   11281/10000000], loss: {'segmentation': 0.1174, 'neural_augmentation': 0.6752, 'total_loss': 0.7926}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.310, Elapsed time:  0.45
2024-07-28 04:17:49 - [34m[1mLOGS   [0m - Epoch:  40 [   11381/10000000], loss: {'segmentation': 0.1148, 'neural_augmentation': 0.643, 'total_loss': 0.7578}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.003, Elapsed time: 11.95
2024-07-28 04:18:00 - [34m[1mLOGS   [0m - Epoch:  40 [   11481/10000000], loss: {'segmentation': 0.1163, 'neural_augmentation': 0.6418, 'total_loss': 0.7581}, LR: [6e-06, 6e-06, 6e-06, 6e-06], Avg. batch load time: 0.002, Elapsed time: 23.07
2024-07-28 04:18:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'segmentation': 0.1159, 'neural_augmentation': 0.6396, 'total_loss': 0.7555}
2024-07-28 04:18:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'segmentation': 0.4492, 'neural_augmentation': 0.0, 'total_loss': 0.4492} || iou=72.3371
2024-07-28 04:18:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:18:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:18:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 11562 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_40_iter_11562.pt
2024-07-28 04:18:16 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 11562 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_40_iter_11562.pt
[31m===========================================================================[0m
2024-07-28 04:18:18 - [32m[1mINFO   [0m - Training epoch 41
2024-07-28 04:18:18 - [34m[1mLOGS   [0m - Epoch:  41 [   11563/10000000], loss: {'segmentation': 0.0993, 'neural_augmentation': 0.6367, 'total_loss': 0.736}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.409, Elapsed time:  0.54
2024-07-28 04:18:29 - [34m[1mLOGS   [0m - Epoch:  41 [   11663/10000000], loss: {'segmentation': 0.1152, 'neural_augmentation': 0.6374, 'total_loss': 0.7526}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.004, Elapsed time: 11.72
2024-07-28 04:18:41 - [34m[1mLOGS   [0m - Epoch:  41 [   11763/10000000], loss: {'segmentation': 0.1152, 'neural_augmentation': 0.641, 'total_loss': 0.7562}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 23.11
2024-07-28 04:18:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'segmentation': 0.1156, 'neural_augmentation': 0.642, 'total_loss': 0.7576}
2024-07-28 04:18:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'segmentation': 0.4331, 'neural_augmentation': 0.0, 'total_loss': 0.4331} || iou=72.7445
2024-07-28 04:18:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:18:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:18:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 11844 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_41_iter_11844.pt
2024-07-28 04:18:56 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 11844 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_41_iter_11844.pt
[31m===========================================================================[0m
2024-07-28 04:18:58 - [32m[1mINFO   [0m - Training epoch 42
2024-07-28 04:18:59 - [34m[1mLOGS   [0m - Epoch:  42 [   11845/10000000], loss: {'segmentation': 0.0994, 'neural_augmentation': 0.6014, 'total_loss': 0.7008}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.350, Elapsed time:  0.48
2024-07-28 04:19:12 - [34m[1mLOGS   [0m - Epoch:  42 [   11945/10000000], loss: {'segmentation': 0.117, 'neural_augmentation': 0.6708, 'total_loss': 0.7878}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.004, Elapsed time: 14.23
2024-07-28 04:19:24 - [34m[1mLOGS   [0m - Epoch:  42 [   12045/10000000], loss: {'segmentation': 0.1158, 'neural_augmentation': 0.6625, 'total_loss': 0.7783}, LR: [5e-06, 5e-06, 5e-06, 5e-06], Avg. batch load time: 0.002, Elapsed time: 25.31
2024-07-28 04:19:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'segmentation': 0.1153, 'neural_augmentation': 0.6621, 'total_loss': 0.7774}
2024-07-28 04:19:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'segmentation': 0.4401, 'neural_augmentation': 0.0, 'total_loss': 0.4401} || iou=72.6833
2024-07-28 04:19:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:19:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:19:38 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 12126 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_42_iter_12126.pt
2024-07-28 04:19:39 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 12126 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_42_iter_12126.pt
[31m===========================================================================[0m
2024-07-28 04:19:41 - [32m[1mINFO   [0m - Training epoch 43
2024-07-28 04:19:41 - [34m[1mLOGS   [0m - Epoch:  43 [   12127/10000000], loss: {'segmentation': 0.0998, 'neural_augmentation': 0.6646, 'total_loss': 0.7644}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.396, Elapsed time:  0.53
2024-07-28 04:19:52 - [34m[1mLOGS   [0m - Epoch:  43 [   12227/10000000], loss: {'segmentation': 0.1131, 'neural_augmentation': 0.6763, 'total_loss': 0.7893}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.004, Elapsed time: 11.61
2024-07-28 04:20:03 - [34m[1mLOGS   [0m - Epoch:  43 [   12327/10000000], loss: {'segmentation': 0.1132, 'neural_augmentation': 0.675, 'total_loss': 0.7882}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.002, Elapsed time: 22.54
2024-07-28 04:20:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'segmentation': 0.1131, 'neural_augmentation': 0.6724, 'total_loss': 0.7856}
2024-07-28 04:20:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'segmentation': 0.4446, 'neural_augmentation': 0.0, 'total_loss': 0.4446} || iou=72.559
2024-07-28 04:20:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:20:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:20:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 12408 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_43_iter_12408.pt
2024-07-28 04:20:18 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 12408 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_43_iter_12408.pt
[31m===========================================================================[0m
2024-07-28 04:20:20 - [32m[1mINFO   [0m - Training epoch 44
2024-07-28 04:20:21 - [34m[1mLOGS   [0m - Epoch:  44 [   12409/10000000], loss: {'segmentation': 0.1162, 'neural_augmentation': 0.726, 'total_loss': 0.8422}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.175, Elapsed time:  0.33
2024-07-28 04:20:32 - [34m[1mLOGS   [0m - Epoch:  44 [   12509/10000000], loss: {'segmentation': 0.1106, 'neural_augmentation': 0.6782, 'total_loss': 0.7888}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.002, Elapsed time: 11.37
2024-07-28 04:20:43 - [34m[1mLOGS   [0m - Epoch:  44 [   12609/10000000], loss: {'segmentation': 0.1111, 'neural_augmentation': 0.679, 'total_loss': 0.7901}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.001, Elapsed time: 22.32
2024-07-28 04:20:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'segmentation': 0.1121, 'neural_augmentation': 0.6789, 'total_loss': 0.791}
2024-07-28 04:20:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'segmentation': 0.4457, 'neural_augmentation': 0.0, 'total_loss': 0.4457} || iou=72.2745
2024-07-28 04:20:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:20:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:20:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 12690 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_44_iter_12690.pt
2024-07-28 04:20:58 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 12690 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_44_iter_12690.pt
[31m===========================================================================[0m
2024-07-28 04:21:00 - [32m[1mINFO   [0m - Training epoch 45
2024-07-28 04:21:00 - [34m[1mLOGS   [0m - Epoch:  45 [   12691/10000000], loss: {'segmentation': 0.0906, 'neural_augmentation': 0.7171, 'total_loss': 0.8077}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.302, Elapsed time:  0.44
2024-07-28 04:21:11 - [34m[1mLOGS   [0m - Epoch:  45 [   12791/10000000], loss: {'segmentation': 0.113, 'neural_augmentation': 0.6963, 'total_loss': 0.8093}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.003, Elapsed time: 11.50
2024-07-28 04:21:22 - [34m[1mLOGS   [0m - Epoch:  45 [   12891/10000000], loss: {'segmentation': 0.1123, 'neural_augmentation': 0.6936, 'total_loss': 0.8059}, LR: [4e-06, 4e-06, 4e-06, 4e-06], Avg. batch load time: 0.002, Elapsed time: 22.50
2024-07-28 04:21:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'segmentation': 0.1124, 'neural_augmentation': 0.6929, 'total_loss': 0.8053}
2024-07-28 04:21:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'segmentation': 0.4466, 'neural_augmentation': 0.0, 'total_loss': 0.4466} || iou=72.4317
2024-07-28 04:21:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:21:35 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:21:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 12972 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_45_iter_12972.pt
2024-07-28 04:21:37 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 12972 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_45_iter_12972.pt
[31m===========================================================================[0m
2024-07-28 04:21:39 - [32m[1mINFO   [0m - Training epoch 46
2024-07-28 04:21:40 - [34m[1mLOGS   [0m - Epoch:  46 [   12973/10000000], loss: {'segmentation': 0.1284, 'neural_augmentation': 0.6964, 'total_loss': 0.8249}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.407, Elapsed time:  0.55
2024-07-28 04:21:51 - [34m[1mLOGS   [0m - Epoch:  46 [   13073/10000000], loss: {'segmentation': 0.1098, 'neural_augmentation': 0.6982, 'total_loss': 0.808}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.004, Elapsed time: 11.74
2024-07-28 04:22:02 - [34m[1mLOGS   [0m - Epoch:  46 [   13173/10000000], loss: {'segmentation': 0.1112, 'neural_augmentation': 0.6967, 'total_loss': 0.8079}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 22.69
2024-07-28 04:22:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'segmentation': 0.1119, 'neural_augmentation': 0.6985, 'total_loss': 0.8105}
2024-07-28 04:22:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'segmentation': 0.4502, 'neural_augmentation': 0.0, 'total_loss': 0.4502} || iou=72.293
2024-07-28 04:22:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:22:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:22:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 13254 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_46_iter_13254.pt
2024-07-28 04:22:17 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 13254 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_46_iter_13254.pt
[31m===========================================================================[0m
2024-07-28 04:22:19 - [32m[1mINFO   [0m - Training epoch 47
2024-07-28 04:22:20 - [34m[1mLOGS   [0m - Epoch:  47 [   13255/10000000], loss: {'segmentation': 0.1078, 'neural_augmentation': 0.746, 'total_loss': 0.8539}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.440, Elapsed time:  0.57
2024-07-28 04:22:31 - [34m[1mLOGS   [0m - Epoch:  47 [   13355/10000000], loss: {'segmentation': 0.1113, 'neural_augmentation': 0.7053, 'total_loss': 0.8166}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.005, Elapsed time: 12.01
2024-07-28 04:22:42 - [34m[1mLOGS   [0m - Epoch:  47 [   13455/10000000], loss: {'segmentation': 0.1107, 'neural_augmentation': 0.7081, 'total_loss': 0.8188}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 22.93
2024-07-28 04:22:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'segmentation': 0.1108, 'neural_augmentation': 0.7062, 'total_loss': 0.817}
2024-07-28 04:22:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'segmentation': 0.4423, 'neural_augmentation': 0.0, 'total_loss': 0.4423} || iou=72.8187
2024-07-28 04:22:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:22:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:22:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 13536 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_47_iter_13536.pt
2024-07-28 04:22:57 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 13536 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_47_iter_13536.pt
[31m===========================================================================[0m
2024-07-28 04:22:59 - [32m[1mINFO   [0m - Training epoch 48
2024-07-28 04:23:00 - [34m[1mLOGS   [0m - Epoch:  48 [   13537/10000000], loss: {'segmentation': 0.1126, 'neural_augmentation': 0.7036, 'total_loss': 0.8161}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.453, Elapsed time:  0.58
2024-07-28 04:23:11 - [34m[1mLOGS   [0m - Epoch:  48 [   13637/10000000], loss: {'segmentation': 0.1099, 'neural_augmentation': 0.7176, 'total_loss': 0.8275}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.005, Elapsed time: 11.68
2024-07-28 04:23:22 - [34m[1mLOGS   [0m - Epoch:  48 [   13737/10000000], loss: {'segmentation': 0.1101, 'neural_augmentation': 0.7184, 'total_loss': 0.8285}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.002, Elapsed time: 22.63
2024-07-28 04:23:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'segmentation': 0.1099, 'neural_augmentation': 0.7158, 'total_loss': 0.8257}
2024-07-28 04:23:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'segmentation': 0.4403, 'neural_augmentation': 0.0, 'total_loss': 0.4403} || iou=72.9096
2024-07-28 04:23:35 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:23:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:23:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 13818 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_48_iter_13818.pt
2024-07-28 04:23:38 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 13818 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_48_iter_13818.pt
[31m===========================================================================[0m
2024-07-28 04:23:40 - [32m[1mINFO   [0m - Training epoch 49
2024-07-28 04:23:40 - [34m[1mLOGS   [0m - Epoch:  49 [   13819/10000000], loss: {'segmentation': 0.1126, 'neural_augmentation': 0.7237, 'total_loss': 0.8363}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.253, Elapsed time:  0.39
2024-07-28 04:23:51 - [34m[1mLOGS   [0m - Epoch:  49 [   13919/10000000], loss: {'segmentation': 0.108, 'neural_augmentation': 0.7109, 'total_loss': 0.8189}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.003, Elapsed time: 11.42
2024-07-28 04:24:02 - [34m[1mLOGS   [0m - Epoch:  49 [   14019/10000000], loss: {'segmentation': 0.1095, 'neural_augmentation': 0.7184, 'total_loss': 0.8279}, LR: [3e-06, 3e-06, 3e-06, 3e-06], Avg. batch load time: 0.001, Elapsed time: 22.41
2024-07-28 04:24:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'segmentation': 0.1095, 'neural_augmentation': 0.7162, 'total_loss': 0.8258}
2024-07-28 04:24:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'segmentation': 0.448, 'neural_augmentation': 0.0, 'total_loss': 0.448} || iou=73.0979
2024-07-28 04:24:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_last.pt
2024-07-28 04:24:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_last.pt
2024-07-28 04:24:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 14100 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/training_checkpoint_epoch_49_iter_14100.pt
2024-07-28 04:24:18 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 14100 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_dci/19_uec_224/train/checkpoint_epoch_49_iter_14100.pt
2024-07-28 04:24:18 - [34m[1mLOGS   [0m - Training took 00:40:15.81
