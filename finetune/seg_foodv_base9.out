nohup: ignoring input
2024-08-01 07:13:50 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-08-01 07:13:51 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-01 07:13:51 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-01 07:13:51 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): Foodv(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-08-01 07:13:51 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
2024-08-01 07:13:51 - [33m[1mWARNING[0m - Unable to compute FLOPs using FVCore. Please check:
(WARNING)Traceback (most recent call last):
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/base_model.py", line 268, in info
(WARNING)    print(flop_count_table(flop_analyzer))
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/print_model_statistics.py", line 632, in flop_count_table
(WARNING)    stats = {params_header: params, flops_header: flops.by_module()}
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 291, in by_module
(WARNING)    stats = self._analyze()
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 551, in _analyze
(WARNING)    graph = _get_scoped_trace_graph(self._model, self._inputs, self._aliases)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 176, in _get_scoped_trace_graph
(WARNING)    graph, _ = _get_trace_graph(module, inputs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 1296, in _get_trace_graph
(WARNING)    outs = ONNXTracedModule(
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
(WARNING)    return self._call_impl(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
(WARNING)    return forward_call(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 138, in forward
(WARNING)    graph, out = torch._C._create_graph_by_tracing(
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 129, in wrapper
(WARNING)    outs.append(self.inner(*trace_inputs))
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
(WARNING)    return self._call_impl(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
(WARNING)    result = forward_call(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _slow_forward
(WARNING)    result = self.forward(*input, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/segmentation/enc_dec.py", line 99, in forward
(WARNING)    enc_end_points: Dict = self.encoder.extract_end_points_all(
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/classification/foodv.py", line 963, in extract_end_points_all
(WARNING)    _, out_dict_forward = self.forward_features_dense_connector(x)
(WARNING)ValueError: too many values to unpack (expected 2)
(WARNING)
[31m=================================================================[0m
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Available GPUs: 4
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Setting --ddp.world-size the same as the number of available gpus.
2024-08-01 07:13:51 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results_base_dci/9_seg_224/train
2024-08-01 07:13:54 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40011
2024-08-01 07:13:57 - [34m[1mLOGS   [0m - Training dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=True 
	num_samples=4983
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			RandomHorizontalFlip(p=0.5), 
			RandomCrop(size=(h=224, w=224), seg_class_max_ratio=0.75, seg_fill=0), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-01 07:13:57 - [34m[1mLOGS   [0m - Validation dataset details are given below
FoodsegDataset(
	root=/ML-A100/team/mm/models/FoodSeg103 
	is_training=False 
	num_samples=2135
	transforms=Compose(
			Resize(size=[224, 224], interpolation=bicubic, maintain_aspect_ratio=False), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
)
2024-08-01 07:13:57 - [34m[1mLOGS   [0m - Training sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=8
)
2024-08-01 07:13:57 - [34m[1mLOGS   [0m - Validation sampler details: BatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	base_im_size=(h=224, w=224)
	base_batch_size=4
)
2024-08-01 07:13:57 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-08-01 07:14:00 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base_dci/train/checkpoint_epoch_9_iter_79060.pt
2024-08-01 07:14:00 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-01 07:14:00 - [32m[1mINFO   [0m - Trainable parameters: ['aspp.aspp_layer.convs.0.block.conv.weight', 'aspp.aspp_layer.convs.0.block.norm.weight', 'aspp.aspp_layer.convs.0.block.norm.bias', 'aspp.aspp_layer.convs.1.block.conv.weight', 'aspp.aspp_layer.convs.1.block.norm.weight', 'aspp.aspp_layer.convs.1.block.norm.bias', 'aspp.aspp_layer.convs.2.block.conv.weight', 'aspp.aspp_layer.convs.2.block.norm.weight', 'aspp.aspp_layer.convs.2.block.norm.bias', 'aspp.aspp_layer.convs.3.block.conv.weight', 'aspp.aspp_layer.convs.3.block.norm.weight', 'aspp.aspp_layer.convs.3.block.norm.bias', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'aspp.aspp_layer.project.block.conv.weight', 'aspp.aspp_layer.project.block.norm.weight', 'aspp.aspp_layer.project.block.norm.bias', 'classifier.block.conv.weight', 'classifier.block.conv.bias']
2024-08-01 07:14:00 - [32m[1mINFO   [0m - Trainable parameters: ['encoder.pos_embed', 'encoder.neural_augmentor.brightness._low', 'encoder.neural_augmentor.brightness._high', 'encoder.neural_augmentor.contrast._low', 'encoder.neural_augmentor.contrast._high', 'encoder.neural_augmentor.noise._low', 'encoder.neural_augmentor.noise._high', 'encoder.patch_embed.backbone.stem.conv1.weight', 'encoder.patch_embed.backbone.stem.conv1.bias', 'encoder.patch_embed.backbone.stem.norm1.weight', 'encoder.patch_embed.backbone.stem.norm1.bias', 'encoder.patch_embed.backbone.stem.conv2.weight', 'encoder.patch_embed.backbone.stem.conv2.bias', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.0.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'encoder.patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.0.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.1.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.2.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.weight', 'encoder.patch_embed.backbone.stages.1.3.pre_norm.bias', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'encoder.patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'encoder.patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'encoder.patch_embed.backbone.pool.proj.weight', 'encoder.patch_embed.backbone.pool.proj.bias', 'encoder.patch_embed.backbone.pool.norm.weight', 'encoder.patch_embed.backbone.pool.norm.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.norm.weight', 'encoder.blocks.0.mlp.norm.bias', 'encoder.blocks.0.mlp.w0.weight', 'encoder.blocks.0.mlp.w0.bias', 'encoder.blocks.0.mlp.w1.weight', 'encoder.blocks.0.mlp.w1.bias', 'encoder.blocks.0.mlp.w2.weight', 'encoder.blocks.0.mlp.w2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.norm.weight', 'encoder.blocks.1.mlp.norm.bias', 'encoder.blocks.1.mlp.w0.weight', 'encoder.blocks.1.mlp.w0.bias', 'encoder.blocks.1.mlp.w1.weight', 'encoder.blocks.1.mlp.w1.bias', 'encoder.blocks.1.mlp.w2.weight', 'encoder.blocks.1.mlp.w2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.norm.weight', 'encoder.blocks.2.mlp.norm.bias', 'encoder.blocks.2.mlp.w0.weight', 'encoder.blocks.2.mlp.w0.bias', 'encoder.blocks.2.mlp.w1.weight', 'encoder.blocks.2.mlp.w1.bias', 'encoder.blocks.2.mlp.w2.weight', 'encoder.blocks.2.mlp.w2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.norm.weight', 'encoder.blocks.3.mlp.norm.bias', 'encoder.blocks.3.mlp.w0.weight', 'encoder.blocks.3.mlp.w0.bias', 'encoder.blocks.3.mlp.w1.weight', 'encoder.blocks.3.mlp.w1.bias', 'encoder.blocks.3.mlp.w2.weight', 'encoder.blocks.3.mlp.w2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.norm.weight', 'encoder.blocks.4.mlp.norm.bias', 'encoder.blocks.4.mlp.w0.weight', 'encoder.blocks.4.mlp.w0.bias', 'encoder.blocks.4.mlp.w1.weight', 'encoder.blocks.4.mlp.w1.bias', 'encoder.blocks.4.mlp.w2.weight', 'encoder.blocks.4.mlp.w2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.norm.weight', 'encoder.blocks.5.mlp.norm.bias', 'encoder.blocks.5.mlp.w0.weight', 'encoder.blocks.5.mlp.w0.bias', 'encoder.blocks.5.mlp.w1.weight', 'encoder.blocks.5.mlp.w1.bias', 'encoder.blocks.5.mlp.w2.weight', 'encoder.blocks.5.mlp.w2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.norm.weight', 'encoder.blocks.6.mlp.norm.bias', 'encoder.blocks.6.mlp.w0.weight', 'encoder.blocks.6.mlp.w0.bias', 'encoder.blocks.6.mlp.w1.weight', 'encoder.blocks.6.mlp.w1.bias', 'encoder.blocks.6.mlp.w2.weight', 'encoder.blocks.6.mlp.w2.bias', 'encoder.pool.proj.weight', 'encoder.pool.proj.bias', 'encoder.pool.norm.weight', 'encoder.pool.norm.bias', 'encoder.blocks1.0.norm1.weight', 'encoder.blocks1.0.norm1.bias', 'encoder.blocks1.0.attn.qkv.weight', 'encoder.blocks1.0.attn.qkv.bias', 'encoder.blocks1.0.attn.proj.weight', 'encoder.blocks1.0.attn.proj.bias', 'encoder.blocks1.0.norm2.weight', 'encoder.blocks1.0.norm2.bias', 'encoder.blocks1.0.mlp.norm.weight', 'encoder.blocks1.0.mlp.norm.bias', 'encoder.blocks1.0.mlp.w0.weight', 'encoder.blocks1.0.mlp.w0.bias', 'encoder.blocks1.0.mlp.w1.weight', 'encoder.blocks1.0.mlp.w1.bias', 'encoder.blocks1.0.mlp.w2.weight', 'encoder.blocks1.0.mlp.w2.bias', 'encoder.blocks1.1.norm1.weight', 'encoder.blocks1.1.norm1.bias', 'encoder.blocks1.1.attn.qkv.weight', 'encoder.blocks1.1.attn.qkv.bias', 'encoder.blocks1.1.attn.proj.weight', 'encoder.blocks1.1.attn.proj.bias', 'encoder.blocks1.1.norm2.weight', 'encoder.blocks1.1.norm2.bias', 'encoder.blocks1.1.mlp.norm.weight', 'encoder.blocks1.1.mlp.norm.bias', 'encoder.blocks1.1.mlp.w0.weight', 'encoder.blocks1.1.mlp.w0.bias', 'encoder.blocks1.1.mlp.w1.weight', 'encoder.blocks1.1.mlp.w1.bias', 'encoder.blocks1.1.mlp.w2.weight', 'encoder.blocks1.1.mlp.w2.bias', 'encoder.blocks1.2.norm1.weight', 'encoder.blocks1.2.norm1.bias', 'encoder.blocks1.2.attn.qkv.weight', 'encoder.blocks1.2.attn.qkv.bias', 'encoder.blocks1.2.attn.proj.weight', 'encoder.blocks1.2.attn.proj.bias', 'encoder.blocks1.2.norm2.weight', 'encoder.blocks1.2.norm2.bias', 'encoder.blocks1.2.mlp.norm.weight', 'encoder.blocks1.2.mlp.norm.bias', 'encoder.blocks1.2.mlp.w0.weight', 'encoder.blocks1.2.mlp.w0.bias', 'encoder.blocks1.2.mlp.w1.weight', 'encoder.blocks1.2.mlp.w1.bias', 'encoder.blocks1.2.mlp.w2.weight', 'encoder.blocks1.2.mlp.w2.bias', 'encoder.blocks1.3.norm1.weight', 'encoder.blocks1.3.norm1.bias', 'encoder.blocks1.3.attn.qkv.weight', 'encoder.blocks1.3.attn.qkv.bias', 'encoder.blocks1.3.attn.proj.weight', 'encoder.blocks1.3.attn.proj.bias', 'encoder.blocks1.3.norm2.weight', 'encoder.blocks1.3.norm2.bias', 'encoder.blocks1.3.mlp.norm.weight', 'encoder.blocks1.3.mlp.norm.bias', 'encoder.blocks1.3.mlp.w0.weight', 'encoder.blocks1.3.mlp.w0.bias', 'encoder.blocks1.3.mlp.w1.weight', 'encoder.blocks1.3.mlp.w1.bias', 'encoder.blocks1.3.mlp.w2.weight', 'encoder.blocks1.3.mlp.w2.bias', 'encoder.blocks1.4.norm1.weight', 'encoder.blocks1.4.norm1.bias', 'encoder.blocks1.4.attn.qkv.weight', 'encoder.blocks1.4.attn.qkv.bias', 'encoder.blocks1.4.attn.proj.weight', 'encoder.blocks1.4.attn.proj.bias', 'encoder.blocks1.4.norm2.weight', 'encoder.blocks1.4.norm2.bias', 'encoder.blocks1.4.mlp.norm.weight', 'encoder.blocks1.4.mlp.norm.bias', 'encoder.blocks1.4.mlp.w0.weight', 'encoder.blocks1.4.mlp.w0.bias', 'encoder.blocks1.4.mlp.w1.weight', 'encoder.blocks1.4.mlp.w1.bias', 'encoder.blocks1.4.mlp.w2.weight', 'encoder.blocks1.4.mlp.w2.bias', 'encoder.blocks1.5.norm1.weight', 'encoder.blocks1.5.norm1.bias', 'encoder.blocks1.5.attn.qkv.weight', 'encoder.blocks1.5.attn.qkv.bias', 'encoder.blocks1.5.attn.proj.weight', 'encoder.blocks1.5.attn.proj.bias', 'encoder.blocks1.5.norm2.weight', 'encoder.blocks1.5.norm2.bias', 'encoder.blocks1.5.mlp.norm.weight', 'encoder.blocks1.5.mlp.norm.bias', 'encoder.blocks1.5.mlp.w0.weight', 'encoder.blocks1.5.mlp.w0.bias', 'encoder.blocks1.5.mlp.w1.weight', 'encoder.blocks1.5.mlp.w1.bias', 'encoder.blocks1.5.mlp.w2.weight', 'encoder.blocks1.5.mlp.w2.bias', 'encoder.blocks1.6.norm1.weight', 'encoder.blocks1.6.norm1.bias', 'encoder.blocks1.6.attn.qkv.weight', 'encoder.blocks1.6.attn.qkv.bias', 'encoder.blocks1.6.attn.proj.weight', 'encoder.blocks1.6.attn.proj.bias', 'encoder.blocks1.6.norm2.weight', 'encoder.blocks1.6.norm2.bias', 'encoder.blocks1.6.mlp.norm.weight', 'encoder.blocks1.6.mlp.norm.bias', 'encoder.blocks1.6.mlp.w0.weight', 'encoder.blocks1.6.mlp.w0.bias', 'encoder.blocks1.6.mlp.w1.weight', 'encoder.blocks1.6.mlp.w1.bias', 'encoder.blocks1.6.mlp.w2.weight', 'encoder.blocks1.6.mlp.w2.bias', 'encoder.mlp.0.weight', 'encoder.mlp.0.bias', 'encoder.mlp.2.weight', 'encoder.mlp.2.bias', 'encoder.fc_norm.weight', 'encoder.fc_norm.bias', 'seg_head.aspp.aspp_layer.convs.0.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.0.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.1.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.2.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.2.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.3.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.3.block.norm.bias', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.conv.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.weight', 'seg_head.aspp.aspp_layer.convs.4.aspp_pool.conv_1x1.block.norm.bias', 'seg_head.aspp.aspp_layer.project.block.conv.weight', 'seg_head.aspp.aspp_layer.project.block.norm.weight', 'seg_head.aspp.aspp_layer.project.block.norm.bias', 'seg_head.classifier.block.conv.weight', 'seg_head.classifier.block.conv.bias']
2024-08-01 07:14:00 - [34m[1mLOGS   [0m - [36mModel[0m
SegEncoderDecoder(
  (encoder): Foodv(
    (neural_augmentor): DistributionNeuralAugmentor(
    	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
    	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
    (patch_embed): HybridEmbed(
      (backbone): MbConvStages(
        (stem): Stem(
          (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm1): LayerNormAct2d(
            (128,), eps=1e-06, elementwise_affine=True
            (drop): Identity()
            (act): GELU()
          )
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (stages): ModuleList(
          (0): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Identity()
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
          (1): Sequential(
            (0): MbConvLNBlock(
              (shortcut): Downsample2d(
                (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
                (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (pre_norm): LayerNormAct2d(
                (128,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (1): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (2): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
            (3): MbConvLNBlock(
              (shortcut): Identity()
              (pre_norm): LayerNormAct2d(
                (256,), eps=1e-06, elementwise_affine=True
                (drop): Identity()
                (act): Identity()
              )
              (down): Identity()
              (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
              (act1): GELU()
              (act2): GELU()
              (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
              (drop_path): Identity()
            )
          )
        )
        (pool): StridedConv(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (proj): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=512, out_features=1024, bias=True)
          (w1): Linear(in_features=512, out_features=1024, bias=True)
          (w2): Linear(in_features=1024, out_features=512, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (pool): StridedConv(
      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
    )
    (blocks1): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): GeGluMlp(
          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (act): GELU(approximate='none')
          (w0): Linear(in_features=1024, out_features=2048, bias=True)
          (w1): Linear(in_features=1024, out_features=2048, bias=True)
          (w2): Linear(in_features=2048, out_features=1024, bias=True)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (mlp): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (classifier_drop): Dropout(p=0.0, inplace=False)
    (classifier): None
  )
  (seg_head): DeeplabV3(
    (upsample_seg_out): UpSample(scale_factor=32.0, mode='bilinear')
    (aspp): Sequential(
      (aspp_layer): ASPP(in_channels=1024, out_channels=224, atrous_rates=[12, 24, 36], is_aspp_sep=False, dropout=0.1)
    )
    (classifier): Conv2d(224, 104, kernel_size=(1, 1), stride=(1, 1))
  )
)
[31m=================================================================[0m
                  SegEncoderDecoder Summary
[31m=================================================================[0m
Total parameters     =  109.316 M
Total trainable parameters =  109.316 M

2024-08-01 07:14:01 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
2024-08-01 07:14:01 - [33m[1mWARNING[0m - Unable to compute FLOPs using FVCore. Please check:
(WARNING)Traceback (most recent call last):
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/base_model.py", line 268, in info
(WARNING)    print(flop_count_table(flop_analyzer))
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/print_model_statistics.py", line 632, in flop_count_table
(WARNING)    stats = {params_header: params, flops_header: flops.by_module()}
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 291, in by_module
(WARNING)    stats = self._analyze()
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 551, in _analyze
(WARNING)    graph = _get_scoped_trace_graph(self._model, self._inputs, self._aliases)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/fvcore/nn/jit_analysis.py", line 176, in _get_scoped_trace_graph
(WARNING)    graph, _ = _get_trace_graph(module, inputs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 1296, in _get_trace_graph
(WARNING)    outs = ONNXTracedModule(
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
(WARNING)    return self._call_impl(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
(WARNING)    return forward_call(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 138, in forward
(WARNING)    graph, out = torch._C._create_graph_by_tracing(
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/jit/_trace.py", line 129, in wrapper
(WARNING)    outs.append(self.inner(*trace_inputs))
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
(WARNING)    return self._call_impl(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
(WARNING)    result = forward_call(*args, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _slow_forward
(WARNING)    result = self.forward(*input, **kwargs)
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/segmentation/enc_dec.py", line 99, in forward
(WARNING)    enc_end_points: Dict = self.encoder.extract_end_points_all(
(WARNING)  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/classification/foodv.py", line 963, in extract_end_points_all
(WARNING)    _, out_dict_forward = self.forward_features_dense_connector(x)
(WARNING)ValueError: too many values to unpack (expected 2)
(WARNING)
[31m=================================================================[0m
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	SegCrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.0  aux_weight=0.4 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - Max. epochs for training: 30
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=30
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-08-01 07:14:01 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results_base_dci/9_seg_224/train/training_checkpoint_last.pt'
2024-08-01 07:14:01 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_dci/9_seg_224/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-01 07:14:03 - [32m[1mINFO   [0m - Training epoch 0
2024-08-01 07:13:55 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40011
base
dci
2024-08-01 07:13:55 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40011
base
dci
2024-08-01 07:13:55 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40011
base
dci
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
2024-08-01 07:16:47 - [34m[1mLOGS   [0m - Exception occurred that interrupted the training:
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 541, in run
    train_loss, train_ckpt_metric = self.train_epoch(epoch)  # 训练入口
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 313, in train_epoch
    pred_label = self.model(samples)  # 看它是怎么prediction的, model是vit，此时进行forward计算,samples为[256,3,224,224],但选择的图片大小为256
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/segmentation/enc_dec.py", line 99, in forward
    enc_end_points: Dict = self.encoder.extract_end_points_all(
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/classification/foodv.py", line 963, in extract_end_points_all
    _, out_dict_forward = self.forward_features_dense_connector(x)
ValueError: too many values to unpack (expected 2)

2024-08-01 07:16:47 - [34m[1mLOGS   [0m - Training took 00:02:45.98
2024-08-01 07:16:50 - [34m[1mLOGS   [0m - Exception occurred that interrupted the training:
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 541, in run
    train_loss, train_ckpt_metric = self.train_epoch(epoch)  # 训练入口
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 313, in train_epoch
    pred_label = self.model(samples)  # 看它是怎么prediction的, model是vit，此时进行forward计算,samples为[256,3,224,224],但选择的图片大小为256
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/segmentation/enc_dec.py", line 99, in forward
    enc_end_points: Dict = self.encoder.extract_end_points_all(
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/classification/foodv.py", line 963, in extract_end_points_all
    _, out_dict_forward = self.forward_features_dense_connector(x)
ValueError: too many values to unpack (expected 2)

Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/finetune/../corenet/cli/main_train.py", line 42, in <module>
    main_worker()
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/finetune/../corenet/cli/main_train.py", line 37, in main_worker
    launcher(callback)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/train_eval_pipelines/default_train_eval.py", line 312, in <lambda>
    return lambda callback: torch.multiprocessing.spawn(
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 241, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 158, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
    fn(i, *args)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/train_eval_pipelines/default_train_eval.py", line 433, in _launcher_distributed_spawn_fn
    callback(train_eval_pipeline)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/cli/main_train.py", line 28, in callback
    train_eval_pipeline.training_engine.run(train_sampler=train_sampler)  # 分两步，先init了training_engine,然后调用default_trainer.py里面的run
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 630, in run
    raise e
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 541, in run
    train_loss, train_ckpt_metric = self.train_epoch(epoch)  # 训练入口
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/engine/default_trainer.py", line 313, in train_epoch
    pred_label = self.model(samples)  # 看它是怎么prediction的, model是vit，此时进行forward计算,samples为[256,3,224,224],但选择的图片大小为256
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/segmentation/enc_dec.py", line 99, in forward
    enc_end_points: Dict = self.encoder.extract_end_points_all(
  File "/ML-A800/home/guoshuyue/madehua/code/corenet/corenet/modeling/models/classification/foodv.py", line 963, in extract_end_points_all
    _, out_dict_forward = self.forward_features_dense_connector(x)
ValueError: too many values to unpack (expected 2)

/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 400 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
