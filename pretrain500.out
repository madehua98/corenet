nohup: ignoring input
2024-07-15 17:19:32 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
small
2024-07-15 17:19:33 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=384, out_features=512, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=6743, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   46.446 M
Total trainable parameters =   46.446 M

2024-07-15 17:19:33 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 46.446M                | 7.461G     |
|  pos_embed                           |  (1, 1, 384)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  1.077M                |  1.881G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.638G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    28.312M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    5.243M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.604G  |
|   patch_embed.backbone.stages        |   0.595M               |   1.13G    |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.495G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.635G  |
|   patch_embed.backbone.pool          |   0.443M               |   0.114G   |
|    patch_embed.backbone.pool.proj    |    0.443M              |    0.113G  |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.655M  |
|  blocks                              |  14.196M               |  3.632G    |
|   blocks.0                           |   1.774M               |   0.454G   |
|    blocks.0.norm1                    |    0.768K              |    0.492M  |
|    blocks.0.attn                     |    0.591M              |    0.151G  |
|    blocks.0.norm2                    |    0.768K              |    0.492M  |
|    blocks.0.mlp                      |    1.182M              |    0.302G  |
|   blocks.1                           |   1.774M               |   0.454G   |
|    blocks.1.norm1                    |    0.768K              |    0.492M  |
|    blocks.1.attn                     |    0.591M              |    0.151G  |
|    blocks.1.norm2                    |    0.768K              |    0.492M  |
|    blocks.1.mlp                      |    1.182M              |    0.302G  |
|   blocks.2                           |   1.774M               |   0.454G   |
|    blocks.2.norm1                    |    0.768K              |    0.492M  |
|    blocks.2.attn                     |    0.591M              |    0.151G  |
|    blocks.2.norm2                    |    0.768K              |    0.492M  |
|    blocks.2.mlp                      |    1.182M              |    0.302G  |
|   blocks.3                           |   1.774M               |   0.454G   |
|    blocks.3.norm1                    |    0.768K              |    0.492M  |
|    blocks.3.attn                     |    0.591M              |    0.151G  |
|    blocks.3.norm2                    |    0.768K              |    0.492M  |
|    blocks.3.mlp                      |    1.182M              |    0.302G  |
|   blocks.4                           |   1.774M               |   0.454G   |
|    blocks.4.norm1                    |    0.768K              |    0.492M  |
|    blocks.4.attn                     |    0.591M              |    0.151G  |
|    blocks.4.norm2                    |    0.768K              |    0.492M  |
|    blocks.4.mlp                      |    1.182M              |    0.302G  |
|   blocks.5                           |   1.774M               |   0.454G   |
|    blocks.5.norm1                    |    0.768K              |    0.492M  |
|    blocks.5.attn                     |    0.591M              |    0.151G  |
|    blocks.5.norm2                    |    0.768K              |    0.492M  |
|    blocks.5.mlp                      |    1.182M              |    0.302G  |
|   blocks.6                           |   1.774M               |   0.454G   |
|    blocks.6.norm1                    |    0.768K              |    0.492M  |
|    blocks.6.attn                     |    0.591M              |    0.151G  |
|    blocks.6.norm2                    |    0.768K              |    0.492M  |
|    blocks.6.mlp                      |    1.182M              |    0.302G  |
|   blocks.7                           |   1.774M               |   0.454G   |
|    blocks.7.norm1                    |    0.768K              |    0.492M  |
|    blocks.7.attn                     |    0.591M              |    0.151G  |
|    blocks.7.norm2                    |    0.768K              |    0.492M  |
|    blocks.7.mlp                      |    1.182M              |    0.302G  |
|  pool                                |  1.771M                |  0.114G    |
|   pool.proj                          |   1.77M                |   0.113G   |
|    pool.proj.weight                  |    (512, 384, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.768K               |   0.492M   |
|    pool.norm.weight                  |    (384,)              |            |
|    pool.norm.bias                    |    (384,)              |            |
|  blocks1                             |  25.219M               |  1.613G    |
|   blocks1.0                          |   3.152M               |   0.202G   |
|    blocks1.0.norm1                   |    1.024K              |    0.164M  |
|    blocks1.0.attn                    |    1.051M              |    67.109M |
|    blocks1.0.norm2                   |    1.024K              |    0.164M  |
|    blocks1.0.mlp                     |    2.1M                |    0.134G  |
|   blocks1.1                          |   3.152M               |   0.202G   |
|    blocks1.1.norm1                   |    1.024K              |    0.164M  |
|    blocks1.1.attn                    |    1.051M              |    67.109M |
|    blocks1.1.norm2                   |    1.024K              |    0.164M  |
|    blocks1.1.mlp                     |    2.1M                |    0.134G  |
|   blocks1.2                          |   3.152M               |   0.202G   |
|    blocks1.2.norm1                   |    1.024K              |    0.164M  |
|    blocks1.2.attn                    |    1.051M              |    67.109M |
|    blocks1.2.norm2                   |    1.024K              |    0.164M  |
|    blocks1.2.mlp                     |    2.1M                |    0.134G  |
|   blocks1.3                          |   3.152M               |   0.202G   |
|    blocks1.3.norm1                   |    1.024K              |    0.164M  |
|    blocks1.3.attn                    |    1.051M              |    67.109M |
|    blocks1.3.norm2                   |    1.024K              |    0.164M  |
|    blocks1.3.mlp                     |    2.1M                |    0.134G  |
|   blocks1.4                          |   3.152M               |   0.202G   |
|    blocks1.4.norm1                   |    1.024K              |    0.164M  |
|    blocks1.4.attn                    |    1.051M              |    67.109M |
|    blocks1.4.norm2                   |    1.024K              |    0.164M  |
|    blocks1.4.mlp                     |    2.1M                |    0.134G  |
|   blocks1.5                          |   3.152M               |   0.202G   |
|    blocks1.5.norm1                   |    1.024K              |    0.164M  |
|    blocks1.5.attn                    |    1.051M              |    67.109M |
|    blocks1.5.norm2                   |    1.024K              |    0.164M  |
|    blocks1.5.mlp                     |    2.1M                |    0.134G  |
|   blocks1.6                          |   3.152M               |   0.202G   |
|    blocks1.6.norm1                   |    1.024K              |    0.164M  |
|    blocks1.6.attn                    |    1.051M              |    67.109M |
|    blocks1.6.norm2                   |    1.024K              |    0.164M  |
|    blocks1.6.mlp                     |    2.1M                |    0.134G  |
|   blocks1.7                          |   3.152M               |   0.202G   |
|    blocks1.7.norm1                   |    1.024K              |    0.164M  |
|    blocks1.7.attn                    |    1.051M              |    67.109M |
|    blocks1.7.norm2                   |    1.024K              |    0.164M  |
|    blocks1.7.mlp                     |    2.1M                |    0.134G  |
|  block_to_block1                     |  0.197M                |  50.332M   |
|   block_to_block1.weight             |   (512, 384)           |            |
|   block_to_block1.bias               |   (512,)               |            |
|  mlp                                 |  0.525M                |  0.168G    |
|   mlp.0                              |   0.263M               |   83.886M  |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   83.886M  |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  3.459M                |  3.452M    |
|   classifier.weight                  |   (6743, 512)          |            |
|   classifier.bias                    |   (6743,)              |            |
2024-07-15 17:19:33 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-15 17:19:33 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.5.ls1', 'blocks.3.ls2', 'blocks1.5.attn.q_norm', 'blocks.4.mlp.norm', 'blocks1.0.attn.q_norm', 'blocks.5.attn.q_norm', 'blocks1.6.ls1', 'patch_embed.backbone.stages.0.0.down', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.4.drop_path2', 'blocks1.4.attn.attn_drop', 'blocks1.2.mlp.norm', 'blocks1.6.ls2', 'neural_augmentor.brightness', 'blocks1.7.attn.q_norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'patch_embed.backbone.stages.0.1.down', 'neural_augmentor.brightness.max_fn', 'patch_embed.backbone.stages.1.0.down', 'blocks.3.attn.attn_drop', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.1.ls2', 'blocks.1.drop_path2', 'patch_embed.backbone.stages.1.0.drop_path', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.0.drop_path1', 'blocks.0.drop_path2', 'blocks.6.attn.attn_drop', 'blocks1.6.attn.attn_drop', 'blocks.2.attn.attn_drop', 'blocks.6.ls1', 'blocks1.7.attn.attn_drop', 'blocks1.7.drop_path1', 'blocks1.2.drop_path1', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stages.0.1.drop_path', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks1.4.drop_path2', 'blocks1.7.ls2', 'patch_embed.backbone.stages.0.0.drop_path', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.2.ls2', 'blocks1.2.ls2', 'blocks.5.drop_path1', 'blocks1.3.drop_path1', 'blocks.5.ls2', 'blocks1.4.mlp.norm', 'neural_augmentor.noise.max_fn', 'blocks1.6.attn.k_norm', 'blocks.0.attn.attn_drop', 'blocks1.1.attn.attn_drop', 'patch_embed.backbone.stages.1.1.down', 'neural_augmentor', 'blocks1.5.ls1', 'blocks1.1.drop_path1', 'blocks1.2.attn.q_norm', 'blocks1.4.attn.q_norm', 'blocks1.0.attn.k_norm', 'blocks1.3.drop_path2', 'blocks1.7.ls1', 'blocks1.1.mlp.norm', 'blocks.0.ls2', 'patch_embed.proj', 'blocks1.6.drop_path1', 'neural_augmentor.contrast.min_fn', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.5.attn.k_norm', 'blocks.6.drop_path1', 'blocks.6.attn.k_norm', 'blocks.0.ls1', 'blocks1.3.ls1', 'blocks1.7.attn.k_norm', 'blocks.7.drop_path1', 'patch_embed.backbone.stem.norm1.drop', 'blocks.2.drop_path1', 'blocks.2.attn.k_norm', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.4.ls2', 'blocks.7.attn.q_norm', 'blocks1.6.mlp.norm', 'blocks1.0.drop_path2', 'blocks1.2.ls1', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks.5.mlp.norm', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks.4.attn.q_norm', 'blocks.4.attn.attn_drop', 'blocks.0.attn.k_norm', 'neural_augmentor.contrast', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.4.drop_path1', 'blocks1.5.attn.k_norm', 'blocks1.4.ls2', 'blocks.2.ls1', 'blocks1.1.attn.q_norm', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.6.ls2', 'blocks.1.ls1', 'blocks.7.ls1', 'blocks.1.attn.q_norm', 'blocks.6.drop_path2', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks1.5.attn.attn_drop', 'blocks.1.attn.attn_drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.6.attn.q_norm', 'blocks.4.ls1', 'blocks1.3.ls2', 'blocks1.7.drop_path2', 'blocks.2.drop_path2', 'blocks.3.drop_path1', 'blocks1.3.attn.q_norm', 'patch_drop', 'blocks.5.drop_path2', 'blocks.4.drop_path1', 'blocks1.5.drop_path2', 'blocks.1.mlp.norm', 'blocks1.5.drop_path1', 'blocks1.6.drop_path2', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.7.drop_path2', 'blocks.1.attn.k_norm', 'blocks.3.drop_path2', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.7.mlp.norm', 'blocks.1.drop_path1', 'blocks.2.mlp.norm', 'blocks.7.attn.k_norm', 'blocks1.4.ls1', 'blocks.0.drop_path1', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'patch_embed.backbone.stages.1.3.down', 'blocks.7.attn.attn_drop', 'blocks.7.ls2', 'blocks1.0.attn.attn_drop', 'blocks.1.ls2', 'neural_augmentor.noise', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.3.mlp.norm', 'blocks.3.attn.q_norm', 'patch_embed.backbone.stages.1.2.down', 'blocks.3.attn.k_norm', 'blocks1.1.attn.k_norm', 'blocks.3.ls1', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.6.attn.q_norm', 'norm', 'norm_pre', 'blocks1.0.ls2', 'blocks1.5.mlp.norm', 'blocks1.3.attn.attn_drop', 'blocks.2.attn.q_norm', 'blocks1.1.ls1', 'blocks.0.attn.q_norm', 'neural_augmentor.brightness.min_fn', 'blocks.3.mlp.norm', 'blocks1.3.attn.k_norm', 'blocks1.2.drop_path2', 'blocks1.2.attn.k_norm', 'blocks.0.mlp.norm', 'blocks1.5.ls2', 'neural_augmentor.contrast.max_fn', 'blocks.6.mlp.norm', 'blocks.5.attn.attn_drop', 'blocks1.0.ls1', 'blocks1.7.mlp.norm', 'blocks1.0.mlp.norm', 'blocks1.2.attn.attn_drop', 'blocks1.1.drop_path2', 'blocks.4.attn.k_norm'}
2024-07-15 17:19:33 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - Available GPUs: 8
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-15 17:19:33 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results500_dci/train
2024-07-15 17:19:37 - [32m[1mINFO   [0m - distributed init (rank 5): tcp://localhost:40002
small
2024-07-15 17:19:37 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40002
small
2024-07-15 17:19:36 - [32m[1mINFO   [0m - distributed init (rank 4): tcp://localhost:40002
small
2024-07-15 17:19:36 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40002
2024-07-15 17:19:39 - [34m[1mLOGS   [0m - Training dataset details are given below
WordnetTaggedClassificationDataset(
	root= 
	is_training=True 
	num_samples=64290000
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	total_tar_files=6429
	max_files_per_tar=10000
	num_synsets=6743
)
2024-07-15 17:19:41 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=True
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=200
	 scales=[(128, 128, 612), (144, 144, 483), (160, 160, 392), (176, 176, 323), (192, 192, 272), (208, 208, 231), (224, 224, 200), (240, 240, 174), (256, 256, 153), (272, 272, 135), (288, 288, 120), (304, 304, 108), (320, 320, 98)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-15 17:19:41 - [34m[1mLOGS   [0m - Number of data workers: 64
small
2024-07-15 17:19:42 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-15 17:19:42 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=384, out_features=512, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=6743, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   46.446 M
Total trainable parameters =   46.446 M

2024-07-15 17:19:42 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-15 17:19:42 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 46.446M                | 7.461G     |
|  pos_embed                           |  (1, 1, 384)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  1.077M                |  1.881G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.638G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    28.312M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    5.243M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.604G  |
|   patch_embed.backbone.stages        |   0.595M               |   1.13G    |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.495G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.635G  |
|   patch_embed.backbone.pool          |   0.443M               |   0.114G   |
|    patch_embed.backbone.pool.proj    |    0.443M              |    0.113G  |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.655M  |
|  blocks                              |  14.196M               |  3.632G    |
|   blocks.0                           |   1.774M               |   0.454G   |
|    blocks.0.norm1                    |    0.768K              |    0.492M  |
|    blocks.0.attn                     |    0.591M              |    0.151G  |
|    blocks.0.norm2                    |    0.768K              |    0.492M  |
|    blocks.0.mlp                      |    1.182M              |    0.302G  |
|   blocks.1                           |   1.774M               |   0.454G   |
|    blocks.1.norm1                    |    0.768K              |    0.492M  |
|    blocks.1.attn                     |    0.591M              |    0.151G  |
|    blocks.1.norm2                    |    0.768K              |    0.492M  |
|    blocks.1.mlp                      |    1.182M              |    0.302G  |
|   blocks.2                           |   1.774M               |   0.454G   |
|    blocks.2.norm1                    |    0.768K              |    0.492M  |
|    blocks.2.attn                     |    0.591M              |    0.151G  |
|    blocks.2.norm2                    |    0.768K              |    0.492M  |
|    blocks.2.mlp                      |    1.182M              |    0.302G  |
|   blocks.3                           |   1.774M               |   0.454G   |
|    blocks.3.norm1                    |    0.768K              |    0.492M  |
|    blocks.3.attn                     |    0.591M              |    0.151G  |
|    blocks.3.norm2                    |    0.768K              |    0.492M  |
|    blocks.3.mlp                      |    1.182M              |    0.302G  |
|   blocks.4                           |   1.774M               |   0.454G   |
|    blocks.4.norm1                    |    0.768K              |    0.492M  |
|    blocks.4.attn                     |    0.591M              |    0.151G  |
|    blocks.4.norm2                    |    0.768K              |    0.492M  |
|    blocks.4.mlp                      |    1.182M              |    0.302G  |
|   blocks.5                           |   1.774M               |   0.454G   |
|    blocks.5.norm1                    |    0.768K              |    0.492M  |
|    blocks.5.attn                     |    0.591M              |    0.151G  |
|    blocks.5.norm2                    |    0.768K              |    0.492M  |
|    blocks.5.mlp                      |    1.182M              |    0.302G  |
|   blocks.6                           |   1.774M               |   0.454G   |
|    blocks.6.norm1                    |    0.768K              |    0.492M  |
|    blocks.6.attn                     |    0.591M              |    0.151G  |
|    blocks.6.norm2                    |    0.768K              |    0.492M  |
|    blocks.6.mlp                      |    1.182M              |    0.302G  |
|   blocks.7                           |   1.774M               |   0.454G   |
|    blocks.7.norm1                    |    0.768K              |    0.492M  |
|    blocks.7.attn                     |    0.591M              |    0.151G  |
|    blocks.7.norm2                    |    0.768K              |    0.492M  |
|    blocks.7.mlp                      |    1.182M              |    0.302G  |
|  pool                                |  1.771M                |  0.114G    |
|   pool.proj                          |   1.77M                |   0.113G   |
|    pool.proj.weight                  |    (512, 384, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.768K               |   0.492M   |
|    pool.norm.weight                  |    (384,)              |            |
|    pool.norm.bias                    |    (384,)              |            |
|  blocks1                             |  25.219M               |  1.613G    |
|   blocks1.0                          |   3.152M               |   0.202G   |
|    blocks1.0.norm1                   |    1.024K              |    0.164M  |
|    blocks1.0.attn                    |    1.051M              |    67.109M |
|    blocks1.0.norm2                   |    1.024K              |    0.164M  |
|    blocks1.0.mlp                     |    2.1M                |    0.134G  |
|   blocks1.1                          |   3.152M               |   0.202G   |
|    blocks1.1.norm1                   |    1.024K              |    0.164M  |
|    blocks1.1.attn                    |    1.051M              |    67.109M |
|    blocks1.1.norm2                   |    1.024K              |    0.164M  |
|    blocks1.1.mlp                     |    2.1M                |    0.134G  |
|   blocks1.2                          |   3.152M               |   0.202G   |
|    blocks1.2.norm1                   |    1.024K              |    0.164M  |
|    blocks1.2.attn                    |    1.051M              |    67.109M |
|    blocks1.2.norm2                   |    1.024K              |    0.164M  |
|    blocks1.2.mlp                     |    2.1M                |    0.134G  |
|   blocks1.3                          |   3.152M               |   0.202G   |
|    blocks1.3.norm1                   |    1.024K              |    0.164M  |
|    blocks1.3.attn                    |    1.051M              |    67.109M |
|    blocks1.3.norm2                   |    1.024K              |    0.164M  |
|    blocks1.3.mlp                     |    2.1M                |    0.134G  |
|   blocks1.4                          |   3.152M               |   0.202G   |
|    blocks1.4.norm1                   |    1.024K              |    0.164M  |
|    blocks1.4.attn                    |    1.051M              |    67.109M |
|    blocks1.4.norm2                   |    1.024K              |    0.164M  |
|    blocks1.4.mlp                     |    2.1M                |    0.134G  |
|   blocks1.5                          |   3.152M               |   0.202G   |
|    blocks1.5.norm1                   |    1.024K              |    0.164M  |
|    blocks1.5.attn                    |    1.051M              |    67.109M |
|    blocks1.5.norm2                   |    1.024K              |    0.164M  |
|    blocks1.5.mlp                     |    2.1M                |    0.134G  |
|   blocks1.6                          |   3.152M               |   0.202G   |
|    blocks1.6.norm1                   |    1.024K              |    0.164M  |
|    blocks1.6.attn                    |    1.051M              |    67.109M |
|    blocks1.6.norm2                   |    1.024K              |    0.164M  |
|    blocks1.6.mlp                     |    2.1M                |    0.134G  |
|   blocks1.7                          |   3.152M               |   0.202G   |
|    blocks1.7.norm1                   |    1.024K              |    0.164M  |
|    blocks1.7.attn                    |    1.051M              |    67.109M |
|    blocks1.7.norm2                   |    1.024K              |    0.164M  |
|    blocks1.7.mlp                     |    2.1M                |    0.134G  |
|  block_to_block1                     |  0.197M                |  50.332M   |
|   block_to_block1.weight             |   (512, 384)           |            |
|   block_to_block1.bias               |   (512,)               |            |
|  mlp                                 |  0.525M                |  0.168G    |
|   mlp.0                              |   0.263M               |   83.886M  |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   83.886M  |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  3.459M                |  3.452M    |
|   classifier.weight                  |   (6743, 512)          |            |
|   classifier.bias                    |   (6743,)              |            |
2024-07-15 17:19:43 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-15 17:19:43 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.2.drop_path1', 'blocks1.6.attn.attn_drop', 'blocks1.7.mlp.norm', 'blocks1.5.attn.attn_drop', 'blocks1.6.ls2', 'blocks1.7.ls2', 'blocks1.0.ls2', 'blocks.7.attn.k_norm', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks.2.attn.k_norm', 'patch_drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks1.6.attn.q_norm', 'blocks1.4.mlp.norm', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.0.attn.q_norm', 'blocks1.6.attn.k_norm', 'blocks1.4.attn.attn_drop', 'blocks1.4.attn.k_norm', 'blocks.7.drop_path2', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.7.ls1', 'blocks1.0.drop_path2', 'blocks.1.attn.k_norm', 'blocks1.3.drop_path2', 'blocks1.4.drop_path2', 'blocks.5.attn.k_norm', 'blocks1.0.attn.attn_drop', 'blocks1.5.ls1', 'blocks.3.drop_path1', 'blocks.4.attn.q_norm', 'blocks.3.mlp.norm', 'blocks.5.mlp.norm', 'blocks1.5.attn.k_norm', 'blocks.6.ls1', 'blocks1.1.ls2', 'blocks1.3.drop_path1', 'blocks1.0.attn.k_norm', 'patch_embed.backbone.stages.1.3.drop_path', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.0.0.down', 'neural_augmentor.brightness', 'blocks.6.mlp.norm', 'blocks1.3.attn.k_norm', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.4.mlp.norm', 'blocks.7.drop_path1', 'patch_embed.backbone.stages.0.1.down', 'blocks1.1.drop_path2', 'blocks1.5.attn.q_norm', 'blocks1.1.mlp.norm', 'blocks1.4.drop_path1', 'norm_pre', 'blocks.3.ls2', 'blocks.1.attn.attn_drop', 'blocks1.2.drop_path2', 'neural_augmentor.contrast', 'patch_embed.backbone.stem.norm1.drop', 'blocks1.6.mlp.norm', 'blocks.7.mlp.norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.3.attn.q_norm', 'neural_augmentor.contrast.min_fn', 'blocks1.1.ls1', 'patch_embed.backbone.stages.1.2.down', 'blocks1.2.drop_path1', 'neural_augmentor.noise', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks1.5.drop_path1', 'blocks.6.ls2', 'blocks.5.drop_path2', 'patch_embed.backbone.stages.1.0.down', 'neural_augmentor.contrast.max_fn', 'blocks.1.attn.q_norm', 'blocks1.0.mlp.norm', 'blocks1.5.ls2', 'blocks1.1.drop_path1', 'blocks1.7.ls1', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.4.ls2', 'blocks.3.attn.k_norm', 'blocks.6.attn.q_norm', 'blocks1.6.ls1', 'blocks.5.attn.attn_drop', 'blocks.4.drop_path2', 'blocks1.1.attn.attn_drop', 'blocks1.1.attn.q_norm', 'blocks.7.attn.q_norm', 'blocks1.6.drop_path1', 'blocks1.5.drop_path2', 'blocks.6.drop_path2', 'blocks.1.ls2', 'blocks.0.drop_path1', 'blocks1.2.attn.attn_drop', 'blocks.1.ls1', 'blocks.5.drop_path1', 'blocks1.0.drop_path1', 'blocks.0.ls2', 'blocks.4.attn.attn_drop', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks1.3.ls2', 'blocks1.0.ls1', 'blocks1.5.mlp.norm', 'blocks.2.mlp.norm', 'neural_augmentor.brightness.max_fn', 'blocks.4.attn.k_norm', 'blocks.2.ls1', 'blocks.2.ls2', 'blocks.7.attn.attn_drop', 'blocks1.2.attn.q_norm', 'patch_embed.backbone.stages.1.1.drop_path', 'patch_embed.backbone.stages.0.1.shortcut', 'patch_embed.backbone.stages.1.3.down', 'blocks1.2.ls1', 'blocks.5.ls2', 'neural_augmentor', 'blocks1.4.ls1', 'norm', 'blocks1.7.drop_path2', 'blocks.4.drop_path1', 'blocks.1.mlp.norm', 'blocks1.3.ls1', 'blocks1.3.attn.q_norm', 'blocks1.7.drop_path1', 'blocks1.7.attn.k_norm', 'neural_augmentor.brightness.min_fn', 'blocks1.2.mlp.norm', 'blocks1.7.attn.attn_drop', 'blocks.1.drop_path1', 'blocks1.4.ls2', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks.3.ls1', 'blocks.6.attn.attn_drop', 'blocks1.7.attn.q_norm', 'blocks.0.attn.attn_drop', 'blocks.0.attn.q_norm', 'blocks.1.drop_path2', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.2.drop_path2', 'blocks.6.drop_path1', 'neural_augmentor.noise.max_fn', 'blocks1.3.attn.attn_drop', 'blocks.5.attn.q_norm', 'blocks.0.attn.k_norm', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.4.attn.q_norm', 'blocks.0.ls1', 'blocks.3.drop_path2', 'neural_augmentor.noise.min_fn', 'blocks1.2.attn.k_norm', 'blocks.0.mlp.norm', 'blocks.0.drop_path2', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.6.attn.k_norm', 'blocks1.3.mlp.norm', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks.4.ls1', 'patch_embed.backbone.stages.1.1.down', 'blocks1.2.ls2', 'blocks1.6.drop_path2', 'blocks.3.attn.attn_drop', 'blocks.5.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.2.attn.q_norm', 'patch_embed.proj', 'blocks.7.ls2'}
2024-07-15 17:19:43 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	BinaryCrossEntropy(  reduction=batch_mean loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - Max. iteration for training: 1000000
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=1e-05
 	 max_lr=0.001
 	 period=990001
 	 warmup_init_lr=1e-06
 	 warmup_iters=10000
 )
2024-07-15 17:19:43 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_last.pt'
2024-07-15 17:19:43 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results500_dci/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-15 17:19:45 - [32m[1mINFO   [0m - Training epoch 0
2024-07-15 17:19:37 - [32m[1mINFO   [0m - distributed init (rank 6): tcp://localhost:40002
small
2024-07-15 17:19:37 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40002
small
2024-07-15 17:19:37 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40002
small
2024-07-15 17:19:36 - [32m[1mINFO   [0m - distributed init (rank 7): tcp://localhost:40002
small
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-15 17:23:37 - [34m[1mLOGS   [0m - Epoch:   0 [       1/ 1000000], loss: {'classification': 4772.3894, 'neural_augmentation': 8.5831, 'total_loss': 4780.9725}, LR: [1e-06, 1e-06], Avg. batch load time: 212.337, Elapsed time: 231.83
2024-07-15 17:26:11 - [34m[1mLOGS   [0m - Epoch:   0 [     501/ 1000000], loss: {'classification': 1583.6029, 'neural_augmentation': 9.2564, 'total_loss': 1592.8592}, LR: [5.1e-05, 5.1e-05], Avg. batch load time: 0.433, Elapsed time: 385.89
2024-07-15 17:28:28 - [34m[1mLOGS   [0m - Epoch:   0 [    1001/ 1000000], loss: {'classification': 806.4905, 'neural_augmentation': 9.2637, 'total_loss': 815.7542}, LR: [0.000101, 0.000101], Avg. batch load time: 0.217, Elapsed time: 522.92
2024-07-15 17:30:53 - [34m[1mLOGS   [0m - Epoch:   0 [    1501/ 1000000], loss: {'classification': 547.4779, 'neural_augmentation': 9.2383, 'total_loss': 556.7161}, LR: [0.000151, 0.000151], Avg. batch load time: 0.145, Elapsed time: 667.72
2024-07-15 17:33:10 - [34m[1mLOGS   [0m - Epoch:   0 [    2001/ 1000000], loss: {'classification': 416.9224, 'neural_augmentation': 9.1919, 'total_loss': 426.1143}, LR: [0.000201, 0.000201], Avg. batch load time: 0.109, Elapsed time: 804.78
2024-07-15 17:35:27 - [34m[1mLOGS   [0m - Epoch:   0 [    2501/ 1000000], loss: {'classification': 340.2951, 'neural_augmentation': 9.128, 'total_loss': 349.4231}, LR: [0.000251, 0.000251], Avg. batch load time: 0.087, Elapsed time: 941.66
2024-07-15 17:37:52 - [34m[1mLOGS   [0m - Epoch:   0 [    3001/ 1000000], loss: {'classification': 288.1722, 'neural_augmentation': 9.0511, 'total_loss': 297.2233}, LR: [0.000301, 0.000301], Avg. batch load time: 0.073, Elapsed time: 1087.10
2024-07-15 17:40:09 - [34m[1mLOGS   [0m - Epoch:   0 [    3501/ 1000000], loss: {'classification': 250.6798, 'neural_augmentation': 8.9566, 'total_loss': 259.6363}, LR: [0.000351, 0.000351], Avg. batch load time: 0.063, Elapsed time: 1224.20
2024-07-15 17:42:36 - [34m[1mLOGS   [0m - Epoch:   0 [    4001/ 1000000], loss: {'classification': 222.9108, 'neural_augmentation': 8.845, 'total_loss': 231.7558}, LR: [0.000401, 0.000401], Avg. batch load time: 0.055, Elapsed time: 1370.71
2024-07-15 17:44:53 - [34m[1mLOGS   [0m - Epoch:   0 [    4501/ 1000000], loss: {'classification': 200.4091, 'neural_augmentation': 8.7104, 'total_loss': 209.1194}, LR: [0.000451, 0.000451], Avg. batch load time: 0.049, Elapsed time: 1508.43
2024-07-15 17:47:11 - [34m[1mLOGS   [0m - Epoch:   0 [    5001/ 1000000], loss: {'classification': 182.7791, 'neural_augmentation': 8.5583, 'total_loss': 191.3374}, LR: [0.0005, 0.0005], Avg. batch load time: 0.044, Elapsed time: 1646.05
2024-07-15 17:49:36 - [34m[1mLOGS   [0m - Epoch:   0 [    5501/ 1000000], loss: {'classification': 167.8919, 'neural_augmentation': 8.3712, 'total_loss': 176.263}, LR: [0.00055, 0.00055], Avg. batch load time: 0.040, Elapsed time: 1791.24
2024-07-15 17:51:54 - [34m[1mLOGS   [0m - Epoch:   0 [    6001/ 1000000], loss: {'classification': 155.7627, 'neural_augmentation': 8.1607, 'total_loss': 163.9234}, LR: [0.0006, 0.0006], Avg. batch load time: 0.037, Elapsed time: 1928.98
2024-07-15 17:54:12 - [34m[1mLOGS   [0m - Epoch:   0 [    6501/ 1000000], loss: {'classification': 145.3407, 'neural_augmentation': 7.9207, 'total_loss': 153.2614}, LR: [0.00065, 0.00065], Avg. batch load time: 0.034, Elapsed time: 2066.75
2024-07-15 17:56:36 - [34m[1mLOGS   [0m - Epoch:   0 [    7001/ 1000000], loss: {'classification': 136.5506, 'neural_augmentation': 7.6637, 'total_loss': 144.2142}, LR: [0.0007, 0.0007], Avg. batch load time: 0.032, Elapsed time: 2210.65
2024-07-15 17:59:02 - [34m[1mLOGS   [0m - Epoch:   0 [    7501/ 1000000], loss: {'classification': 128.6963, 'neural_augmentation': 7.3851, 'total_loss': 136.0814}, LR: [0.00075, 0.00075], Avg. batch load time: 0.030, Elapsed time: 2357.10
2024-07-15 18:01:42 - [34m[1mLOGS   [0m - Epoch:   0 [    8001/ 1000000], loss: {'classification': 122.1029, 'neural_augmentation': 7.1133, 'total_loss': 129.2162}, LR: [0.0008, 0.0008], Avg. batch load time: 0.029, Elapsed time: 2517.21
2024-07-15 18:04:23 - [34m[1mLOGS   [0m - Epoch:   0 [    8501/ 1000000], loss: {'classification': 116.3833, 'neural_augmentation': 6.8469, 'total_loss': 123.2302}, LR: [0.00085, 0.00085], Avg. batch load time: 0.030, Elapsed time: 2677.92
2024-07-15 18:07:07 - [34m[1mLOGS   [0m - Epoch:   0 [    9001/ 1000000], loss: {'classification': 111.2145, 'neural_augmentation': 6.5823, 'total_loss': 117.7969}, LR: [0.0009, 0.0009], Avg. batch load time: 0.030, Elapsed time: 2842.29
2024-07-15 18:10:05 - [34m[1mLOGS   [0m - Epoch:   0 [    9501/ 1000000], loss: {'classification': 106.3838, 'neural_augmentation': 6.3195, 'total_loss': 112.7033}, LR: [0.00095, 0.00095], Avg. batch load time: 0.030, Elapsed time: 3019.97
2024-07-15 18:12:51 - [34m[1mLOGS   [0m - Epoch:   0 [   10001/ 1000000], loss: {'classification': 102.1445, 'neural_augmentation': 6.0767, 'total_loss': 108.2212}, LR: [0.001, 0.001], Avg. batch load time: 0.030, Elapsed time: 3186.20
2024-07-15 18:15:39 - [34m[1mLOGS   [0m - Epoch:   0 [   10501/ 1000000], loss: {'classification': 98.5164, 'neural_augmentation': 5.8545, 'total_loss': 104.3709}, LR: [0.001, 0.001], Avg. batch load time: 0.030, Elapsed time: 3353.96
2024-07-15 18:18:25 - [34m[1mLOGS   [0m - Epoch:   0 [   11001/ 1000000], loss: {'classification': 95.1994, 'neural_augmentation': 5.644, 'total_loss': 100.8434}, LR: [0.001, 0.001], Avg. batch load time: 0.031, Elapsed time: 3520.37
2024-07-15 18:21:23 - [34m[1mLOGS   [0m - Epoch:   0 [   11501/ 1000000], loss: {'classification': 92.0723, 'neural_augmentation': 5.4396, 'total_loss': 97.5119}, LR: [0.001, 0.001], Avg. batch load time: 0.032, Elapsed time: 3698.44
2024-07-15 18:24:21 - [34m[1mLOGS   [0m - Epoch:   0 [   12001/ 1000000], loss: {'classification': 89.2387, 'neural_augmentation': 5.2501, 'total_loss': 94.4888}, LR: [0.001, 0.001], Avg. batch load time: 0.033, Elapsed time: 3876.33
2024-07-15 18:27:10 - [34m[1mLOGS   [0m - Epoch:   0 [   12501/ 1000000], loss: {'classification': 86.763, 'neural_augmentation': 5.0813, 'total_loss': 91.8442}, LR: [0.001, 0.001], Avg. batch load time: 0.033, Elapsed time: 4044.61
2024-07-15 18:30:10 - [34m[1mLOGS   [0m - Epoch:   0 [   13001/ 1000000], loss: {'classification': 84.3202, 'neural_augmentation': 4.9118, 'total_loss': 89.232}, LR: [0.001, 0.001], Avg. batch load time: 0.034, Elapsed time: 4224.73
2024-07-15 18:33:22 - [34m[1mLOGS   [0m - Epoch:   0 [   13501/ 1000000], loss: {'classification': 82.0585, 'neural_augmentation': 4.7533, 'total_loss': 86.8119}, LR: [0.001, 0.001], Avg. batch load time: 0.035, Elapsed time: 4416.63
2024-07-15 18:36:12 - [34m[1mLOGS   [0m - Epoch:   0 [   14001/ 1000000], loss: {'classification': 79.9632, 'neural_augmentation': 4.6048, 'total_loss': 84.568}, LR: [0.001, 0.001], Avg. batch load time: 0.035, Elapsed time: 4587.29
2024-07-15 18:39:45 - [34m[1mLOGS   [0m - Epoch:   0 [   14501/ 1000000], loss: {'classification': 78.1104, 'neural_augmentation': 4.4719, 'total_loss': 82.5824}, LR: [0.001, 0.001], Avg. batch load time: 0.038, Elapsed time: 4800.41
2024-07-15 18:44:31 - [34m[1mLOGS   [0m - Epoch:   0 [   15001/ 1000000], loss: {'classification': 76.214, 'neural_augmentation': 4.3349, 'total_loss': 80.5489}, LR: [0.001, 0.001], Avg. batch load time: 0.046, Elapsed time: 5085.64
2024-07-15 18:49:11 - [34m[1mLOGS   [0m - Epoch:   0 [   15501/ 1000000], loss: {'classification': 74.519, 'neural_augmentation': 4.2123, 'total_loss': 78.7313}, LR: [0.001, 0.001], Avg. batch load time: 0.052, Elapsed time: 5366.42
2024-07-15 18:54:04 - [34m[1mLOGS   [0m - Epoch:   0 [   16001/ 1000000], loss: {'classification': 72.8316, 'neural_augmentation': 4.09, 'total_loss': 76.9216}, LR: [0.001, 0.001], Avg. batch load time: 0.058, Elapsed time: 5658.75
2024-07-15 18:58:38 - [34m[1mLOGS   [0m - Epoch:   0 [   16501/ 1000000], loss: {'classification': 71.2309, 'neural_augmentation': 3.9722, 'total_loss': 75.2031}, LR: [0.001, 0.001], Avg. batch load time: 0.064, Elapsed time: 5933.01
2024-07-15 19:03:29 - [34m[1mLOGS   [0m - Epoch:   0 [   17001/ 1000000], loss: {'classification': 69.8335, 'neural_augmentation': 3.8674, 'total_loss': 73.7009}, LR: [0.001, 0.001], Avg. batch load time: 0.070, Elapsed time: 6224.45
2024-07-15 19:08:01 - [34m[1mLOGS   [0m - Epoch:   0 [   17501/ 1000000], loss: {'classification': 68.5106, 'neural_augmentation': 3.768, 'total_loss': 72.2786}, LR: [0.001, 0.001], Avg. batch load time: 0.075, Elapsed time: 6495.66
2024-07-15 19:12:38 - [34m[1mLOGS   [0m - Epoch:   0 [   18001/ 1000000], loss: {'classification': 67.2777, 'neural_augmentation': 3.675, 'total_loss': 70.9526}, LR: [0.001, 0.001], Avg. batch load time: 0.080, Elapsed time: 6773.15
2024-07-15 19:17:12 - [34m[1mLOGS   [0m - Epoch:   0 [   18501/ 1000000], loss: {'classification': 66.1132, 'neural_augmentation': 3.5867, 'total_loss': 69.6999}, LR: [0.001, 0.001], Avg. batch load time: 0.083, Elapsed time: 7046.78
2024-07-15 19:21:55 - [34m[1mLOGS   [0m - Epoch:   0 [   19001/ 1000000], loss: {'classification': 64.9795, 'neural_augmentation': 3.5006, 'total_loss': 68.4801}, LR: [0.001, 0.001], Avg. batch load time: 0.088, Elapsed time: 7329.76
2024-07-15 19:26:31 - [34m[1mLOGS   [0m - Epoch:   0 [   19501/ 1000000], loss: {'classification': 63.8883, 'neural_augmentation': 3.4173, 'total_loss': 67.3056}, LR: [0.001, 0.001], Avg. batch load time: 0.092, Elapsed time: 7606.24
2024-07-15 19:31:04 - [34m[1mLOGS   [0m - Epoch:   0 [   20001/ 1000000], loss: {'classification': 62.9371, 'neural_augmentation': 3.3444, 'total_loss': 66.2815}, LR: [0.001, 0.001], Avg. batch load time: 0.095, Elapsed time: 7879.07
2024-07-15 19:35:39 - [34m[1mLOGS   [0m - Epoch:   0 [   20501/ 1000000], loss: {'classification': 61.9278, 'neural_augmentation': 3.2665, 'total_loss': 65.1943}, LR: [0.001, 0.001], Avg. batch load time: 0.098, Elapsed time: 8154.14
2024-07-15 19:40:54 - [34m[1mLOGS   [0m - Epoch:   0 [   21001/ 1000000], loss: {'classification': 60.9853, 'neural_augmentation': 3.1935, 'total_loss': 64.1788}, LR: [0.001, 0.001], Avg. batch load time: 0.103, Elapsed time: 8469.05
2024-07-15 19:45:20 - [34m[1mLOGS   [0m - Epoch:   0 [   21501/ 1000000], loss: {'classification': 60.1124, 'neural_augmentation': 3.1262, 'total_loss': 63.2386}, LR: [0.001, 0.001], Avg. batch load time: 0.105, Elapsed time: 8734.70
2024-07-15 19:49:56 - [34m[1mLOGS   [0m - Epoch:   0 [   22001/ 1000000], loss: {'classification': 59.2692, 'neural_augmentation': 3.061, 'total_loss': 62.3302}, LR: [0.001, 0.001], Avg. batch load time: 0.108, Elapsed time: 9010.88
2024-07-15 19:54:57 - [34m[1mLOGS   [0m - Epoch:   0 [   22501/ 1000000], loss: {'classification': 58.4597, 'neural_augmentation': 2.998, 'total_loss': 61.4577}, LR: [0.001, 0.001], Avg. batch load time: 0.111, Elapsed time: 9311.58
2024-07-15 19:59:40 - [34m[1mLOGS   [0m - Epoch:   0 [   23001/ 1000000], loss: {'classification': 57.69, 'neural_augmentation': 2.9382, 'total_loss': 60.6281}, LR: [0.001, 0.001], Avg. batch load time: 0.115, Elapsed time: 9595.51
2024-07-15 20:04:09 - [34m[1mLOGS   [0m - Epoch:   0 [   23501/ 1000000], loss: {'classification': 56.9611, 'neural_augmentation': 2.8816, 'total_loss': 59.8426}, LR: [0.001, 0.001], Avg. batch load time: 0.117, Elapsed time: 9864.44
2024-07-15 20:08:39 - [34m[1mLOGS   [0m - Epoch:   0 [   24001/ 1000000], loss: {'classification': 56.2627, 'neural_augmentation': 2.8269, 'total_loss': 59.0897}, LR: [0.001, 0.001], Avg. batch load time: 0.119, Elapsed time: 10134.42
2024-07-15 20:13:29 - [34m[1mLOGS   [0m - Epoch:   0 [   24501/ 1000000], loss: {'classification': 55.5868, 'neural_augmentation': 2.7739, 'total_loss': 58.3608}, LR: [0.000999, 0.000999], Avg. batch load time: 0.122, Elapsed time: 10423.91
2024-07-15 20:19:05 - [34m[1mLOGS   [0m - Epoch:   0 [   25001/ 1000000], loss: {'classification': 55.171, 'neural_augmentation': 2.7251, 'total_loss': 57.8961}, LR: [0.000999, 0.000999], Avg. batch load time: 0.126, Elapsed time: 10759.81
2024-07-15 20:26:43 - [34m[1mLOGS   [0m - Epoch:   0 [   25501/ 1000000], loss: {'classification': 55.0057, 'neural_augmentation': 2.6761, 'total_loss': 57.6818}, LR: [0.000999, 0.000999], Avg. batch load time: 0.133, Elapsed time: 11218.51
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 20:33:55 - [34m[1mLOGS   [0m - Epoch:   0 [   26001/ 1000000], loss: {'classification': 54.8394, 'neural_augmentation': 2.6276, 'total_loss': 57.467}, LR: [0.000999, 0.000999], Avg. batch load time: 0.139, Elapsed time: 11649.75
2024-07-15 20:41:42 - [34m[1mLOGS   [0m - Epoch:   0 [   26501/ 1000000], loss: {'classification': 54.675, 'neural_augmentation': 2.5797, 'total_loss': 57.2547}, LR: [0.000999, 0.000999], Avg. batch load time: 0.146, Elapsed time: 12116.93
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 20:49:19 - [34m[1mLOGS   [0m - Epoch:   0 [   27001/ 1000000], loss: {'classification': 54.5205, 'neural_augmentation': 2.5352, 'total_loss': 57.0557}, LR: [0.000999, 0.000999], Avg. batch load time: 0.154, Elapsed time: 12574.13
2024-07-15 20:56:47 - [34m[1mLOGS   [0m - Epoch:   0 [   27501/ 1000000], loss: {'classification': 54.3727, 'neural_augmentation': 2.4923, 'total_loss': 56.865}, LR: [0.000999, 0.000999], Avg. batch load time: 0.159, Elapsed time: 13021.53
2024-07-15 21:04:26 - [34m[1mLOGS   [0m - Epoch:   0 [   28001/ 1000000], loss: {'classification': 54.2201, 'neural_augmentation': 2.4484, 'total_loss': 56.6684}, LR: [0.000999, 0.000999], Avg. batch load time: 0.163, Elapsed time: 13481.19
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 21:11:49 - [34m[1mLOGS   [0m - Epoch:   0 [   28501/ 1000000], loss: {'classification': 54.0809, 'neural_augmentation': 2.4085, 'total_loss': 56.4893}, LR: [0.000999, 0.000999], Avg. batch load time: 0.167, Elapsed time: 13924.28
2024-07-15 21:19:40 - [34m[1mLOGS   [0m - Epoch:   0 [   29001/ 1000000], loss: {'classification': 53.9428, 'neural_augmentation': 2.3685, 'total_loss': 56.3113}, LR: [0.000999, 0.000999], Avg. batch load time: 0.173, Elapsed time: 14394.58
2024-07-15 21:26:59 - [34m[1mLOGS   [0m - Epoch:   0 [   29501/ 1000000], loss: {'classification': 53.813, 'neural_augmentation': 2.3307, 'total_loss': 56.1436}, LR: [0.000999, 0.000999], Avg. batch load time: 0.177, Elapsed time: 14833.98
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
2024-07-15 21:35:00 - [34m[1mLOGS   [0m - Epoch:   0 [   30001/ 1000000], loss: {'classification': 53.6809, 'neural_augmentation': 2.2921, 'total_loss': 55.973}, LR: [0.000999, 0.000999], Avg. batch load time: 0.183, Elapsed time: 15315.18
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 21:42:23 - [34m[1mLOGS   [0m - Epoch:   0 [   30501/ 1000000], loss: {'classification': 53.559, 'neural_augmentation': 2.257, 'total_loss': 55.816}, LR: [0.000999, 0.000999], Avg. batch load time: 0.186, Elapsed time: 15758.29
2024-07-15 21:50:38 - [34m[1mLOGS   [0m - Epoch:   0 [   31001/ 1000000], loss: {'classification': 53.4325, 'neural_augmentation': 2.2216, 'total_loss': 55.6541}, LR: [0.000999, 0.000999], Avg. batch load time: 0.192, Elapsed time: 16253.30
2024-07-15 21:56:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 53.3286, 'neural_augmentation': 2.192, 'total_loss': 55.5207}
2024-07-15 21:56:17 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_best.pt
2024-07-15 21:56:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_last.pt
2024-07-15 21:56:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_last.pt
2024-07-15 21:56:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 31440 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_epoch_0_iter_31440.pt
2024-07-15 21:56:20 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 31440 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_epoch_0_iter_31440.pt
[31m===========================================================================[0m
2024-07-15 21:56:22 - [32m[1mINFO   [0m - Training epoch 1
2024-07-15 21:58:00 - [34m[1mLOGS   [0m - Epoch:   1 [   31441/ 1000000], loss: {'classification': 41.9002, 'neural_augmentation': 0.1476, 'total_loss': 42.0478}, LR: [0.000999, 0.000999], Avg. batch load time: 97.424, Elapsed time: 98.07
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 22:01:41 - [34m[1mLOGS   [0m - Epoch:   1 [   31941/ 1000000], loss: {'classification': 30.2626, 'neural_augmentation': 0.1587, 'total_loss': 30.4213}, LR: [0.000999, 0.000999], Avg. batch load time: 0.329, Elapsed time: 319.61
2024-07-15 22:05:26 - [34m[1mLOGS   [0m - Epoch:   1 [   32441/ 1000000], loss: {'classification': 29.6163, 'neural_augmentation': 0.1623, 'total_loss': 29.7786}, LR: [0.000999, 0.000999], Avg. batch load time: 0.226, Elapsed time: 544.21
2024-07-15 22:09:01 - [34m[1mLOGS   [0m - Epoch:   1 [   32941/ 1000000], loss: {'classification': 29.2733, 'neural_augmentation': 0.1638, 'total_loss': 29.4371}, LR: [0.000999, 0.000999], Avg. batch load time: 0.178, Elapsed time: 759.02
2024-07-15 22:12:43 - [34m[1mLOGS   [0m - Epoch:   1 [   33441/ 1000000], loss: {'classification': 29.0513, 'neural_augmentation': 0.1649, 'total_loss': 29.2162}, LR: [0.000999, 0.000999], Avg. batch load time: 0.155, Elapsed time: 981.44
2024-07-15 22:16:30 - [34m[1mLOGS   [0m - Epoch:   1 [   33941/ 1000000], loss: {'classification': 28.9184, 'neural_augmentation': 0.1659, 'total_loss': 29.0843}, LR: [0.000999, 0.000999], Avg. batch load time: 0.139, Elapsed time: 1208.29
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 22:20:27 - [34m[1mLOGS   [0m - Epoch:   1 [   34441/ 1000000], loss: {'classification': 28.8003, 'neural_augmentation': 0.1665, 'total_loss': 28.9668}, LR: [0.000999, 0.000999], Avg. batch load time: 0.137, Elapsed time: 1445.25
2024-07-15 22:24:21 - [34m[1mLOGS   [0m - Epoch:   1 [   34941/ 1000000], loss: {'classification': 28.7216, 'neural_augmentation': 0.167, 'total_loss': 28.8885}, LR: [0.000998, 0.000998], Avg. batch load time: 0.137, Elapsed time: 1679.54
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 22:28:04 - [34m[1mLOGS   [0m - Epoch:   1 [   35441/ 1000000], loss: {'classification': 28.6552, 'neural_augmentation': 0.1673, 'total_loss': 28.8224}, LR: [0.000998, 0.000998], Avg. batch load time: 0.130, Elapsed time: 1902.12
2024-07-15 22:31:56 - [34m[1mLOGS   [0m - Epoch:   1 [   35941/ 1000000], loss: {'classification': 28.598, 'neural_augmentation': 0.1673, 'total_loss': 28.7653}, LR: [0.000998, 0.000998], Avg. batch load time: 0.130, Elapsed time: 2134.45
2024-07-15 22:35:39 - [34m[1mLOGS   [0m - Epoch:   1 [   36441/ 1000000], loss: {'classification': 28.558, 'neural_augmentation': 0.1673, 'total_loss': 28.7253}, LR: [0.000998, 0.000998], Avg. batch load time: 0.128, Elapsed time: 2357.37
2024-07-15 22:39:32 - [34m[1mLOGS   [0m - Epoch:   1 [   36941/ 1000000], loss: {'classification': 28.5144, 'neural_augmentation': 0.1671, 'total_loss': 28.6815}, LR: [0.000998, 0.000998], Avg. batch load time: 0.126, Elapsed time: 2590.58
2024-07-15 22:43:35 - [34m[1mLOGS   [0m - Epoch:   1 [   37441/ 1000000], loss: {'classification': 28.4772, 'neural_augmentation': 0.1668, 'total_loss': 28.644}, LR: [0.000998, 0.000998], Avg. batch load time: 0.126, Elapsed time: 2832.92
2024-07-15 22:47:19 - [34m[1mLOGS   [0m - Epoch:   1 [   37941/ 1000000], loss: {'classification': 28.4407, 'neural_augmentation': 0.1666, 'total_loss': 28.6073}, LR: [0.000998, 0.000998], Avg. batch load time: 0.128, Elapsed time: 3057.08
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 22:51:13 - [34m[1mLOGS   [0m - Epoch:   1 [   38441/ 1000000], loss: {'classification': 28.4066, 'neural_augmentation': 0.1662, 'total_loss': 28.5728}, LR: [0.000998, 0.000998], Avg. batch load time: 0.126, Elapsed time: 3291.70
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 22:55:03 - [34m[1mLOGS   [0m - Epoch:   1 [   38941/ 1000000], loss: {'classification': 28.3713, 'neural_augmentation': 0.1658, 'total_loss': 28.5371}, LR: [0.000998, 0.000998], Avg. batch load time: 0.125, Elapsed time: 3521.68
2024-07-15 22:59:06 - [34m[1mLOGS   [0m - Epoch:   1 [   39441/ 1000000], loss: {'classification': 28.3387, 'neural_augmentation': 0.1653, 'total_loss': 28.5041}, LR: [0.000998, 0.000998], Avg. batch load time: 0.125, Elapsed time: 3764.58
2024-07-15 23:03:00 - [34m[1mLOGS   [0m - Epoch:   1 [   39941/ 1000000], loss: {'classification': 28.3149, 'neural_augmentation': 0.1649, 'total_loss': 28.4798}, LR: [0.000998, 0.000998], Avg. batch load time: 0.125, Elapsed time: 3998.45
2024-07-15 23:06:39 - [34m[1mLOGS   [0m - Epoch:   1 [   40441/ 1000000], loss: {'classification': 28.2882, 'neural_augmentation': 0.1645, 'total_loss': 28.4527}, LR: [0.000998, 0.000998], Avg. batch load time: 0.125, Elapsed time: 4217.71
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 23:10:25 - [34m[1mLOGS   [0m - Epoch:   1 [   40941/ 1000000], loss: {'classification': 28.267, 'neural_augmentation': 0.1641, 'total_loss': 28.4311}, LR: [0.000998, 0.000998], Avg. batch load time: 0.124, Elapsed time: 4442.93
2024-07-15 23:14:21 - [34m[1mLOGS   [0m - Epoch:   1 [   41441/ 1000000], loss: {'classification': 28.2447, 'neural_augmentation': 0.1637, 'total_loss': 28.4084}, LR: [0.000998, 0.000998], Avg. batch load time: 0.126, Elapsed time: 4678.91
2024-07-15 23:18:00 - [34m[1mLOGS   [0m - Epoch:   1 [   41941/ 1000000], loss: {'classification': 28.225, 'neural_augmentation': 0.1633, 'total_loss': 28.3883}, LR: [0.000997, 0.000997], Avg. batch load time: 0.124, Elapsed time: 4897.93
2024-07-15 23:21:26 - [34m[1mLOGS   [0m - Epoch:   1 [   42441/ 1000000], loss: {'classification': 28.2101, 'neural_augmentation': 0.1629, 'total_loss': 28.373}, LR: [0.000997, 0.000997], Avg. batch load time: 0.123, Elapsed time: 5104.12
2024-07-15 23:25:11 - [34m[1mLOGS   [0m - Epoch:   1 [   42941/ 1000000], loss: {'classification': 28.1921, 'neural_augmentation': 0.1624, 'total_loss': 28.3545}, LR: [0.000997, 0.000997], Avg. batch load time: 0.124, Elapsed time: 5328.95
2024-07-15 23:28:59 - [34m[1mLOGS   [0m - Epoch:   1 [   43441/ 1000000], loss: {'classification': 28.175, 'neural_augmentation': 0.162, 'total_loss': 28.337}, LR: [0.000997, 0.000997], Avg. batch load time: 0.122, Elapsed time: 5557.88
2024-07-15 23:32:43 - [34m[1mLOGS   [0m - Epoch:   1 [   43941/ 1000000], loss: {'classification': 28.1575, 'neural_augmentation': 0.1615, 'total_loss': 28.319}, LR: [0.000997, 0.000997], Avg. batch load time: 0.121, Elapsed time: 5781.83
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 23:36:29 - [34m[1mLOGS   [0m - Epoch:   1 [   44441/ 1000000], loss: {'classification': 28.1428, 'neural_augmentation': 0.1611, 'total_loss': 28.3039}, LR: [0.000997, 0.000997], Avg. batch load time: 0.120, Elapsed time: 6007.32
2024-07-15 23:40:15 - [34m[1mLOGS   [0m - Epoch:   1 [   44941/ 1000000], loss: {'classification': 28.125, 'neural_augmentation': 0.1606, 'total_loss': 28.2857}, LR: [0.000997, 0.000997], Avg. batch load time: 0.120, Elapsed time: 6233.32
2024-07-15 23:44:06 - [34m[1mLOGS   [0m - Epoch:   1 [   45441/ 1000000], loss: {'classification': 28.1112, 'neural_augmentation': 0.1602, 'total_loss': 28.2714}, LR: [0.000997, 0.000997], Avg. batch load time: 0.120, Elapsed time: 6463.93
2024-07-15 23:47:50 - [34m[1mLOGS   [0m - Epoch:   1 [   45941/ 1000000], loss: {'classification': 28.0966, 'neural_augmentation': 0.1598, 'total_loss': 28.2564}, LR: [0.000997, 0.000997], Avg. batch load time: 0.118, Elapsed time: 6688.78
2024-07-15 23:51:35 - [34m[1mLOGS   [0m - Epoch:   1 [   46441/ 1000000], loss: {'classification': 28.0842, 'neural_augmentation': 0.1594, 'total_loss': 28.2436}, LR: [0.000997, 0.000997], Avg. batch load time: 0.119, Elapsed time: 6913.81
2024-07-15 23:55:17 - [34m[1mLOGS   [0m - Epoch:   1 [   46941/ 1000000], loss: {'classification': 28.0713, 'neural_augmentation': 0.159, 'total_loss': 28.2303}, LR: [0.000997, 0.000997], Avg. batch load time: 0.117, Elapsed time: 7135.59
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-15 23:59:05 - [34m[1mLOGS   [0m - Epoch:   1 [   47441/ 1000000], loss: {'classification': 28.0603, 'neural_augmentation': 0.1586, 'total_loss': 28.2189}, LR: [0.000997, 0.000997], Avg. batch load time: 0.117, Elapsed time: 7363.74
2024-07-16 00:02:43 - [34m[1mLOGS   [0m - Epoch:   1 [   47941/ 1000000], loss: {'classification': 28.0471, 'neural_augmentation': 0.1582, 'total_loss': 28.2053}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 7581.37
2024-07-16 00:06:29 - [34m[1mLOGS   [0m - Epoch:   1 [   48441/ 1000000], loss: {'classification': 28.0348, 'neural_augmentation': 0.1578, 'total_loss': 28.1926}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 7807.49
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
2024-07-16 00:10:05 - [34m[1mLOGS   [0m - Epoch:   1 [   48941/ 1000000], loss: {'classification': 28.0212, 'neural_augmentation': 0.1574, 'total_loss': 28.1786}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 8023.86
2024-07-16 00:14:12 - [34m[1mLOGS   [0m - Epoch:   1 [   49441/ 1000000], loss: {'classification': 28.0105, 'neural_augmentation': 0.157, 'total_loss': 28.1675}, LR: [0.000996, 0.000996], Avg. batch load time: 0.118, Elapsed time: 8270.40
2024-07-16 00:17:52 - [34m[1mLOGS   [0m - Epoch:   1 [   49941/ 1000000], loss: {'classification': 27.998, 'neural_augmentation': 0.1566, 'total_loss': 28.1546}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 8490.10
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
2024-07-16 00:22:02 - [34m[1mLOGS   [0m - Epoch:   1 [   50441/ 1000000], loss: {'classification': 27.9859, 'neural_augmentation': 0.1562, 'total_loss': 28.1421}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 8740.75
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 00:25:39 - [34m[1mLOGS   [0m - Epoch:   1 [   50941/ 1000000], loss: {'classification': 27.9762, 'neural_augmentation': 0.1559, 'total_loss': 28.1321}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 8957.19
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 00:29:28 - [34m[1mLOGS   [0m - Epoch:   1 [   51441/ 1000000], loss: {'classification': 27.9664, 'neural_augmentation': 0.1555, 'total_loss': 28.122}, LR: [0.000996, 0.000996], Avg. batch load time: 0.116, Elapsed time: 9186.57
2024-07-16 00:33:14 - [34m[1mLOGS   [0m - Epoch:   1 [   51941/ 1000000], loss: {'classification': 27.9561, 'neural_augmentation': 0.1552, 'total_loss': 28.1113}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 9411.91
2024-07-16 00:37:03 - [34m[1mLOGS   [0m - Epoch:   1 [   52441/ 1000000], loss: {'classification': 27.9461, 'neural_augmentation': 0.1548, 'total_loss': 28.1009}, LR: [0.000996, 0.000996], Avg. batch load time: 0.117, Elapsed time: 9641.23
2024-07-16 00:40:52 - [34m[1mLOGS   [0m - Epoch:   1 [   52941/ 1000000], loss: {'classification': 27.9363, 'neural_augmentation': 0.1545, 'total_loss': 28.0908}, LR: [0.000995, 0.000995], Avg. batch load time: 0.116, Elapsed time: 9870.13
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 00:44:52 - [34m[1mLOGS   [0m - Epoch:   1 [   53441/ 1000000], loss: {'classification': 27.9279, 'neural_augmentation': 0.1542, 'total_loss': 28.0821}, LR: [0.000995, 0.000995], Avg. batch load time: 0.117, Elapsed time: 10110.56
2024-07-16 00:48:44 - [34m[1mLOGS   [0m - Epoch:   1 [   53941/ 1000000], loss: {'classification': 27.9175, 'neural_augmentation': 0.1539, 'total_loss': 28.0713}, LR: [0.000995, 0.000995], Avg. batch load time: 0.116, Elapsed time: 10342.89
2024-07-16 00:52:18 - [34m[1mLOGS   [0m - Epoch:   1 [   54441/ 1000000], loss: {'classification': 27.9097, 'neural_augmentation': 0.1536, 'total_loss': 28.0632}, LR: [0.000995, 0.000995], Avg. batch load time: 0.115, Elapsed time: 10556.04
2024-07-16 00:56:15 - [34m[1mLOGS   [0m - Epoch:   1 [   54941/ 1000000], loss: {'classification': 27.9014, 'neural_augmentation': 0.1533, 'total_loss': 28.0547}, LR: [0.000995, 0.000995], Avg. batch load time: 0.115, Elapsed time: 10793.56
2024-07-16 01:00:04 - [34m[1mLOGS   [0m - Epoch:   1 [   55441/ 1000000], loss: {'classification': 27.8919, 'neural_augmentation': 0.153, 'total_loss': 28.0448}, LR: [0.000995, 0.000995], Avg. batch load time: 0.115, Elapsed time: 11022.10
2024-07-16 01:03:53 - [34m[1mLOGS   [0m - Epoch:   1 [   55941/ 1000000], loss: {'classification': 27.882, 'neural_augmentation': 0.1527, 'total_loss': 28.0346}, LR: [0.000995, 0.000995], Avg. batch load time: 0.115, Elapsed time: 11250.94
2024-07-16 01:07:46 - [34m[1mLOGS   [0m - Epoch:   1 [   56441/ 1000000], loss: {'classification': 27.8725, 'neural_augmentation': 0.1523, 'total_loss': 28.0249}, LR: [0.000995, 0.000995], Avg. batch load time: 0.116, Elapsed time: 11484.82
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 01:11:22 - [34m[1mLOGS   [0m - Epoch:   1 [   56941/ 1000000], loss: {'classification': 27.8652, 'neural_augmentation': 0.1521, 'total_loss': 28.0173}, LR: [0.000995, 0.000995], Avg. batch load time: 0.115, Elapsed time: 11700.71
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 01:15:02 - [34m[1mLOGS   [0m - Epoch:   1 [   57441/ 1000000], loss: {'classification': 27.8574, 'neural_augmentation': 0.1518, 'total_loss': 28.0092}, LR: [0.000994, 0.000994], Avg. batch load time: 0.115, Elapsed time: 11919.95
2024-07-16 01:19:01 - [34m[1mLOGS   [0m - Epoch:   1 [   57941/ 1000000], loss: {'classification': 27.851, 'neural_augmentation': 0.1515, 'total_loss': 28.0025}, LR: [0.000994, 0.000994], Avg. batch load time: 0.115, Elapsed time: 12159.36
2024-07-16 01:22:57 - [34m[1mLOGS   [0m - Epoch:   1 [   58441/ 1000000], loss: {'classification': 27.8441, 'neural_augmentation': 0.1512, 'total_loss': 27.9953}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 12395.74
2024-07-16 01:26:51 - [34m[1mLOGS   [0m - Epoch:   1 [   58941/ 1000000], loss: {'classification': 27.8366, 'neural_augmentation': 0.1509, 'total_loss': 27.9875}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 12629.02
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 01:30:42 - [34m[1mLOGS   [0m - Epoch:   1 [   59441/ 1000000], loss: {'classification': 27.8304, 'neural_augmentation': 0.1507, 'total_loss': 27.9811}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 12860.50
2024-07-16 01:34:30 - [34m[1mLOGS   [0m - Epoch:   1 [   59941/ 1000000], loss: {'classification': 27.824, 'neural_augmentation': 0.1505, 'total_loss': 27.9745}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 13088.40
2024-07-16 01:38:22 - [34m[1mLOGS   [0m - Epoch:   1 [   60441/ 1000000], loss: {'classification': 27.8169, 'neural_augmentation': 0.1502, 'total_loss': 27.967}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 13320.49
2024-07-16 01:42:09 - [34m[1mLOGS   [0m - Epoch:   1 [   60941/ 1000000], loss: {'classification': 27.8112, 'neural_augmentation': 0.1499, 'total_loss': 27.9611}, LR: [0.000994, 0.000994], Avg. batch load time: 0.116, Elapsed time: 13547.39
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 01:45:47 - [34m[1mLOGS   [0m - Epoch:   1 [   61441/ 1000000], loss: {'classification': 27.8055, 'neural_augmentation': 0.1497, 'total_loss': 27.9553}, LR: [0.000993, 0.000993], Avg. batch load time: 0.116, Elapsed time: 13765.34
2024-07-16 01:49:40 - [34m[1mLOGS   [0m - Epoch:   1 [   61941/ 1000000], loss: {'classification': 27.7981, 'neural_augmentation': 0.1495, 'total_loss': 27.9475}, LR: [0.000993, 0.000993], Avg. batch load time: 0.116, Elapsed time: 13998.84
2024-07-16 01:53:15 - [34m[1mLOGS   [0m - Epoch:   1 [   62441/ 1000000], loss: {'classification': 27.7902, 'neural_augmentation': 0.1492, 'total_loss': 27.9394}, LR: [0.000993, 0.000993], Avg. batch load time: 0.115, Elapsed time: 14213.69
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 01:57:22 - [34m[1mLOGS   [0m - Epoch:   1 [   62941/ 1000000], loss: {'classification': 27.7835, 'neural_augmentation': 0.149, 'total_loss': 27.9325}, LR: [0.000993, 0.000993], Avg. batch load time: 0.116, Elapsed time: 14459.94
2024-07-16 01:58:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 27.7799, 'neural_augmentation': 0.1489, 'total_loss': 27.9288}
2024-07-16 01:58:43 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_best.pt
2024-07-16 01:58:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_last.pt
2024-07-16 01:58:45 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_last.pt
2024-07-16 01:58:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 63169 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_epoch_1_iter_63169.pt
2024-07-16 01:58:46 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 63169 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_epoch_1_iter_63169.pt
[31m===========================================================================[0m
2024-07-16 01:58:48 - [32m[1mINFO   [0m - Training epoch 2
2024-07-16 02:00:04 - [34m[1mLOGS   [0m - Epoch:   2 [   63170/ 1000000], loss: {'classification': 27.8804, 'neural_augmentation': 0.1343, 'total_loss': 28.0146}, LR: [0.000993, 0.000993], Avg. batch load time: 75.862, Elapsed time: 76.14
2024-07-16 02:04:09 - [34m[1mLOGS   [0m - Epoch:   2 [   63670/ 1000000], loss: {'classification': 27.3815, 'neural_augmentation': 0.135, 'total_loss': 27.5165}, LR: [0.000993, 0.000993], Avg. batch load time: 0.312, Elapsed time: 320.95
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 02:07:57 - [34m[1mLOGS   [0m - Epoch:   2 [   64170/ 1000000], loss: {'classification': 27.3737, 'neural_augmentation': 0.1352, 'total_loss': 27.5089}, LR: [0.000993, 0.000993], Avg. batch load time: 0.212, Elapsed time: 548.86
2024-07-16 02:11:43 - [34m[1mLOGS   [0m - Epoch:   2 [   64670/ 1000000], loss: {'classification': 27.3525, 'neural_augmentation': 0.1349, 'total_loss': 27.4874}, LR: [0.000993, 0.000993], Avg. batch load time: 0.166, Elapsed time: 775.19
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 02:15:47 - [34m[1mLOGS   [0m - Epoch:   2 [   65170/ 1000000], loss: {'classification': 27.3787, 'neural_augmentation': 0.1347, 'total_loss': 27.5134}, LR: [0.000992, 0.000992], Avg. batch load time: 0.153, Elapsed time: 1019.23
2024-07-16 02:19:24 - [34m[1mLOGS   [0m - Epoch:   2 [   65670/ 1000000], loss: {'classification': 27.3739, 'neural_augmentation': 0.1345, 'total_loss': 27.5084}, LR: [0.000992, 0.000992], Avg. batch load time: 0.144, Elapsed time: 1236.69
2024-07-16 02:23:09 - [34m[1mLOGS   [0m - Epoch:   2 [   66170/ 1000000], loss: {'classification': 27.3854, 'neural_augmentation': 0.1345, 'total_loss': 27.52}, LR: [0.000992, 0.000992], Avg. batch load time: 0.136, Elapsed time: 1460.87
2024-07-16 02:26:59 - [34m[1mLOGS   [0m - Epoch:   2 [   66670/ 1000000], loss: {'classification': 27.3951, 'neural_augmentation': 0.1346, 'total_loss': 27.5297}, LR: [0.000992, 0.000992], Avg. batch load time: 0.138, Elapsed time: 1691.01
2024-07-16 02:30:34 - [34m[1mLOGS   [0m - Epoch:   2 [   67170/ 1000000], loss: {'classification': 27.3901, 'neural_augmentation': 0.1346, 'total_loss': 27.5247}, LR: [0.000992, 0.000992], Avg. batch load time: 0.130, Elapsed time: 1906.34
2024-07-16 02:34:14 - [34m[1mLOGS   [0m - Epoch:   2 [   67670/ 1000000], loss: {'classification': 27.3865, 'neural_augmentation': 0.1345, 'total_loss': 27.521}, LR: [0.000992, 0.000992], Avg. batch load time: 0.127, Elapsed time: 2126.47
2024-07-16 02:38:07 - [34m[1mLOGS   [0m - Epoch:   2 [   68170/ 1000000], loss: {'classification': 27.3889, 'neural_augmentation': 0.1344, 'total_loss': 27.5233}, LR: [0.000992, 0.000992], Avg. batch load time: 0.127, Elapsed time: 2359.68
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 02:41:51 - [34m[1mLOGS   [0m - Epoch:   2 [   68670/ 1000000], loss: {'classification': 27.385, 'neural_augmentation': 0.1344, 'total_loss': 27.5194}, LR: [0.000991, 0.000991], Avg. batch load time: 0.124, Elapsed time: 2583.70
2024-07-16 02:45:49 - [34m[1mLOGS   [0m - Epoch:   2 [   69170/ 1000000], loss: {'classification': 27.3831, 'neural_augmentation': 0.1343, 'total_loss': 27.5174}, LR: [0.000991, 0.000991], Avg. batch load time: 0.125, Elapsed time: 2821.06
2024-07-16 02:49:33 - [34m[1mLOGS   [0m - Epoch:   2 [   69670/ 1000000], loss: {'classification': 27.3768, 'neural_augmentation': 0.1342, 'total_loss': 27.511}, LR: [0.000991, 0.000991], Avg. batch load time: 0.124, Elapsed time: 3045.70
2024-07-16 02:53:36 - [34m[1mLOGS   [0m - Epoch:   2 [   70170/ 1000000], loss: {'classification': 27.374, 'neural_augmentation': 0.1341, 'total_loss': 27.5081}, LR: [0.000991, 0.000991], Avg. batch load time: 0.122, Elapsed time: 3288.38
2024-07-16 02:57:26 - [34m[1mLOGS   [0m - Epoch:   2 [   70670/ 1000000], loss: {'classification': 27.3721, 'neural_augmentation': 0.134, 'total_loss': 27.5061}, LR: [0.000991, 0.000991], Avg. batch load time: 0.124, Elapsed time: 3518.47
2024-07-16 03:01:08 - [34m[1mLOGS   [0m - Epoch:   2 [   71170/ 1000000], loss: {'classification': 27.37, 'neural_augmentation': 0.1339, 'total_loss': 27.5039}, LR: [0.000991, 0.000991], Avg. batch load time: 0.121, Elapsed time: 3740.73
2024-07-16 03:04:59 - [34m[1mLOGS   [0m - Epoch:   2 [   71670/ 1000000], loss: {'classification': 27.3686, 'neural_augmentation': 0.1338, 'total_loss': 27.5024}, LR: [0.000991, 0.000991], Avg. batch load time: 0.123, Elapsed time: 3971.26
2024-07-16 03:08:48 - [34m[1mLOGS   [0m - Epoch:   2 [   72170/ 1000000], loss: {'classification': 27.3644, 'neural_augmentation': 0.1337, 'total_loss': 27.4981}, LR: [0.00099, 0.00099], Avg. batch load time: 0.125, Elapsed time: 4199.79
2024-07-16 03:12:37 - [34m[1mLOGS   [0m - Epoch:   2 [   72670/ 1000000], loss: {'classification': 27.3635, 'neural_augmentation': 0.1336, 'total_loss': 27.4971}, LR: [0.00099, 0.00099], Avg. batch load time: 0.124, Elapsed time: 4429.76
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 03:16:25 - [34m[1mLOGS   [0m - Epoch:   2 [   73170/ 1000000], loss: {'classification': 27.3613, 'neural_augmentation': 0.1335, 'total_loss': 27.4948}, LR: [0.00099, 0.00099], Avg. batch load time: 0.124, Elapsed time: 4657.51
2024-07-16 03:20:10 - [34m[1mLOGS   [0m - Epoch:   2 [   73670/ 1000000], loss: {'classification': 27.3554, 'neural_augmentation': 0.1335, 'total_loss': 27.4888}, LR: [0.00099, 0.00099], Avg. batch load time: 0.123, Elapsed time: 4882.66
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 03:23:50 - [34m[1mLOGS   [0m - Epoch:   2 [   74170/ 1000000], loss: {'classification': 27.3503, 'neural_augmentation': 0.1334, 'total_loss': 27.4837}, LR: [0.00099, 0.00099], Avg. batch load time: 0.123, Elapsed time: 5101.84
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 03:27:46 - [34m[1mLOGS   [0m - Epoch:   2 [   74670/ 1000000], loss: {'classification': 27.348, 'neural_augmentation': 0.1333, 'total_loss': 27.4813}, LR: [0.00099, 0.00099], Avg. batch load time: 0.124, Elapsed time: 5338.31
2024-07-16 03:31:22 - [34m[1mLOGS   [0m - Epoch:   2 [   75170/ 1000000], loss: {'classification': 27.3425, 'neural_augmentation': 0.1333, 'total_loss': 27.4757}, LR: [0.000989, 0.000989], Avg. batch load time: 0.121, Elapsed time: 5554.10
2024-07-16 03:35:03 - [34m[1mLOGS   [0m - Epoch:   2 [   75670/ 1000000], loss: {'classification': 27.3396, 'neural_augmentation': 0.1332, 'total_loss': 27.4728}, LR: [0.000989, 0.000989], Avg. batch load time: 0.121, Elapsed time: 5775.39
2024-07-16 03:38:46 - [34m[1mLOGS   [0m - Epoch:   2 [   76170/ 1000000], loss: {'classification': 27.3368, 'neural_augmentation': 0.1331, 'total_loss': 27.4699}, LR: [0.000989, 0.000989], Avg. batch load time: 0.120, Elapsed time: 5997.88
2024-07-16 03:42:40 - [34m[1mLOGS   [0m - Epoch:   2 [   76670/ 1000000], loss: {'classification': 27.3334, 'neural_augmentation': 0.133, 'total_loss': 27.4665}, LR: [0.000989, 0.000989], Avg. batch load time: 0.121, Elapsed time: 6232.39
2024-07-16 03:46:19 - [34m[1mLOGS   [0m - Epoch:   2 [   77170/ 1000000], loss: {'classification': 27.3314, 'neural_augmentation': 0.133, 'total_loss': 27.4644}, LR: [0.000989, 0.000989], Avg. batch load time: 0.121, Elapsed time: 6451.49
2024-07-16 03:50:06 - [34m[1mLOGS   [0m - Epoch:   2 [   77670/ 1000000], loss: {'classification': 27.3286, 'neural_augmentation': 0.1329, 'total_loss': 27.4615}, LR: [0.000989, 0.000989], Avg. batch load time: 0.120, Elapsed time: 6678.23
2024-07-16 03:53:44 - [34m[1mLOGS   [0m - Epoch:   2 [   78170/ 1000000], loss: {'classification': 27.3286, 'neural_augmentation': 0.1329, 'total_loss': 27.4615}, LR: [0.000988, 0.000988], Avg. batch load time: 0.119, Elapsed time: 6896.16
2024-07-16 03:57:33 - [34m[1mLOGS   [0m - Epoch:   2 [   78670/ 1000000], loss: {'classification': 27.3261, 'neural_augmentation': 0.1328, 'total_loss': 27.4589}, LR: [0.000988, 0.000988], Avg. batch load time: 0.119, Elapsed time: 7125.35
2024-07-16 04:01:21 - [34m[1mLOGS   [0m - Epoch:   2 [   79170/ 1000000], loss: {'classification': 27.3234, 'neural_augmentation': 0.1327, 'total_loss': 27.4561}, LR: [0.000988, 0.000988], Avg. batch load time: 0.119, Elapsed time: 7353.51
2024-07-16 04:05:21 - [34m[1mLOGS   [0m - Epoch:   2 [   79670/ 1000000], loss: {'classification': 27.3194, 'neural_augmentation': 0.1327, 'total_loss': 27.452}, LR: [0.000988, 0.000988], Avg. batch load time: 0.120, Elapsed time: 7592.83
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 04:08:58 - [34m[1mLOGS   [0m - Epoch:   2 [   80170/ 1000000], loss: {'classification': 27.3179, 'neural_augmentation': 0.1326, 'total_loss': 27.4506}, LR: [0.000988, 0.000988], Avg. batch load time: 0.120, Elapsed time: 7810.47
2024-07-16 04:12:39 - [34m[1mLOGS   [0m - Epoch:   2 [   80670/ 1000000], loss: {'classification': 27.3159, 'neural_augmentation': 0.1326, 'total_loss': 27.4485}, LR: [0.000988, 0.000988], Avg. batch load time: 0.119, Elapsed time: 8030.87
2024-07-16 04:16:26 - [34m[1mLOGS   [0m - Epoch:   2 [   81170/ 1000000], loss: {'classification': 27.3124, 'neural_augmentation': 0.1325, 'total_loss': 27.4449}, LR: [0.000987, 0.000987], Avg. batch load time: 0.119, Elapsed time: 8258.14
2024-07-16 04:19:57 - [34m[1mLOGS   [0m - Epoch:   2 [   81670/ 1000000], loss: {'classification': 27.3106, 'neural_augmentation': 0.1325, 'total_loss': 27.4431}, LR: [0.000987, 0.000987], Avg. batch load time: 0.117, Elapsed time: 8468.92
2024-07-16 04:23:53 - [34m[1mLOGS   [0m - Epoch:   2 [   82170/ 1000000], loss: {'classification': 27.3096, 'neural_augmentation': 0.1324, 'total_loss': 27.442}, LR: [0.000987, 0.000987], Avg. batch load time: 0.118, Elapsed time: 8705.02
2024-07-16 04:27:39 - [34m[1mLOGS   [0m - Epoch:   2 [   82670/ 1000000], loss: {'classification': 27.3073, 'neural_augmentation': 0.1324, 'total_loss': 27.4397}, LR: [0.000987, 0.000987], Avg. batch load time: 0.117, Elapsed time: 8931.65
2024-07-16 04:31:12 - [34m[1mLOGS   [0m - Epoch:   2 [   83170/ 1000000], loss: {'classification': 27.3054, 'neural_augmentation': 0.1323, 'total_loss': 27.4378}, LR: [0.000987, 0.000987], Avg. batch load time: 0.116, Elapsed time: 9144.39
2024-07-16 04:35:02 - [34m[1mLOGS   [0m - Epoch:   2 [   83670/ 1000000], loss: {'classification': 27.3041, 'neural_augmentation': 0.1323, 'total_loss': 27.4363}, LR: [0.000987, 0.000987], Avg. batch load time: 0.116, Elapsed time: 9374.53
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 04:38:41 - [34m[1mLOGS   [0m - Epoch:   2 [   84170/ 1000000], loss: {'classification': 27.3029, 'neural_augmentation': 0.1322, 'total_loss': 27.4351}, LR: [0.000986, 0.000986], Avg. batch load time: 0.116, Elapsed time: 9593.65
2024-07-16 04:42:22 - [34m[1mLOGS   [0m - Epoch:   2 [   84670/ 1000000], loss: {'classification': 27.3018, 'neural_augmentation': 0.1322, 'total_loss': 27.434}, LR: [0.000986, 0.000986], Avg. batch load time: 0.115, Elapsed time: 9814.02
2024-07-16 04:45:59 - [34m[1mLOGS   [0m - Epoch:   2 [   85170/ 1000000], loss: {'classification': 27.3, 'neural_augmentation': 0.1321, 'total_loss': 27.4321}, LR: [0.000986, 0.000986], Avg. batch load time: 0.114, Elapsed time: 10031.54
2024-07-16 04:49:37 - [34m[1mLOGS   [0m - Epoch:   2 [   85670/ 1000000], loss: {'classification': 27.2988, 'neural_augmentation': 0.1321, 'total_loss': 27.4309}, LR: [0.000986, 0.000986], Avg. batch load time: 0.113, Elapsed time: 10249.47
2024-07-16 04:53:23 - [34m[1mLOGS   [0m - Epoch:   2 [   86170/ 1000000], loss: {'classification': 27.2965, 'neural_augmentation': 0.132, 'total_loss': 27.4285}, LR: [0.000986, 0.000986], Avg. batch load time: 0.114, Elapsed time: 10475.52
2024-07-16 04:56:59 - [34m[1mLOGS   [0m - Epoch:   2 [   86670/ 1000000], loss: {'classification': 27.294, 'neural_augmentation': 0.1319, 'total_loss': 27.426}, LR: [0.000985, 0.000985], Avg. batch load time: 0.114, Elapsed time: 10691.20
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 05:00:44 - [34m[1mLOGS   [0m - Epoch:   2 [   87170/ 1000000], loss: {'classification': 27.2929, 'neural_augmentation': 0.1319, 'total_loss': 27.4248}, LR: [0.000985, 0.000985], Avg. batch load time: 0.114, Elapsed time: 10916.49
2024-07-16 05:04:35 - [34m[1mLOGS   [0m - Epoch:   2 [   87670/ 1000000], loss: {'classification': 27.2905, 'neural_augmentation': 0.1318, 'total_loss': 27.4223}, LR: [0.000985, 0.000985], Avg. batch load time: 0.114, Elapsed time: 11146.92
2024-07-16 05:08:15 - [34m[1mLOGS   [0m - Epoch:   2 [   88170/ 1000000], loss: {'classification': 27.2887, 'neural_augmentation': 0.1318, 'total_loss': 27.4205}, LR: [0.000985, 0.000985], Avg. batch load time: 0.113, Elapsed time: 11367.40
2024-07-16 05:11:54 - [34m[1mLOGS   [0m - Epoch:   2 [   88670/ 1000000], loss: {'classification': 27.2861, 'neural_augmentation': 0.1318, 'total_loss': 27.4178}, LR: [0.000985, 0.000985], Avg. batch load time: 0.113, Elapsed time: 11586.31
2024-07-16 05:15:43 - [34m[1mLOGS   [0m - Epoch:   2 [   89170/ 1000000], loss: {'classification': 27.2855, 'neural_augmentation': 0.1317, 'total_loss': 27.4173}, LR: [0.000984, 0.000984], Avg. batch load time: 0.114, Elapsed time: 11815.45
2024-07-16 05:19:32 - [34m[1mLOGS   [0m - Epoch:   2 [   89670/ 1000000], loss: {'classification': 27.2848, 'neural_augmentation': 0.1317, 'total_loss': 27.4165}, LR: [0.000984, 0.000984], Avg. batch load time: 0.114, Elapsed time: 12044.61
2024-07-16 05:23:06 - [34m[1mLOGS   [0m - Epoch:   2 [   90170/ 1000000], loss: {'classification': 27.2825, 'neural_augmentation': 0.1316, 'total_loss': 27.4142}, LR: [0.000984, 0.000984], Avg. batch load time: 0.114, Elapsed time: 12258.16
2024-07-16 05:26:57 - [34m[1mLOGS   [0m - Epoch:   2 [   90670/ 1000000], loss: {'classification': 27.281, 'neural_augmentation': 0.1316, 'total_loss': 27.4126}, LR: [0.000984, 0.000984], Avg. batch load time: 0.114, Elapsed time: 12489.42
2024-07-16 05:30:45 - [34m[1mLOGS   [0m - Epoch:   2 [   91170/ 1000000], loss: {'classification': 27.2785, 'neural_augmentation': 0.1315, 'total_loss': 27.41}, LR: [0.000984, 0.000984], Avg. batch load time: 0.114, Elapsed time: 12717.16
2024-07-16 05:34:40 - [34m[1mLOGS   [0m - Epoch:   2 [   91670/ 1000000], loss: {'classification': 27.2766, 'neural_augmentation': 0.1315, 'total_loss': 27.4081}, LR: [0.000983, 0.000983], Avg. batch load time: 0.114, Elapsed time: 12952.10
2024-07-16 05:38:20 - [34m[1mLOGS   [0m - Epoch:   2 [   92170/ 1000000], loss: {'classification': 27.275, 'neural_augmentation': 0.1314, 'total_loss': 27.4064}, LR: [0.000983, 0.000983], Avg. batch load time: 0.114, Elapsed time: 13171.87
2024-07-16 05:42:10 - [34m[1mLOGS   [0m - Epoch:   2 [   92670/ 1000000], loss: {'classification': 27.2721, 'neural_augmentation': 0.1314, 'total_loss': 27.4035}, LR: [0.000983, 0.000983], Avg. batch load time: 0.115, Elapsed time: 13401.92
2024-07-16 05:46:04 - [34m[1mLOGS   [0m - Epoch:   2 [   93170/ 1000000], loss: {'classification': 27.2717, 'neural_augmentation': 0.1313, 'total_loss': 27.403}, LR: [0.000983, 0.000983], Avg. batch load time: 0.115, Elapsed time: 13636.79
2024-07-16 05:49:37 - [34m[1mLOGS   [0m - Epoch:   2 [   93670/ 1000000], loss: {'classification': 27.2699, 'neural_augmentation': 0.1313, 'total_loss': 27.4012}, LR: [0.000983, 0.000983], Avg. batch load time: 0.115, Elapsed time: 13849.54
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 05:53:21 - [34m[1mLOGS   [0m - Epoch:   2 [   94170/ 1000000], loss: {'classification': 27.268, 'neural_augmentation': 0.1313, 'total_loss': 27.3993}, LR: [0.000982, 0.000982], Avg. batch load time: 0.114, Elapsed time: 14073.12
2024-07-16 05:57:15 - [34m[1mLOGS   [0m - Epoch:   2 [   94670/ 1000000], loss: {'classification': 27.2661, 'neural_augmentation': 0.1312, 'total_loss': 27.3973}, LR: [0.000982, 0.000982], Avg. batch load time: 0.114, Elapsed time: 14307.12
2024-07-16 05:58:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 27.2655, 'neural_augmentation': 0.1312, 'total_loss': 27.3967}
2024-07-16 05:58:18 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_best.pt
2024-07-16 05:58:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_last.pt
2024-07-16 05:58:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_last.pt
2024-07-16 05:58:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 94829 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_epoch_2_iter_94829.pt
2024-07-16 05:58:21 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 94829 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_epoch_2_iter_94829.pt
[31m===========================================================================[0m
2024-07-16 05:58:23 - [32m[1mINFO   [0m - Training epoch 3
2024-07-16 05:59:39 - [34m[1mLOGS   [0m - Epoch:   3 [   94830/ 1000000], loss: {'classification': 26.1429, 'neural_augmentation': 0.1356, 'total_loss': 26.2785}, LR: [0.000982, 0.000982], Avg. batch load time: 75.429, Elapsed time: 75.98
2024-07-16 06:03:37 - [34m[1mLOGS   [0m - Epoch:   3 [   95330/ 1000000], loss: {'classification': 27.1153, 'neural_augmentation': 0.1287, 'total_loss': 27.2441}, LR: [0.000982, 0.000982], Avg. batch load time: 0.328, Elapsed time: 314.24
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 06:07:36 - [34m[1mLOGS   [0m - Epoch:   3 [   95830/ 1000000], loss: {'classification': 27.1785, 'neural_augmentation': 0.1287, 'total_loss': 27.3072}, LR: [0.000982, 0.000982], Avg. batch load time: 0.245, Elapsed time: 553.71
2024-07-16 06:11:13 - [34m[1mLOGS   [0m - Epoch:   3 [   96330/ 1000000], loss: {'classification': 27.1797, 'neural_augmentation': 0.1287, 'total_loss': 27.3084}, LR: [0.000982, 0.000982], Avg. batch load time: 0.191, Elapsed time: 770.34
2024-07-16 06:14:53 - [34m[1mLOGS   [0m - Epoch:   3 [   96830/ 1000000], loss: {'classification': 27.177, 'neural_augmentation': 0.1286, 'total_loss': 27.3057}, LR: [0.000981, 0.000981], Avg. batch load time: 0.173, Elapsed time: 990.66
2024-07-16 06:18:41 - [34m[1mLOGS   [0m - Epoch:   3 [   97330/ 1000000], loss: {'classification': 27.1669, 'neural_augmentation': 0.1286, 'total_loss': 27.2955}, LR: [0.000981, 0.000981], Avg. batch load time: 0.165, Elapsed time: 1218.67
2024-07-16 06:22:19 - [34m[1mLOGS   [0m - Epoch:   3 [   97830/ 1000000], loss: {'classification': 27.1626, 'neural_augmentation': 0.1286, 'total_loss': 27.2912}, LR: [0.000981, 0.000981], Avg. batch load time: 0.155, Elapsed time: 1435.86
2024-07-16 06:26:10 - [34m[1mLOGS   [0m - Epoch:   3 [   98330/ 1000000], loss: {'classification': 27.1622, 'neural_augmentation': 0.1285, 'total_loss': 27.2907}, LR: [0.000981, 0.000981], Avg. batch load time: 0.151, Elapsed time: 1666.97
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 06:29:55 - [34m[1mLOGS   [0m - Epoch:   3 [   98830/ 1000000], loss: {'classification': 27.1512, 'neural_augmentation': 0.1284, 'total_loss': 27.2796}, LR: [0.00098, 0.00098], Avg. batch load time: 0.146, Elapsed time: 1892.48
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 06:33:38 - [34m[1mLOGS   [0m - Epoch:   3 [   99330/ 1000000], loss: {'classification': 27.1495, 'neural_augmentation': 0.1284, 'total_loss': 27.2779}, LR: [0.00098, 0.00098], Avg. batch load time: 0.143, Elapsed time: 2115.36
2024-07-16 06:37:10 - [34m[1mLOGS   [0m - Epoch:   3 [   99830/ 1000000], loss: {'classification': 27.1445, 'neural_augmentation': 0.1284, 'total_loss': 27.2729}, LR: [0.00098, 0.00098], Avg. batch load time: 0.139, Elapsed time: 2327.34
2024-07-16 06:41:02 - [34m[1mLOGS   [0m - Epoch:   3 [  100330/ 1000000], loss: {'classification': 27.1387, 'neural_augmentation': 0.1284, 'total_loss': 27.2671}, LR: [0.00098, 0.00098], Avg. batch load time: 0.133, Elapsed time: 2559.25
2024-07-16 06:44:57 - [34m[1mLOGS   [0m - Epoch:   3 [  100830/ 1000000], loss: {'classification': 27.1403, 'neural_augmentation': 0.1284, 'total_loss': 27.2687}, LR: [0.00098, 0.00098], Avg. batch load time: 0.134, Elapsed time: 2794.10
2024-07-16 06:48:39 - [34m[1mLOGS   [0m - Epoch:   3 [  101330/ 1000000], loss: {'classification': 27.1395, 'neural_augmentation': 0.1283, 'total_loss': 27.2678}, LR: [0.000979, 0.000979], Avg. batch load time: 0.133, Elapsed time: 3016.03
2024-07-16 06:52:04 - [34m[1mLOGS   [0m - Epoch:   3 [  101830/ 1000000], loss: {'classification': 27.1376, 'neural_augmentation': 0.1283, 'total_loss': 27.266}, LR: [0.000979, 0.000979], Avg. batch load time: 0.128, Elapsed time: 3221.26
2024-07-16 06:55:56 - [34m[1mLOGS   [0m - Epoch:   3 [  102330/ 1000000], loss: {'classification': 27.1366, 'neural_augmentation': 0.1284, 'total_loss': 27.265}, LR: [0.000979, 0.000979], Avg. batch load time: 0.130, Elapsed time: 3452.83
2024-07-16 06:59:51 - [34m[1mLOGS   [0m - Epoch:   3 [  102830/ 1000000], loss: {'classification': 27.1333, 'neural_augmentation': 0.1283, 'total_loss': 27.2617}, LR: [0.000979, 0.000979], Avg. batch load time: 0.131, Elapsed time: 3688.31
2024-07-16 07:03:35 - [34m[1mLOGS   [0m - Epoch:   3 [  103330/ 1000000], loss: {'classification': 27.1355, 'neural_augmentation': 0.1283, 'total_loss': 27.2638}, LR: [0.000978, 0.000978], Avg. batch load time: 0.131, Elapsed time: 3912.02
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 07:07:08 - [34m[1mLOGS   [0m - Epoch:   3 [  103830/ 1000000], loss: {'classification': 27.1332, 'neural_augmentation': 0.1283, 'total_loss': 27.2615}, LR: [0.000978, 0.000978], Avg. batch load time: 0.127, Elapsed time: 4124.81
2024-07-16 07:10:53 - [34m[1mLOGS   [0m - Epoch:   3 [  104330/ 1000000], loss: {'classification': 27.1332, 'neural_augmentation': 0.1282, 'total_loss': 27.2614}, LR: [0.000978, 0.000978], Avg. batch load time: 0.126, Elapsed time: 4350.02
2024-07-16 07:14:42 - [34m[1mLOGS   [0m - Epoch:   3 [  104830/ 1000000], loss: {'classification': 27.1299, 'neural_augmentation': 0.1282, 'total_loss': 27.2581}, LR: [0.000978, 0.000978], Avg. batch load time: 0.126, Elapsed time: 4579.50
2024-07-16 07:18:50 - [34m[1mLOGS   [0m - Epoch:   3 [  105330/ 1000000], loss: {'classification': 27.1294, 'neural_augmentation': 0.1282, 'total_loss': 27.2576}, LR: [0.000978, 0.000978], Avg. batch load time: 0.125, Elapsed time: 4826.95
2024-07-16 07:22:28 - [34m[1mLOGS   [0m - Epoch:   3 [  105830/ 1000000], loss: {'classification': 27.1272, 'neural_augmentation': 0.1282, 'total_loss': 27.2554}, LR: [0.000977, 0.000977], Avg. batch load time: 0.125, Elapsed time: 5044.98
2024-07-16 07:25:47 - [34m[1mLOGS   [0m - Epoch:   3 [  106330/ 1000000], loss: {'classification': 27.125, 'neural_augmentation': 0.1281, 'total_loss': 27.2531}, LR: [0.000977, 0.000977], Avg. batch load time: 0.122, Elapsed time: 5244.32
2024-07-16 07:29:38 - [34m[1mLOGS   [0m - Epoch:   3 [  106830/ 1000000], loss: {'classification': 27.1234, 'neural_augmentation': 0.1281, 'total_loss': 27.2515}, LR: [0.000977, 0.000977], Avg. batch load time: 0.123, Elapsed time: 5475.27
2024-07-16 07:33:23 - [34m[1mLOGS   [0m - Epoch:   3 [  107330/ 1000000], loss: {'classification': 27.1232, 'neural_augmentation': 0.1281, 'total_loss': 27.2513}, LR: [0.000977, 0.000977], Avg. batch load time: 0.123, Elapsed time: 5700.72
2024-07-16 07:37:03 - [34m[1mLOGS   [0m - Epoch:   3 [  107830/ 1000000], loss: {'classification': 27.1218, 'neural_augmentation': 0.1281, 'total_loss': 27.2499}, LR: [0.000976, 0.000976], Avg. batch load time: 0.123, Elapsed time: 5920.68
2024-07-16 07:40:51 - [34m[1mLOGS   [0m - Epoch:   3 [  108330/ 1000000], loss: {'classification': 27.1196, 'neural_augmentation': 0.1281, 'total_loss': 27.2477}, LR: [0.000976, 0.000976], Avg. batch load time: 0.122, Elapsed time: 6148.45
2024-07-16 07:44:27 - [34m[1mLOGS   [0m - Epoch:   3 [  108830/ 1000000], loss: {'classification': 27.1212, 'neural_augmentation': 0.1281, 'total_loss': 27.2494}, LR: [0.000976, 0.000976], Avg. batch load time: 0.121, Elapsed time: 6364.50
2024-07-16 07:48:26 - [34m[1mLOGS   [0m - Epoch:   3 [  109330/ 1000000], loss: {'classification': 27.1191, 'neural_augmentation': 0.1281, 'total_loss': 27.2472}, LR: [0.000976, 0.000976], Avg. batch load time: 0.121, Elapsed time: 6603.55
2024-07-16 07:52:02 - [34m[1mLOGS   [0m - Epoch:   3 [  109830/ 1000000], loss: {'classification': 27.1194, 'neural_augmentation': 0.1281, 'total_loss': 27.2474}, LR: [0.000975, 0.000975], Avg. batch load time: 0.121, Elapsed time: 6819.36
2024-07-16 07:56:05 - [34m[1mLOGS   [0m - Epoch:   3 [  110330/ 1000000], loss: {'classification': 27.1161, 'neural_augmentation': 0.128, 'total_loss': 27.2442}, LR: [0.000975, 0.000975], Avg. batch load time: 0.122, Elapsed time: 7062.02
2024-07-16 08:00:02 - [34m[1mLOGS   [0m - Epoch:   3 [  110830/ 1000000], loss: {'classification': 27.1149, 'neural_augmentation': 0.128, 'total_loss': 27.243}, LR: [0.000975, 0.000975], Avg. batch load time: 0.122, Elapsed time: 7299.38
2024-07-16 08:03:54 - [34m[1mLOGS   [0m - Epoch:   3 [  111330/ 1000000], loss: {'classification': 27.113, 'neural_augmentation': 0.128, 'total_loss': 27.241}, LR: [0.000975, 0.000975], Avg. batch load time: 0.124, Elapsed time: 7531.03
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 08:07:39 - [34m[1mLOGS   [0m - Epoch:   3 [  111830/ 1000000], loss: {'classification': 27.1131, 'neural_augmentation': 0.128, 'total_loss': 27.2411}, LR: [0.000974, 0.000974], Avg. batch load time: 0.123, Elapsed time: 7756.29
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 08:11:24 - [34m[1mLOGS   [0m - Epoch:   3 [  112330/ 1000000], loss: {'classification': 27.1109, 'neural_augmentation': 0.128, 'total_loss': 27.2389}, LR: [0.000974, 0.000974], Avg. batch load time: 0.122, Elapsed time: 7981.42
2024-07-16 08:15:04 - [34m[1mLOGS   [0m - Epoch:   3 [  112830/ 1000000], loss: {'classification': 27.1086, 'neural_augmentation': 0.128, 'total_loss': 27.2366}, LR: [0.000974, 0.000974], Avg. batch load time: 0.121, Elapsed time: 8201.07
2024-07-16 08:18:56 - [34m[1mLOGS   [0m - Epoch:   3 [  113330/ 1000000], loss: {'classification': 27.1058, 'neural_augmentation': 0.128, 'total_loss': 27.2337}, LR: [0.000974, 0.000974], Avg. batch load time: 0.121, Elapsed time: 8433.50
2024-07-16 08:23:12 - [34m[1mLOGS   [0m - Epoch:   3 [  113830/ 1000000], loss: {'classification': 27.1034, 'neural_augmentation': 0.1279, 'total_loss': 27.2314}, LR: [0.000973, 0.000973], Avg. batch load time: 0.123, Elapsed time: 8689.10
2024-07-16 08:27:30 - [34m[1mLOGS   [0m - Epoch:   3 [  114330/ 1000000], loss: {'classification': 27.1015, 'neural_augmentation': 0.1279, 'total_loss': 27.2294}, LR: [0.000973, 0.000973], Avg. batch load time: 0.123, Elapsed time: 8947.51
2024-07-16 08:31:37 - [34m[1mLOGS   [0m - Epoch:   3 [  114830/ 1000000], loss: {'classification': 27.0997, 'neural_augmentation': 0.1279, 'total_loss': 27.2276}, LR: [0.000973, 0.000973], Avg. batch load time: 0.124, Elapsed time: 9194.74
2024-07-16 08:35:48 - [34m[1mLOGS   [0m - Epoch:   3 [  115330/ 1000000], loss: {'classification': 27.0993, 'neural_augmentation': 0.1279, 'total_loss': 27.2272}, LR: [0.000973, 0.000973], Avg. batch load time: 0.124, Elapsed time: 9445.24
2024-07-16 08:40:03 - [34m[1mLOGS   [0m - Epoch:   3 [  115830/ 1000000], loss: {'classification': 27.0999, 'neural_augmentation': 0.1279, 'total_loss': 27.2278}, LR: [0.000972, 0.000972], Avg. batch load time: 0.125, Elapsed time: 9700.37
2024-07-16 08:44:13 - [34m[1mLOGS   [0m - Epoch:   3 [  116330/ 1000000], loss: {'classification': 27.0994, 'neural_augmentation': 0.1279, 'total_loss': 27.2272}, LR: [0.000972, 0.000972], Avg. batch load time: 0.126, Elapsed time: 9950.44
2024-07-16 08:48:04 - [34m[1mLOGS   [0m - Epoch:   3 [  116830/ 1000000], loss: {'classification': 27.0976, 'neural_augmentation': 0.1279, 'total_loss': 27.2254}, LR: [0.000972, 0.000972], Avg. batch load time: 0.126, Elapsed time: 10181.21
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 08:52:31 - [34m[1mLOGS   [0m - Epoch:   3 [  117330/ 1000000], loss: {'classification': 27.0977, 'neural_augmentation': 0.1279, 'total_loss': 27.2256}, LR: [0.000972, 0.000972], Avg. batch load time: 0.127, Elapsed time: 10448.69
2024-07-16 08:56:26 - [34m[1mLOGS   [0m - Epoch:   3 [  117830/ 1000000], loss: {'classification': 27.0972, 'neural_augmentation': 0.1279, 'total_loss': 27.225}, LR: [0.000971, 0.000971], Avg. batch load time: 0.127, Elapsed time: 10683.52
2024-07-16 09:00:28 - [34m[1mLOGS   [0m - Epoch:   3 [  118330/ 1000000], loss: {'classification': 27.0955, 'neural_augmentation': 0.1279, 'total_loss': 27.2234}, LR: [0.000971, 0.000971], Avg. batch load time: 0.128, Elapsed time: 10925.10
2024-07-16 09:04:34 - [34m[1mLOGS   [0m - Epoch:   3 [  118830/ 1000000], loss: {'classification': 27.0947, 'neural_augmentation': 0.1279, 'total_loss': 27.2225}, LR: [0.000971, 0.000971], Avg. batch load time: 0.128, Elapsed time: 11171.47
2024-07-16 09:08:36 - [34m[1mLOGS   [0m - Epoch:   3 [  119330/ 1000000], loss: {'classification': 27.0937, 'neural_augmentation': 0.1279, 'total_loss': 27.2216}, LR: [0.000971, 0.000971], Avg. batch load time: 0.128, Elapsed time: 11413.16
2024-07-16 09:12:54 - [34m[1mLOGS   [0m - Epoch:   3 [  119830/ 1000000], loss: {'classification': 27.0927, 'neural_augmentation': 0.1278, 'total_loss': 27.2206}, LR: [0.00097, 0.00097], Avg. batch load time: 0.129, Elapsed time: 11671.41
2024-07-16 09:16:56 - [34m[1mLOGS   [0m - Epoch:   3 [  120330/ 1000000], loss: {'classification': 27.0922, 'neural_augmentation': 0.1278, 'total_loss': 27.2201}, LR: [0.00097, 0.00097], Avg. batch load time: 0.129, Elapsed time: 11913.37
2024-07-16 09:21:25 - [34m[1mLOGS   [0m - Epoch:   3 [  120830/ 1000000], loss: {'classification': 27.091, 'neural_augmentation': 0.1278, 'total_loss': 27.2188}, LR: [0.00097, 0.00097], Avg. batch load time: 0.130, Elapsed time: 12182.72
2024-07-16 09:25:32 - [34m[1mLOGS   [0m - Epoch:   3 [  121330/ 1000000], loss: {'classification': 27.0901, 'neural_augmentation': 0.1278, 'total_loss': 27.2179}, LR: [0.000969, 0.000969], Avg. batch load time: 0.129, Elapsed time: 12429.69
2024-07-16 09:29:44 - [34m[1mLOGS   [0m - Epoch:   3 [  121830/ 1000000], loss: {'classification': 27.0881, 'neural_augmentation': 0.1278, 'total_loss': 27.216}, LR: [0.000969, 0.000969], Avg. batch load time: 0.131, Elapsed time: 12681.19
2024-07-16 09:33:59 - [34m[1mLOGS   [0m - Epoch:   3 [  122330/ 1000000], loss: {'classification': 27.0877, 'neural_augmentation': 0.1278, 'total_loss': 27.2155}, LR: [0.000969, 0.000969], Avg. batch load time: 0.131, Elapsed time: 12936.48
2024-07-16 09:38:03 - [34m[1mLOGS   [0m - Epoch:   3 [  122830/ 1000000], loss: {'classification': 27.0882, 'neural_augmentation': 0.1278, 'total_loss': 27.216}, LR: [0.000969, 0.000969], Avg. batch load time: 0.131, Elapsed time: 13180.12
2024-07-16 09:42:24 - [34m[1mLOGS   [0m - Epoch:   3 [  123330/ 1000000], loss: {'classification': 27.0865, 'neural_augmentation': 0.1278, 'total_loss': 27.2143}, LR: [0.000968, 0.000968], Avg. batch load time: 0.131, Elapsed time: 13440.82
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 09:46:27 - [34m[1mLOGS   [0m - Epoch:   3 [  123830/ 1000000], loss: {'classification': 27.0854, 'neural_augmentation': 0.1278, 'total_loss': 27.2132}, LR: [0.000968, 0.000968], Avg. batch load time: 0.131, Elapsed time: 13684.39
2024-07-16 09:50:30 - [34m[1mLOGS   [0m - Epoch:   3 [  124330/ 1000000], loss: {'classification': 27.0839, 'neural_augmentation': 0.1278, 'total_loss': 27.2118}, LR: [0.000968, 0.000968], Avg. batch load time: 0.131, Elapsed time: 13927.23
2024-07-16 09:54:30 - [34m[1mLOGS   [0m - Epoch:   3 [  124830/ 1000000], loss: {'classification': 27.0844, 'neural_augmentation': 0.1278, 'total_loss': 27.2122}, LR: [0.000968, 0.000968], Avg. batch load time: 0.132, Elapsed time: 14166.85
2024-07-16 09:58:38 - [34m[1mLOGS   [0m - Epoch:   3 [  125330/ 1000000], loss: {'classification': 27.084, 'neural_augmentation': 0.1278, 'total_loss': 27.2118}, LR: [0.000967, 0.000967], Avg. batch load time: 0.132, Elapsed time: 14415.56
2024-07-16 10:02:25 - [34m[1mLOGS   [0m - Epoch:   3 [  125830/ 1000000], loss: {'classification': 27.0837, 'neural_augmentation': 0.1278, 'total_loss': 27.2115}, LR: [0.000967, 0.000967], Avg. batch load time: 0.131, Elapsed time: 14642.13
2024-07-16 10:06:51 - [34m[1mLOGS   [0m - Epoch:   3 [  126330/ 1000000], loss: {'classification': 27.0827, 'neural_augmentation': 0.1278, 'total_loss': 27.2105}, LR: [0.000967, 0.000967], Avg. batch load time: 0.132, Elapsed time: 14907.91
2024-07-16 10:07:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 27.0817, 'neural_augmentation': 0.1278, 'total_loss': 27.2095}
2024-07-16 10:07:52 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_best.pt
2024-07-16 10:07:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_last.pt
2024-07-16 10:07:54 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_last.pt
2024-07-16 10:07:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 126502 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/training_checkpoint_epoch_3_iter_126502.pt
2024-07-16 10:07:55 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 126502 is saved at: /ML-A100/team/mm/models/catlip_data/results500_dci/train/checkpoint_epoch_3_iter_126502.pt
[31m===========================================================================[0m
2024-07-16 10:07:57 - [32m[1mINFO   [0m - Training epoch 4
2024-07-16 10:09:11 - [34m[1mLOGS   [0m - Epoch:   4 [  126503/ 1000000], loss: {'classification': 25.3253, 'neural_augmentation': 0.1191, 'total_loss': 25.4443}, LR: [0.000967, 0.000967], Avg. batch load time: 73.231, Elapsed time: 73.84
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 10:13:46 - [34m[1mLOGS   [0m - Epoch:   4 [  127003/ 1000000], loss: {'classification': 26.9663, 'neural_augmentation': 0.1274, 'total_loss': 27.0937}, LR: [0.000966, 0.000966], Avg. batch load time: 0.410, Elapsed time: 348.94
2024-07-16 10:17:44 - [34m[1mLOGS   [0m - Epoch:   4 [  127503/ 1000000], loss: {'classification': 26.9699, 'neural_augmentation': 0.1274, 'total_loss': 27.0973}, LR: [0.000966, 0.000966], Avg. batch load time: 0.276, Elapsed time: 586.47
2024-07-16 10:21:42 - [34m[1mLOGS   [0m - Epoch:   4 [  128003/ 1000000], loss: {'classification': 26.9987, 'neural_augmentation': 0.1276, 'total_loss': 27.1263}, LR: [0.000966, 0.000966], Avg. batch load time: 0.224, Elapsed time: 824.75
2024-07-16 10:25:52 - [34m[1mLOGS   [0m - Epoch:   4 [  128503/ 1000000], loss: {'classification': 27.0087, 'neural_augmentation': 0.1277, 'total_loss': 27.1363}, LR: [0.000965, 0.000965], Avg. batch load time: 0.212, Elapsed time: 1074.14
2024-07-16 10:30:07 - [34m[1mLOGS   [0m - Epoch:   4 [  129003/ 1000000], loss: {'classification': 27.0167, 'neural_augmentation': 0.1276, 'total_loss': 27.1443}, LR: [0.000965, 0.000965], Avg. batch load time: 0.201, Elapsed time: 1329.53
2024-07-16 10:34:10 - [34m[1mLOGS   [0m - Epoch:   4 [  129503/ 1000000], loss: {'classification': 27.0127, 'neural_augmentation': 0.1275, 'total_loss': 27.1402}, LR: [0.000965, 0.000965], Avg. batch load time: 0.192, Elapsed time: 1572.10
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 10:38:24 - [34m[1mLOGS   [0m - Epoch:   4 [  130003/ 1000000], loss: {'classification': 27.009, 'neural_augmentation': 0.1275, 'total_loss': 27.1365}, LR: [0.000965, 0.000965], Avg. batch load time: 0.190, Elapsed time: 1826.41
2024-07-16 10:42:24 - [34m[1mLOGS   [0m - Epoch:   4 [  130503/ 1000000], loss: {'classification': 27.0027, 'neural_augmentation': 0.1274, 'total_loss': 27.1301}, LR: [0.000964, 0.000964], Avg. batch load time: 0.182, Elapsed time: 2066.50
2024-07-16 10:46:33 - [34m[1mLOGS   [0m - Epoch:   4 [  131003/ 1000000], loss: {'classification': 27.0048, 'neural_augmentation': 0.1275, 'total_loss': 27.1322}, LR: [0.000964, 0.000964], Avg. batch load time: 0.182, Elapsed time: 2315.73
2024-07-16 10:50:49 - [34m[1mLOGS   [0m - Epoch:   4 [  131503/ 1000000], loss: {'classification': 26.9989, 'neural_augmentation': 0.1274, 'total_loss': 27.1264}, LR: [0.000964, 0.000964], Avg. batch load time: 0.178, Elapsed time: 2571.07
2024-07-16 10:55:08 - [34m[1mLOGS   [0m - Epoch:   4 [  132003/ 1000000], loss: {'classification': 26.9958, 'neural_augmentation': 0.1275, 'total_loss': 27.1232}, LR: [0.000963, 0.000963], Avg. batch load time: 0.175, Elapsed time: 2830.67
2024-07-16 10:59:24 - [34m[1mLOGS   [0m - Epoch:   4 [  132503/ 1000000], loss: {'classification': 26.9955, 'neural_augmentation': 0.1275, 'total_loss': 27.123}, LR: [0.000963, 0.000963], Avg. batch load time: 0.175, Elapsed time: 3086.17
2024-07-16 11:03:26 - [34m[1mLOGS   [0m - Epoch:   4 [  133003/ 1000000], loss: {'classification': 26.9932, 'neural_augmentation': 0.1275, 'total_loss': 27.1206}, LR: [0.000963, 0.000963], Avg. batch load time: 0.172, Elapsed time: 3328.34
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 11:07:41 - [34m[1mLOGS   [0m - Epoch:   4 [  133503/ 1000000], loss: {'classification': 26.9938, 'neural_augmentation': 0.1275, 'total_loss': 27.1213}, LR: [0.000962, 0.000962], Avg. batch load time: 0.169, Elapsed time: 3583.09
Terminated
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
    with _resource_sharer.get_connection(self._id) as conn:
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 509, in Client
    answer_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 752, in answer_challenge
    deliver_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 740, in deliver_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    response = connection.recv_bytes(256)        # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
ConnectionResetError: [Errno 104] Connection reset by peer
Exception in thread Thread-1 (_pin_memory_loop):
Traceback (most recent call last):
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 53, in _pin_memory_loop
    do_one_step()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 30, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 752, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
2024-07-16 11:10:32 - [34m[1mLOGS   [0m - Keyboard interruption. Exiting from early training
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
