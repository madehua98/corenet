nohup: å¿½ç•¥è¾“å…¥
2024-06-06 18:04:49 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
2024-06-06 18:04:50 - [32m[1mINFO   [0m - Trainable parameters: ['cls_token', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-06-06 18:04:50 - [34m[1mLOGS   [0m - [36mModel[0m
VisionTransformer(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_emb): Sequential(
    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
    (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
    (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
  )
  (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
  (transformer): Sequential(
    (0): FlashTransformerEncoder
    (1): FlashTransformerEncoder
    (2): FlashTransformerEncoder
    (3): FlashTransformerEncoder
    (4): FlashTransformerEncoder
    (5): FlashTransformerEncoder
    (6): FlashTransformerEncoder
    (7): FlashTransformerEncoder
    (8): FlashTransformerEncoder
    (9): FlashTransformerEncoder
    (10): FlashTransformerEncoder
    (11): FlashTransformerEncoder
  )
  (classifier): LinearLayer(in_features=768, out_features=24320, bias=True, channel_first=False)
  (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
  (emb_dropout): Dropout(p=0.0, inplace=False)
)
[31m=================================================================[0m
                  VisionTransformer Summary
[31m=================================================================[0m
Total parameters     =  104.657 M
Total trainable parameters =  104.657 M

2024-06-06 18:04:50 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-06-06 18:04:50 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.105G                 | 17.031G    |
|  cls_token                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_emb                           |  0.748M                |  0.262G    |
|   patch_emb.0.block                  |   9.6K                 |   30.106M  |
|    patch_emb.0.block.conv            |    9.216K              |    28.901M |
|    patch_emb.0.block.norm            |    0.384K              |    1.204M  |
|   patch_emb.1.block                  |   0.148M               |   0.116G   |
|    patch_emb.1.block.conv            |    0.147M              |    0.116G  |
|    patch_emb.1.block.norm            |    0.384K              |    0.301M  |
|   patch_emb.2.block.conv             |   0.591M               |   0.116G   |
|    patch_emb.2.block.conv.weight     |    (768, 192, 2, 2)    |            |
|    patch_emb.2.block.conv.bias       |    (768,)              |            |
|  post_transformer_norm               |  1.536K                |  0.756M    |
|   post_transformer_norm.weight       |   (768,)               |            |
|   post_transformer_norm.bias         |   (768,)               |            |
|  transformer                         |  85.054M               |  16.75G    |
|   transformer.0                      |   7.088M               |   1.396G   |
|    transformer.0.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.0.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.1                      |   7.088M               |   1.396G   |
|    transformer.1.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.1.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.2                      |   7.088M               |   1.396G   |
|    transformer.2.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.2.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.3                      |   7.088M               |   1.396G   |
|    transformer.3.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.3.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.4                      |   7.088M               |   1.396G   |
|    transformer.4.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.4.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.5                      |   7.088M               |   1.396G   |
|    transformer.5.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.5.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.6                      |   7.088M               |   1.396G   |
|    transformer.6.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.6.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.7                      |   7.088M               |   1.396G   |
|    transformer.7.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.7.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.8                      |   7.088M               |   1.396G   |
|    transformer.8.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.8.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.9                      |   7.088M               |   1.396G   |
|    transformer.9.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.9.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.10                     |   7.088M               |   1.396G   |
|    transformer.10.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.10.pre_norm_ffn       |    4.724M              |    0.93G   |
|   transformer.11                     |   7.088M               |   1.396G   |
|    transformer.11.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.11.pre_norm_ffn       |    4.724M              |    0.93G   |
|  classifier                          |  18.702M               |  18.678M   |
|   classifier.weight                  |   (24320, 768)         |            |
|   classifier.bias                    |   (24320,)             |            |
|  pos_embed.pos_embed                 |  0.151M                |  0         |
|   pos_embed.pos_embed.pos_embed      |   (1, 1, 196, 768)     |            |
2024-06-06 18:04:51 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-06-06 18:04:51 - [33m[1mWARNING[0m - Uncalled Modules:
{'neural_augmentor.brightness', 'transformer.10.drop_path', 'neural_augmentor.contrast.max_fn', 'transformer.0.drop_path', 'neural_augmentor.contrast.min_fn', 'transformer.6.drop_path', 'neural_augmentor.contrast', 'transformer.8.drop_path', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.noise.min_fn', 'neural_augmentor.brightness.max_fn', 'transformer.7.drop_path', 'transformer.3.drop_path', 'neural_augmentor.noise', 'transformer.5.drop_path', 'transformer.9.drop_path', 'transformer.2.drop_path', 'neural_augmentor.noise.max_fn', 'transformer.1.drop_path', 'transformer.11.drop_path', 'neural_augmentor', 'transformer.4.drop_path'}
2024-06-06 18:04:51 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 14, 'aten::scaled_dot_product_attention': 12, 'aten::sub': 1})
[31m=================================================================[0m
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - Available GPUs: 2
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - Directory exists at: results_catlip/train
2024-06-06 18:04:51 - [34m[1mLOGS   [0m - Setting dataset.workers to 56.
2024-06-06 18:04:55 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://127.0.0.1:2345
2024-06-06 18:04:56 - [34m[1mLOGS   [0m - Training dataset details are given below
WordnetTaggedClassificationDataset(
	root= 
	is_training=True 
	num_samples=1040000
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	total_tar_files=104
	max_files_per_tar=10000
	num_synsets=24320
)
2024-06-06 18:04:56 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=True
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=512
	 scales=[(128, 128, 1568), (144, 144, 1238), (160, 160, 1003), (176, 176, 829), (192, 192, 696), (208, 208, 593), (224, 224, 512), (240, 240, 446), (256, 256, 392), (272, 272, 347), (288, 288, 309), (304, 304, 277), (320, 320, 250)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-06-06 18:04:56 - [34m[1mLOGS   [0m - Number of data workers: 56
2024-06-06 18:04:57 - [32m[1mINFO   [0m - Trainable parameters: ['cls_token', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_emb.0.block.conv.weight', 'patch_emb.0.block.norm.weight', 'patch_emb.0.block.norm.bias', 'patch_emb.1.block.conv.weight', 'patch_emb.1.block.norm.weight', 'patch_emb.1.block.norm.bias', 'patch_emb.2.block.conv.weight', 'patch_emb.2.block.conv.bias', 'post_transformer_norm.weight', 'post_transformer_norm.bias', 'transformer.0.pre_norm_mha.0.weight', 'transformer.0.pre_norm_mha.0.bias', 'transformer.0.pre_norm_mha.1.qkv_proj.weight', 'transformer.0.pre_norm_mha.1.qkv_proj.bias', 'transformer.0.pre_norm_mha.1.out_proj_attn.weight', 'transformer.0.pre_norm_mha.1.out_proj_attn.bias', 'transformer.0.pre_norm_ffn.0.weight', 'transformer.0.pre_norm_ffn.0.bias', 'transformer.0.pre_norm_ffn.1.weight', 'transformer.0.pre_norm_ffn.1.bias', 'transformer.0.pre_norm_ffn.4.weight', 'transformer.0.pre_norm_ffn.4.bias', 'transformer.1.pre_norm_mha.0.weight', 'transformer.1.pre_norm_mha.0.bias', 'transformer.1.pre_norm_mha.1.qkv_proj.weight', 'transformer.1.pre_norm_mha.1.qkv_proj.bias', 'transformer.1.pre_norm_mha.1.out_proj_attn.weight', 'transformer.1.pre_norm_mha.1.out_proj_attn.bias', 'transformer.1.pre_norm_ffn.0.weight', 'transformer.1.pre_norm_ffn.0.bias', 'transformer.1.pre_norm_ffn.1.weight', 'transformer.1.pre_norm_ffn.1.bias', 'transformer.1.pre_norm_ffn.4.weight', 'transformer.1.pre_norm_ffn.4.bias', 'transformer.2.pre_norm_mha.0.weight', 'transformer.2.pre_norm_mha.0.bias', 'transformer.2.pre_norm_mha.1.qkv_proj.weight', 'transformer.2.pre_norm_mha.1.qkv_proj.bias', 'transformer.2.pre_norm_mha.1.out_proj_attn.weight', 'transformer.2.pre_norm_mha.1.out_proj_attn.bias', 'transformer.2.pre_norm_ffn.0.weight', 'transformer.2.pre_norm_ffn.0.bias', 'transformer.2.pre_norm_ffn.1.weight', 'transformer.2.pre_norm_ffn.1.bias', 'transformer.2.pre_norm_ffn.4.weight', 'transformer.2.pre_norm_ffn.4.bias', 'transformer.3.pre_norm_mha.0.weight', 'transformer.3.pre_norm_mha.0.bias', 'transformer.3.pre_norm_mha.1.qkv_proj.weight', 'transformer.3.pre_norm_mha.1.qkv_proj.bias', 'transformer.3.pre_norm_mha.1.out_proj_attn.weight', 'transformer.3.pre_norm_mha.1.out_proj_attn.bias', 'transformer.3.pre_norm_ffn.0.weight', 'transformer.3.pre_norm_ffn.0.bias', 'transformer.3.pre_norm_ffn.1.weight', 'transformer.3.pre_norm_ffn.1.bias', 'transformer.3.pre_norm_ffn.4.weight', 'transformer.3.pre_norm_ffn.4.bias', 'transformer.4.pre_norm_mha.0.weight', 'transformer.4.pre_norm_mha.0.bias', 'transformer.4.pre_norm_mha.1.qkv_proj.weight', 'transformer.4.pre_norm_mha.1.qkv_proj.bias', 'transformer.4.pre_norm_mha.1.out_proj_attn.weight', 'transformer.4.pre_norm_mha.1.out_proj_attn.bias', 'transformer.4.pre_norm_ffn.0.weight', 'transformer.4.pre_norm_ffn.0.bias', 'transformer.4.pre_norm_ffn.1.weight', 'transformer.4.pre_norm_ffn.1.bias', 'transformer.4.pre_norm_ffn.4.weight', 'transformer.4.pre_norm_ffn.4.bias', 'transformer.5.pre_norm_mha.0.weight', 'transformer.5.pre_norm_mha.0.bias', 'transformer.5.pre_norm_mha.1.qkv_proj.weight', 'transformer.5.pre_norm_mha.1.qkv_proj.bias', 'transformer.5.pre_norm_mha.1.out_proj_attn.weight', 'transformer.5.pre_norm_mha.1.out_proj_attn.bias', 'transformer.5.pre_norm_ffn.0.weight', 'transformer.5.pre_norm_ffn.0.bias', 'transformer.5.pre_norm_ffn.1.weight', 'transformer.5.pre_norm_ffn.1.bias', 'transformer.5.pre_norm_ffn.4.weight', 'transformer.5.pre_norm_ffn.4.bias', 'transformer.6.pre_norm_mha.0.weight', 'transformer.6.pre_norm_mha.0.bias', 'transformer.6.pre_norm_mha.1.qkv_proj.weight', 'transformer.6.pre_norm_mha.1.qkv_proj.bias', 'transformer.6.pre_norm_mha.1.out_proj_attn.weight', 'transformer.6.pre_norm_mha.1.out_proj_attn.bias', 'transformer.6.pre_norm_ffn.0.weight', 'transformer.6.pre_norm_ffn.0.bias', 'transformer.6.pre_norm_ffn.1.weight', 'transformer.6.pre_norm_ffn.1.bias', 'transformer.6.pre_norm_ffn.4.weight', 'transformer.6.pre_norm_ffn.4.bias', 'transformer.7.pre_norm_mha.0.weight', 'transformer.7.pre_norm_mha.0.bias', 'transformer.7.pre_norm_mha.1.qkv_proj.weight', 'transformer.7.pre_norm_mha.1.qkv_proj.bias', 'transformer.7.pre_norm_mha.1.out_proj_attn.weight', 'transformer.7.pre_norm_mha.1.out_proj_attn.bias', 'transformer.7.pre_norm_ffn.0.weight', 'transformer.7.pre_norm_ffn.0.bias', 'transformer.7.pre_norm_ffn.1.weight', 'transformer.7.pre_norm_ffn.1.bias', 'transformer.7.pre_norm_ffn.4.weight', 'transformer.7.pre_norm_ffn.4.bias', 'transformer.8.pre_norm_mha.0.weight', 'transformer.8.pre_norm_mha.0.bias', 'transformer.8.pre_norm_mha.1.qkv_proj.weight', 'transformer.8.pre_norm_mha.1.qkv_proj.bias', 'transformer.8.pre_norm_mha.1.out_proj_attn.weight', 'transformer.8.pre_norm_mha.1.out_proj_attn.bias', 'transformer.8.pre_norm_ffn.0.weight', 'transformer.8.pre_norm_ffn.0.bias', 'transformer.8.pre_norm_ffn.1.weight', 'transformer.8.pre_norm_ffn.1.bias', 'transformer.8.pre_norm_ffn.4.weight', 'transformer.8.pre_norm_ffn.4.bias', 'transformer.9.pre_norm_mha.0.weight', 'transformer.9.pre_norm_mha.0.bias', 'transformer.9.pre_norm_mha.1.qkv_proj.weight', 'transformer.9.pre_norm_mha.1.qkv_proj.bias', 'transformer.9.pre_norm_mha.1.out_proj_attn.weight', 'transformer.9.pre_norm_mha.1.out_proj_attn.bias', 'transformer.9.pre_norm_ffn.0.weight', 'transformer.9.pre_norm_ffn.0.bias', 'transformer.9.pre_norm_ffn.1.weight', 'transformer.9.pre_norm_ffn.1.bias', 'transformer.9.pre_norm_ffn.4.weight', 'transformer.9.pre_norm_ffn.4.bias', 'transformer.10.pre_norm_mha.0.weight', 'transformer.10.pre_norm_mha.0.bias', 'transformer.10.pre_norm_mha.1.qkv_proj.weight', 'transformer.10.pre_norm_mha.1.qkv_proj.bias', 'transformer.10.pre_norm_mha.1.out_proj_attn.weight', 'transformer.10.pre_norm_mha.1.out_proj_attn.bias', 'transformer.10.pre_norm_ffn.0.weight', 'transformer.10.pre_norm_ffn.0.bias', 'transformer.10.pre_norm_ffn.1.weight', 'transformer.10.pre_norm_ffn.1.bias', 'transformer.10.pre_norm_ffn.4.weight', 'transformer.10.pre_norm_ffn.4.bias', 'transformer.11.pre_norm_mha.0.weight', 'transformer.11.pre_norm_mha.0.bias', 'transformer.11.pre_norm_mha.1.qkv_proj.weight', 'transformer.11.pre_norm_mha.1.qkv_proj.bias', 'transformer.11.pre_norm_mha.1.out_proj_attn.weight', 'transformer.11.pre_norm_mha.1.out_proj_attn.bias', 'transformer.11.pre_norm_ffn.0.weight', 'transformer.11.pre_norm_ffn.0.bias', 'transformer.11.pre_norm_ffn.1.weight', 'transformer.11.pre_norm_ffn.1.bias', 'transformer.11.pre_norm_ffn.4.weight', 'transformer.11.pre_norm_ffn.4.bias', 'classifier.weight', 'classifier.bias', 'pos_embed.pos_embed.pos_embed']
2024-06-06 18:04:57 - [34m[1mLOGS   [0m - [36mModel[0m
VisionTransformer(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_emb): Sequential(
    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=GELU)
    (1): Conv2d(192, 192, kernel_size=(2, 2), stride=(2, 2), bias=False, normalization=BatchNorm2d, activation=GELU)
    (2): Conv2d(192, 768, kernel_size=(2, 2), stride=(2, 2))
  )
  (post_transformer_norm): LayerNormFP32((768,), eps=1e-06, elementwise_affine=True)
  (transformer): Sequential(
    (0): FlashTransformerEncoder
    (1): FlashTransformerEncoder
    (2): FlashTransformerEncoder
    (3): FlashTransformerEncoder
    (4): FlashTransformerEncoder
    (5): FlashTransformerEncoder
    (6): FlashTransformerEncoder
    (7): FlashTransformerEncoder
    (8): FlashTransformerEncoder
    (9): FlashTransformerEncoder
    (10): FlashTransformerEncoder
    (11): FlashTransformerEncoder
  )
  (classifier): LinearLayer(in_features=768, out_features=24320, bias=True, channel_first=False)
  (pos_embed): LearnablePositionalEmbedding(num_embeddings=196, embedding_dim=768, padding_idx=None, sequence_first=False)
  (emb_dropout): Dropout(p=0.0, inplace=False)
)
[31m=================================================================[0m
                  VisionTransformer Summary
[31m=================================================================[0m
Total parameters     =  104.657 M
Total trainable parameters =  104.657 M

2024-06-06 18:04:57 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-06-06 18:04:57 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.105G                 | 17.031G    |
|  cls_token                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_emb                           |  0.748M                |  0.262G    |
|   patch_emb.0.block                  |   9.6K                 |   30.106M  |
|    patch_emb.0.block.conv            |    9.216K              |    28.901M |
|    patch_emb.0.block.norm            |    0.384K              |    1.204M  |
|   patch_emb.1.block                  |   0.148M               |   0.116G   |
|    patch_emb.1.block.conv            |    0.147M              |    0.116G  |
|    patch_emb.1.block.norm            |    0.384K              |    0.301M  |
|   patch_emb.2.block.conv             |   0.591M               |   0.116G   |
|    patch_emb.2.block.conv.weight     |    (768, 192, 2, 2)    |            |
|    patch_emb.2.block.conv.bias       |    (768,)              |            |
|  post_transformer_norm               |  1.536K                |  0.756M    |
|   post_transformer_norm.weight       |   (768,)               |            |
|   post_transformer_norm.bias         |   (768,)               |            |
|  transformer                         |  85.054M               |  16.75G    |
|   transformer.0                      |   7.088M               |   1.396G   |
|    transformer.0.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.0.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.1                      |   7.088M               |   1.396G   |
|    transformer.1.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.1.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.2                      |   7.088M               |   1.396G   |
|    transformer.2.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.2.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.3                      |   7.088M               |   1.396G   |
|    transformer.3.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.3.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.4                      |   7.088M               |   1.396G   |
|    transformer.4.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.4.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.5                      |   7.088M               |   1.396G   |
|    transformer.5.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.5.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.6                      |   7.088M               |   1.396G   |
|    transformer.6.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.6.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.7                      |   7.088M               |   1.396G   |
|    transformer.7.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.7.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.8                      |   7.088M               |   1.396G   |
|    transformer.8.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.8.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.9                      |   7.088M               |   1.396G   |
|    transformer.9.pre_norm_mha        |    2.364M              |    0.466G  |
|    transformer.9.pre_norm_ffn        |    4.724M              |    0.93G   |
|   transformer.10                     |   7.088M               |   1.396G   |
|    transformer.10.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.10.pre_norm_ffn       |    4.724M              |    0.93G   |
|   transformer.11                     |   7.088M               |   1.396G   |
|    transformer.11.pre_norm_mha       |    2.364M              |    0.466G  |
|    transformer.11.pre_norm_ffn       |    4.724M              |    0.93G   |
|  classifier                          |  18.702M               |  18.678M   |
|   classifier.weight                  |   (24320, 768)         |            |
|   classifier.bias                    |   (24320,)             |            |
|  pos_embed.pos_embed                 |  0.151M                |  0         |
|   pos_embed.pos_embed.pos_embed      |   (1, 1, 196, 768)     |            |
2024-06-06 18:04:58 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-06-06 18:04:58 - [33m[1mWARNING[0m - Uncalled Modules:
{'transformer.2.drop_path', 'transformer.11.drop_path', 'transformer.5.drop_path', 'neural_augmentor.brightness.max_fn', 'neural_augmentor', 'transformer.6.drop_path', 'transformer.4.drop_path', 'transformer.3.drop_path', 'transformer.1.drop_path', 'neural_augmentor.brightness.min_fn', 'neural_augmentor.contrast.max_fn', 'transformer.10.drop_path', 'neural_augmentor.noise', 'transformer.0.drop_path', 'neural_augmentor.contrast', 'neural_augmentor.contrast.min_fn', 'transformer.8.drop_path', 'neural_augmentor.noise.max_fn', 'transformer.7.drop_path', 'transformer.9.drop_path', 'neural_augmentor.brightness', 'neural_augmentor.noise.min_fn'}
2024-06-06 18:04:58 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 25, 'aten::gelu': 14, 'aten::scaled_dot_product_attention': 12, 'aten::sub': 1})
[31m=================================================================[0m
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	BinaryCrossEntropy(  reduction=batch_mean loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - [36mOptimizer[0m
AdamWOptimizer (
	 amsgrad: [False, False]
	 betas: [(0.9, 0.999), (0.9, 0.999)]
	 capturable: [False, False]
	 differentiable: [False, False]
	 eps: [1e-08, 1e-08]
	 foreach: [None, None]
	 fused: [None, None]
	 lr: [0.1, 0.1]
	 maximize: [False, False]
	 weight_decay: [0.2, 0.0]
)
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - Max. iteration for training: 200000
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=1e-05
 	 max_lr=0.001
 	 period=190001
 	 warmup_init_lr=1e-06
 	 warmup_iters=10000
 )
2024-06-06 18:04:58 - [34m[1mLOGS   [0m - Using EMA
2024-06-06 18:04:59 - [34m[1mLOGS   [0m - Loaded checkpoint from results_catlip/train/training_checkpoint_last.pt
2024-06-06 18:04:59 - [34m[1mLOGS   [0m - Resuming training for epoch 4
2024-06-06 18:04:59 - [32m[1mINFO   [0m - Configuration file is stored here: [36mresults_catlip/train/config.yaml[0m
[31m===========================================================================[0m
2024-06-06 18:05:01 - [32m[1mINFO   [0m - Training epoch 4
2024-06-06 18:04:55 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://127.0.0.1:2345
2024-06-06 18:10:28 - [34m[1mLOGS   [0m - Epoch:   4 [    3186/  200000], loss: {'classification': 9.296, 'neural_augmentation': 9.1013, 'total_loss': 18.3972}, LR: [0.000319, 0.000319], Avg. batch load time: 311.277, Elapsed time: 326.56
2024-06-06 18:50:40 - [34m[1mLOGS   [0m - Epoch:   4 [    3686/  200000], loss: {'classification': 9.1029, 'neural_augmentation': 8.2932, 'total_loss': 17.396}, LR: [0.000369, 0.000369], Avg. batch load time: 1.586, Elapsed time: 2738.33
2024-06-06 19:17:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 9.0132, 'neural_augmentation': 8.2107, 'total_loss': 17.2239}
2024-06-06 19:18:02 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-06 19:19:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-06 19:19:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-06 19:19:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 3961 is saved at: results_catlip/train/training_checkpoint_epoch_4_iter_3961.pt
2024-06-06 19:19:38 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 3961 is saved at: results_catlip/train/checkpoint_epoch_4_iter_3961.pt
2024-06-06 19:19:43 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-06 19:19:47 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-06 19:19:59 - [34m[1mLOGS   [0m - EMA model state for epoch 4/iteration 3961 is saved at: results_catlip/train/checkpoint_ema_epoch_4_iter_3961.pt
[31m===========================================================================[0m
2024-06-06 19:20:01 - [32m[1mINFO   [0m - Training epoch 5
2024-06-06 19:28:04 - [34m[1mLOGS   [0m - Epoch:   5 [    3962/  200000], loss: {'classification': 8.8436, 'neural_augmentation': 7.6976, 'total_loss': 16.5412}, LR: [0.000397, 0.000397], Avg. batch load time: 148.779, Elapsed time: 482.95
2024-06-06 20:20:59 - [34m[1mLOGS   [0m - Epoch:   5 [    4462/  200000], loss: {'classification': 8.6284, 'neural_augmentation': 7.7169, 'total_loss': 16.3453}, LR: [0.000447, 0.000447], Avg. batch load time: 0.393, Elapsed time: 3657.82
2024-06-06 20:56:01 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 8.5247, 'neural_augmentation': 7.563, 'total_loss': 16.0877}
2024-06-06 20:56:27 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-06 20:57:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-06 20:57:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-06 20:58:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 4751 is saved at: results_catlip/train/training_checkpoint_epoch_5_iter_4751.pt
2024-06-06 20:58:32 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 4751 is saved at: results_catlip/train/checkpoint_epoch_5_iter_4751.pt
2024-06-06 20:58:37 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-06 20:58:39 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-06 20:58:48 - [34m[1mLOGS   [0m - EMA model state for epoch 5/iteration 4751 is saved at: results_catlip/train/checkpoint_ema_epoch_5_iter_4751.pt
[31m===========================================================================[0m
2024-06-06 20:58:50 - [32m[1mINFO   [0m - Training epoch 6
2024-06-06 21:01:13 - [34m[1mLOGS   [0m - Epoch:   6 [    4752/  200000], loss: {'classification': 7.7695, 'neural_augmentation': 7.2709, 'total_loss': 15.0404}, LR: [0.000476, 0.000476], Avg. batch load time: 141.109, Elapsed time: 143.08
2024-06-06 21:37:30 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-06 21:37:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-06 21:38:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 4999 is saved at: results_catlip/train/training_checkpoint_epoch_6_iter_4999.pt
2024-06-06 21:39:20 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 4999 is saved at: results_catlip/train/checkpoint_epoch_6_iter_4999.pt
2024-06-06 21:39:41 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-06 21:40:11 - [34m[1mLOGS   [0m - EMA model state for epoch 6/iteration 4999 is saved at: results_catlip/train/checkpoint_ema_epoch_6_iter_4999.pt
2024-06-06 21:40:11 - [32m[1mINFO   [0m - Checkpoints saved after 4999 updates at: results_catlip/train
[31m======================================================================================================================================================[0m
2024-06-06 22:01:06 - [34m[1mLOGS   [0m - Epoch:   6 [    5252/  200000], loss: {'classification': 8.0694, 'neural_augmentation': 6.878, 'total_loss': 14.9474}, LR: [0.000526, 0.000526], Avg. batch load time: 2.216, Elapsed time: 3736.26
2024-06-06 22:23:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 7.9729, 'neural_augmentation': 6.7137, 'total_loss': 14.6866}
2024-06-06 22:23:13 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-06 22:23:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-06 22:23:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-06 22:23:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 5567 is saved at: results_catlip/train/training_checkpoint_epoch_6_iter_5567.pt
2024-06-06 22:23:21 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 5567 is saved at: results_catlip/train/checkpoint_epoch_6_iter_5567.pt
2024-06-06 22:23:23 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-06 22:23:24 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-06 22:23:29 - [34m[1mLOGS   [0m - EMA model state for epoch 6/iteration 5567 is saved at: results_catlip/train/checkpoint_ema_epoch_6_iter_5567.pt
[31m===========================================================================[0m
2024-06-06 22:23:31 - [32m[1mINFO   [0m - Training epoch 7
2024-06-06 22:26:58 - [34m[1mLOGS   [0m - Epoch:   7 [    5568/  200000], loss: {'classification': 7.3905, 'neural_augmentation': 6.4767, 'total_loss': 13.8672}, LR: [0.000557, 0.000557], Avg. batch load time: 204.327, Elapsed time: 207.33
2024-06-06 23:23:17 - [34m[1mLOGS   [0m - Epoch:   7 [    6068/  200000], loss: {'classification': 7.4399, 'neural_augmentation': 5.884, 'total_loss': 13.3239}, LR: [0.000607, 0.000607], Avg. batch load time: 1.907, Elapsed time: 3586.05
2024-06-06 23:54:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 7.3466, 'neural_augmentation': 5.6642, 'total_loss': 13.0108}
2024-06-06 23:55:15 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-06 23:56:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-06 23:56:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-06 23:57:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 6380 is saved at: results_catlip/train/training_checkpoint_epoch_7_iter_6380.pt
2024-06-06 23:58:00 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 6380 is saved at: results_catlip/train/checkpoint_epoch_7_iter_6380.pt
2024-06-06 23:58:28 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-06 23:58:37 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-06 23:59:08 - [34m[1mLOGS   [0m - EMA model state for epoch 7/iteration 6380 is saved at: results_catlip/train/checkpoint_ema_epoch_7_iter_6380.pt
[31m===========================================================================[0m
2024-06-06 23:59:10 - [32m[1mINFO   [0m - Training epoch 8
2024-06-07 00:01:33 - [34m[1mLOGS   [0m - Epoch:   8 [    6381/  200000], loss: {'classification': 6.6654, 'neural_augmentation': 5.0742, 'total_loss': 11.7396}, LR: [0.000638, 0.000638], Avg. batch load time: 138.884, Elapsed time: 142.26
2024-06-07 00:51:20 - [34m[1mLOGS   [0m - Epoch:   8 [    6881/  200000], loss: {'classification': 6.8797, 'neural_augmentation': 4.7253, 'total_loss': 11.605}, LR: [0.000688, 0.000688], Avg. batch load time: 1.148, Elapsed time: 3129.48
2024-06-07 01:28:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 6.7839, 'neural_augmentation': 4.5231, 'total_loss': 11.307}
2024-06-07 01:29:09 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-07 01:30:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 01:30:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 01:30:29 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 7168 is saved at: results_catlip/train/training_checkpoint_epoch_8_iter_7168.pt
2024-06-07 01:30:36 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 7168 is saved at: results_catlip/train/checkpoint_epoch_8_iter_7168.pt
2024-06-07 01:30:41 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 01:30:52 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-07 01:31:11 - [34m[1mLOGS   [0m - EMA model state for epoch 8/iteration 7168 is saved at: results_catlip/train/checkpoint_ema_epoch_8_iter_7168.pt
[31m===========================================================================[0m
2024-06-07 01:31:13 - [32m[1mINFO   [0m - Training epoch 9
2024-06-07 01:35:24 - [34m[1mLOGS   [0m - Epoch:   9 [    7169/  200000], loss: {'classification': 6.2299, 'neural_augmentation': 3.8804, 'total_loss': 10.1104}, LR: [0.000717, 0.000717], Avg. batch load time: 243.177, Elapsed time: 251.16
2024-06-07 02:29:17 - [34m[1mLOGS   [0m - Epoch:   9 [    7669/  200000], loss: {'classification': 6.3351, 'neural_augmentation': 3.6859, 'total_loss': 10.021}, LR: [0.000767, 0.000767], Avg. batch load time: 1.233, Elapsed time: 3484.01
2024-06-07 02:55:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 6.2605, 'neural_augmentation': 3.508, 'total_loss': 9.7686}
2024-06-07 02:56:16 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-07 02:57:00 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 02:57:08 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 02:57:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 7958 is saved at: results_catlip/train/training_checkpoint_epoch_9_iter_7958.pt
2024-06-07 02:57:30 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 7958 is saved at: results_catlip/train/checkpoint_epoch_9_iter_7958.pt
2024-06-07 02:57:32 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 02:57:36 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-07 02:57:41 - [34m[1mLOGS   [0m - EMA model state for epoch 9/iteration 7958 is saved at: results_catlip/train/checkpoint_ema_epoch_9_iter_7958.pt
[31m===========================================================================[0m
2024-06-07 02:57:43 - [32m[1mINFO   [0m - Training epoch 10
2024-06-07 03:04:21 - [34m[1mLOGS   [0m - Epoch:  10 [    7959/  200000], loss: {'classification': 6.0199, 'neural_augmentation': 3.0097, 'total_loss': 9.0295}, LR: [0.000796, 0.000796], Avg. batch load time: 394.210, Elapsed time: 397.77
2024-06-07 03:48:10 - [34m[1mLOGS   [0m - Epoch:  10 [    8459/  200000], loss: {'classification': 5.9155, 'neural_augmentation': 2.7757, 'total_loss': 8.6912}, LR: [0.000846, 0.000846], Avg. batch load time: 0.844, Elapsed time: 3027.22
2024-06-07 04:22:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 5.8453, 'neural_augmentation': 2.6225, 'total_loss': 8.4678}
2024-06-07 04:22:21 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-07 04:23:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 04:23:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 04:24:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 8781 is saved at: results_catlip/train/training_checkpoint_epoch_10_iter_8781.pt
2024-06-07 04:24:27 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 8781 is saved at: results_catlip/train/checkpoint_epoch_10_iter_8781.pt
2024-06-07 04:24:49 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 04:25:06 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-07 04:25:31 - [34m[1mLOGS   [0m - EMA model state for epoch 10/iteration 8781 is saved at: results_catlip/train/checkpoint_ema_epoch_10_iter_8781.pt
[31m===========================================================================[0m
2024-06-07 04:25:33 - [32m[1mINFO   [0m - Training epoch 11
2024-06-07 04:35:45 - [34m[1mLOGS   [0m - Epoch:  11 [    8782/  200000], loss: {'classification': 5.6434, 'neural_augmentation': 2.3073, 'total_loss': 7.9507}, LR: [0.000878, 0.000878], Avg. batch load time: 607.132, Elapsed time: 611.78
2024-06-07 05:18:23 - [34m[1mLOGS   [0m - Epoch:  11 [    9282/  200000], loss: {'classification': 5.5238, 'neural_augmentation': 2.0654, 'total_loss': 7.5892}, LR: [0.000928, 0.000928], Avg. batch load time: 1.956, Elapsed time: 3169.91
2024-06-07 05:47:10 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 5.4879, 'neural_augmentation': 1.9601, 'total_loss': 7.448}
2024-06-07 05:47:23 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-07 05:48:42 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 05:48:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 05:49:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 9592 is saved at: results_catlip/train/training_checkpoint_epoch_11_iter_9592.pt
2024-06-07 05:49:07 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 9592 is saved at: results_catlip/train/checkpoint_epoch_11_iter_9592.pt
2024-06-07 05:49:22 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 05:49:34 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-07 05:50:07 - [34m[1mLOGS   [0m - EMA model state for epoch 11/iteration 9592 is saved at: results_catlip/train/checkpoint_ema_epoch_11_iter_9592.pt
[31m===========================================================================[0m
2024-06-07 05:50:09 - [32m[1mINFO   [0m - Training epoch 12
2024-06-07 05:55:20 - [34m[1mLOGS   [0m - Epoch:  12 [    9593/  200000], loss: {'classification': 4.7964, 'neural_augmentation': 1.7103, 'total_loss': 6.5066}, LR: [0.000959, 0.000959], Avg. batch load time: 305.892, Elapsed time: 310.89
2024-06-07 06:59:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 07:00:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 07:01:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 9999 is saved at: results_catlip/train/training_checkpoint_epoch_12_iter_9999.pt
2024-06-07 07:01:58 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 9999 is saved at: results_catlip/train/checkpoint_epoch_12_iter_9999.pt
2024-06-07 07:02:37 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 07:02:54 - [34m[1mLOGS   [0m - EMA model state for epoch 12/iteration 9999 is saved at: results_catlip/train/checkpoint_ema_epoch_12_iter_9999.pt
2024-06-07 07:02:55 - [32m[1mINFO   [0m - Checkpoints saved after 9999 updates at: results_catlip/train
[31m======================================================================================================================================================[0m
2024-06-07 07:14:13 - [34m[1mLOGS   [0m - Epoch:  12 [   10093/  200000], loss: {'classification': 5.2376, 'neural_augmentation': 1.5724, 'total_loss': 6.81}, LR: [0.001, 0.001], Avg. batch load time: 2.777, Elapsed time: 5043.90
2024-06-07 07:45:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 5.195, 'neural_augmentation': 1.5008, 'total_loss': 6.6958}
2024-06-07 07:45:37 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at results_catlip/train/checkpoint_best.pt
2024-06-07 07:46:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: results_catlip/train/training_checkpoint_last.pt
2024-06-07 07:46:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: results_catlip/train/checkpoint_last.pt
2024-06-07 07:48:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 10385 is saved at: results_catlip/train/training_checkpoint_epoch_12_iter_10385.pt
2024-06-07 07:48:42 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 10385 is saved at: results_catlip/train/checkpoint_epoch_12_iter_10385.pt
2024-06-07 07:49:01 - [34m[1mLOGS   [0m - Last EMA model state is saved at: results_catlip/train/checkpoint_ema_last.pt
2024-06-07 07:49:19 - [34m[1mLOGS   [0m - Best EMA checkpoint with score 0.00 is saved at results_catlip/train/checkpoint_ema_best.pt
2024-06-07 07:50:11 - [34m[1mLOGS   [0m - EMA model state for epoch 12/iteration 10385 is saved at: results_catlip/train/checkpoint_ema_epoch_12_iter_10385.pt
[31m===========================================================================[0m
2024-06-07 07:50:13 - [32m[1mINFO   [0m - Training epoch 13
2024-06-07 07:52:26 - [34m[1mLOGS   [0m - Epoch:  13 [   10386/  200000], loss: {'classification': 4.5587, 'neural_augmentation': 1.4218, 'total_loss': 5.9805}, LR: [0.001, 0.001], Avg. batch load time: 126.014, Elapsed time: 132.79
2024-06-07 08:42:26 - [34m[1mLOGS   [0m - Epoch:  13 [   10886/  200000], loss: {'classification': 4.9321, 'neural_augmentation': 1.2369, 'total_loss': 6.169}, LR: [0.001, 0.001], Avg. batch load time: 1.455, Elapsed time: 3132.23
Traceback (most recent call last):
  File "/home/data_llm/madehua/corenet/venv/bin/corenet-train", line 8, in <module>
    sys.exit(main_worker())
             ^^^^^^^^^^^^^
  File "/home/data_llm/madehua/corenet/corenet/cli/main_train.py", line 37, in main_worker
    launcher(callback)
  File "/home/data_llm/madehua/corenet/corenet/train_eval_pipelines/default_train_eval.py", line 310, in <lambda>
    return lambda callback: torch.multiprocessing.spawn(
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data_llm/madehua/corenet/venv/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 241, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data_llm/madehua/corenet/venv/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
              ^^^^^^^^^^^^^^
  File "/home/data_llm/madehua/corenet/venv/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGTERM
/home/data_llm/anaconda3/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 352 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
