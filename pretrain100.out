nohup: ignoring input
2024-07-16 18:53:31 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
small
2024-07-16 18:53:32 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-16 18:53:32 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=384, out_features=512, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=10717, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   48.484 M
Total trainable parameters =   48.484 M

2024-07-16 18:53:32 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-16 18:53:32 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 48.484M                | 7.463G     |
|  pos_embed                           |  (1, 1, 384)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  1.077M                |  1.881G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.638G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    28.312M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    5.243M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.604G  |
|   patch_embed.backbone.stages        |   0.595M               |   1.13G    |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.495G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.635G  |
|   patch_embed.backbone.pool          |   0.443M               |   0.114G   |
|    patch_embed.backbone.pool.proj    |    0.443M              |    0.113G  |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.655M  |
|  blocks                              |  14.196M               |  3.632G    |
|   blocks.0                           |   1.774M               |   0.454G   |
|    blocks.0.norm1                    |    0.768K              |    0.492M  |
|    blocks.0.attn                     |    0.591M              |    0.151G  |
|    blocks.0.norm2                    |    0.768K              |    0.492M  |
|    blocks.0.mlp                      |    1.182M              |    0.302G  |
|   blocks.1                           |   1.774M               |   0.454G   |
|    blocks.1.norm1                    |    0.768K              |    0.492M  |
|    blocks.1.attn                     |    0.591M              |    0.151G  |
|    blocks.1.norm2                    |    0.768K              |    0.492M  |
|    blocks.1.mlp                      |    1.182M              |    0.302G  |
|   blocks.2                           |   1.774M               |   0.454G   |
|    blocks.2.norm1                    |    0.768K              |    0.492M  |
|    blocks.2.attn                     |    0.591M              |    0.151G  |
|    blocks.2.norm2                    |    0.768K              |    0.492M  |
|    blocks.2.mlp                      |    1.182M              |    0.302G  |
|   blocks.3                           |   1.774M               |   0.454G   |
|    blocks.3.norm1                    |    0.768K              |    0.492M  |
|    blocks.3.attn                     |    0.591M              |    0.151G  |
|    blocks.3.norm2                    |    0.768K              |    0.492M  |
|    blocks.3.mlp                      |    1.182M              |    0.302G  |
|   blocks.4                           |   1.774M               |   0.454G   |
|    blocks.4.norm1                    |    0.768K              |    0.492M  |
|    blocks.4.attn                     |    0.591M              |    0.151G  |
|    blocks.4.norm2                    |    0.768K              |    0.492M  |
|    blocks.4.mlp                      |    1.182M              |    0.302G  |
|   blocks.5                           |   1.774M               |   0.454G   |
|    blocks.5.norm1                    |    0.768K              |    0.492M  |
|    blocks.5.attn                     |    0.591M              |    0.151G  |
|    blocks.5.norm2                    |    0.768K              |    0.492M  |
|    blocks.5.mlp                      |    1.182M              |    0.302G  |
|   blocks.6                           |   1.774M               |   0.454G   |
|    blocks.6.norm1                    |    0.768K              |    0.492M  |
|    blocks.6.attn                     |    0.591M              |    0.151G  |
|    blocks.6.norm2                    |    0.768K              |    0.492M  |
|    blocks.6.mlp                      |    1.182M              |    0.302G  |
|   blocks.7                           |   1.774M               |   0.454G   |
|    blocks.7.norm1                    |    0.768K              |    0.492M  |
|    blocks.7.attn                     |    0.591M              |    0.151G  |
|    blocks.7.norm2                    |    0.768K              |    0.492M  |
|    blocks.7.mlp                      |    1.182M              |    0.302G  |
|  pool                                |  1.771M                |  0.114G    |
|   pool.proj                          |   1.77M                |   0.113G   |
|    pool.proj.weight                  |    (512, 384, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.768K               |   0.492M   |
|    pool.norm.weight                  |    (384,)              |            |
|    pool.norm.bias                    |    (384,)              |            |
|  blocks1                             |  25.219M               |  1.613G    |
|   blocks1.0                          |   3.152M               |   0.202G   |
|    blocks1.0.norm1                   |    1.024K              |    0.164M  |
|    blocks1.0.attn                    |    1.051M              |    67.109M |
|    blocks1.0.norm2                   |    1.024K              |    0.164M  |
|    blocks1.0.mlp                     |    2.1M                |    0.134G  |
|   blocks1.1                          |   3.152M               |   0.202G   |
|    blocks1.1.norm1                   |    1.024K              |    0.164M  |
|    blocks1.1.attn                    |    1.051M              |    67.109M |
|    blocks1.1.norm2                   |    1.024K              |    0.164M  |
|    blocks1.1.mlp                     |    2.1M                |    0.134G  |
|   blocks1.2                          |   3.152M               |   0.202G   |
|    blocks1.2.norm1                   |    1.024K              |    0.164M  |
|    blocks1.2.attn                    |    1.051M              |    67.109M |
|    blocks1.2.norm2                   |    1.024K              |    0.164M  |
|    blocks1.2.mlp                     |    2.1M                |    0.134G  |
|   blocks1.3                          |   3.152M               |   0.202G   |
|    blocks1.3.norm1                   |    1.024K              |    0.164M  |
|    blocks1.3.attn                    |    1.051M              |    67.109M |
|    blocks1.3.norm2                   |    1.024K              |    0.164M  |
|    blocks1.3.mlp                     |    2.1M                |    0.134G  |
|   blocks1.4                          |   3.152M               |   0.202G   |
|    blocks1.4.norm1                   |    1.024K              |    0.164M  |
|    blocks1.4.attn                    |    1.051M              |    67.109M |
|    blocks1.4.norm2                   |    1.024K              |    0.164M  |
|    blocks1.4.mlp                     |    2.1M                |    0.134G  |
|   blocks1.5                          |   3.152M               |   0.202G   |
|    blocks1.5.norm1                   |    1.024K              |    0.164M  |
|    blocks1.5.attn                    |    1.051M              |    67.109M |
|    blocks1.5.norm2                   |    1.024K              |    0.164M  |
|    blocks1.5.mlp                     |    2.1M                |    0.134G  |
|   blocks1.6                          |   3.152M               |   0.202G   |
|    blocks1.6.norm1                   |    1.024K              |    0.164M  |
|    blocks1.6.attn                    |    1.051M              |    67.109M |
|    blocks1.6.norm2                   |    1.024K              |    0.164M  |
|    blocks1.6.mlp                     |    2.1M                |    0.134G  |
|   blocks1.7                          |   3.152M               |   0.202G   |
|    blocks1.7.norm1                   |    1.024K              |    0.164M  |
|    blocks1.7.attn                    |    1.051M              |    67.109M |
|    blocks1.7.norm2                   |    1.024K              |    0.164M  |
|    blocks1.7.mlp                     |    2.1M                |    0.134G  |
|  block_to_block1                     |  0.197M                |  50.332M   |
|   block_to_block1.weight             |   (512, 384)           |            |
|   block_to_block1.bias               |   (512,)               |            |
|  mlp                                 |  0.525M                |  0.168G    |
|   mlp.0                              |   0.263M               |   83.886M  |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   83.886M  |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  5.498M                |  5.487M    |
|   classifier.weight                  |   (10717, 512)         |            |
|   classifier.bias                    |   (10717,)             |            |
2024-07-16 18:53:32 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-16 18:53:32 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.1.drop_path2', 'blocks1.2.ls2', 'patch_embed.backbone.stages.1.0.down', 'blocks1.2.ls1', 'blocks.4.attn.k_norm', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.6.ls2', 'blocks.4.drop_path1', 'blocks1.3.attn.k_norm', 'blocks1.6.drop_path2', 'patch_embed.backbone.stem.norm1.drop', 'blocks.4.attn.q_norm', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.6.ls1', 'blocks.5.mlp.norm', 'blocks1.2.mlp.norm', 'blocks1.0.ls2', 'blocks.5.drop_path1', 'blocks1.2.drop_path2', 'blocks1.5.ls1', 'blocks.3.ls1', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.2.ls1', 'blocks1.1.ls1', 'blocks.3.attn.q_norm', 'blocks.2.mlp.norm', 'blocks1.5.drop_path1', 'patch_embed.backbone.stages.1.3.down', 'blocks.2.attn.attn_drop', 'blocks.3.drop_path2', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.3.mlp.norm', 'blocks.0.ls2', 'blocks.1.ls2', 'blocks1.7.attn.q_norm', 'norm', 'patch_embed.backbone.stages.1.2.shortcut', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.7.ls1', 'blocks.1.attn.attn_drop', 'neural_augmentor', 'blocks.1.drop_path1', 'blocks1.6.drop_path1', 'blocks.7.attn.k_norm', 'blocks1.7.attn.attn_drop', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.1.2.down', 'blocks1.4.drop_path2', 'blocks1.0.drop_path2', 'blocks.0.drop_path2', 'blocks.5.attn.attn_drop', 'blocks1.3.drop_path1', 'blocks1.4.ls1', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.5.drop_path2', 'blocks1.0.mlp.norm', 'blocks1.0.drop_path1', 'neural_augmentor.contrast', 'blocks1.7.drop_path1', 'blocks.7.drop_path2', 'blocks.6.attn.k_norm', 'blocks1.1.ls2', 'blocks.0.attn.k_norm', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.4.attn.attn_drop', 'neural_augmentor.brightness', 'blocks1.1.drop_path1', 'blocks.5.ls1', 'blocks1.2.attn.attn_drop', 'blocks1.2.attn.k_norm', 'patch_embed.backbone.stages.0.0.drop_path', 'neural_augmentor.brightness.min_fn', 'patch_embed.backbone.stages.0.1.down', 'blocks.0.ls1', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.2.attn.q_norm', 'blocks.6.drop_path1', 'blocks1.3.ls1', 'blocks.4.ls1', 'blocks1.2.drop_path1', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.3.ls2', 'blocks.0.attn.attn_drop', 'neural_augmentor.contrast.min_fn', 'blocks1.5.attn.attn_drop', 'neural_augmentor.contrast.max_fn', 'blocks1.3.drop_path2', 'blocks1.5.drop_path2', 'blocks.2.drop_path1', 'blocks1.3.attn.q_norm', 'blocks1.5.attn.k_norm', 'neural_augmentor.noise.min_fn', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.5.ls2', 'patch_embed.backbone.stages.1.1.down', 'blocks1.6.ls1', 'neural_augmentor.noise.max_fn', 'blocks1.1.attn.q_norm', 'blocks1.0.attn.q_norm', 'blocks.7.attn.attn_drop', 'blocks1.4.attn.q_norm', 'blocks1.4.mlp.norm', 'blocks1.6.attn.q_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.2.ls2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.7.mlp.norm', 'blocks.1.attn.k_norm', 'norm_pre', 'blocks1.2.attn.q_norm', 'blocks.3.mlp.norm', 'blocks.1.ls1', 'blocks1.3.attn.attn_drop', 'blocks.4.attn.attn_drop', 'neural_augmentor.noise', 'blocks.0.drop_path1', 'blocks.3.attn.k_norm', 'patch_embed.proj', 'blocks.7.drop_path1', 'patch_drop', 'blocks1.0.attn.k_norm', 'blocks.3.ls2', 'blocks.4.drop_path2', 'blocks.6.mlp.norm', 'blocks1.7.attn.k_norm', 'blocks1.6.ls2', 'blocks.4.mlp.norm', 'blocks1.7.mlp.norm', 'blocks.7.ls1', 'neural_augmentor.brightness.max_fn', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks.6.attn.attn_drop', 'blocks1.6.attn.attn_drop', 'blocks.0.attn.q_norm', 'blocks.0.mlp.norm', 'blocks1.1.drop_path2', 'blocks.3.attn.attn_drop', 'blocks1.4.ls2', 'blocks1.6.attn.k_norm', 'blocks.7.attn.q_norm', 'blocks1.5.mlp.norm', 'blocks.2.attn.k_norm', 'blocks1.0.ls1', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.0.0.down', 'blocks.5.ls2', 'blocks1.0.attn.attn_drop', 'blocks1.4.drop_path1', 'blocks1.7.drop_path2', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks1.1.mlp.norm', 'blocks.6.drop_path2', 'blocks.7.ls2', 'blocks.5.attn.k_norm', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks.1.mlp.norm', 'blocks.2.drop_path2', 'blocks1.7.ls2', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks1.5.attn.q_norm', 'blocks.5.attn.q_norm', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks1.6.mlp.norm', 'blocks.1.attn.q_norm', 'blocks.4.ls2', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks1.1.attn.attn_drop'}
2024-07-16 18:53:32 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-16 18:53:32 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-16 18:53:32 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-16 18:53:33 - [34m[1mLOGS   [0m - Available GPUs: 8
2024-07-16 18:53:33 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-16 18:53:33 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results100_dci/train
2024-07-16 18:53:36 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:40002
small
2024-07-16 18:53:37 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:40002
small
2024-07-16 18:53:37 - [32m[1mINFO   [0m - distributed init (rank 4): tcp://localhost:40002
small
2024-07-16 18:53:37 - [32m[1mINFO   [0m - distributed init (rank 6): tcp://localhost:40002
small
2024-07-16 18:53:37 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:40002
small
2024-07-16 18:53:36 - [32m[1mINFO   [0m - distributed init (rank 5): tcp://localhost:40002
small
2024-07-16 18:53:37 - [32m[1mINFO   [0m - distributed init (rank 7): tcp://localhost:40002
small
2024-07-16 18:53:36 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:40002
2024-07-16 18:53:38 - [34m[1mLOGS   [0m - Training dataset details are given below
WordnetTaggedClassificationDataset(
	root= 
	is_training=True 
	num_samples=64290000
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	total_tar_files=6429
	max_files_per_tar=10000
	num_synsets=10717
)
2024-07-16 18:53:40 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=True
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=200
	 scales=[(128, 128, 612), (144, 144, 483), (160, 160, 392), (176, 176, 323), (192, 192, 272), (208, 208, 231), (224, 224, 200), (240, 240, 174), (256, 256, 153), (272, 272, 135), (288, 288, 120), (304, 304, 108), (320, 320, 98)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-16 18:53:40 - [34m[1mLOGS   [0m - Number of data workers: 64
small
2024-07-16 18:53:42 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (64,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (64,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(384, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=384, out_features=512, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=512, out_features=10717, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =   48.484 M
Total trainable parameters =   48.484 M

2024-07-16 18:53:42 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 48.484M                | 7.463G     |
|  pos_embed                           |  (1, 1, 384)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  1.077M                |  1.881G    |
|   patch_embed.backbone.stem          |   38.848K              |   0.638G   |
|    patch_embed.backbone.stem.conv1   |    1.792K              |    28.312M |
|    patch_embed.backbone.stem.norm1   |    0.128K              |    5.243M  |
|    patch_embed.backbone.stem.conv2   |    36.928K             |    0.604G  |
|   patch_embed.backbone.stages        |   0.595M               |   1.13G    |
|    patch_embed.backbone.stages.0     |    71.552K             |    0.495G  |
|    patch_embed.backbone.stages.1     |    0.524M              |    0.635G  |
|   patch_embed.backbone.pool          |   0.443M               |   0.114G   |
|    patch_embed.backbone.pool.proj    |    0.443M              |    0.113G  |
|    patch_embed.backbone.pool.norm    |    0.256K              |    0.655M  |
|  blocks                              |  14.196M               |  3.632G    |
|   blocks.0                           |   1.774M               |   0.454G   |
|    blocks.0.norm1                    |    0.768K              |    0.492M  |
|    blocks.0.attn                     |    0.591M              |    0.151G  |
|    blocks.0.norm2                    |    0.768K              |    0.492M  |
|    blocks.0.mlp                      |    1.182M              |    0.302G  |
|   blocks.1                           |   1.774M               |   0.454G   |
|    blocks.1.norm1                    |    0.768K              |    0.492M  |
|    blocks.1.attn                     |    0.591M              |    0.151G  |
|    blocks.1.norm2                    |    0.768K              |    0.492M  |
|    blocks.1.mlp                      |    1.182M              |    0.302G  |
|   blocks.2                           |   1.774M               |   0.454G   |
|    blocks.2.norm1                    |    0.768K              |    0.492M  |
|    blocks.2.attn                     |    0.591M              |    0.151G  |
|    blocks.2.norm2                    |    0.768K              |    0.492M  |
|    blocks.2.mlp                      |    1.182M              |    0.302G  |
|   blocks.3                           |   1.774M               |   0.454G   |
|    blocks.3.norm1                    |    0.768K              |    0.492M  |
|    blocks.3.attn                     |    0.591M              |    0.151G  |
|    blocks.3.norm2                    |    0.768K              |    0.492M  |
|    blocks.3.mlp                      |    1.182M              |    0.302G  |
|   blocks.4                           |   1.774M               |   0.454G   |
|    blocks.4.norm1                    |    0.768K              |    0.492M  |
|    blocks.4.attn                     |    0.591M              |    0.151G  |
|    blocks.4.norm2                    |    0.768K              |    0.492M  |
|    blocks.4.mlp                      |    1.182M              |    0.302G  |
|   blocks.5                           |   1.774M               |   0.454G   |
|    blocks.5.norm1                    |    0.768K              |    0.492M  |
|    blocks.5.attn                     |    0.591M              |    0.151G  |
|    blocks.5.norm2                    |    0.768K              |    0.492M  |
|    blocks.5.mlp                      |    1.182M              |    0.302G  |
|   blocks.6                           |   1.774M               |   0.454G   |
|    blocks.6.norm1                    |    0.768K              |    0.492M  |
|    blocks.6.attn                     |    0.591M              |    0.151G  |
|    blocks.6.norm2                    |    0.768K              |    0.492M  |
|    blocks.6.mlp                      |    1.182M              |    0.302G  |
|   blocks.7                           |   1.774M               |   0.454G   |
|    blocks.7.norm1                    |    0.768K              |    0.492M  |
|    blocks.7.attn                     |    0.591M              |    0.151G  |
|    blocks.7.norm2                    |    0.768K              |    0.492M  |
|    blocks.7.mlp                      |    1.182M              |    0.302G  |
|  pool                                |  1.771M                |  0.114G    |
|   pool.proj                          |   1.77M                |   0.113G   |
|    pool.proj.weight                  |    (512, 384, 3, 3)    |            |
|    pool.proj.bias                    |    (512,)              |            |
|   pool.norm                          |   0.768K               |   0.492M   |
|    pool.norm.weight                  |    (384,)              |            |
|    pool.norm.bias                    |    (384,)              |            |
|  blocks1                             |  25.219M               |  1.613G    |
|   blocks1.0                          |   3.152M               |   0.202G   |
|    blocks1.0.norm1                   |    1.024K              |    0.164M  |
|    blocks1.0.attn                    |    1.051M              |    67.109M |
|    blocks1.0.norm2                   |    1.024K              |    0.164M  |
|    blocks1.0.mlp                     |    2.1M                |    0.134G  |
|   blocks1.1                          |   3.152M               |   0.202G   |
|    blocks1.1.norm1                   |    1.024K              |    0.164M  |
|    blocks1.1.attn                    |    1.051M              |    67.109M |
|    blocks1.1.norm2                   |    1.024K              |    0.164M  |
|    blocks1.1.mlp                     |    2.1M                |    0.134G  |
|   blocks1.2                          |   3.152M               |   0.202G   |
|    blocks1.2.norm1                   |    1.024K              |    0.164M  |
|    blocks1.2.attn                    |    1.051M              |    67.109M |
|    blocks1.2.norm2                   |    1.024K              |    0.164M  |
|    blocks1.2.mlp                     |    2.1M                |    0.134G  |
|   blocks1.3                          |   3.152M               |   0.202G   |
|    blocks1.3.norm1                   |    1.024K              |    0.164M  |
|    blocks1.3.attn                    |    1.051M              |    67.109M |
|    blocks1.3.norm2                   |    1.024K              |    0.164M  |
|    blocks1.3.mlp                     |    2.1M                |    0.134G  |
|   blocks1.4                          |   3.152M               |   0.202G   |
|    blocks1.4.norm1                   |    1.024K              |    0.164M  |
|    blocks1.4.attn                    |    1.051M              |    67.109M |
|    blocks1.4.norm2                   |    1.024K              |    0.164M  |
|    blocks1.4.mlp                     |    2.1M                |    0.134G  |
|   blocks1.5                          |   3.152M               |   0.202G   |
|    blocks1.5.norm1                   |    1.024K              |    0.164M  |
|    blocks1.5.attn                    |    1.051M              |    67.109M |
|    blocks1.5.norm2                   |    1.024K              |    0.164M  |
|    blocks1.5.mlp                     |    2.1M                |    0.134G  |
|   blocks1.6                          |   3.152M               |   0.202G   |
|    blocks1.6.norm1                   |    1.024K              |    0.164M  |
|    blocks1.6.attn                    |    1.051M              |    67.109M |
|    blocks1.6.norm2                   |    1.024K              |    0.164M  |
|    blocks1.6.mlp                     |    2.1M                |    0.134G  |
|   blocks1.7                          |   3.152M               |   0.202G   |
|    blocks1.7.norm1                   |    1.024K              |    0.164M  |
|    blocks1.7.attn                    |    1.051M              |    67.109M |
|    blocks1.7.norm2                   |    1.024K              |    0.164M  |
|    blocks1.7.mlp                     |    2.1M                |    0.134G  |
|  block_to_block1                     |  0.197M                |  50.332M   |
|   block_to_block1.weight             |   (512, 384)           |            |
|   block_to_block1.bias               |   (512,)               |            |
|  mlp                                 |  0.525M                |  0.168G    |
|   mlp.0                              |   0.263M               |   83.886M  |
|    mlp.0.weight                      |    (512, 512)          |            |
|    mlp.0.bias                        |    (512,)              |            |
|   mlp.2                              |   0.263M               |   83.886M  |
|    mlp.2.weight                      |    (512, 512)          |            |
|    mlp.2.bias                        |    (512,)              |            |
|  fc_norm                             |  1.024K                |  2.56K     |
|   fc_norm.weight                     |   (512,)               |            |
|   fc_norm.bias                       |   (512,)               |            |
|  classifier                          |  5.498M                |  5.487M    |
|   classifier.weight                  |   (10717, 512)         |            |
|   classifier.bias                    |   (10717,)             |            |
2024-07-16 18:53:42 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-16 18:53:42 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks1.5.ls2', 'blocks.6.drop_path1', 'blocks.1.attn.q_norm', 'blocks.1.attn.k_norm', 'blocks1.5.mlp.norm', 'blocks1.7.attn.k_norm', 'patch_embed.backbone.stages.0.1.down', 'patch_embed.backbone.stages.0.0.down', 'neural_augmentor', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'patch_drop', 'blocks.6.attn.attn_drop', 'norm', 'blocks.1.drop_path1', 'blocks.7.drop_path1', 'blocks1.3.ls2', 'patch_embed.backbone.stem.norm1.drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.7.ls1', 'blocks1.5.attn.attn_drop', 'blocks1.0.ls1', 'blocks.5.drop_path1', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks.1.ls1', 'blocks.3.ls2', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.1.attn.attn_drop', 'blocks1.1.mlp.norm', 'blocks.0.attn.attn_drop', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.0.drop_path1', 'blocks1.4.ls2', 'blocks.0.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'neural_augmentor.contrast.min_fn', 'blocks1.3.drop_path1', 'blocks1.2.ls2', 'blocks1.1.ls1', 'blocks1.4.drop_path1', 'blocks1.6.attn.k_norm', 'blocks.0.drop_path1', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.4.ls1', 'blocks.4.drop_path2', 'blocks.6.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks.6.drop_path2', 'blocks1.1.attn.attn_drop', 'blocks.6.ls2', 'blocks.5.mlp.norm', 'blocks1.4.mlp.norm', 'blocks1.0.attn.q_norm', 'neural_augmentor.contrast', 'blocks1.4.attn.attn_drop', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.3.mlp.norm', 'blocks.6.mlp.norm', 'neural_augmentor.brightness.max_fn', 'blocks.1.drop_path2', 'blocks.2.ls1', 'blocks.0.ls2', 'patch_embed.proj', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.0.attn.q_norm', 'blocks1.6.drop_path2', 'blocks.1.ls2', 'blocks.0.drop_path2', 'blocks1.3.attn.k_norm', 'blocks.3.attn.k_norm', 'blocks.4.attn.q_norm', 'blocks1.0.mlp.norm', 'blocks.2.drop_path2', 'blocks.6.attn.q_norm', 'blocks1.6.attn.q_norm', 'blocks1.6.ls2', 'blocks1.6.mlp.norm', 'blocks.5.ls1', 'blocks1.3.mlp.norm', 'blocks.2.attn.q_norm', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks.5.drop_path2', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.3.drop_path2', 'blocks.2.drop_path1', 'neural_augmentor.noise.max_fn', 'patch_embed.backbone.stages.1.1.drop_path', 'neural_augmentor.brightness', 'neural_augmentor.noise.min_fn', 'blocks.0.mlp.norm', 'blocks1.0.attn.attn_drop', 'blocks.4.ls2', 'blocks1.1.drop_path1', 'blocks1.5.ls1', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks.3.ls1', 'blocks.4.mlp.norm', 'blocks1.4.ls1', 'blocks1.7.mlp.norm', 'blocks1.0.drop_path2', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.7.mlp.norm', 'neural_augmentor.noise', 'blocks.6.ls1', 'blocks.2.attn.k_norm', 'blocks1.7.attn.q_norm', 'patch_embed.backbone.stages.1.3.down', 'blocks1.3.attn.attn_drop', 'blocks.4.drop_path1', 'neural_augmentor.contrast.max_fn', 'blocks.3.attn.q_norm', 'blocks.3.attn.attn_drop', 'norm_pre', 'blocks.2.mlp.norm', 'blocks1.1.attn.q_norm', 'blocks.5.attn.k_norm', 'blocks1.6.ls1', 'neural_augmentor.brightness.min_fn', 'blocks.4.attn.attn_drop', 'blocks1.6.attn.attn_drop', 'blocks.4.attn.k_norm', 'blocks.7.drop_path2', 'blocks1.6.drop_path1', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.1.0.down', 'blocks1.7.attn.attn_drop', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.2.drop_path1', 'blocks1.0.attn.k_norm', 'blocks1.2.attn.q_norm', 'blocks1.7.drop_path2', 'patch_embed.backbone.stages.1.2.down', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.5.ls2', 'blocks.7.attn.k_norm', 'blocks1.2.drop_path2', 'blocks.7.attn.q_norm', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.3.attn.q_norm', 'blocks1.2.attn.k_norm', 'blocks1.7.drop_path1', 'blocks1.5.attn.k_norm', 'blocks.5.attn.attn_drop', 'blocks1.4.attn.q_norm', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.7.attn.attn_drop', 'blocks1.2.mlp.norm', 'blocks1.3.drop_path2', 'blocks1.2.attn.attn_drop', 'blocks.5.attn.q_norm', 'blocks1.5.drop_path2', 'blocks.2.ls2', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'patch_embed.backbone.stages.1.1.down', 'blocks1.2.ls1', 'blocks1.3.ls1', 'blocks1.4.drop_path2', 'blocks1.1.ls2', 'blocks.0.attn.k_norm', 'blocks.1.mlp.norm', 'blocks1.7.ls2', 'blocks1.1.drop_path2', 'blocks1.7.ls1', 'blocks.7.ls2', 'blocks1.4.attn.k_norm', 'blocks1.5.drop_path1', 'blocks1.0.ls2'}
2024-07-16 18:53:42 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::sum': 2, 'aten::div': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	BinaryCrossEntropy(  reduction=batch_mean loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - Max. iteration for training: 200000
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=1e-05
 	 max_lr=0.001
 	 period=190001
 	 warmup_init_lr=1e-06
 	 warmup_iters=10000
 )
2024-07-16 18:53:42 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/results100_dci/train/training_checkpoint_last.pt'
2024-07-16 18:53:42 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results100_dci/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-16 18:53:44 - [32m[1mINFO   [0m - Training epoch 0
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [128, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [128, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-16 18:57:52 - [34m[1mLOGS   [0m - Epoch:   0 [       1/  200000], loss: {'classification': 7544.0425, 'neural_augmentation': 8.994, 'total_loss': 7553.0369}, LR: [1e-06, 1e-06], Avg. batch load time: 241.306, Elapsed time: 247.77
2024-07-16 19:00:31 - [34m[1mLOGS   [0m - Epoch:   0 [     501/  200000], loss: {'classification': 2602.3782, 'neural_augmentation': 9.2613, 'total_loss': 2611.6395}, LR: [5.1e-05, 5.1e-05], Avg. batch load time: 0.497, Elapsed time: 406.58
2024-07-16 19:02:50 - [34m[1mLOGS   [0m - Epoch:   0 [    1001/  200000], loss: {'classification': 1317.285, 'neural_augmentation': 9.261, 'total_loss': 1326.546}, LR: [0.000101, 0.000101], Avg. batch load time: 0.249, Elapsed time: 545.13
2024-07-16 19:05:14 - [34m[1mLOGS   [0m - Epoch:   0 [    1501/  200000], loss: {'classification': 888.9119, 'neural_augmentation': 9.2378, 'total_loss': 898.1497}, LR: [0.000151, 0.000151], Avg. batch load time: 0.167, Elapsed time: 689.58
2024-07-16 19:07:33 - [34m[1mLOGS   [0m - Epoch:   0 [    2001/  200000], loss: {'classification': 673.0314, 'neural_augmentation': 9.1878, 'total_loss': 682.2192}, LR: [0.000201, 0.000201], Avg. batch load time: 0.125, Elapsed time: 828.18
2024-07-16 19:09:51 - [34m[1mLOGS   [0m - Epoch:   0 [    2501/  200000], loss: {'classification': 546.3565, 'neural_augmentation': 9.125, 'total_loss': 555.4814}, LR: [0.000251, 0.000251], Avg. batch load time: 0.100, Elapsed time: 966.70
2024-07-16 19:12:18 - [34m[1mLOGS   [0m - Epoch:   0 [    3001/  200000], loss: {'classification': 460.2024, 'neural_augmentation': 9.0489, 'total_loss': 469.2514}, LR: [0.000301, 0.000301], Avg. batch load time: 0.084, Elapsed time: 1113.51
2024-07-16 19:14:37 - [34m[1mLOGS   [0m - Epoch:   0 [    3501/  200000], loss: {'classification': 398.2317, 'neural_augmentation': 8.9576, 'total_loss': 407.1893}, LR: [0.000351, 0.000351], Avg. batch load time: 0.072, Elapsed time: 1252.06
2024-07-16 19:17:03 - [34m[1mLOGS   [0m - Epoch:   0 [    4001/  200000], loss: {'classification': 352.346, 'neural_augmentation': 8.8487, 'total_loss': 361.1947}, LR: [0.000401, 0.000401], Avg. batch load time: 0.063, Elapsed time: 1398.09
2024-07-16 19:19:22 - [34m[1mLOGS   [0m - Epoch:   0 [    4501/  200000], loss: {'classification': 315.1742, 'neural_augmentation': 8.7178, 'total_loss': 323.892}, LR: [0.000451, 0.000451], Avg. batch load time: 0.056, Elapsed time: 1537.03
2024-07-16 19:21:41 - [34m[1mLOGS   [0m - Epoch:   0 [    5001/  200000], loss: {'classification': 286.0636, 'neural_augmentation': 8.5709, 'total_loss': 294.6345}, LR: [0.0005, 0.0005], Avg. batch load time: 0.051, Elapsed time: 1676.10
2024-07-16 19:24:06 - [34m[1mLOGS   [0m - Epoch:   0 [    5501/  200000], loss: {'classification': 261.4944, 'neural_augmentation': 8.3916, 'total_loss': 269.886}, LR: [0.00055, 0.00055], Avg. batch load time: 0.046, Elapsed time: 1821.06
2024-07-16 19:26:33 - [34m[1mLOGS   [0m - Epoch:   0 [    6001/  200000], loss: {'classification': 241.4925, 'neural_augmentation': 8.1888, 'total_loss': 249.6813}, LR: [0.0006, 0.0006], Avg. batch load time: 0.043, Elapsed time: 1968.60
2024-07-16 19:29:16 - [34m[1mLOGS   [0m - Epoch:   0 [    6501/  200000], loss: {'classification': 224.3152, 'neural_augmentation': 7.9551, 'total_loss': 232.2703}, LR: [0.00065, 0.00065], Avg. batch load time: 0.042, Elapsed time: 2131.41
2024-07-16 19:31:51 - [34m[1mLOGS   [0m - Epoch:   0 [    7001/  200000], loss: {'classification': 209.8397, 'neural_augmentation': 7.7011, 'total_loss': 217.5407}, LR: [0.0007, 0.0007], Avg. batch load time: 0.040, Elapsed time: 2286.15
2024-07-16 19:34:44 - [34m[1mLOGS   [0m - Epoch:   0 [    7501/  200000], loss: {'classification': 196.9107, 'neural_augmentation': 7.4229, 'total_loss': 204.3336}, LR: [0.00075, 0.00075], Avg. batch load time: 0.041, Elapsed time: 2459.30
2024-07-16 19:37:37 - [34m[1mLOGS   [0m - Epoch:   0 [    8001/  200000], loss: {'classification': 186.0649, 'neural_augmentation': 7.1498, 'total_loss': 193.2146}, LR: [0.0008, 0.0008], Avg. batch load time: 0.040, Elapsed time: 2632.91
2024-07-16 19:40:10 - [34m[1mLOGS   [0m - Epoch:   0 [    8501/  200000], loss: {'classification': 176.6613, 'neural_augmentation': 6.8823, 'total_loss': 183.5436}, LR: [0.00085, 0.00085], Avg. batch load time: 0.039, Elapsed time: 2785.45
2024-07-16 19:43:01 - [34m[1mLOGS   [0m - Epoch:   0 [    9001/  200000], loss: {'classification': 168.1626, 'neural_augmentation': 6.616, 'total_loss': 174.7786}, LR: [0.0009, 0.0009], Avg. batch load time: 0.039, Elapsed time: 2956.08
2024-07-16 19:45:47 - [34m[1mLOGS   [0m - Epoch:   0 [    9501/  200000], loss: {'classification': 160.2416, 'neural_augmentation': 6.3498, 'total_loss': 166.5914}, LR: [0.00095, 0.00095], Avg. batch load time: 0.038, Elapsed time: 3122.78
2024-07-16 19:48:46 - [34m[1mLOGS   [0m - Epoch:   0 [   10001/  200000], loss: {'classification': 153.3078, 'neural_augmentation': 6.1039, 'total_loss': 159.4116}, LR: [0.001, 0.001], Avg. batch load time: 0.039, Elapsed time: 3301.03
2024-07-16 19:51:29 - [34m[1mLOGS   [0m - Epoch:   0 [   10501/  200000], loss: {'classification': 147.3177, 'neural_augmentation': 5.88, 'total_loss': 153.1976}, LR: [0.001, 0.001], Avg. batch load time: 0.038, Elapsed time: 3464.66
2024-07-16 19:53:59 - [34m[1mLOGS   [0m - Epoch:   0 [   11001/  200000], loss: {'classification': 141.8616, 'neural_augmentation': 5.6709, 'total_loss': 147.5326}, LR: [0.001, 0.001], Avg. batch load time: 0.037, Elapsed time: 3614.54
2024-07-16 19:56:52 - [34m[1mLOGS   [0m - Epoch:   0 [   11501/  200000], loss: {'classification': 136.7128, 'neural_augmentation': 5.468, 'total_loss': 142.1808}, LR: [0.001, 0.001], Avg. batch load time: 0.037, Elapsed time: 3787.55
2024-07-16 19:59:41 - [34m[1mLOGS   [0m - Epoch:   0 [   12001/  200000], loss: {'classification': 132.0542, 'neural_augmentation': 5.2792, 'total_loss': 137.3334}, LR: [0.001, 0.001], Avg. batch load time: 0.037, Elapsed time: 3956.38
2024-07-16 20:02:22 - [34m[1mLOGS   [0m - Epoch:   0 [   12501/  200000], loss: {'classification': 127.9942, 'neural_augmentation': 5.1115, 'total_loss': 133.1057}, LR: [0.001, 0.001], Avg. batch load time: 0.037, Elapsed time: 4117.10
2024-07-16 20:05:03 - [34m[1mLOGS   [0m - Epoch:   0 [   13001/  200000], loss: {'classification': 123.9892, 'neural_augmentation': 4.9431, 'total_loss': 128.9324}, LR: [0.000999, 0.000999], Avg. batch load time: 0.037, Elapsed time: 4278.44
2024-07-16 20:07:59 - [34m[1mLOGS   [0m - Epoch:   0 [   13501/  200000], loss: {'classification': 120.29, 'neural_augmentation': 4.7854, 'total_loss': 125.0754}, LR: [0.000999, 0.000999], Avg. batch load time: 0.037, Elapsed time: 4454.26
2024-07-16 20:10:46 - [34m[1mLOGS   [0m - Epoch:   0 [   14001/  200000], loss: {'classification': 116.8671, 'neural_augmentation': 4.6372, 'total_loss': 121.5043}, LR: [0.000999, 0.000999], Avg. batch load time: 0.037, Elapsed time: 4621.30
2024-07-16 20:14:17 - [34m[1mLOGS   [0m - Epoch:   0 [   14501/  200000], loss: {'classification': 113.8349, 'neural_augmentation': 4.5041, 'total_loss': 118.339}, LR: [0.000999, 0.000999], Avg. batch load time: 0.040, Elapsed time: 4832.41
2024-07-16 20:18:54 - [34m[1mLOGS   [0m - Epoch:   0 [   15001/  200000], loss: {'classification': 110.7361, 'neural_augmentation': 4.3665, 'total_loss': 115.1026}, LR: [0.000998, 0.000998], Avg. batch load time: 0.047, Elapsed time: 5109.55
2024-07-16 20:23:44 - [34m[1mLOGS   [0m - Epoch:   0 [   15501/  200000], loss: {'classification': 107.9754, 'neural_augmentation': 4.2433, 'total_loss': 112.2187}, LR: [0.000998, 0.000998], Avg. batch load time: 0.054, Elapsed time: 5399.75
2024-07-16 20:28:41 - [34m[1mLOGS   [0m - Epoch:   0 [   16001/  200000], loss: {'classification': 105.2297, 'neural_augmentation': 4.1202, 'total_loss': 109.3498}, LR: [0.000998, 0.000998], Avg. batch load time: 0.060, Elapsed time: 5696.85
2024-07-16 20:33:31 - [34m[1mLOGS   [0m - Epoch:   0 [   16501/  200000], loss: {'classification': 102.6116, 'neural_augmentation': 4.0013, 'total_loss': 106.6129}, LR: [0.000997, 0.000997], Avg. batch load time: 0.067, Elapsed time: 5986.89
2024-07-16 20:38:18 - [34m[1mLOGS   [0m - Epoch:   0 [   17001/  200000], loss: {'classification': 100.3121, 'neural_augmentation': 3.8955, 'total_loss': 104.2076}, LR: [0.000997, 0.000997], Avg. batch load time: 0.073, Elapsed time: 6273.23
2024-07-16 20:42:59 - [34m[1mLOGS   [0m - Epoch:   0 [   17501/  200000], loss: {'classification': 98.1359, 'neural_augmentation': 3.7949, 'total_loss': 101.9308}, LR: [0.000996, 0.000996], Avg. batch load time: 0.077, Elapsed time: 6554.31
2024-07-16 20:47:39 - [34m[1mLOGS   [0m - Epoch:   0 [   18001/  200000], loss: {'classification': 96.1092, 'neural_augmentation': 3.7009, 'total_loss': 99.8101}, LR: [0.000996, 0.000996], Avg. batch load time: 0.082, Elapsed time: 6834.93
2024-07-16 20:52:20 - [34m[1mLOGS   [0m - Epoch:   0 [   18501/  200000], loss: {'classification': 94.1972, 'neural_augmentation': 3.6118, 'total_loss': 97.809}, LR: [0.000995, 0.000995], Avg. batch load time: 0.086, Elapsed time: 7115.04
2024-07-16 20:57:07 - [34m[1mLOGS   [0m - Epoch:   0 [   19001/  200000], loss: {'classification': 92.3361, 'neural_augmentation': 3.5249, 'total_loss': 95.861}, LR: [0.000995, 0.000995], Avg. batch load time: 0.090, Elapsed time: 7402.34
2024-07-16 21:01:52 - [34m[1mLOGS   [0m - Epoch:   0 [   19501/  200000], loss: {'classification': 90.544, 'neural_augmentation': 3.4408, 'total_loss': 93.9848}, LR: [0.000994, 0.000994], Avg. batch load time: 0.095, Elapsed time: 7687.91
2024-07-16 21:06:28 - [34m[1mLOGS   [0m - Epoch:   0 [   20001/  200000], loss: {'classification': 88.9818, 'neural_augmentation': 3.3673, 'total_loss': 92.3491}, LR: [0.000993, 0.000993], Avg. batch load time: 0.098, Elapsed time: 7963.77
2024-07-16 21:11:02 - [34m[1mLOGS   [0m - Epoch:   0 [   20501/  200000], loss: {'classification': 87.3216, 'neural_augmentation': 3.2887, 'total_loss': 90.6103}, LR: [0.000993, 0.000993], Avg. batch load time: 0.101, Elapsed time: 8237.54
2024-07-16 21:16:22 - [34m[1mLOGS   [0m - Epoch:   0 [   21001/  200000], loss: {'classification': 85.7688, 'neural_augmentation': 3.215, 'total_loss': 88.9838}, LR: [0.000992, 0.000992], Avg. batch load time: 0.106, Elapsed time: 8557.87
2024-07-16 21:20:54 - [34m[1mLOGS   [0m - Epoch:   0 [   21501/  200000], loss: {'classification': 84.3369, 'neural_augmentation': 3.147, 'total_loss': 87.4839}, LR: [0.000991, 0.000991], Avg. batch load time: 0.109, Elapsed time: 8829.51
2024-07-16 21:25:26 - [34m[1mLOGS   [0m - Epoch:   0 [   22001/  200000], loss: {'classification': 82.9526, 'neural_augmentation': 3.0812, 'total_loss': 86.0338}, LR: [0.00099, 0.00099], Avg. batch load time: 0.112, Elapsed time: 9101.05
2024-07-16 21:30:33 - [34m[1mLOGS   [0m - Epoch:   0 [   22501/  200000], loss: {'classification': 81.6227, 'neural_augmentation': 3.0176, 'total_loss': 84.6403}, LR: [0.000989, 0.000989], Avg. batch load time: 0.115, Elapsed time: 9408.16
2024-07-16 21:35:13 - [34m[1mLOGS   [0m - Epoch:   0 [   23001/  200000], loss: {'classification': 80.3583, 'neural_augmentation': 2.9572, 'total_loss': 83.3155}, LR: [0.000989, 0.000989], Avg. batch load time: 0.119, Elapsed time: 9688.61
2024-07-16 21:39:55 - [34m[1mLOGS   [0m - Epoch:   0 [   23501/  200000], loss: {'classification': 79.1628, 'neural_augmentation': 2.9001, 'total_loss': 82.0629}, LR: [0.000988, 0.000988], Avg. batch load time: 0.122, Elapsed time: 9970.19
2024-07-16 21:44:31 - [34m[1mLOGS   [0m - Epoch:   0 [   24001/  200000], loss: {'classification': 78.0153, 'neural_augmentation': 2.845, 'total_loss': 80.8603}, LR: [0.000987, 0.000987], Avg. batch load time: 0.124, Elapsed time: 10246.71
2024-07-16 21:49:14 - [34m[1mLOGS   [0m - Epoch:   0 [   24501/  200000], loss: {'classification': 76.9051, 'neural_augmentation': 2.7915, 'total_loss': 79.6965}, LR: [0.000986, 0.000986], Avg. batch load time: 0.126, Elapsed time: 10529.37
2024-07-16 21:55:01 - [34m[1mLOGS   [0m - Epoch:   0 [   25001/  200000], loss: {'classification': 76.0892, 'neural_augmentation': 2.7422, 'total_loss': 78.8314}, LR: [0.000985, 0.000985], Avg. batch load time: 0.131, Elapsed time: 10876.08
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 22:02:53 - [34m[1mLOGS   [0m - Epoch:   0 [   25501/  200000], loss: {'classification': 75.5193, 'neural_augmentation': 2.6927, 'total_loss': 78.2121}, LR: [0.000984, 0.000984], Avg. batch load time: 0.139, Elapsed time: 11348.99
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 22:10:20 - [34m[1mLOGS   [0m - Epoch:   0 [   26001/  200000], loss: {'classification': 74.9551, 'neural_augmentation': 2.6438, 'total_loss': 77.5989}, LR: [0.000983, 0.000983], Avg. batch load time: 0.145, Elapsed time: 11795.32
2024-07-16 22:18:08 - [34m[1mLOGS   [0m - Epoch:   0 [   26501/  200000], loss: {'classification': 74.3985, 'neural_augmentation': 2.5956, 'total_loss': 76.994}, LR: [0.000982, 0.000982], Avg. batch load time: 0.151, Elapsed time: 12263.83
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 22:25:48 - [34m[1mLOGS   [0m - Epoch:   0 [   27001/  200000], loss: {'classification': 73.8795, 'neural_augmentation': 2.5508, 'total_loss': 76.4302}, LR: [0.000981, 0.000981], Avg. batch load time: 0.157, Elapsed time: 12723.37
2024-07-16 22:33:16 - [34m[1mLOGS   [0m - Epoch:   0 [   27501/  200000], loss: {'classification': 73.3825, 'neural_augmentation': 2.5075, 'total_loss': 75.89}, LR: [0.000979, 0.000979], Avg. batch load time: 0.163, Elapsed time: 13171.19
2024-07-16 22:41:28 - [34m[1mLOGS   [0m - Epoch:   0 [   28001/  200000], loss: {'classification': 72.8732, 'neural_augmentation': 2.4633, 'total_loss': 75.3365}, LR: [0.000978, 0.000978], Avg. batch load time: 0.169, Elapsed time: 13663.76
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 22:48:54 - [34m[1mLOGS   [0m - Epoch:   0 [   28501/  200000], loss: {'classification': 72.4092, 'neural_augmentation': 2.4231, 'total_loss': 74.8323}, LR: [0.000977, 0.000977], Avg. batch load time: 0.175, Elapsed time: 14109.03
2024-07-16 22:56:51 - [34m[1mLOGS   [0m - Epoch:   0 [   29001/  200000], loss: {'classification': 71.9471, 'neural_augmentation': 2.3828, 'total_loss': 74.33}, LR: [0.000976, 0.000976], Avg. batch load time: 0.180, Elapsed time: 14586.76
2024-07-16 23:03:56 - [34m[1mLOGS   [0m - Epoch:   0 [   29501/  200000], loss: {'classification': 71.512, 'neural_augmentation': 2.3447, 'total_loss': 73.8567}, LR: [0.000974, 0.000974], Avg. batch load time: 0.185, Elapsed time: 15011.79
2024-07-16 23:12:08 - [34m[1mLOGS   [0m - Epoch:   0 [   30001/  200000], loss: {'classification': 71.0682, 'neural_augmentation': 2.3059, 'total_loss': 73.374}, LR: [0.000973, 0.000973], Avg. batch load time: 0.191, Elapsed time: 15503.61
2024-07-16 23:19:40 - [34m[1mLOGS   [0m - Epoch:   0 [   30501/  200000], loss: {'classification': 70.6629, 'neural_augmentation': 2.2705, 'total_loss': 72.9335}, LR: [0.000972, 0.000972], Avg. batch load time: 0.195, Elapsed time: 15955.72
2024-07-16 23:27:33 - [34m[1mLOGS   [0m - Epoch:   0 [   31001/  200000], loss: {'classification': 70.2519, 'neural_augmentation': 2.2349, 'total_loss': 72.4868}, LR: [0.00097, 0.00097], Avg. batch load time: 0.200, Elapsed time: 16428.94
2024-07-16 23:33:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 69.9105, 'neural_augmentation': 2.2052, 'total_loss': 72.1157}
2024-07-16 23:33:40 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results100_dci/train/checkpoint_best.pt
2024-07-16 23:33:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results100_dci/train/training_checkpoint_last.pt
2024-07-16 23:33:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results100_dci/train/checkpoint_last.pt
2024-07-16 23:33:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 31440 is saved at: /ML-A100/team/mm/models/catlip_data/results100_dci/train/training_checkpoint_epoch_0_iter_31440.pt
2024-07-16 23:33:42 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 31440 is saved at: /ML-A100/team/mm/models/catlip_data/results100_dci/train/checkpoint_epoch_0_iter_31440.pt
[31m===========================================================================[0m
2024-07-16 23:33:44 - [32m[1mINFO   [0m - Training epoch 1
2024-07-16 23:35:24 - [34m[1mLOGS   [0m - Epoch:   1 [   31441/  200000], loss: {'classification': 41.8303, 'neural_augmentation': 0.1494, 'total_loss': 41.9797}, LR: [0.000969, 0.000969], Avg. batch load time: 99.303, Elapsed time: 100.00
2024-07-16 23:39:09 - [34m[1mLOGS   [0m - Epoch:   1 [   31941/  200000], loss: {'classification': 30.3232, 'neural_augmentation': 0.1582, 'total_loss': 30.4814}, LR: [0.000968, 0.000968], Avg. batch load time: 0.317, Elapsed time: 325.35
2024-07-16 23:42:56 - [34m[1mLOGS   [0m - Epoch:   1 [   32441/  200000], loss: {'classification': 29.6832, 'neural_augmentation': 0.1621, 'total_loss': 29.8452}, LR: [0.000966, 0.000966], Avg. batch load time: 0.213, Elapsed time: 551.80
2024-07-16 23:46:32 - [34m[1mLOGS   [0m - Epoch:   1 [   32941/  200000], loss: {'classification': 29.399, 'neural_augmentation': 0.1641, 'total_loss': 29.5631}, LR: [0.000965, 0.000965], Avg. batch load time: 0.172, Elapsed time: 768.47
2024-07-16 23:50:17 - [34m[1mLOGS   [0m - Epoch:   1 [   33441/  200000], loss: {'classification': 29.1943, 'neural_augmentation': 0.1652, 'total_loss': 29.3595}, LR: [0.000963, 0.000963], Avg. batch load time: 0.152, Elapsed time: 992.84
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-16 23:54:07 - [34m[1mLOGS   [0m - Epoch:   1 [   33941/  200000], loss: {'classification': 29.0577, 'neural_augmentation': 0.1662, 'total_loss': 29.2239}, LR: [0.000962, 0.000962], Avg. batch load time: 0.141, Elapsed time: 1223.44
2024-07-16 23:58:07 - [34m[1mLOGS   [0m - Epoch:   1 [   34441/  200000], loss: {'classification': 28.9466, 'neural_augmentation': 0.1672, 'total_loss': 29.1137}, LR: [0.00096, 0.00096], Avg. batch load time: 0.133, Elapsed time: 1462.78
2024-07-17 00:02:14 - [34m[1mLOGS   [0m - Epoch:   1 [   34941/  200000], loss: {'classification': 28.8759, 'neural_augmentation': 0.1678, 'total_loss': 29.0437}, LR: [0.000959, 0.000959], Avg. batch load time: 0.136, Elapsed time: 1710.10
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 00:06:05 - [34m[1mLOGS   [0m - Epoch:   1 [   35441/  200000], loss: {'classification': 28.8076, 'neural_augmentation': 0.1681, 'total_loss': 28.9757}, LR: [0.000957, 0.000957], Avg. batch load time: 0.132, Elapsed time: 1941.61
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 00:10:04 - [34m[1mLOGS   [0m - Epoch:   1 [   35941/  200000], loss: {'classification': 28.7534, 'neural_augmentation': 0.1683, 'total_loss': 28.9218}, LR: [0.000955, 0.000955], Avg. batch load time: 0.135, Elapsed time: 2180.08
2024-07-17 00:13:48 - [34m[1mLOGS   [0m - Epoch:   1 [   36441/  200000], loss: {'classification': 28.7171, 'neural_augmentation': 0.1686, 'total_loss': 28.8857}, LR: [0.000953, 0.000953], Avg. batch load time: 0.132, Elapsed time: 2404.13
2024-07-17 00:18:06 - [34m[1mLOGS   [0m - Epoch:   1 [   36941/  200000], loss: {'classification': 28.6733, 'neural_augmentation': 0.1687, 'total_loss': 28.842}, LR: [0.000952, 0.000952], Avg. batch load time: 0.131, Elapsed time: 2662.04
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 00:22:10 - [34m[1mLOGS   [0m - Epoch:   1 [   37441/  200000], loss: {'classification': 28.6329, 'neural_augmentation': 0.1687, 'total_loss': 28.8016}, LR: [0.00095, 0.00095], Avg. batch load time: 0.128, Elapsed time: 2905.85
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 00:26:10 - [34m[1mLOGS   [0m - Epoch:   1 [   37941/  200000], loss: {'classification': 28.5942, 'neural_augmentation': 0.1687, 'total_loss': 28.7629}, LR: [0.000948, 0.000948], Avg. batch load time: 0.130, Elapsed time: 3145.86
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 00:30:16 - [34m[1mLOGS   [0m - Epoch:   1 [   38441/  200000], loss: {'classification': 28.5609, 'neural_augmentation': 0.1687, 'total_loss': 28.7296}, LR: [0.000946, 0.000946], Avg. batch load time: 0.130, Elapsed time: 3391.80
2024-07-17 00:34:10 - [34m[1mLOGS   [0m - Epoch:   1 [   38941/  200000], loss: {'classification': 28.5276, 'neural_augmentation': 0.1685, 'total_loss': 28.6961}, LR: [0.000944, 0.000944], Avg. batch load time: 0.131, Elapsed time: 3626.21
2024-07-17 00:38:33 - [34m[1mLOGS   [0m - Epoch:   1 [   39441/  200000], loss: {'classification': 28.4982, 'neural_augmentation': 0.1685, 'total_loss': 28.6667}, LR: [0.000942, 0.000942], Avg. batch load time: 0.131, Elapsed time: 3888.67
2024-07-17 00:42:41 - [34m[1mLOGS   [0m - Epoch:   1 [   39941/  200000], loss: {'classification': 28.4774, 'neural_augmentation': 0.1684, 'total_loss': 28.6458}, LR: [0.000941, 0.000941], Avg. batch load time: 0.132, Elapsed time: 4137.57
2024-07-17 00:46:38 - [34m[1mLOGS   [0m - Epoch:   1 [   40441/  200000], loss: {'classification': 28.4517, 'neural_augmentation': 0.1683, 'total_loss': 28.62}, LR: [0.000939, 0.000939], Avg. batch load time: 0.132, Elapsed time: 4373.71
2024-07-17 00:50:34 - [34m[1mLOGS   [0m - Epoch:   1 [   40941/  200000], loss: {'classification': 28.4318, 'neural_augmentation': 0.1682, 'total_loss': 28.5999}, LR: [0.000937, 0.000937], Avg. batch load time: 0.130, Elapsed time: 4610.40
2024-07-17 00:54:48 - [34m[1mLOGS   [0m - Epoch:   1 [   41441/  200000], loss: {'classification': 28.4061, 'neural_augmentation': 0.168, 'total_loss': 28.5741}, LR: [0.000935, 0.000935], Avg. batch load time: 0.130, Elapsed time: 4864.52
2024-07-17 00:58:55 - [34m[1mLOGS   [0m - Epoch:   1 [   41941/  200000], loss: {'classification': 28.3812, 'neural_augmentation': 0.1678, 'total_loss': 28.549}, LR: [0.000933, 0.000933], Avg. batch load time: 0.130, Elapsed time: 5111.50
2024-07-17 01:02:31 - [34m[1mLOGS   [0m - Epoch:   1 [   42441/  200000], loss: {'classification': 28.3627, 'neural_augmentation': 0.1677, 'total_loss': 28.5304}, LR: [0.00093, 0.00093], Avg. batch load time: 0.129, Elapsed time: 5327.24
2024-07-17 01:06:35 - [34m[1mLOGS   [0m - Epoch:   1 [   42941/  200000], loss: {'classification': 28.3425, 'neural_augmentation': 0.1676, 'total_loss': 28.5101}, LR: [0.000928, 0.000928], Avg. batch load time: 0.129, Elapsed time: 5571.02
2024-07-17 01:10:36 - [34m[1mLOGS   [0m - Epoch:   1 [   43441/  200000], loss: {'classification': 28.327, 'neural_augmentation': 0.1675, 'total_loss': 28.4945}, LR: [0.000926, 0.000926], Avg. batch load time: 0.128, Elapsed time: 5812.32
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:14:27 - [34m[1mLOGS   [0m - Epoch:   1 [   43941/  200000], loss: {'classification': 28.308, 'neural_augmentation': 0.1673, 'total_loss': 28.4754}, LR: [0.000924, 0.000924], Avg. batch load time: 0.128, Elapsed time: 6042.92
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:18:32 - [34m[1mLOGS   [0m - Epoch:   1 [   44441/  200000], loss: {'classification': 28.2905, 'neural_augmentation': 0.1672, 'total_loss': 28.4578}, LR: [0.000922, 0.000922], Avg. batch load time: 0.128, Elapsed time: 6288.43
2024-07-17 01:22:30 - [34m[1mLOGS   [0m - Epoch:   1 [   44941/  200000], loss: {'classification': 28.2707, 'neural_augmentation': 0.1671, 'total_loss': 28.4378}, LR: [0.00092, 0.00092], Avg. batch load time: 0.128, Elapsed time: 6525.98
2024-07-17 01:26:32 - [34m[1mLOGS   [0m - Epoch:   1 [   45441/  200000], loss: {'classification': 28.2555, 'neural_augmentation': 0.167, 'total_loss': 28.4225}, LR: [0.000917, 0.000917], Avg. batch load time: 0.129, Elapsed time: 6768.11
2024-07-17 01:30:27 - [34m[1mLOGS   [0m - Epoch:   1 [   45941/  200000], loss: {'classification': 28.2405, 'neural_augmentation': 0.167, 'total_loss': 28.4075}, LR: [0.000915, 0.000915], Avg. batch load time: 0.127, Elapsed time: 7003.31
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:34:22 - [34m[1mLOGS   [0m - Epoch:   1 [   46441/  200000], loss: {'classification': 28.2254, 'neural_augmentation': 0.1669, 'total_loss': 28.3923}, LR: [0.000913, 0.000913], Avg. batch load time: 0.127, Elapsed time: 7238.52
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:38:27 - [34m[1mLOGS   [0m - Epoch:   1 [   46941/  200000], loss: {'classification': 28.2094, 'neural_augmentation': 0.1669, 'total_loss': 28.3763}, LR: [0.00091, 0.00091], Avg. batch load time: 0.127, Elapsed time: 7483.40
2024-07-17 01:42:19 - [34m[1mLOGS   [0m - Epoch:   1 [   47441/  200000], loss: {'classification': 28.1957, 'neural_augmentation': 0.1669, 'total_loss': 28.3626}, LR: [0.000908, 0.000908], Avg. batch load time: 0.127, Elapsed time: 7715.63
2024-07-17 01:46:15 - [34m[1mLOGS   [0m - Epoch:   1 [   47941/  200000], loss: {'classification': 28.1822, 'neural_augmentation': 0.1669, 'total_loss': 28.3491}, LR: [0.000906, 0.000906], Avg. batch load time: 0.127, Elapsed time: 7950.90
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:50:15 - [34m[1mLOGS   [0m - Epoch:   1 [   48441/  200000], loss: {'classification': 28.1678, 'neural_augmentation': 0.1669, 'total_loss': 28.3347}, LR: [0.000903, 0.000903], Avg. batch load time: 0.127, Elapsed time: 8190.78
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/PIL/JpegImagePlugin.py:853: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file
  warnings.warn(
2024-07-17 01:54:08 - [34m[1mLOGS   [0m - Epoch:   1 [   48941/  200000], loss: {'classification': 28.1547, 'neural_augmentation': 0.1669, 'total_loss': 28.3216}, LR: [0.000901, 0.000901], Avg. batch load time: 0.126, Elapsed time: 8424.51
2024-07-17 01:58:35 - [34m[1mLOGS   [0m - Epoch:   1 [   49441/  200000], loss: {'classification': 28.1408, 'neural_augmentation': 0.167, 'total_loss': 28.3078}, LR: [0.000898, 0.000898], Avg. batch load time: 0.128, Elapsed time: 8691.29
