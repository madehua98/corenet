nohup: ignoring input
2024-08-07 06:08:22 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
dci
2024-08-07 06:08:26 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-07 06:08:26 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=6743, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =  109.299 M
Total trainable parameters =  109.299 M

2024-08-07 06:08:26 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-07 06:08:26 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.109G                 | 13.071G    |
|  pos_embed                           |  (1, 1, 512)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  3.653M                |  5.52G     |
|   patch_embed.backbone.stem          |   0.151M               |   1.901G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    43.352M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    8.028M  |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    1.85G   |
|   patch_embed.backbone.stages        |   2.321M               |   3.387G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.478G  |
|    patch_embed.backbone.stages.1     |    2.047M              |    1.909G  |
|   patch_embed.backbone.pool          |   1.181M               |   0.232G   |
|    patch_embed.backbone.pool.proj    |    1.18M               |    0.231G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.004M  |
|  blocks                              |  18.404M               |  3.607G    |
|   blocks.0                           |   2.629M               |   0.515G   |
|    blocks.0.norm1                    |    1.024K              |    0.502M  |
|    blocks.0.attn                     |    1.051M              |    0.206G  |
|    blocks.0.norm2                    |    1.024K              |    0.502M  |
|    blocks.0.mlp                      |    1.576M              |    0.309G  |
|   blocks.1                           |   2.629M               |   0.515G   |
|    blocks.1.norm1                    |    1.024K              |    0.502M  |
|    blocks.1.attn                     |    1.051M              |    0.206G  |
|    blocks.1.norm2                    |    1.024K              |    0.502M  |
|    blocks.1.mlp                      |    1.576M              |    0.309G  |
|   blocks.2                           |   2.629M               |   0.515G   |
|    blocks.2.norm1                    |    1.024K              |    0.502M  |
|    blocks.2.attn                     |    1.051M              |    0.206G  |
|    blocks.2.norm2                    |    1.024K              |    0.502M  |
|    blocks.2.mlp                      |    1.576M              |    0.309G  |
|   blocks.3                           |   2.629M               |   0.515G   |
|    blocks.3.norm1                    |    1.024K              |    0.502M  |
|    blocks.3.attn                     |    1.051M              |    0.206G  |
|    blocks.3.norm2                    |    1.024K              |    0.502M  |
|    blocks.3.mlp                      |    1.576M              |    0.309G  |
|   blocks.4                           |   2.629M               |   0.515G   |
|    blocks.4.norm1                    |    1.024K              |    0.502M  |
|    blocks.4.attn                     |    1.051M              |    0.206G  |
|    blocks.4.norm2                    |    1.024K              |    0.502M  |
|    blocks.4.mlp                      |    1.576M              |    0.309G  |
|   blocks.5                           |   2.629M               |   0.515G   |
|    blocks.5.norm1                    |    1.024K              |    0.502M  |
|    blocks.5.attn                     |    1.051M              |    0.206G  |
|    blocks.5.norm2                    |    1.024K              |    0.502M  |
|    blocks.5.mlp                      |    1.576M              |    0.309G  |
|   blocks.6                           |   2.629M               |   0.515G   |
|    blocks.6.norm1                    |    1.024K              |    0.502M  |
|    blocks.6.attn                     |    1.051M              |    0.206G  |
|    blocks.6.norm2                    |    1.024K              |    0.502M  |
|    blocks.6.mlp                      |    1.576M              |    0.309G  |
|  pool                                |  4.721M                |  0.232G    |
|   pool.proj                          |   4.72M                |   0.231G   |
|    pool.proj.weight                  |    (1024, 512, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.024K               |   0.502M   |
|    pool.norm.weight                  |    (512,)              |            |
|    pool.norm.bias                    |    (512,)              |            |
|  blocks1                             |  73.508M               |  3.602G    |
|   blocks1.0                          |   10.501M              |   0.515G   |
|    blocks1.0.norm1                   |    2.048K              |    0.251M  |
|    blocks1.0.attn                    |    4.198M              |    0.206G  |
|    blocks1.0.norm2                   |    2.048K              |    0.251M  |
|    blocks1.0.mlp                     |    6.299M              |    0.309G  |
|   blocks1.1                          |   10.501M              |   0.515G   |
|    blocks1.1.norm1                   |    2.048K              |    0.251M  |
|    blocks1.1.attn                    |    4.198M              |    0.206G  |
|    blocks1.1.norm2                   |    2.048K              |    0.251M  |
|    blocks1.1.mlp                     |    6.299M              |    0.309G  |
|   blocks1.2                          |   10.501M              |   0.515G   |
|    blocks1.2.norm1                   |    2.048K              |    0.251M  |
|    blocks1.2.attn                    |    4.198M              |    0.206G  |
|    blocks1.2.norm2                   |    2.048K              |    0.251M  |
|    blocks1.2.mlp                     |    6.299M              |    0.309G  |
|   blocks1.3                          |   10.501M              |   0.515G   |
|    blocks1.3.norm1                   |    2.048K              |    0.251M  |
|    blocks1.3.attn                    |    4.198M              |    0.206G  |
|    blocks1.3.norm2                   |    2.048K              |    0.251M  |
|    blocks1.3.mlp                     |    6.299M              |    0.309G  |
|   blocks1.4                          |   10.501M              |   0.515G   |
|    blocks1.4.norm1                   |    2.048K              |    0.251M  |
|    blocks1.4.attn                    |    4.198M              |    0.206G  |
|    blocks1.4.norm2                   |    2.048K              |    0.251M  |
|    blocks1.4.mlp                     |    6.299M              |    0.309G  |
|   blocks1.5                          |   10.501M              |   0.515G   |
|    blocks1.5.norm1                   |    2.048K              |    0.251M  |
|    blocks1.5.attn                    |    4.198M              |    0.206G  |
|    blocks1.5.norm2                   |    2.048K              |    0.251M  |
|    blocks1.5.mlp                     |    6.299M              |    0.309G  |
|   blocks1.6                          |   10.501M              |   0.515G   |
|    blocks1.6.norm1                   |    2.048K              |    0.251M  |
|    blocks1.6.attn                    |    4.198M              |    0.206G  |
|    blocks1.6.norm2                   |    2.048K              |    0.251M  |
|    blocks1.6.mlp                     |    6.299M              |    0.309G  |
|  mlp                                 |  2.099M                |  0.103G    |
|   mlp.0                              |   1.05M                |   51.38M   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   51.38M   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  6.912M                |  6.905M    |
|   classifier.weight                  |   (6743, 1024)         |            |
|   classifier.bias                    |   (6743,)              |            |
2024-08-07 06:08:27 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-07 06:08:27 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks1.5.attn.k_norm', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.5.attn.attn_drop', 'blocks1.1.drop_path1', 'blocks.3.attn.attn_drop', 'blocks1.1.attn.q_norm', 'blocks.2.attn.attn_drop', 'blocks.1.attn.attn_drop', 'neural_augmentor.brightness.max_fn', 'blocks1.1.drop_path2', 'blocks1.3.attn.attn_drop', 'blocks.6.drop_path1', 'patch_embed.proj', 'blocks.1.drop_path1', 'blocks.5.drop_path2', 'blocks1.3.drop_path2', 'blocks.4.ls1', 'blocks1.6.drop_path2', 'blocks1.5.ls1', 'blocks1.6.attn.k_norm', 'neural_augmentor.noise', 'patch_embed.backbone.stages.1.3.down', 'blocks1.3.ls2', 'neural_augmentor.brightness', 'patch_embed.backbone.stages.0.1.down', 'blocks1.2.drop_path1', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.3.attn.k_norm', 'neural_augmentor.brightness.min_fn', 'blocks.1.drop_path2', 'blocks1.4.attn.q_norm', 'neural_augmentor.contrast', 'patch_embed.backbone.stages.1.1.down', 'blocks1.6.attn.attn_drop', 'blocks.4.drop_path1', 'blocks.6.attn.attn_drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks.3.ls2', 'norm', 'blocks.3.attn.k_norm', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks.6.attn.k_norm', 'blocks1.3.drop_path1', 'blocks1.5.drop_path1', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.1.0.down', 'blocks1.0.attn.k_norm', 'blocks.6.drop_path2', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks1.0.attn.q_norm', 'blocks1.5.drop_path2', 'patch_embed.backbone.stages.1.3.drop_path', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.4.attn.attn_drop', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'neural_augmentor', 'blocks1.4.ls1', 'blocks1.1.attn.attn_drop', 'patch_embed.backbone.stages.0.1.shortcut', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.5.ls1', 'blocks.4.drop_path2', 'blocks1.2.drop_path2', 'blocks1.0.attn.attn_drop', 'patch_embed.backbone.stages.0.0.down', 'blocks.5.drop_path1', 'blocks.2.ls1', 'blocks1.2.attn.q_norm', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks1.4.drop_path2', 'blocks.0.ls2', 'blocks.2.drop_path1', 'blocks.0.drop_path2', 'blocks1.4.drop_path1', 'blocks1.0.ls2', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks1.4.ls2', 'blocks.4.ls2', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.0.ls1', 'blocks1.4.attn.k_norm', 'blocks.4.attn.q_norm', 'blocks1.0.drop_path2', 'blocks.0.attn.attn_drop', 'blocks1.3.attn.q_norm', 'patch_embed.backbone.stages.1.1.shortcut', 'neural_augmentor.contrast.min_fn', 'blocks1.0.drop_path1', 'blocks.2.ls2', 'blocks.3.ls1', 'blocks.3.attn.q_norm', 'blocks1.1.ls1', 'blocks.1.attn.k_norm', 'blocks.4.attn.attn_drop', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'patch_embed.backbone.stages.1.2.down', 'blocks.1.ls1', 'blocks.0.attn.q_norm', 'norm_pre', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'neural_augmentor.contrast.max_fn', 'blocks1.2.attn.k_norm', 'patch_embed.backbone.stem.norm1.drop', 'blocks1.6.ls2', 'blocks1.6.ls1', 'blocks1.5.ls2', 'blocks1.2.attn.attn_drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.2.attn.k_norm', 'blocks.5.attn.k_norm', 'blocks1.5.attn.attn_drop', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.0.ls1', 'neural_augmentor.noise.min_fn', 'blocks.3.drop_path2', 'blocks1.1.ls2', 'blocks.0.drop_path1', 'blocks.0.attn.k_norm', 'blocks.5.attn.q_norm', 'neural_augmentor.noise.max_fn', 'blocks1.2.ls1', 'blocks.2.attn.q_norm', 'blocks1.2.ls2', 'blocks1.6.drop_path1', 'blocks.2.drop_path2', 'blocks.3.drop_path1', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.1.attn.q_norm', 'blocks.6.ls2', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.6.ls1', 'blocks1.1.attn.k_norm', 'blocks1.6.attn.q_norm', 'blocks.1.ls2', 'blocks1.3.ls1', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.5.ls2', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.4.attn.k_norm', 'patch_drop'}
2024-08-07 06:08:27 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-07 06:08:27 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-08-07 06:08:27 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-08-07 06:08:27 - [34m[1mLOGS   [0m - Available GPUs: 8
2024-08-07 06:08:27 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-08-07 06:08:27 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train
2024-08-07 06:08:32 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://localhost:20000
2024-08-07 06:08:41 - [34m[1mLOGS   [0m - Training dataset details are given below
WordnetTaggedClassificationDataset(
	root= 
	is_training=True 
	num_samples=64290000
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	total_tar_files=6429
	max_files_per_tar=10000
	num_synsets=6743
)
2024-08-07 06:08:43 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=True
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=100
	 scales=[(128, 128, 306), (144, 144, 241), (160, 160, 196), (176, 176, 161), (192, 192, 136), (208, 208, 115), (224, 224, 100), (240, 240, 87), (256, 256, 76), (272, 272, 67), (288, 288, 60), (304, 304, 54), (320, 320, 49)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-08-07 06:08:43 - [34m[1mLOGS   [0m - Number of data workers: 64
base
dci
2024-08-07 06:08:45 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.norm.weight', 'blocks.0.mlp.norm.bias', 'blocks.0.mlp.w0.weight', 'blocks.0.mlp.w0.bias', 'blocks.0.mlp.w1.weight', 'blocks.0.mlp.w1.bias', 'blocks.0.mlp.w2.weight', 'blocks.0.mlp.w2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.norm.weight', 'blocks.1.mlp.norm.bias', 'blocks.1.mlp.w0.weight', 'blocks.1.mlp.w0.bias', 'blocks.1.mlp.w1.weight', 'blocks.1.mlp.w1.bias', 'blocks.1.mlp.w2.weight', 'blocks.1.mlp.w2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.norm.weight', 'blocks.2.mlp.norm.bias', 'blocks.2.mlp.w0.weight', 'blocks.2.mlp.w0.bias', 'blocks.2.mlp.w1.weight', 'blocks.2.mlp.w1.bias', 'blocks.2.mlp.w2.weight', 'blocks.2.mlp.w2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.norm.weight', 'blocks.3.mlp.norm.bias', 'blocks.3.mlp.w0.weight', 'blocks.3.mlp.w0.bias', 'blocks.3.mlp.w1.weight', 'blocks.3.mlp.w1.bias', 'blocks.3.mlp.w2.weight', 'blocks.3.mlp.w2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.norm.weight', 'blocks.4.mlp.norm.bias', 'blocks.4.mlp.w0.weight', 'blocks.4.mlp.w0.bias', 'blocks.4.mlp.w1.weight', 'blocks.4.mlp.w1.bias', 'blocks.4.mlp.w2.weight', 'blocks.4.mlp.w2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.norm.weight', 'blocks.5.mlp.norm.bias', 'blocks.5.mlp.w0.weight', 'blocks.5.mlp.w0.bias', 'blocks.5.mlp.w1.weight', 'blocks.5.mlp.w1.bias', 'blocks.5.mlp.w2.weight', 'blocks.5.mlp.w2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.norm.weight', 'blocks.6.mlp.norm.bias', 'blocks.6.mlp.w0.weight', 'blocks.6.mlp.w0.bias', 'blocks.6.mlp.w1.weight', 'blocks.6.mlp.w1.bias', 'blocks.6.mlp.w2.weight', 'blocks.6.mlp.w2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.norm.weight', 'blocks1.0.mlp.norm.bias', 'blocks1.0.mlp.w0.weight', 'blocks1.0.mlp.w0.bias', 'blocks1.0.mlp.w1.weight', 'blocks1.0.mlp.w1.bias', 'blocks1.0.mlp.w2.weight', 'blocks1.0.mlp.w2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.norm.weight', 'blocks1.1.mlp.norm.bias', 'blocks1.1.mlp.w0.weight', 'blocks1.1.mlp.w0.bias', 'blocks1.1.mlp.w1.weight', 'blocks1.1.mlp.w1.bias', 'blocks1.1.mlp.w2.weight', 'blocks1.1.mlp.w2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.norm.weight', 'blocks1.2.mlp.norm.bias', 'blocks1.2.mlp.w0.weight', 'blocks1.2.mlp.w0.bias', 'blocks1.2.mlp.w1.weight', 'blocks1.2.mlp.w1.bias', 'blocks1.2.mlp.w2.weight', 'blocks1.2.mlp.w2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.norm.weight', 'blocks1.3.mlp.norm.bias', 'blocks1.3.mlp.w0.weight', 'blocks1.3.mlp.w0.bias', 'blocks1.3.mlp.w1.weight', 'blocks1.3.mlp.w1.bias', 'blocks1.3.mlp.w2.weight', 'blocks1.3.mlp.w2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.norm.weight', 'blocks1.4.mlp.norm.bias', 'blocks1.4.mlp.w0.weight', 'blocks1.4.mlp.w0.bias', 'blocks1.4.mlp.w1.weight', 'blocks1.4.mlp.w1.bias', 'blocks1.4.mlp.w2.weight', 'blocks1.4.mlp.w2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.norm.weight', 'blocks1.5.mlp.norm.bias', 'blocks1.5.mlp.w0.weight', 'blocks1.5.mlp.w0.bias', 'blocks1.5.mlp.w1.weight', 'blocks1.5.mlp.w1.bias', 'blocks1.5.mlp.w2.weight', 'blocks1.5.mlp.w2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.norm.weight', 'blocks1.6.mlp.norm.bias', 'blocks1.6.mlp.w0.weight', 'blocks1.6.mlp.w0.bias', 'blocks1.6.mlp.w1.weight', 'blocks1.6.mlp.w1.bias', 'blocks1.6.mlp.w2.weight', 'blocks1.6.mlp.w2.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-08-07 06:08:45 - [34m[1mLOGS   [0m - [36mModel[0m
Foodv(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=512, out_features=1024, bias=True)
        (w1): Linear(in_features=512, out_features=1024, bias=True)
        (w2): Linear(in_features=1024, out_features=512, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): GeGluMlp(
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (act): GELU(approximate='none')
        (w0): Linear(in_features=1024, out_features=2048, bias=True)
        (w1): Linear(in_features=1024, out_features=2048, bias=True)
        (w2): Linear(in_features=2048, out_features=1024, bias=True)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=6743, bias=True, channel_first=False)
)
[31m=================================================================[0m
                              Foodv Summary
[31m=================================================================[0m
Total parameters     =  109.299 M
Total trainable parameters =  109.299 M

2024-08-07 06:08:46 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 224, 224]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.109G                 | 13.071G    |
|  pos_embed                           |  (1, 1, 512)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  3.653M                |  5.52G     |
|   patch_embed.backbone.stem          |   0.151M               |   1.901G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    43.352M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    8.028M  |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    1.85G   |
|   patch_embed.backbone.stages        |   2.321M               |   3.387G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.478G  |
|    patch_embed.backbone.stages.1     |    2.047M              |    1.909G  |
|   patch_embed.backbone.pool          |   1.181M               |   0.232G   |
|    patch_embed.backbone.pool.proj    |    1.18M               |    0.231G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.004M  |
|  blocks                              |  18.404M               |  3.607G    |
|   blocks.0                           |   2.629M               |   0.515G   |
|    blocks.0.norm1                    |    1.024K              |    0.502M  |
|    blocks.0.attn                     |    1.051M              |    0.206G  |
|    blocks.0.norm2                    |    1.024K              |    0.502M  |
|    blocks.0.mlp                      |    1.576M              |    0.309G  |
|   blocks.1                           |   2.629M               |   0.515G   |
|    blocks.1.norm1                    |    1.024K              |    0.502M  |
|    blocks.1.attn                     |    1.051M              |    0.206G  |
|    blocks.1.norm2                    |    1.024K              |    0.502M  |
|    blocks.1.mlp                      |    1.576M              |    0.309G  |
|   blocks.2                           |   2.629M               |   0.515G   |
|    blocks.2.norm1                    |    1.024K              |    0.502M  |
|    blocks.2.attn                     |    1.051M              |    0.206G  |
|    blocks.2.norm2                    |    1.024K              |    0.502M  |
|    blocks.2.mlp                      |    1.576M              |    0.309G  |
|   blocks.3                           |   2.629M               |   0.515G   |
|    blocks.3.norm1                    |    1.024K              |    0.502M  |
|    blocks.3.attn                     |    1.051M              |    0.206G  |
|    blocks.3.norm2                    |    1.024K              |    0.502M  |
|    blocks.3.mlp                      |    1.576M              |    0.309G  |
|   blocks.4                           |   2.629M               |   0.515G   |
|    blocks.4.norm1                    |    1.024K              |    0.502M  |
|    blocks.4.attn                     |    1.051M              |    0.206G  |
|    blocks.4.norm2                    |    1.024K              |    0.502M  |
|    blocks.4.mlp                      |    1.576M              |    0.309G  |
|   blocks.5                           |   2.629M               |   0.515G   |
|    blocks.5.norm1                    |    1.024K              |    0.502M  |
|    blocks.5.attn                     |    1.051M              |    0.206G  |
|    blocks.5.norm2                    |    1.024K              |    0.502M  |
|    blocks.5.mlp                      |    1.576M              |    0.309G  |
|   blocks.6                           |   2.629M               |   0.515G   |
|    blocks.6.norm1                    |    1.024K              |    0.502M  |
|    blocks.6.attn                     |    1.051M              |    0.206G  |
|    blocks.6.norm2                    |    1.024K              |    0.502M  |
|    blocks.6.mlp                      |    1.576M              |    0.309G  |
|  pool                                |  4.721M                |  0.232G    |
|   pool.proj                          |   4.72M                |   0.231G   |
|    pool.proj.weight                  |    (1024, 512, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.024K               |   0.502M   |
|    pool.norm.weight                  |    (512,)              |            |
|    pool.norm.bias                    |    (512,)              |            |
|  blocks1                             |  73.508M               |  3.602G    |
|   blocks1.0                          |   10.501M              |   0.515G   |
|    blocks1.0.norm1                   |    2.048K              |    0.251M  |
|    blocks1.0.attn                    |    4.198M              |    0.206G  |
|    blocks1.0.norm2                   |    2.048K              |    0.251M  |
|    blocks1.0.mlp                     |    6.299M              |    0.309G  |
|   blocks1.1                          |   10.501M              |   0.515G   |
|    blocks1.1.norm1                   |    2.048K              |    0.251M  |
|    blocks1.1.attn                    |    4.198M              |    0.206G  |
|    blocks1.1.norm2                   |    2.048K              |    0.251M  |
|    blocks1.1.mlp                     |    6.299M              |    0.309G  |
|   blocks1.2                          |   10.501M              |   0.515G   |
|    blocks1.2.norm1                   |    2.048K              |    0.251M  |
|    blocks1.2.attn                    |    4.198M              |    0.206G  |
|    blocks1.2.norm2                   |    2.048K              |    0.251M  |
|    blocks1.2.mlp                     |    6.299M              |    0.309G  |
|   blocks1.3                          |   10.501M              |   0.515G   |
|    blocks1.3.norm1                   |    2.048K              |    0.251M  |
|    blocks1.3.attn                    |    4.198M              |    0.206G  |
|    blocks1.3.norm2                   |    2.048K              |    0.251M  |
|    blocks1.3.mlp                     |    6.299M              |    0.309G  |
|   blocks1.4                          |   10.501M              |   0.515G   |
|    blocks1.4.norm1                   |    2.048K              |    0.251M  |
|    blocks1.4.attn                    |    4.198M              |    0.206G  |
|    blocks1.4.norm2                   |    2.048K              |    0.251M  |
|    blocks1.4.mlp                     |    6.299M              |    0.309G  |
|   blocks1.5                          |   10.501M              |   0.515G   |
|    blocks1.5.norm1                   |    2.048K              |    0.251M  |
|    blocks1.5.attn                    |    4.198M              |    0.206G  |
|    blocks1.5.norm2                   |    2.048K              |    0.251M  |
|    blocks1.5.mlp                     |    6.299M              |    0.309G  |
|   blocks1.6                          |   10.501M              |   0.515G   |
|    blocks1.6.norm1                   |    2.048K              |    0.251M  |
|    blocks1.6.attn                    |    4.198M              |    0.206G  |
|    blocks1.6.norm2                   |    2.048K              |    0.251M  |
|    blocks1.6.mlp                     |    6.299M              |    0.309G  |
|  mlp                                 |  2.099M                |  0.103G    |
|   mlp.0                              |   1.05M                |   51.38M   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   51.38M   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  6.912M                |  6.905M    |
|   classifier.weight                  |   (6743, 1024)         |            |
|   classifier.bias                    |   (6743,)              |            |
2024-08-07 06:08:46 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-08-07 06:08:46 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks1.0.ls2', 'blocks.2.drop_path1', 'patch_embed.backbone.stages.0.1.down', 'blocks1.6.drop_path2', 'neural_augmentor.brightness.min_fn', 'blocks1.3.ls2', 'patch_embed.backbone.stages.0.0.down', 'neural_augmentor.noise', 'blocks1.1.attn.attn_drop', 'norm', 'blocks1.3.ls1', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks1.0.attn.attn_drop', 'blocks1.6.attn.attn_drop', 'blocks1.0.drop_path1', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks.2.ls2', 'blocks.5.ls1', 'blocks1.2.drop_path2', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks.6.ls2', 'blocks1.4.ls2', 'neural_augmentor', 'blocks.0.ls2', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'patch_embed.backbone.stages.1.2.down', 'blocks1.5.ls1', 'blocks1.6.drop_path1', 'blocks1.1.drop_path2', 'blocks1.0.ls1', 'neural_augmentor.contrast', 'blocks1.5.drop_path1', 'blocks1.4.attn.k_norm', 'neural_augmentor.noise.min_fn', 'blocks.4.drop_path1', 'blocks.3.attn.q_norm', 'blocks.5.ls2', 'blocks.2.ls1', 'blocks1.6.ls1', 'blocks.4.attn.q_norm', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.6.ls2', 'blocks.1.ls1', 'blocks1.1.attn.q_norm', 'blocks.6.drop_path1', 'blocks1.5.ls2', 'blocks.3.ls1', 'blocks.4.attn.k_norm', 'blocks1.3.attn.k_norm', 'blocks.1.attn.k_norm', 'neural_augmentor.contrast.min_fn', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks1.2.attn.q_norm', 'blocks.1.attn.q_norm', 'blocks.4.attn.attn_drop', 'blocks.0.drop_path1', 'patch_embed.proj', 'blocks.2.drop_path2', 'neural_augmentor.brightness', 'blocks1.1.drop_path1', 'blocks1.5.drop_path2', 'neural_augmentor.contrast.max_fn', 'blocks.0.attn.attn_drop', 'blocks.1.attn.attn_drop', 'blocks1.2.ls2', 'blocks1.0.drop_path2', 'blocks.0.attn.q_norm', 'patch_embed.backbone.stem.norm1.drop', 'blocks.1.drop_path1', 'patch_drop', 'blocks.3.drop_path2', 'blocks.6.attn.q_norm', 'patch_embed.backbone.stages.1.0.drop_path', 'patch_embed.backbone.stages.1.1.down', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks1.4.attn.q_norm', 'neural_augmentor.noise.max_fn', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks.1.drop_path2', 'blocks.3.drop_path1', 'blocks1.3.drop_path1', 'blocks1.4.drop_path2', 'blocks.5.attn.q_norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'norm_pre', 'patch_embed.backbone.stages.1.0.down', 'blocks1.4.drop_path1', 'blocks.0.drop_path2', 'neural_augmentor.brightness.max_fn', 'blocks.6.ls1', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks1.0.attn.q_norm', 'blocks1.2.attn.k_norm', 'blocks1.2.ls1', 'blocks.2.attn.attn_drop', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'patch_embed.backbone.stages.1.2.drop_path', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks.5.attn.attn_drop', 'patch_embed.backbone.stages.1.2.shortcut', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'blocks.0.attn.k_norm', 'blocks.0.ls1', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.5.drop_path1', 'blocks1.5.attn.k_norm', 'blocks.2.attn.q_norm', 'blocks.6.drop_path2', 'blocks.4.ls1', 'blocks.3.attn.k_norm', 'blocks.4.ls2', 'blocks1.5.attn.attn_drop', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks1.4.ls1', 'blocks1.2.drop_path1', 'blocks1.6.attn.k_norm', 'blocks1.3.attn.attn_drop', 'blocks.5.drop_path2', 'blocks1.1.attn.k_norm', 'blocks.6.attn.attn_drop', 'blocks1.1.ls1', 'blocks.5.attn.k_norm', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.0.attn.k_norm', 'blocks.3.attn.attn_drop', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks.1.ls2', 'blocks1.6.attn.q_norm', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks1.1.ls2', 'blocks.6.attn.k_norm', 'blocks1.2.attn.attn_drop', 'blocks.4.drop_path2', 'patch_embed.backbone.stages.1.3.down', 'blocks1.3.drop_path2', 'blocks.2.attn.k_norm', 'blocks1.4.attn.attn_drop', 'blocks.3.ls2', 'blocks1.3.attn.q_norm'}
2024-08-07 06:08:46 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 35, 'aten::gelu': 28, 'aten::scaled_dot_product_attention': 14, 'aten::mul': 14, 'aten::avg_pool2d': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	BinaryCrossEntropy(  reduction=batch_mean loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - Max. iteration for training: 200000
2024-08-07 06:08:46 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=1e-05
 	 max_lr=0.001
 	 period=180001
 	 warmup_init_lr=1e-06
 	 warmup_iters=20000
 )
2024-08-07 06:08:49 - [34m[1mLOGS   [0m - Loaded checkpoint from /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_last.pt
2024-08-07 06:08:49 - [34m[1mLOGS   [0m - Resuming training for epoch 15
2024-08-07 06:08:49 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/results_base_noc/train/config.yaml[0m
[31m===========================================================================[0m
2024-08-07 06:08:51 - [32m[1mINFO   [0m - Training epoch 15
2024-08-07 06:08:35 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://localhost:20000
base
dci
2024-08-07 06:08:33 - [32m[1mINFO   [0m - distributed init (rank 6): tcp://localhost:20000
base
dci
2024-08-07 06:08:33 - [32m[1mINFO   [0m - distributed init (rank 4): tcp://localhost:20000
base
dci
2024-08-07 06:08:36 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://localhost:20000
base
dci
2024-08-07 06:08:33 - [32m[1mINFO   [0m - distributed init (rank 7): tcp://localhost:20000
base
dci
2024-08-07 06:08:33 - [32m[1mINFO   [0m - distributed init (rank 5): tcp://localhost:20000
base
dci
2024-08-07 06:08:33 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://localhost:20000
base
dci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-08-07 06:13:17 - [34m[1mLOGS   [0m - Epoch:  15 [  118781/  200000], loss: {'classification': 33.8256, 'neural_augmentation': 0.4557, 'total_loss': 34.2812}, LR: [0.000429, 0.000429], Avg. batch load time: 262.060, Elapsed time: 265.35
2024-08-07 06:15:26 - [34m[1mLOGS   [0m - Epoch:  15 [  118843/  200000], loss: {'classification': 33.4642, 'neural_augmentation': 0.4582, 'total_loss': 33.9224}, LR: [0.000429, 0.000429], Avg. batch load time: 0.526, Elapsed time: 394.79
2024-08-07 06:17:32 - [34m[1mLOGS   [0m - Epoch:  15 [  118906/  200000], loss: {'classification': 33.4583, 'neural_augmentation': 0.458, 'total_loss': 33.9163}, LR: [0.000428, 0.000428], Avg. batch load time: 0.264, Elapsed time: 521.09
2024-08-07 06:19:37 - [34m[1mLOGS   [0m - Epoch:  15 [  118968/  200000], loss: {'classification': 33.518, 'neural_augmentation': 0.4583, 'total_loss': 33.9764}, LR: [0.000428, 0.000428], Avg. batch load time: 0.176, Elapsed time: 646.19
2024-08-07 06:21:42 - [34m[1mLOGS   [0m - Epoch:  15 [  119031/  200000], loss: {'classification': 33.5605, 'neural_augmentation': 0.4584, 'total_loss': 34.0189}, LR: [0.000427, 0.000427], Avg. batch load time: 0.133, Elapsed time: 770.99
2024-08-07 06:23:47 - [34m[1mLOGS   [0m - Epoch:  15 [  119093/  200000], loss: {'classification': 33.5728, 'neural_augmentation': 0.4586, 'total_loss': 34.0314}, LR: [0.000427, 0.000427], Avg. batch load time: 0.106, Elapsed time: 895.87
2024-08-07 06:25:52 - [34m[1mLOGS   [0m - Epoch:  15 [  119156/  200000], loss: {'classification': 33.569, 'neural_augmentation': 0.4587, 'total_loss': 34.0277}, LR: [0.000426, 0.000426], Avg. batch load time: 0.089, Elapsed time: 1020.74
2024-08-07 06:27:57 - [34m[1mLOGS   [0m - Epoch:  15 [  119218/  200000], loss: {'classification': 33.5651, 'neural_augmentation': 0.4588, 'total_loss': 34.0239}, LR: [0.000426, 0.000426], Avg. batch load time: 0.076, Elapsed time: 1145.44
2024-08-07 06:30:01 - [34m[1mLOGS   [0m - Epoch:  15 [  119281/  200000], loss: {'classification': 33.5558, 'neural_augmentation': 0.459, 'total_loss': 34.0148}, LR: [0.000425, 0.000425], Avg. batch load time: 0.067, Elapsed time: 1270.26
2024-08-07 06:32:06 - [34m[1mLOGS   [0m - Epoch:  15 [  119343/  200000], loss: {'classification': 33.5499, 'neural_augmentation': 0.4592, 'total_loss': 34.0091}, LR: [0.000425, 0.000425], Avg. batch load time: 0.060, Elapsed time: 1394.90
2024-08-07 06:34:12 - [34m[1mLOGS   [0m - Epoch:  15 [  119406/  200000], loss: {'classification': 33.5496, 'neural_augmentation': 0.4593, 'total_loss': 34.009}, LR: [0.000424, 0.000424], Avg. batch load time: 0.054, Elapsed time: 1521.11
2024-08-07 06:36:19 - [34m[1mLOGS   [0m - Epoch:  15 [  119468/  200000], loss: {'classification': 33.5434, 'neural_augmentation': 0.4595, 'total_loss': 34.0029}, LR: [0.000424, 0.000424], Avg. batch load time: 0.049, Elapsed time: 1647.70
2024-08-07 06:38:23 - [34m[1mLOGS   [0m - Epoch:  15 [  119531/  200000], loss: {'classification': 33.5427, 'neural_augmentation': 0.4597, 'total_loss': 34.0024}, LR: [0.000423, 0.000423], Avg. batch load time: 0.045, Elapsed time: 1772.10
2024-08-07 06:40:28 - [34m[1mLOGS   [0m - Epoch:  15 [  119593/  200000], loss: {'classification': 33.5433, 'neural_augmentation': 0.4598, 'total_loss': 34.0032}, LR: [0.000423, 0.000423], Avg. batch load time: 0.042, Elapsed time: 1896.72
2024-08-07 06:42:33 - [34m[1mLOGS   [0m - Epoch:  15 [  119656/  200000], loss: {'classification': 33.5434, 'neural_augmentation': 0.46, 'total_loss': 34.0034}, LR: [0.000422, 0.000422], Avg. batch load time: 0.039, Elapsed time: 2021.52
2024-08-07 06:44:37 - [34m[1mLOGS   [0m - Epoch:  15 [  119718/  200000], loss: {'classification': 33.5424, 'neural_augmentation': 0.4602, 'total_loss': 34.0026}, LR: [0.000421, 0.000421], Avg. batch load time: 0.036, Elapsed time: 2146.11
2024-08-07 06:46:42 - [34m[1mLOGS   [0m - Epoch:  15 [  119781/  200000], loss: {'classification': 33.5386, 'neural_augmentation': 0.4604, 'total_loss': 33.9989}, LR: [0.000421, 0.000421], Avg. batch load time: 0.034, Elapsed time: 2270.47
2024-08-07 06:48:46 - [34m[1mLOGS   [0m - Epoch:  15 [  119843/  200000], loss: {'classification': 33.5415, 'neural_augmentation': 0.4605, 'total_loss': 34.002}, LR: [0.00042, 0.00042], Avg. batch load time: 0.032, Elapsed time: 2395.29
2024-08-07 06:50:51 - [34m[1mLOGS   [0m - Epoch:  15 [  119906/  200000], loss: {'classification': 33.5377, 'neural_augmentation': 0.4607, 'total_loss': 33.9984}, LR: [0.00042, 0.00042], Avg. batch load time: 0.030, Elapsed time: 2519.96
2024-08-07 06:52:56 - [34m[1mLOGS   [0m - Epoch:  15 [  119968/  200000], loss: {'classification': 33.5334, 'neural_augmentation': 0.4608, 'total_loss': 33.9943}, LR: [0.000419, 0.000419], Avg. batch load time: 0.029, Elapsed time: 2644.61
2024-08-07 06:55:00 - [34m[1mLOGS   [0m - Epoch:  15 [  120031/  200000], loss: {'classification': 33.529, 'neural_augmentation': 0.461, 'total_loss': 33.99}, LR: [0.000419, 0.000419], Avg. batch load time: 0.027, Elapsed time: 2769.08
2024-08-07 06:57:05 - [34m[1mLOGS   [0m - Epoch:  15 [  120093/  200000], loss: {'classification': 33.5299, 'neural_augmentation': 0.4611, 'total_loss': 33.991}, LR: [0.000418, 0.000418], Avg. batch load time: 0.026, Elapsed time: 2893.50
2024-08-07 06:59:09 - [34m[1mLOGS   [0m - Epoch:  15 [  120156/  200000], loss: {'classification': 33.5357, 'neural_augmentation': 0.4613, 'total_loss': 33.997}, LR: [0.000418, 0.000418], Avg. batch load time: 0.025, Elapsed time: 3018.17
2024-08-07 07:01:18 - [34m[1mLOGS   [0m - Epoch:  15 [  120218/  200000], loss: {'classification': 33.5351, 'neural_augmentation': 0.4614, 'total_loss': 33.9965}, LR: [0.000417, 0.000417], Avg. batch load time: 0.024, Elapsed time: 3146.78
2024-08-07 07:03:23 - [34m[1mLOGS   [0m - Epoch:  15 [  120281/  200000], loss: {'classification': 33.5331, 'neural_augmentation': 0.4616, 'total_loss': 33.9947}, LR: [0.000417, 0.000417], Avg. batch load time: 0.023, Elapsed time: 3271.32
2024-08-07 07:05:27 - [34m[1mLOGS   [0m - Epoch:  15 [  120343/  200000], loss: {'classification': 33.536, 'neural_augmentation': 0.4617, 'total_loss': 33.9977}, LR: [0.000416, 0.000416], Avg. batch load time: 0.022, Elapsed time: 3395.93
2024-08-07 07:07:32 - [34m[1mLOGS   [0m - Epoch:  15 [  120406/  200000], loss: {'classification': 33.5371, 'neural_augmentation': 0.4619, 'total_loss': 33.999}, LR: [0.000416, 0.000416], Avg. batch load time: 0.021, Elapsed time: 3520.52
2024-08-07 07:09:37 - [34m[1mLOGS   [0m - Epoch:  15 [  120468/  200000], loss: {'classification': 33.5351, 'neural_augmentation': 0.462, 'total_loss': 33.9971}, LR: [0.000415, 0.000415], Avg. batch load time: 0.021, Elapsed time: 3645.46
2024-08-07 07:11:42 - [34m[1mLOGS   [0m - Epoch:  15 [  120531/  200000], loss: {'classification': 33.5348, 'neural_augmentation': 0.4622, 'total_loss': 33.997}, LR: [0.000415, 0.000415], Avg. batch load time: 0.020, Elapsed time: 3770.51
2024-08-07 07:13:47 - [34m[1mLOGS   [0m - Epoch:  15 [  120593/  200000], loss: {'classification': 33.5328, 'neural_augmentation': 0.4624, 'total_loss': 33.9952}, LR: [0.000414, 0.000414], Avg. batch load time: 0.019, Elapsed time: 3895.39
2024-08-07 07:15:51 - [34m[1mLOGS   [0m - Epoch:  15 [  120656/  200000], loss: {'classification': 33.531, 'neural_augmentation': 0.4625, 'total_loss': 33.9935}, LR: [0.000413, 0.000413], Avg. batch load time: 0.019, Elapsed time: 4020.10
2024-08-07 07:17:56 - [34m[1mLOGS   [0m - Epoch:  15 [  120718/  200000], loss: {'classification': 33.5307, 'neural_augmentation': 0.4627, 'total_loss': 33.9934}, LR: [0.000413, 0.000413], Avg. batch load time: 0.018, Elapsed time: 4144.56
2024-08-07 07:20:01 - [34m[1mLOGS   [0m - Epoch:  15 [  120781/  200000], loss: {'classification': 33.531, 'neural_augmentation': 0.4628, 'total_loss': 33.9938}, LR: [0.000412, 0.000412], Avg. batch load time: 0.018, Elapsed time: 4269.42
2024-08-07 07:22:05 - [34m[1mLOGS   [0m - Epoch:  15 [  120843/  200000], loss: {'classification': 33.5288, 'neural_augmentation': 0.463, 'total_loss': 33.9918}, LR: [0.000412, 0.000412], Avg. batch load time: 0.017, Elapsed time: 4394.26
2024-08-07 07:24:10 - [34m[1mLOGS   [0m - Epoch:  15 [  120906/  200000], loss: {'classification': 33.5289, 'neural_augmentation': 0.4631, 'total_loss': 33.992}, LR: [0.000411, 0.000411], Avg. batch load time: 0.017, Elapsed time: 4519.20
2024-08-07 07:26:20 - [34m[1mLOGS   [0m - Epoch:  15 [  120968/  200000], loss: {'classification': 33.5265, 'neural_augmentation': 0.4633, 'total_loss': 33.9898}, LR: [0.000411, 0.000411], Avg. batch load time: 0.016, Elapsed time: 4648.96
2024-08-07 07:28:25 - [34m[1mLOGS   [0m - Epoch:  15 [  121031/  200000], loss: {'classification': 33.5242, 'neural_augmentation': 0.4634, 'total_loss': 33.9876}, LR: [0.00041, 0.00041], Avg. batch load time: 0.016, Elapsed time: 4773.92
2024-08-07 07:30:30 - [34m[1mLOGS   [0m - Epoch:  15 [  121093/  200000], loss: {'classification': 33.5228, 'neural_augmentation': 0.4636, 'total_loss': 33.9864}, LR: [0.00041, 0.00041], Avg. batch load time: 0.015, Elapsed time: 4898.78
2024-08-07 07:32:35 - [34m[1mLOGS   [0m - Epoch:  15 [  121156/  200000], loss: {'classification': 33.5215, 'neural_augmentation': 0.4637, 'total_loss': 33.9853}, LR: [0.000409, 0.000409], Avg. batch load time: 0.015, Elapsed time: 5023.47
2024-08-07 07:34:39 - [34m[1mLOGS   [0m - Epoch:  15 [  121218/  200000], loss: {'classification': 33.5193, 'neural_augmentation': 0.4639, 'total_loss': 33.9832}, LR: [0.000409, 0.000409], Avg. batch load time: 0.015, Elapsed time: 5148.10
2024-08-07 07:36:44 - [34m[1mLOGS   [0m - Epoch:  15 [  121281/  200000], loss: {'classification': 33.5194, 'neural_augmentation': 0.464, 'total_loss': 33.9834}, LR: [0.000408, 0.000408], Avg. batch load time: 0.014, Elapsed time: 5272.45
2024-08-07 07:38:49 - [34m[1mLOGS   [0m - Epoch:  15 [  121343/  200000], loss: {'classification': 33.5188, 'neural_augmentation': 0.4642, 'total_loss': 33.983}, LR: [0.000408, 0.000408], Avg. batch load time: 0.014, Elapsed time: 5397.36
2024-08-07 07:40:53 - [34m[1mLOGS   [0m - Epoch:  15 [  121406/  200000], loss: {'classification': 33.519, 'neural_augmentation': 0.4644, 'total_loss': 33.9833}, LR: [0.000407, 0.000407], Avg. batch load time: 0.014, Elapsed time: 5521.88
2024-08-07 07:42:58 - [34m[1mLOGS   [0m - Epoch:  15 [  121468/  200000], loss: {'classification': 33.5192, 'neural_augmentation': 0.4645, 'total_loss': 33.9837}, LR: [0.000407, 0.000407], Avg. batch load time: 0.013, Elapsed time: 5646.54
2024-08-07 07:45:02 - [34m[1mLOGS   [0m - Epoch:  15 [  121531/  200000], loss: {'classification': 33.5184, 'neural_augmentation': 0.4647, 'total_loss': 33.9831}, LR: [0.000406, 0.000406], Avg. batch load time: 0.013, Elapsed time: 5771.25
2024-08-07 07:47:07 - [34m[1mLOGS   [0m - Epoch:  15 [  121593/  200000], loss: {'classification': 33.5164, 'neural_augmentation': 0.4649, 'total_loss': 33.9812}, LR: [0.000406, 0.000406], Avg. batch load time: 0.013, Elapsed time: 5895.87
2024-08-07 07:49:12 - [34m[1mLOGS   [0m - Epoch:  15 [  121656/  200000], loss: {'classification': 33.5168, 'neural_augmentation': 0.465, 'total_loss': 33.9818}, LR: [0.000405, 0.000405], Avg. batch load time: 0.013, Elapsed time: 6020.54
2024-08-07 07:51:17 - [34m[1mLOGS   [0m - Epoch:  15 [  121718/  200000], loss: {'classification': 33.5161, 'neural_augmentation': 0.4652, 'total_loss': 33.9812}, LR: [0.000404, 0.000404], Avg. batch load time: 0.012, Elapsed time: 6145.33
2024-08-07 07:53:25 - [34m[1mLOGS   [0m - Epoch:  15 [  121781/  200000], loss: {'classification': 33.5141, 'neural_augmentation': 0.4653, 'total_loss': 33.9794}, LR: [0.000404, 0.000404], Avg. batch load time: 0.012, Elapsed time: 6273.58
2024-08-07 07:55:29 - [34m[1mLOGS   [0m - Epoch:  15 [  121843/  200000], loss: {'classification': 33.5093, 'neural_augmentation': 0.4655, 'total_loss': 33.9748}, LR: [0.000403, 0.000403], Avg. batch load time: 0.012, Elapsed time: 6397.78
2024-08-07 07:57:34 - [34m[1mLOGS   [0m - Epoch:  15 [  121906/  200000], loss: {'classification': 33.5086, 'neural_augmentation': 0.4656, 'total_loss': 33.9742}, LR: [0.000403, 0.000403], Avg. batch load time: 0.012, Elapsed time: 6522.56
2024-08-07 07:59:38 - [34m[1mLOGS   [0m - Epoch:  15 [  121968/  200000], loss: {'classification': 33.5082, 'neural_augmentation': 0.4658, 'total_loss': 33.974}, LR: [0.000402, 0.000402], Avg. batch load time: 0.011, Elapsed time: 6647.22
2024-08-07 08:01:43 - [34m[1mLOGS   [0m - Epoch:  15 [  122031/  200000], loss: {'classification': 33.5079, 'neural_augmentation': 0.4659, 'total_loss': 33.9739}, LR: [0.000402, 0.000402], Avg. batch load time: 0.011, Elapsed time: 6772.02
2024-08-07 08:03:48 - [34m[1mLOGS   [0m - Epoch:  15 [  122093/  200000], loss: {'classification': 33.5075, 'neural_augmentation': 0.4661, 'total_loss': 33.9736}, LR: [0.000401, 0.000401], Avg. batch load time: 0.011, Elapsed time: 6897.17
2024-08-07 08:05:53 - [34m[1mLOGS   [0m - Epoch:  15 [  122156/  200000], loss: {'classification': 33.5052, 'neural_augmentation': 0.4663, 'total_loss': 33.9715}, LR: [0.000401, 0.000401], Avg. batch load time: 0.011, Elapsed time: 7021.90
2024-08-07 08:07:58 - [34m[1mLOGS   [0m - Epoch:  15 [  122218/  200000], loss: {'classification': 33.5049, 'neural_augmentation': 0.4664, 'total_loss': 33.9713}, LR: [0.0004, 0.0004], Avg. batch load time: 0.011, Elapsed time: 7146.33
2024-08-07 08:10:02 - [34m[1mLOGS   [0m - Epoch:  15 [  122281/  200000], loss: {'classification': 33.5047, 'neural_augmentation': 0.4666, 'total_loss': 33.9712}, LR: [0.0004, 0.0004], Avg. batch load time: 0.011, Elapsed time: 7270.93
2024-08-07 08:12:07 - [34m[1mLOGS   [0m - Epoch:  15 [  122343/  200000], loss: {'classification': 33.5034, 'neural_augmentation': 0.4667, 'total_loss': 33.9702}, LR: [0.000399, 0.000399], Avg. batch load time: 0.010, Elapsed time: 7395.68
2024-08-07 08:14:12 - [34m[1mLOGS   [0m - Epoch:  15 [  122406/  200000], loss: {'classification': 33.5025, 'neural_augmentation': 0.4669, 'total_loss': 33.9694}, LR: [0.000399, 0.000399], Avg. batch load time: 0.010, Elapsed time: 7520.62
2024-08-07 08:16:16 - [34m[1mLOGS   [0m - Epoch:  15 [  122468/  200000], loss: {'classification': 33.5021, 'neural_augmentation': 0.467, 'total_loss': 33.9692}, LR: [0.000398, 0.000398], Avg. batch load time: 0.010, Elapsed time: 7645.10
2024-08-07 08:18:26 - [34m[1mLOGS   [0m - Epoch:  15 [  122531/  200000], loss: {'classification': 33.5006, 'neural_augmentation': 0.4672, 'total_loss': 33.9678}, LR: [0.000398, 0.000398], Avg. batch load time: 0.010, Elapsed time: 7775.02
2024-08-07 08:20:30 - [34m[1mLOGS   [0m - Epoch:  15 [  122593/  200000], loss: {'classification': 33.498, 'neural_augmentation': 0.4673, 'total_loss': 33.9653}, LR: [0.000397, 0.000397], Avg. batch load time: 0.010, Elapsed time: 7899.11
2024-08-07 08:22:35 - [34m[1mLOGS   [0m - Epoch:  15 [  122656/  200000], loss: {'classification': 33.4968, 'neural_augmentation': 0.4675, 'total_loss': 33.9643}, LR: [0.000397, 0.000397], Avg. batch load time: 0.010, Elapsed time: 8023.56
2024-08-07 08:24:39 - [34m[1mLOGS   [0m - Epoch:  15 [  122718/  200000], loss: {'classification': 33.4963, 'neural_augmentation': 0.4677, 'total_loss': 33.964}, LR: [0.000396, 0.000396], Avg. batch load time: 0.009, Elapsed time: 8147.72
2024-08-07 08:26:44 - [34m[1mLOGS   [0m - Epoch:  15 [  122781/  200000], loss: {'classification': 33.4959, 'neural_augmentation': 0.4678, 'total_loss': 33.9637}, LR: [0.000396, 0.000396], Avg. batch load time: 0.009, Elapsed time: 8272.39
2024-08-07 08:28:48 - [34m[1mLOGS   [0m - Epoch:  15 [  122843/  200000], loss: {'classification': 33.496, 'neural_augmentation': 0.468, 'total_loss': 33.964}, LR: [0.000395, 0.000395], Avg. batch load time: 0.009, Elapsed time: 8396.98
2024-08-07 08:30:53 - [34m[1mLOGS   [0m - Epoch:  15 [  122906/  200000], loss: {'classification': 33.4955, 'neural_augmentation': 0.4681, 'total_loss': 33.9636}, LR: [0.000394, 0.000394], Avg. batch load time: 0.009, Elapsed time: 8521.51
2024-08-07 08:32:57 - [34m[1mLOGS   [0m - Epoch:  15 [  122968/  200000], loss: {'classification': 33.4929, 'neural_augmentation': 0.4683, 'total_loss': 33.9612}, LR: [0.000394, 0.000394], Avg. batch load time: 0.009, Elapsed time: 8645.78
2024-08-07 08:35:01 - [34m[1mLOGS   [0m - Epoch:  15 [  123031/  200000], loss: {'classification': 33.4929, 'neural_augmentation': 0.4684, 'total_loss': 33.9613}, LR: [0.000393, 0.000393], Avg. batch load time: 0.009, Elapsed time: 8770.28
2024-08-07 08:37:06 - [34m[1mLOGS   [0m - Epoch:  15 [  123093/  200000], loss: {'classification': 33.4927, 'neural_augmentation': 0.4686, 'total_loss': 33.9613}, LR: [0.000393, 0.000393], Avg. batch load time: 0.009, Elapsed time: 8894.78
2024-08-07 08:39:10 - [34m[1mLOGS   [0m - Epoch:  15 [  123156/  200000], loss: {'classification': 33.492, 'neural_augmentation': 0.4687, 'total_loss': 33.9607}, LR: [0.000392, 0.000392], Avg. batch load time: 0.009, Elapsed time: 9019.23
2024-08-07 08:41:15 - [34m[1mLOGS   [0m - Epoch:  15 [  123218/  200000], loss: {'classification': 33.4903, 'neural_augmentation': 0.4689, 'total_loss': 33.9592}, LR: [0.000392, 0.000392], Avg. batch load time: 0.009, Elapsed time: 9143.80
2024-08-07 08:43:25 - [34m[1mLOGS   [0m - Epoch:  15 [  123281/  200000], loss: {'classification': 33.4893, 'neural_augmentation': 0.4691, 'total_loss': 33.9584}, LR: [0.000391, 0.000391], Avg. batch load time: 0.008, Elapsed time: 9273.39
2024-08-07 08:45:29 - [34m[1mLOGS   [0m - Epoch:  15 [  123343/  200000], loss: {'classification': 33.4891, 'neural_augmentation': 0.4692, 'total_loss': 33.9583}, LR: [0.000391, 0.000391], Avg. batch load time: 0.008, Elapsed time: 9397.89
2024-08-07 08:47:34 - [34m[1mLOGS   [0m - Epoch:  15 [  123406/  200000], loss: {'classification': 33.488, 'neural_augmentation': 0.4694, 'total_loss': 33.9573}, LR: [0.00039, 0.00039], Avg. batch load time: 0.008, Elapsed time: 9522.60
2024-08-07 08:49:38 - [34m[1mLOGS   [0m - Epoch:  15 [  123468/  200000], loss: {'classification': 33.4856, 'neural_augmentation': 0.4695, 'total_loss': 33.9551}, LR: [0.00039, 0.00039], Avg. batch load time: 0.008, Elapsed time: 9647.23
2024-08-07 08:51:43 - [34m[1mLOGS   [0m - Epoch:  15 [  123531/  200000], loss: {'classification': 33.4852, 'neural_augmentation': 0.4697, 'total_loss': 33.9549}, LR: [0.000389, 0.000389], Avg. batch load time: 0.008, Elapsed time: 9771.80
2024-08-07 08:53:47 - [34m[1mLOGS   [0m - Epoch:  15 [  123593/  200000], loss: {'classification': 33.4848, 'neural_augmentation': 0.4698, 'total_loss': 33.9546}, LR: [0.000389, 0.000389], Avg. batch load time: 0.008, Elapsed time: 9896.14
2024-08-07 08:55:52 - [34m[1mLOGS   [0m - Epoch:  15 [  123656/  200000], loss: {'classification': 33.4856, 'neural_augmentation': 0.47, 'total_loss': 33.9556}, LR: [0.000388, 0.000388], Avg. batch load time: 0.008, Elapsed time: 10020.92
2024-08-07 08:57:56 - [34m[1mLOGS   [0m - Epoch:  15 [  123718/  200000], loss: {'classification': 33.4841, 'neural_augmentation': 0.4701, 'total_loss': 33.9542}, LR: [0.000388, 0.000388], Avg. batch load time: 0.008, Elapsed time: 10145.20
2024-08-07 09:00:01 - [34m[1mLOGS   [0m - Epoch:  15 [  123781/  200000], loss: {'classification': 33.4838, 'neural_augmentation': 0.4703, 'total_loss': 33.9541}, LR: [0.000387, 0.000387], Avg. batch load time: 0.008, Elapsed time: 10269.93
2024-08-07 09:02:06 - [34m[1mLOGS   [0m - Epoch:  15 [  123843/  200000], loss: {'classification': 33.484, 'neural_augmentation': 0.4705, 'total_loss': 33.9545}, LR: [0.000387, 0.000387], Avg. batch load time: 0.008, Elapsed time: 10394.56
2024-08-07 09:04:10 - [34m[1mLOGS   [0m - Epoch:  15 [  123906/  200000], loss: {'classification': 33.4827, 'neural_augmentation': 0.4706, 'total_loss': 33.9533}, LR: [0.000386, 0.000386], Avg. batch load time: 0.008, Elapsed time: 10519.01
2024-08-07 09:06:15 - [34m[1mLOGS   [0m - Epoch:  15 [  123968/  200000], loss: {'classification': 33.4822, 'neural_augmentation': 0.4708, 'total_loss': 33.953}, LR: [0.000386, 0.000386], Avg. batch load time: 0.007, Elapsed time: 10643.70
2024-08-07 09:08:20 - [34m[1mLOGS   [0m - Epoch:  15 [  124031/  200000], loss: {'classification': 33.482, 'neural_augmentation': 0.4709, 'total_loss': 33.9529}, LR: [0.000385, 0.000385], Avg. batch load time: 0.007, Elapsed time: 10768.33
2024-08-07 09:10:29 - [34m[1mLOGS   [0m - Epoch:  15 [  124093/  200000], loss: {'classification': 33.4803, 'neural_augmentation': 0.4711, 'total_loss': 33.9514}, LR: [0.000384, 0.000384], Avg. batch load time: 0.007, Elapsed time: 10898.18
2024-08-07 09:12:34 - [34m[1mLOGS   [0m - Epoch:  15 [  124156/  200000], loss: {'classification': 33.4792, 'neural_augmentation': 0.4712, 'total_loss': 33.9504}, LR: [0.000384, 0.000384], Avg. batch load time: 0.007, Elapsed time: 11022.63
2024-08-07 09:14:38 - [34m[1mLOGS   [0m - Epoch:  15 [  124218/  200000], loss: {'classification': 33.4785, 'neural_augmentation': 0.4714, 'total_loss': 33.9499}, LR: [0.000383, 0.000383], Avg. batch load time: 0.007, Elapsed time: 11147.12
2024-08-07 09:16:43 - [34m[1mLOGS   [0m - Epoch:  15 [  124281/  200000], loss: {'classification': 33.4775, 'neural_augmentation': 0.4716, 'total_loss': 33.949}, LR: [0.000383, 0.000383], Avg. batch load time: 0.007, Elapsed time: 11271.67
2024-08-07 09:18:47 - [34m[1mLOGS   [0m - Epoch:  15 [  124343/  200000], loss: {'classification': 33.4758, 'neural_augmentation': 0.4717, 'total_loss': 33.9475}, LR: [0.000382, 0.000382], Avg. batch load time: 0.007, Elapsed time: 11396.25
2024-08-07 09:20:52 - [34m[1mLOGS   [0m - Epoch:  15 [  124406/  200000], loss: {'classification': 33.4747, 'neural_augmentation': 0.4719, 'total_loss': 33.9466}, LR: [0.000382, 0.000382], Avg. batch load time: 0.007, Elapsed time: 11520.79
2024-08-07 09:22:57 - [34m[1mLOGS   [0m - Epoch:  15 [  124468/  200000], loss: {'classification': 33.4756, 'neural_augmentation': 0.472, 'total_loss': 33.9476}, LR: [0.000381, 0.000381], Avg. batch load time: 0.007, Elapsed time: 11645.81
2024-08-07 09:25:02 - [34m[1mLOGS   [0m - Epoch:  15 [  124531/  200000], loss: {'classification': 33.4759, 'neural_augmentation': 0.4722, 'total_loss': 33.9481}, LR: [0.000381, 0.000381], Avg. batch load time: 0.007, Elapsed time: 11770.64
2024-08-07 09:27:07 - [34m[1mLOGS   [0m - Epoch:  15 [  124593/  200000], loss: {'classification': 33.4753, 'neural_augmentation': 0.4724, 'total_loss': 33.9476}, LR: [0.00038, 0.00038], Avg. batch load time: 0.007, Elapsed time: 11895.44
2024-08-07 09:29:11 - [34m[1mLOGS   [0m - Epoch:  15 [  124656/  200000], loss: {'classification': 33.4745, 'neural_augmentation': 0.4725, 'total_loss': 33.947}, LR: [0.00038, 0.00038], Avg. batch load time: 0.007, Elapsed time: 12019.67
2024-08-07 09:31:15 - [34m[1mLOGS   [0m - Epoch:  15 [  124718/  200000], loss: {'classification': 33.4739, 'neural_augmentation': 0.4727, 'total_loss': 33.9465}, LR: [0.000379, 0.000379], Avg. batch load time: 0.007, Elapsed time: 12144.07
2024-08-07 09:33:20 - [34m[1mLOGS   [0m - Epoch:  15 [  124781/  200000], loss: {'classification': 33.4725, 'neural_augmentation': 0.4728, 'total_loss': 33.9454}, LR: [0.000379, 0.000379], Avg. batch load time: 0.007, Elapsed time: 12268.57
2024-08-07 09:35:33 - [34m[1mLOGS   [0m - Epoch:  15 [  124843/  200000], loss: {'classification': 33.4718, 'neural_augmentation': 0.473, 'total_loss': 33.9448}, LR: [0.000378, 0.000378], Avg. batch load time: 0.007, Elapsed time: 12402.02
2024-08-07 09:37:38 - [34m[1mLOGS   [0m - Epoch:  15 [  124906/  200000], loss: {'classification': 33.4708, 'neural_augmentation': 0.4731, 'total_loss': 33.9439}, LR: [0.000378, 0.000378], Avg. batch load time: 0.007, Elapsed time: 12526.66
2024-08-07 09:39:42 - [34m[1mLOGS   [0m - Epoch:  15 [  124968/  200000], loss: {'classification': 33.4705, 'neural_augmentation': 0.4733, 'total_loss': 33.9438}, LR: [0.000377, 0.000377], Avg. batch load time: 0.006, Elapsed time: 12651.28
2024-08-07 09:41:47 - [34m[1mLOGS   [0m - Epoch:  15 [  125031/  200000], loss: {'classification': 33.4694, 'neural_augmentation': 0.4734, 'total_loss': 33.9429}, LR: [0.000377, 0.000377], Avg. batch load time: 0.006, Elapsed time: 12776.13
2024-08-07 09:43:52 - [34m[1mLOGS   [0m - Epoch:  15 [  125093/  200000], loss: {'classification': 33.4689, 'neural_augmentation': 0.4736, 'total_loss': 33.9425}, LR: [0.000376, 0.000376], Avg. batch load time: 0.006, Elapsed time: 12900.85
2024-08-07 09:45:57 - [34m[1mLOGS   [0m - Epoch:  15 [  125156/  200000], loss: {'classification': 33.4675, 'neural_augmentation': 0.4737, 'total_loss': 33.9412}, LR: [0.000376, 0.000376], Avg. batch load time: 0.006, Elapsed time: 13025.33
2024-08-07 09:48:01 - [34m[1mLOGS   [0m - Epoch:  15 [  125218/  200000], loss: {'classification': 33.467, 'neural_augmentation': 0.4739, 'total_loss': 33.9409}, LR: [0.000375, 0.000375], Avg. batch load time: 0.006, Elapsed time: 13149.76
2024-08-07 09:50:06 - [34m[1mLOGS   [0m - Epoch:  15 [  125281/  200000], loss: {'classification': 33.4671, 'neural_augmentation': 0.4741, 'total_loss': 33.9412}, LR: [0.000375, 0.000375], Avg. batch load time: 0.006, Elapsed time: 13274.57
2024-08-07 09:52:11 - [34m[1mLOGS   [0m - Epoch:  15 [  125343/  200000], loss: {'classification': 33.4664, 'neural_augmentation': 0.4742, 'total_loss': 33.9406}, LR: [0.000374, 0.000374], Avg. batch load time: 0.006, Elapsed time: 13399.49
2024-08-07 09:54:15 - [34m[1mLOGS   [0m - Epoch:  15 [  125406/  200000], loss: {'classification': 33.4662, 'neural_augmentation': 0.4744, 'total_loss': 33.9405}, LR: [0.000374, 0.000374], Avg. batch load time: 0.006, Elapsed time: 13524.25
2024-08-07 09:56:20 - [34m[1mLOGS   [0m - Epoch:  15 [  125468/  200000], loss: {'classification': 33.4656, 'neural_augmentation': 0.4745, 'total_loss': 33.9401}, LR: [0.000373, 0.000373], Avg. batch load time: 0.006, Elapsed time: 13648.97
2024-08-07 09:58:25 - [34m[1mLOGS   [0m - Epoch:  15 [  125531/  200000], loss: {'classification': 33.4651, 'neural_augmentation': 0.4747, 'total_loss': 33.9398}, LR: [0.000372, 0.000372], Avg. batch load time: 0.006, Elapsed time: 13773.83
2024-08-07 10:00:37 - [34m[1mLOGS   [0m - Epoch:  15 [  125593/  200000], loss: {'classification': 33.4638, 'neural_augmentation': 0.4749, 'total_loss': 33.9387}, LR: [0.000372, 0.000372], Avg. batch load time: 0.006, Elapsed time: 13905.49
2024-08-07 10:02:43 - [34m[1mLOGS   [0m - Epoch:  15 [  125656/  200000], loss: {'classification': 33.4632, 'neural_augmentation': 0.475, 'total_loss': 33.9382}, LR: [0.000371, 0.000371], Avg. batch load time: 0.006, Elapsed time: 14031.63
2024-08-07 10:04:47 - [34m[1mLOGS   [0m - Epoch:  15 [  125718/  200000], loss: {'classification': 33.4622, 'neural_augmentation': 0.4752, 'total_loss': 33.9374}, LR: [0.000371, 0.000371], Avg. batch load time: 0.006, Elapsed time: 14156.11
2024-08-07 10:06:52 - [34m[1mLOGS   [0m - Epoch:  15 [  125781/  200000], loss: {'classification': 33.4615, 'neural_augmentation': 0.4753, 'total_loss': 33.9368}, LR: [0.00037, 0.00037], Avg. batch load time: 0.006, Elapsed time: 14280.38
2024-08-07 10:08:56 - [34m[1mLOGS   [0m - Epoch:  15 [  125843/  200000], loss: {'classification': 33.4612, 'neural_augmentation': 0.4755, 'total_loss': 33.9366}, LR: [0.00037, 0.00037], Avg. batch load time: 0.006, Elapsed time: 14404.99
2024-08-07 10:11:01 - [34m[1mLOGS   [0m - Epoch:  15 [  125906/  200000], loss: {'classification': 33.4605, 'neural_augmentation': 0.4756, 'total_loss': 33.9361}, LR: [0.000369, 0.000369], Avg. batch load time: 0.006, Elapsed time: 14529.73
2024-08-07 10:13:05 - [34m[1mLOGS   [0m - Epoch:  15 [  125968/  200000], loss: {'classification': 33.4595, 'neural_augmentation': 0.4758, 'total_loss': 33.9353}, LR: [0.000369, 0.000369], Avg. batch load time: 0.006, Elapsed time: 14654.17
2024-08-07 10:15:10 - [34m[1mLOGS   [0m - Epoch:  15 [  126031/  200000], loss: {'classification': 33.4589, 'neural_augmentation': 0.4759, 'total_loss': 33.9348}, LR: [0.000368, 0.000368], Avg. batch load time: 0.006, Elapsed time: 14778.91
2024-08-07 10:17:15 - [34m[1mLOGS   [0m - Epoch:  15 [  126093/  200000], loss: {'classification': 33.4588, 'neural_augmentation': 0.4761, 'total_loss': 33.9349}, LR: [0.000368, 0.000368], Avg. batch load time: 0.006, Elapsed time: 14903.74
2024-08-07 10:19:19 - [34m[1mLOGS   [0m - Epoch:  15 [  126156/  200000], loss: {'classification': 33.4589, 'neural_augmentation': 0.4762, 'total_loss': 33.9351}, LR: [0.000367, 0.000367], Avg. batch load time: 0.006, Elapsed time: 15028.22
2024-08-07 10:21:24 - [34m[1mLOGS   [0m - Epoch:  15 [  126218/  200000], loss: {'classification': 33.4589, 'neural_augmentation': 0.4764, 'total_loss': 33.9352}, LR: [0.000367, 0.000367], Avg. batch load time: 0.006, Elapsed time: 15152.59
2024-08-07 10:23:28 - [34m[1mLOGS   [0m - Epoch:  15 [  126281/  200000], loss: {'classification': 33.4584, 'neural_augmentation': 0.4765, 'total_loss': 33.9349}, LR: [0.000366, 0.000366], Avg. batch load time: 0.006, Elapsed time: 15276.86
2024-08-07 10:25:34 - [34m[1mLOGS   [0m - Epoch:  15 [  126343/  200000], loss: {'classification': 33.4576, 'neural_augmentation': 0.4767, 'total_loss': 33.9343}, LR: [0.000366, 0.000366], Avg. batch load time: 0.005, Elapsed time: 15403.17
2024-08-07 10:27:46 - [34m[1mLOGS   [0m - Epoch:  15 [  126406/  200000], loss: {'classification': 33.4565, 'neural_augmentation': 0.4768, 'total_loss': 33.9334}, LR: [0.000365, 0.000365], Avg. batch load time: 0.005, Elapsed time: 15534.74
2024-08-07 10:29:50 - [34m[1mLOGS   [0m - Epoch:  15 [  126468/  200000], loss: {'classification': 33.4548, 'neural_augmentation': 0.477, 'total_loss': 33.9318}, LR: [0.000365, 0.000365], Avg. batch load time: 0.005, Elapsed time: 15659.29
2024-08-07 10:31:55 - [34m[1mLOGS   [0m - Epoch:  15 [  126531/  200000], loss: {'classification': 33.4548, 'neural_augmentation': 0.4771, 'total_loss': 33.932}, LR: [0.000364, 0.000364], Avg. batch load time: 0.005, Elapsed time: 15783.54
2024-08-07 10:33:59 - [34m[1mLOGS   [0m - Epoch:  15 [  126593/  200000], loss: {'classification': 33.4544, 'neural_augmentation': 0.4773, 'total_loss': 33.9317}, LR: [0.000364, 0.000364], Avg. batch load time: 0.005, Elapsed time: 15907.86
2024-08-07 10:36:03 - [34m[1mLOGS   [0m - Epoch:  15 [  126656/  200000], loss: {'classification': 33.4534, 'neural_augmentation': 0.4774, 'total_loss': 33.9309}, LR: [0.000363, 0.000363], Avg. batch load time: 0.005, Elapsed time: 16032.23
2024-08-07 10:37:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 33.4523, 'neural_augmentation': 0.4776, 'total_loss': 33.9299}
2024-08-07 10:37:42 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_best.pt
2024-08-07 10:37:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_last.pt
2024-08-07 10:37:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_last.pt
2024-08-07 10:37:45 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 126704 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_epoch_15_iter_126704.pt
2024-08-07 10:37:46 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 126704 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_epoch_15_iter_126704.pt
[31m===========================================================================[0m
2024-08-07 10:37:48 - [32m[1mINFO   [0m - Training epoch 16
2024-08-07 10:39:01 - [34m[1mLOGS   [0m - Epoch:  16 [  126704/  200000], loss: {'classification': 33.4279, 'neural_augmentation': 0.4978, 'total_loss': 33.9257}, LR: [0.000363, 0.000363], Avg. batch load time: 60.234, Elapsed time: 73.02
2024-08-07 10:41:08 - [34m[1mLOGS   [0m - Epoch:  16 [  126766/  200000], loss: {'classification': 33.3669, 'neural_augmentation': 0.4977, 'total_loss': 33.8646}, LR: [0.000362, 0.000362], Avg. batch load time: 0.121, Elapsed time: 199.79
2024-08-07 10:43:11 - [34m[1mLOGS   [0m - Epoch:  16 [  126829/  200000], loss: {'classification': 33.3477, 'neural_augmentation': 0.4975, 'total_loss': 33.8452}, LR: [0.000362, 0.000362], Avg. batch load time: 0.061, Elapsed time: 323.68
2024-08-07 10:45:16 - [34m[1mLOGS   [0m - Epoch:  16 [  126891/  200000], loss: {'classification': 33.3021, 'neural_augmentation': 0.4976, 'total_loss': 33.7997}, LR: [0.000361, 0.000361], Avg. batch load time: 0.041, Elapsed time: 447.77
2024-08-07 10:47:19 - [34m[1mLOGS   [0m - Epoch:  16 [  126954/  200000], loss: {'classification': 33.2935, 'neural_augmentation': 0.4976, 'total_loss': 33.7911}, LR: [0.000361, 0.000361], Avg. batch load time: 0.031, Elapsed time: 571.61
2024-08-07 10:49:23 - [34m[1mLOGS   [0m - Epoch:  16 [  127016/  200000], loss: {'classification': 33.2841, 'neural_augmentation': 0.4978, 'total_loss': 33.7819}, LR: [0.00036, 0.00036], Avg. batch load time: 0.025, Elapsed time: 695.53
2024-08-07 10:51:27 - [34m[1mLOGS   [0m - Epoch:  16 [  127079/  200000], loss: {'classification': 33.2834, 'neural_augmentation': 0.4979, 'total_loss': 33.7812}, LR: [0.00036, 0.00036], Avg. batch load time: 0.021, Elapsed time: 819.72
2024-08-07 10:53:32 - [34m[1mLOGS   [0m - Epoch:  16 [  127141/  200000], loss: {'classification': 33.2933, 'neural_augmentation': 0.498, 'total_loss': 33.7913}, LR: [0.000359, 0.000359], Avg. batch load time: 0.018, Elapsed time: 944.03
2024-08-07 10:55:36 - [34m[1mLOGS   [0m - Epoch:  16 [  127204/  200000], loss: {'classification': 33.303, 'neural_augmentation': 0.4981, 'total_loss': 33.8011}, LR: [0.000359, 0.000359], Avg. batch load time: 0.016, Elapsed time: 1068.33
2024-08-07 10:57:40 - [34m[1mLOGS   [0m - Epoch:  16 [  127266/  200000], loss: {'classification': 33.2985, 'neural_augmentation': 0.4983, 'total_loss': 33.7968}, LR: [0.000358, 0.000358], Avg. batch load time: 0.014, Elapsed time: 1192.38
2024-08-07 10:59:44 - [34m[1mLOGS   [0m - Epoch:  16 [  127329/  200000], loss: {'classification': 33.2978, 'neural_augmentation': 0.4985, 'total_loss': 33.7963}, LR: [0.000358, 0.000358], Avg. batch load time: 0.013, Elapsed time: 1316.56
2024-08-07 11:01:48 - [34m[1mLOGS   [0m - Epoch:  16 [  127391/  200000], loss: {'classification': 33.2934, 'neural_augmentation': 0.4987, 'total_loss': 33.7921}, LR: [0.000357, 0.000357], Avg. batch load time: 0.012, Elapsed time: 1440.22
2024-08-07 11:03:57 - [34m[1mLOGS   [0m - Epoch:  16 [  127454/  200000], loss: {'classification': 33.2891, 'neural_augmentation': 0.4988, 'total_loss': 33.7879}, LR: [0.000357, 0.000357], Avg. batch load time: 0.011, Elapsed time: 1569.01
2024-08-07 11:06:06 - [34m[1mLOGS   [0m - Epoch:  16 [  127516/  200000], loss: {'classification': 33.2931, 'neural_augmentation': 0.499, 'total_loss': 33.7921}, LR: [0.000356, 0.000356], Avg. batch load time: 0.010, Elapsed time: 1698.08
2024-08-07 11:08:10 - [34m[1mLOGS   [0m - Epoch:  16 [  127579/  200000], loss: {'classification': 33.293, 'neural_augmentation': 0.4991, 'total_loss': 33.7921}, LR: [0.000356, 0.000356], Avg. batch load time: 0.010, Elapsed time: 1822.14
2024-08-07 11:10:14 - [34m[1mLOGS   [0m - Epoch:  16 [  127641/  200000], loss: {'classification': 33.293, 'neural_augmentation': 0.4993, 'total_loss': 33.7923}, LR: [0.000355, 0.000355], Avg. batch load time: 0.009, Elapsed time: 1945.95
2024-08-07 11:12:18 - [34m[1mLOGS   [0m - Epoch:  16 [  127704/  200000], loss: {'classification': 33.2949, 'neural_augmentation': 0.4994, 'total_loss': 33.7943}, LR: [0.000354, 0.000354], Avg. batch load time: 0.009, Elapsed time: 2069.99
2024-08-07 11:14:22 - [34m[1mLOGS   [0m - Epoch:  16 [  127766/  200000], loss: {'classification': 33.2924, 'neural_augmentation': 0.4996, 'total_loss': 33.792}, LR: [0.000354, 0.000354], Avg. batch load time: 0.008, Elapsed time: 2194.22
2024-08-07 11:16:26 - [34m[1mLOGS   [0m - Epoch:  16 [  127829/  200000], loss: {'classification': 33.2878, 'neural_augmentation': 0.4997, 'total_loss': 33.7875}, LR: [0.000353, 0.000353], Avg. batch load time: 0.008, Elapsed time: 2318.26
2024-08-07 11:18:30 - [34m[1mLOGS   [0m - Epoch:  16 [  127891/  200000], loss: {'classification': 33.2912, 'neural_augmentation': 0.4999, 'total_loss': 33.7911}, LR: [0.000353, 0.000353], Avg. batch load time: 0.007, Elapsed time: 2442.27
2024-08-07 11:20:34 - [34m[1mLOGS   [0m - Epoch:  16 [  127954/  200000], loss: {'classification': 33.2861, 'neural_augmentation': 0.5001, 'total_loss': 33.7861}, LR: [0.000352, 0.000352], Avg. batch load time: 0.007, Elapsed time: 2566.30
2024-08-07 11:22:38 - [34m[1mLOGS   [0m - Epoch:  16 [  128016/  200000], loss: {'classification': 33.2934, 'neural_augmentation': 0.5002, 'total_loss': 33.7936}, LR: [0.000352, 0.000352], Avg. batch load time: 0.007, Elapsed time: 2690.72
2024-08-07 11:24:43 - [34m[1mLOGS   [0m - Epoch:  16 [  128079/  200000], loss: {'classification': 33.2919, 'neural_augmentation': 0.5004, 'total_loss': 33.7923}, LR: [0.000351, 0.000351], Avg. batch load time: 0.007, Elapsed time: 2814.78
2024-08-07 11:26:46 - [34m[1mLOGS   [0m - Epoch:  16 [  128141/  200000], loss: {'classification': 33.2887, 'neural_augmentation': 0.5005, 'total_loss': 33.7892}, LR: [0.000351, 0.000351], Avg. batch load time: 0.006, Elapsed time: 2938.73
2024-08-07 11:28:52 - [34m[1mLOGS   [0m - Epoch:  16 [  128204/  200000], loss: {'classification': 33.2849, 'neural_augmentation': 0.5007, 'total_loss': 33.7856}, LR: [0.00035, 0.00035], Avg. batch load time: 0.006, Elapsed time: 3064.59
2024-08-07 11:31:04 - [34m[1mLOGS   [0m - Epoch:  16 [  128266/  200000], loss: {'classification': 33.2803, 'neural_augmentation': 0.5008, 'total_loss': 33.7811}, LR: [0.00035, 0.00035], Avg. batch load time: 0.006, Elapsed time: 3196.58
2024-08-07 11:33:08 - [34m[1mLOGS   [0m - Epoch:  16 [  128329/  200000], loss: {'classification': 33.2795, 'neural_augmentation': 0.501, 'total_loss': 33.7805}, LR: [0.000349, 0.000349], Avg. batch load time: 0.006, Elapsed time: 3320.58
2024-08-07 11:35:12 - [34m[1mLOGS   [0m - Epoch:  16 [  128391/  200000], loss: {'classification': 33.2773, 'neural_augmentation': 0.5011, 'total_loss': 33.7784}, LR: [0.000349, 0.000349], Avg. batch load time: 0.005, Elapsed time: 3444.54
2024-08-07 11:37:16 - [34m[1mLOGS   [0m - Epoch:  16 [  128454/  200000], loss: {'classification': 33.2772, 'neural_augmentation': 0.5013, 'total_loss': 33.7784}, LR: [0.000348, 0.000348], Avg. batch load time: 0.005, Elapsed time: 3568.65
2024-08-07 11:39:20 - [34m[1mLOGS   [0m - Epoch:  16 [  128516/  200000], loss: {'classification': 33.2769, 'neural_augmentation': 0.5014, 'total_loss': 33.7783}, LR: [0.000348, 0.000348], Avg. batch load time: 0.005, Elapsed time: 3692.34
2024-08-07 11:41:24 - [34m[1mLOGS   [0m - Epoch:  16 [  128579/  200000], loss: {'classification': 33.2845, 'neural_augmentation': 0.5016, 'total_loss': 33.7861}, LR: [0.000347, 0.000347], Avg. batch load time: 0.005, Elapsed time: 3816.65
2024-08-07 11:43:29 - [34m[1mLOGS   [0m - Epoch:  16 [  128641/  200000], loss: {'classification': 33.287, 'neural_augmentation': 0.5017, 'total_loss': 33.7887}, LR: [0.000347, 0.000347], Avg. batch load time: 0.005, Elapsed time: 3941.05
2024-08-07 11:45:33 - [34m[1mLOGS   [0m - Epoch:  16 [  128704/  200000], loss: {'classification': 33.2855, 'neural_augmentation': 0.5019, 'total_loss': 33.7874}, LR: [0.000346, 0.000346], Avg. batch load time: 0.005, Elapsed time: 4065.24
2024-08-07 11:47:37 - [34m[1mLOGS   [0m - Epoch:  16 [  128766/  200000], loss: {'classification': 33.2851, 'neural_augmentation': 0.5021, 'total_loss': 33.7871}, LR: [0.000346, 0.000346], Avg. batch load time: 0.005, Elapsed time: 4189.54
2024-08-07 11:49:41 - [34m[1mLOGS   [0m - Epoch:  16 [  128829/  200000], loss: {'classification': 33.286, 'neural_augmentation': 0.5022, 'total_loss': 33.7883}, LR: [0.000345, 0.000345], Avg. batch load time: 0.005, Elapsed time: 4313.65
2024-08-07 11:51:45 - [34m[1mLOGS   [0m - Epoch:  16 [  128891/  200000], loss: {'classification': 33.2854, 'neural_augmentation': 0.5024, 'total_loss': 33.7878}, LR: [0.000345, 0.000345], Avg. batch load time: 0.004, Elapsed time: 4437.57
2024-08-07 11:53:51 - [34m[1mLOGS   [0m - Epoch:  16 [  128954/  200000], loss: {'classification': 33.2812, 'neural_augmentation': 0.5025, 'total_loss': 33.7837}, LR: [0.000344, 0.000344], Avg. batch load time: 0.004, Elapsed time: 4563.39
2024-08-07 11:56:01 - [34m[1mLOGS   [0m - Epoch:  16 [  129016/  200000], loss: {'classification': 33.2786, 'neural_augmentation': 0.5027, 'total_loss': 33.7813}, LR: [0.000344, 0.000344], Avg. batch load time: 0.004, Elapsed time: 4693.64
2024-08-07 11:58:05 - [34m[1mLOGS   [0m - Epoch:  16 [  129079/  200000], loss: {'classification': 33.2793, 'neural_augmentation': 0.5028, 'total_loss': 33.7821}, LR: [0.000343, 0.000343], Avg. batch load time: 0.004, Elapsed time: 4817.73
2024-08-07 12:00:09 - [34m[1mLOGS   [0m - Epoch:  16 [  129141/  200000], loss: {'classification': 33.2782, 'neural_augmentation': 0.503, 'total_loss': 33.7812}, LR: [0.000343, 0.000343], Avg. batch load time: 0.004, Elapsed time: 4941.60
2024-08-07 12:02:14 - [34m[1mLOGS   [0m - Epoch:  16 [  129204/  200000], loss: {'classification': 33.2784, 'neural_augmentation': 0.5031, 'total_loss': 33.7815}, LR: [0.000342, 0.000342], Avg. batch load time: 0.004, Elapsed time: 5065.77
2024-08-07 12:04:18 - [34m[1mLOGS   [0m - Epoch:  16 [  129266/  200000], loss: {'classification': 33.2793, 'neural_augmentation': 0.5033, 'total_loss': 33.7826}, LR: [0.000342, 0.000342], Avg. batch load time: 0.004, Elapsed time: 5189.94
2024-08-07 12:06:22 - [34m[1mLOGS   [0m - Epoch:  16 [  129329/  200000], loss: {'classification': 33.2788, 'neural_augmentation': 0.5034, 'total_loss': 33.7822}, LR: [0.000341, 0.000341], Avg. batch load time: 0.004, Elapsed time: 5314.10
2024-08-07 12:08:26 - [34m[1mLOGS   [0m - Epoch:  16 [  129391/  200000], loss: {'classification': 33.2788, 'neural_augmentation': 0.5036, 'total_loss': 33.7824}, LR: [0.000341, 0.000341], Avg. batch load time: 0.004, Elapsed time: 5438.39
2024-08-07 12:10:30 - [34m[1mLOGS   [0m - Epoch:  16 [  129454/  200000], loss: {'classification': 33.2781, 'neural_augmentation': 0.5037, 'total_loss': 33.7818}, LR: [0.00034, 0.00034], Avg. batch load time: 0.004, Elapsed time: 5562.37
2024-08-07 12:12:34 - [34m[1mLOGS   [0m - Epoch:  16 [  129516/  200000], loss: {'classification': 33.2782, 'neural_augmentation': 0.5039, 'total_loss': 33.7821}, LR: [0.00034, 0.00034], Avg. batch load time: 0.004, Elapsed time: 5686.39
2024-08-07 12:14:38 - [34m[1mLOGS   [0m - Epoch:  16 [  129579/  200000], loss: {'classification': 33.2783, 'neural_augmentation': 0.504, 'total_loss': 33.7823}, LR: [0.000339, 0.000339], Avg. batch load time: 0.004, Elapsed time: 5810.50
2024-08-07 12:16:42 - [34m[1mLOGS   [0m - Epoch:  16 [  129641/  200000], loss: {'classification': 33.2787, 'neural_augmentation': 0.5042, 'total_loss': 33.7828}, LR: [0.000339, 0.000339], Avg. batch load time: 0.004, Elapsed time: 5934.52
2024-08-07 12:18:46 - [34m[1mLOGS   [0m - Epoch:  16 [  129704/  200000], loss: {'classification': 33.2746, 'neural_augmentation': 0.5043, 'total_loss': 33.779}, LR: [0.000338, 0.000338], Avg. batch load time: 0.004, Elapsed time: 6058.33
2024-08-07 12:20:53 - [34m[1mLOGS   [0m - Epoch:  16 [  129766/  200000], loss: {'classification': 33.273, 'neural_augmentation': 0.5045, 'total_loss': 33.7775}, LR: [0.000338, 0.000338], Avg. batch load time: 0.003, Elapsed time: 6185.68
2024-08-07 12:23:02 - [34m[1mLOGS   [0m - Epoch:  16 [  129829/  200000], loss: {'classification': 33.2728, 'neural_augmentation': 0.5046, 'total_loss': 33.7774}, LR: [0.000337, 0.000337], Avg. batch load time: 0.003, Elapsed time: 6314.48
2024-08-07 12:25:06 - [34m[1mLOGS   [0m - Epoch:  16 [  129891/  200000], loss: {'classification': 33.2711, 'neural_augmentation': 0.5048, 'total_loss': 33.7759}, LR: [0.000337, 0.000337], Avg. batch load time: 0.003, Elapsed time: 6438.42
2024-08-07 12:27:10 - [34m[1mLOGS   [0m - Epoch:  16 [  129954/  200000], loss: {'classification': 33.2708, 'neural_augmentation': 0.5049, 'total_loss': 33.7757}, LR: [0.000336, 0.000336], Avg. batch load time: 0.003, Elapsed time: 6562.67
2024-08-07 12:29:15 - [34m[1mLOGS   [0m - Epoch:  16 [  130016/  200000], loss: {'classification': 33.2701, 'neural_augmentation': 0.5051, 'total_loss': 33.7752}, LR: [0.000336, 0.000336], Avg. batch load time: 0.003, Elapsed time: 6686.78
2024-08-07 12:31:19 - [34m[1mLOGS   [0m - Epoch:  16 [  130079/  200000], loss: {'classification': 33.2707, 'neural_augmentation': 0.5052, 'total_loss': 33.7759}, LR: [0.000335, 0.000335], Avg. batch load time: 0.003, Elapsed time: 6811.03
2024-08-07 12:33:23 - [34m[1mLOGS   [0m - Epoch:  16 [  130141/  200000], loss: {'classification': 33.2701, 'neural_augmentation': 0.5054, 'total_loss': 33.7755}, LR: [0.000335, 0.000335], Avg. batch load time: 0.003, Elapsed time: 6935.04
2024-08-07 12:35:27 - [34m[1mLOGS   [0m - Epoch:  16 [  130204/  200000], loss: {'classification': 33.2713, 'neural_augmentation': 0.5055, 'total_loss': 33.7768}, LR: [0.000334, 0.000334], Avg. batch load time: 0.003, Elapsed time: 7059.29
2024-08-07 12:37:31 - [34m[1mLOGS   [0m - Epoch:  16 [  130266/  200000], loss: {'classification': 33.2691, 'neural_augmentation': 0.5057, 'total_loss': 33.7748}, LR: [0.000334, 0.000334], Avg. batch load time: 0.003, Elapsed time: 7183.11
2024-08-07 12:39:35 - [34m[1mLOGS   [0m - Epoch:  16 [  130329/  200000], loss: {'classification': 33.2686, 'neural_augmentation': 0.5058, 'total_loss': 33.7744}, LR: [0.000333, 0.000333], Avg. batch load time: 0.003, Elapsed time: 7307.20
2024-08-07 12:41:39 - [34m[1mLOGS   [0m - Epoch:  16 [  130391/  200000], loss: {'classification': 33.2682, 'neural_augmentation': 0.506, 'total_loss': 33.7742}, LR: [0.000333, 0.000333], Avg. batch load time: 0.003, Elapsed time: 7431.01
2024-08-07 12:43:43 - [34m[1mLOGS   [0m - Epoch:  16 [  130454/  200000], loss: {'classification': 33.2679, 'neural_augmentation': 0.5061, 'total_loss': 33.774}, LR: [0.000332, 0.000332], Avg. batch load time: 0.003, Elapsed time: 7555.38
2024-08-07 12:45:49 - [34m[1mLOGS   [0m - Epoch:  16 [  130516/  200000], loss: {'classification': 33.2669, 'neural_augmentation': 0.5063, 'total_loss': 33.7731}, LR: [0.000332, 0.000332], Avg. batch load time: 0.003, Elapsed time: 7680.79
2024-08-07 12:47:58 - [34m[1mLOGS   [0m - Epoch:  16 [  130579/  200000], loss: {'classification': 33.2656, 'neural_augmentation': 0.5064, 'total_loss': 33.772}, LR: [0.000331, 0.000331], Avg. batch load time: 0.003, Elapsed time: 7809.97
2024-08-07 12:50:02 - [34m[1mLOGS   [0m - Epoch:  16 [  130641/  200000], loss: {'classification': 33.2652, 'neural_augmentation': 0.5066, 'total_loss': 33.7717}, LR: [0.000331, 0.000331], Avg. batch load time: 0.003, Elapsed time: 7933.99
2024-08-07 12:52:06 - [34m[1mLOGS   [0m - Epoch:  16 [  130704/  200000], loss: {'classification': 33.2644, 'neural_augmentation': 0.5067, 'total_loss': 33.7711}, LR: [0.00033, 0.00033], Avg. batch load time: 0.003, Elapsed time: 8058.17
2024-08-07 12:54:10 - [34m[1mLOGS   [0m - Epoch:  16 [  130766/  200000], loss: {'classification': 33.2641, 'neural_augmentation': 0.5069, 'total_loss': 33.7709}, LR: [0.000329, 0.000329], Avg. batch load time: 0.003, Elapsed time: 8182.10
2024-08-07 12:56:14 - [34m[1mLOGS   [0m - Epoch:  16 [  130829/  200000], loss: {'classification': 33.2639, 'neural_augmentation': 0.507, 'total_loss': 33.7709}, LR: [0.000329, 0.000329], Avg. batch load time: 0.003, Elapsed time: 8306.20
2024-08-07 12:58:18 - [34m[1mLOGS   [0m - Epoch:  16 [  130891/  200000], loss: {'classification': 33.264, 'neural_augmentation': 0.5072, 'total_loss': 33.7711}, LR: [0.000328, 0.000328], Avg. batch load time: 0.003, Elapsed time: 8430.20
2024-08-07 13:00:22 - [34m[1mLOGS   [0m - Epoch:  16 [  130954/  200000], loss: {'classification': 33.2614, 'neural_augmentation': 0.5073, 'total_loss': 33.7687}, LR: [0.000328, 0.000328], Avg. batch load time: 0.003, Elapsed time: 8553.84
2024-08-07 13:02:26 - [34m[1mLOGS   [0m - Epoch:  16 [  131016/  200000], loss: {'classification': 33.262, 'neural_augmentation': 0.5074, 'total_loss': 33.7694}, LR: [0.000327, 0.000327], Avg. batch load time: 0.003, Elapsed time: 8678.10
2024-08-07 13:04:30 - [34m[1mLOGS   [0m - Epoch:  16 [  131079/  200000], loss: {'classification': 33.2612, 'neural_augmentation': 0.5076, 'total_loss': 33.7688}, LR: [0.000327, 0.000327], Avg. batch load time: 0.003, Elapsed time: 8802.20
2024-08-07 13:06:34 - [34m[1mLOGS   [0m - Epoch:  16 [  131141/  200000], loss: {'classification': 33.2598, 'neural_augmentation': 0.5077, 'total_loss': 33.7675}, LR: [0.000326, 0.000326], Avg. batch load time: 0.003, Elapsed time: 8926.26
2024-08-07 13:08:38 - [34m[1mLOGS   [0m - Epoch:  16 [  131204/  200000], loss: {'classification': 33.2587, 'neural_augmentation': 0.5079, 'total_loss': 33.7666}, LR: [0.000326, 0.000326], Avg. batch load time: 0.003, Elapsed time: 9050.47
2024-08-07 13:10:44 - [34m[1mLOGS   [0m - Epoch:  16 [  131266/  200000], loss: {'classification': 33.2572, 'neural_augmentation': 0.508, 'total_loss': 33.7652}, LR: [0.000325, 0.000325], Avg. batch load time: 0.003, Elapsed time: 9176.00
2024-08-07 13:12:56 - [34m[1mLOGS   [0m - Epoch:  16 [  131329/  200000], loss: {'classification': 33.2557, 'neural_augmentation': 0.5082, 'total_loss': 33.7639}, LR: [0.000325, 0.000325], Avg. batch load time: 0.003, Elapsed time: 9308.03
2024-08-07 13:15:00 - [34m[1mLOGS   [0m - Epoch:  16 [  131391/  200000], loss: {'classification': 33.2553, 'neural_augmentation': 0.5083, 'total_loss': 33.7637}, LR: [0.000324, 0.000324], Avg. batch load time: 0.003, Elapsed time: 9431.84
2024-08-07 13:17:04 - [34m[1mLOGS   [0m - Epoch:  16 [  131454/  200000], loss: {'classification': 33.2545, 'neural_augmentation': 0.5085, 'total_loss': 33.763}, LR: [0.000324, 0.000324], Avg. batch load time: 0.003, Elapsed time: 9556.13
2024-08-07 13:19:08 - [34m[1mLOGS   [0m - Epoch:  16 [  131516/  200000], loss: {'classification': 33.2536, 'neural_augmentation': 0.5086, 'total_loss': 33.7622}, LR: [0.000323, 0.000323], Avg. batch load time: 0.003, Elapsed time: 9680.01
2024-08-07 13:21:12 - [34m[1mLOGS   [0m - Epoch:  16 [  131579/  200000], loss: {'classification': 33.2534, 'neural_augmentation': 0.5088, 'total_loss': 33.7622}, LR: [0.000323, 0.000323], Avg. batch load time: 0.003, Elapsed time: 9803.84
2024-08-07 13:23:16 - [34m[1mLOGS   [0m - Epoch:  16 [  131641/  200000], loss: {'classification': 33.2525, 'neural_augmentation': 0.5089, 'total_loss': 33.7614}, LR: [0.000322, 0.000322], Avg. batch load time: 0.003, Elapsed time: 9927.92
2024-08-07 13:25:20 - [34m[1mLOGS   [0m - Epoch:  16 [  131704/  200000], loss: {'classification': 33.2515, 'neural_augmentation': 0.5091, 'total_loss': 33.7606}, LR: [0.000322, 0.000322], Avg. batch load time: 0.003, Elapsed time: 10052.13
2024-08-07 13:27:24 - [34m[1mLOGS   [0m - Epoch:  16 [  131766/  200000], loss: {'classification': 33.2511, 'neural_augmentation': 0.5092, 'total_loss': 33.7603}, LR: [0.000321, 0.000321], Avg. batch load time: 0.003, Elapsed time: 10176.29
2024-08-07 13:29:28 - [34m[1mLOGS   [0m - Epoch:  16 [  131829/  200000], loss: {'classification': 33.2523, 'neural_augmentation': 0.5094, 'total_loss': 33.7617}, LR: [0.000321, 0.000321], Avg. batch load time: 0.003, Elapsed time: 10300.73
2024-08-07 13:31:32 - [34m[1mLOGS   [0m - Epoch:  16 [  131891/  200000], loss: {'classification': 33.2512, 'neural_augmentation': 0.5095, 'total_loss': 33.7608}, LR: [0.00032, 0.00032], Avg. batch load time: 0.002, Elapsed time: 10424.63
2024-08-07 13:33:36 - [34m[1mLOGS   [0m - Epoch:  16 [  131954/  200000], loss: {'classification': 33.2505, 'neural_augmentation': 0.5097, 'total_loss': 33.7602}, LR: [0.00032, 0.00032], Avg. batch load time: 0.002, Elapsed time: 10548.67
2024-08-07 13:35:41 - [34m[1mLOGS   [0m - Epoch:  16 [  132016/  200000], loss: {'classification': 33.2497, 'neural_augmentation': 0.5098, 'total_loss': 33.7595}, LR: [0.000319, 0.000319], Avg. batch load time: 0.002, Elapsed time: 10672.86
2024-08-07 13:37:53 - [34m[1mLOGS   [0m - Epoch:  16 [  132079/  200000], loss: {'classification': 33.2483, 'neural_augmentation': 0.5099, 'total_loss': 33.7582}, LR: [0.000319, 0.000319], Avg. batch load time: 0.002, Elapsed time: 10805.54
2024-08-07 13:39:58 - [34m[1mLOGS   [0m - Epoch:  16 [  132141/  200000], loss: {'classification': 33.2479, 'neural_augmentation': 0.5101, 'total_loss': 33.758}, LR: [0.000318, 0.000318], Avg. batch load time: 0.002, Elapsed time: 10929.77
2024-08-07 13:42:01 - [34m[1mLOGS   [0m - Epoch:  16 [  132204/  200000], loss: {'classification': 33.2474, 'neural_augmentation': 0.5102, 'total_loss': 33.7577}, LR: [0.000318, 0.000318], Avg. batch load time: 0.002, Elapsed time: 11053.65
2024-08-07 13:44:06 - [34m[1mLOGS   [0m - Epoch:  16 [  132266/  200000], loss: {'classification': 33.247, 'neural_augmentation': 0.5104, 'total_loss': 33.7574}, LR: [0.000317, 0.000317], Avg. batch load time: 0.002, Elapsed time: 11177.95
2024-08-07 13:46:10 - [34m[1mLOGS   [0m - Epoch:  16 [  132329/  200000], loss: {'classification': 33.2475, 'neural_augmentation': 0.5105, 'total_loss': 33.758}, LR: [0.000317, 0.000317], Avg. batch load time: 0.002, Elapsed time: 11302.41
2024-08-07 13:48:14 - [34m[1mLOGS   [0m - Epoch:  16 [  132391/  200000], loss: {'classification': 33.2451, 'neural_augmentation': 0.5107, 'total_loss': 33.7558}, LR: [0.000316, 0.000316], Avg. batch load time: 0.002, Elapsed time: 11426.36
2024-08-07 13:50:18 - [34m[1mLOGS   [0m - Epoch:  16 [  132454/  200000], loss: {'classification': 33.2433, 'neural_augmentation': 0.5108, 'total_loss': 33.7541}, LR: [0.000316, 0.000316], Avg. batch load time: 0.002, Elapsed time: 11550.26
2024-08-07 13:52:22 - [34m[1mLOGS   [0m - Epoch:  16 [  132516/  200000], loss: {'classification': 33.2421, 'neural_augmentation': 0.511, 'total_loss': 33.7531}, LR: [0.000315, 0.000315], Avg. batch load time: 0.002, Elapsed time: 11674.26
2024-08-07 13:54:26 - [34m[1mLOGS   [0m - Epoch:  16 [  132579/  200000], loss: {'classification': 33.2413, 'neural_augmentation': 0.5111, 'total_loss': 33.7525}, LR: [0.000315, 0.000315], Avg. batch load time: 0.002, Elapsed time: 11798.30
2024-08-07 13:56:30 - [34m[1mLOGS   [0m - Epoch:  16 [  132641/  200000], loss: {'classification': 33.2405, 'neural_augmentation': 0.5113, 'total_loss': 33.7518}, LR: [0.000314, 0.000314], Avg. batch load time: 0.002, Elapsed time: 11922.28
2024-08-07 13:58:34 - [34m[1mLOGS   [0m - Epoch:  16 [  132704/  200000], loss: {'classification': 33.2394, 'neural_augmentation': 0.5114, 'total_loss': 33.7508}, LR: [0.000314, 0.000314], Avg. batch load time: 0.002, Elapsed time: 12046.33
2024-08-07 14:00:38 - [34m[1mLOGS   [0m - Epoch:  16 [  132766/  200000], loss: {'classification': 33.2385, 'neural_augmentation': 0.5115, 'total_loss': 33.7501}, LR: [0.000313, 0.000313], Avg. batch load time: 0.002, Elapsed time: 12170.53
2024-08-07 14:02:44 - [34m[1mLOGS   [0m - Epoch:  16 [  132829/  200000], loss: {'classification': 33.2374, 'neural_augmentation': 0.5117, 'total_loss': 33.7491}, LR: [0.000313, 0.000313], Avg. batch load time: 0.002, Elapsed time: 12296.28
2024-08-07 14:04:56 - [34m[1mLOGS   [0m - Epoch:  16 [  132891/  200000], loss: {'classification': 33.2373, 'neural_augmentation': 0.5118, 'total_loss': 33.7491}, LR: [0.000312, 0.000312], Avg. batch load time: 0.002, Elapsed time: 12428.40
2024-08-07 14:07:00 - [34m[1mLOGS   [0m - Epoch:  16 [  132954/  200000], loss: {'classification': 33.2354, 'neural_augmentation': 0.512, 'total_loss': 33.7474}, LR: [0.000312, 0.000312], Avg. batch load time: 0.002, Elapsed time: 12552.28
2024-08-07 14:09:04 - [34m[1mLOGS   [0m - Epoch:  16 [  133016/  200000], loss: {'classification': 33.2335, 'neural_augmentation': 0.5121, 'total_loss': 33.7457}, LR: [0.000311, 0.000311], Avg. batch load time: 0.002, Elapsed time: 12676.09
2024-08-07 14:11:08 - [34m[1mLOGS   [0m - Epoch:  16 [  133079/  200000], loss: {'classification': 33.2328, 'neural_augmentation': 0.5123, 'total_loss': 33.7451}, LR: [0.000311, 0.000311], Avg. batch load time: 0.002, Elapsed time: 12800.26
2024-08-07 14:13:12 - [34m[1mLOGS   [0m - Epoch:  16 [  133141/  200000], loss: {'classification': 33.2318, 'neural_augmentation': 0.5124, 'total_loss': 33.7442}, LR: [0.00031, 0.00031], Avg. batch load time: 0.002, Elapsed time: 12924.44
2024-08-07 14:15:16 - [34m[1mLOGS   [0m - Epoch:  16 [  133204/  200000], loss: {'classification': 33.2308, 'neural_augmentation': 0.5126, 'total_loss': 33.7433}, LR: [0.00031, 0.00031], Avg. batch load time: 0.002, Elapsed time: 13048.49
2024-08-07 14:17:20 - [34m[1mLOGS   [0m - Epoch:  16 [  133266/  200000], loss: {'classification': 33.2303, 'neural_augmentation': 0.5127, 'total_loss': 33.743}, LR: [0.000309, 0.000309], Avg. batch load time: 0.002, Elapsed time: 13172.56
2024-08-07 14:19:24 - [34m[1mLOGS   [0m - Epoch:  16 [  133329/  200000], loss: {'classification': 33.2297, 'neural_augmentation': 0.5129, 'total_loss': 33.7426}, LR: [0.000309, 0.000309], Avg. batch load time: 0.002, Elapsed time: 13296.59
2024-08-07 14:21:28 - [34m[1mLOGS   [0m - Epoch:  16 [  133391/  200000], loss: {'classification': 33.2287, 'neural_augmentation': 0.513, 'total_loss': 33.7417}, LR: [0.000308, 0.000308], Avg. batch load time: 0.002, Elapsed time: 13420.62
2024-08-07 14:23:32 - [34m[1mLOGS   [0m - Epoch:  16 [  133454/  200000], loss: {'classification': 33.2276, 'neural_augmentation': 0.5131, 'total_loss': 33.7408}, LR: [0.000308, 0.000308], Avg. batch load time: 0.002, Elapsed time: 13544.57
2024-08-07 14:25:36 - [34m[1mLOGS   [0m - Epoch:  16 [  133516/  200000], loss: {'classification': 33.2271, 'neural_augmentation': 0.5133, 'total_loss': 33.7404}, LR: [0.000307, 0.000307], Avg. batch load time: 0.002, Elapsed time: 13668.61
2024-08-07 14:27:42 - [34m[1mLOGS   [0m - Epoch:  16 [  133579/  200000], loss: {'classification': 33.2266, 'neural_augmentation': 0.5134, 'total_loss': 33.74}, LR: [0.000307, 0.000307], Avg. batch load time: 0.002, Elapsed time: 13794.55
2024-08-07 14:29:53 - [34m[1mLOGS   [0m - Epoch:  16 [  133641/  200000], loss: {'classification': 33.2249, 'neural_augmentation': 0.5136, 'total_loss': 33.7385}, LR: [0.000307, 0.000307], Avg. batch load time: 0.002, Elapsed time: 13925.07
2024-08-07 14:31:57 - [34m[1mLOGS   [0m - Epoch:  16 [  133704/  200000], loss: {'classification': 33.224, 'neural_augmentation': 0.5137, 'total_loss': 33.7377}, LR: [0.000306, 0.000306], Avg. batch load time: 0.002, Elapsed time: 14049.08
2024-08-07 14:34:01 - [34m[1mLOGS   [0m - Epoch:  16 [  133766/  200000], loss: {'classification': 33.2234, 'neural_augmentation': 0.5139, 'total_loss': 33.7372}, LR: [0.000306, 0.000306], Avg. batch load time: 0.002, Elapsed time: 14173.43
2024-08-07 14:36:05 - [34m[1mLOGS   [0m - Epoch:  16 [  133829/  200000], loss: {'classification': 33.2223, 'neural_augmentation': 0.514, 'total_loss': 33.7363}, LR: [0.000305, 0.000305], Avg. batch load time: 0.002, Elapsed time: 14297.41
2024-08-07 14:38:09 - [34m[1mLOGS   [0m - Epoch:  16 [  133891/  200000], loss: {'classification': 33.2216, 'neural_augmentation': 0.5142, 'total_loss': 33.7357}, LR: [0.000305, 0.000305], Avg. batch load time: 0.002, Elapsed time: 14421.31
2024-08-07 14:40:13 - [34m[1mLOGS   [0m - Epoch:  16 [  133954/  200000], loss: {'classification': 33.2206, 'neural_augmentation': 0.5143, 'total_loss': 33.7349}, LR: [0.000304, 0.000304], Avg. batch load time: 0.002, Elapsed time: 14545.33
2024-08-07 14:42:17 - [34m[1mLOGS   [0m - Epoch:  16 [  134016/  200000], loss: {'classification': 33.2202, 'neural_augmentation': 0.5145, 'total_loss': 33.7346}, LR: [0.000304, 0.000304], Avg. batch load time: 0.002, Elapsed time: 14669.48
2024-08-07 14:44:21 - [34m[1mLOGS   [0m - Epoch:  16 [  134079/  200000], loss: {'classification': 33.2191, 'neural_augmentation': 0.5146, 'total_loss': 33.7337}, LR: [0.000303, 0.000303], Avg. batch load time: 0.002, Elapsed time: 14793.34
2024-08-07 14:46:25 - [34m[1mLOGS   [0m - Epoch:  16 [  134141/  200000], loss: {'classification': 33.2179, 'neural_augmentation': 0.5147, 'total_loss': 33.7326}, LR: [0.000303, 0.000303], Avg. batch load time: 0.002, Elapsed time: 14917.26
2024-08-07 14:48:29 - [34m[1mLOGS   [0m - Epoch:  16 [  134204/  200000], loss: {'classification': 33.2167, 'neural_augmentation': 0.5149, 'total_loss': 33.7316}, LR: [0.000302, 0.000302], Avg. batch load time: 0.002, Elapsed time: 15041.38
2024-08-07 14:50:33 - [34m[1mLOGS   [0m - Epoch:  16 [  134266/  200000], loss: {'classification': 33.2159, 'neural_augmentation': 0.515, 'total_loss': 33.7309}, LR: [0.000302, 0.000302], Avg. batch load time: 0.002, Elapsed time: 15165.70
2024-08-07 14:52:37 - [34m[1mLOGS   [0m - Epoch:  16 [  134329/  200000], loss: {'classification': 33.2139, 'neural_augmentation': 0.5152, 'total_loss': 33.7291}, LR: [0.000301, 0.000301], Avg. batch load time: 0.002, Elapsed time: 15289.67
2024-08-07 14:54:50 - [34m[1mLOGS   [0m - Epoch:  16 [  134391/  200000], loss: {'classification': 33.2128, 'neural_augmentation': 0.5153, 'total_loss': 33.7281}, LR: [0.000301, 0.000301], Avg. batch load time: 0.002, Elapsed time: 15422.51
2024-08-07 14:56:56 - [34m[1mLOGS   [0m - Epoch:  16 [  134454/  200000], loss: {'classification': 33.2114, 'neural_augmentation': 0.5155, 'total_loss': 33.7269}, LR: [0.0003, 0.0003], Avg. batch load time: 0.002, Elapsed time: 15548.39
2024-08-07 14:59:01 - [34m[1mLOGS   [0m - Epoch:  16 [  134516/  200000], loss: {'classification': 33.2105, 'neural_augmentation': 0.5156, 'total_loss': 33.7261}, LR: [0.0003, 0.0003], Avg. batch load time: 0.002, Elapsed time: 15672.76
2024-08-07 15:01:05 - [34m[1mLOGS   [0m - Epoch:  16 [  134579/  200000], loss: {'classification': 33.2097, 'neural_augmentation': 0.5158, 'total_loss': 33.7254}, LR: [0.000299, 0.000299], Avg. batch load time: 0.002, Elapsed time: 15796.82
2024-08-07 15:03:08 - [34m[1mLOGS   [0m - Epoch:  16 [  134641/  200000], loss: {'classification': 33.209, 'neural_augmentation': 0.5159, 'total_loss': 33.7248}, LR: [0.000299, 0.000299], Avg. batch load time: 0.002, Elapsed time: 15920.50
2024-08-07 15:04:11 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 33.2089, 'neural_augmentation': 0.516, 'total_loss': 33.7248}
2024-08-07 15:04:14 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_best.pt
2024-08-07 15:04:15 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_last.pt
2024-08-07 15:04:16 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_last.pt
2024-08-07 15:04:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 134673 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_epoch_16_iter_134673.pt
2024-08-07 15:04:17 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 134673 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_epoch_16_iter_134673.pt
[31m===========================================================================[0m
2024-08-07 15:04:19 - [32m[1mINFO   [0m - Training epoch 17
2024-08-07 15:05:32 - [34m[1mLOGS   [0m - Epoch:  17 [  134673/  200000], loss: {'classification': 33.3744, 'neural_augmentation': 0.5313, 'total_loss': 33.9057}, LR: [0.000298, 0.000298], Avg. batch load time: 71.058, Elapsed time: 73.12
2024-08-07 15:07:36 - [34m[1mLOGS   [0m - Epoch:  17 [  134735/  200000], loss: {'classification': 32.9724, 'neural_augmentation': 0.5348, 'total_loss': 33.5072}, LR: [0.000298, 0.000298], Avg. batch load time: 0.143, Elapsed time: 196.78
2024-08-07 15:09:40 - [34m[1mLOGS   [0m - Epoch:  17 [  134798/  200000], loss: {'classification': 33.0261, 'neural_augmentation': 0.5349, 'total_loss': 33.561}, LR: [0.000297, 0.000297], Avg. batch load time: 0.072, Elapsed time: 320.57
2024-08-07 15:11:43 - [34m[1mLOGS   [0m - Epoch:  17 [  134860/  200000], loss: {'classification': 33.0405, 'neural_augmentation': 0.535, 'total_loss': 33.5756}, LR: [0.000297, 0.000297], Avg. batch load time: 0.048, Elapsed time: 444.22
2024-08-07 15:13:47 - [34m[1mLOGS   [0m - Epoch:  17 [  134923/  200000], loss: {'classification': 33.0491, 'neural_augmentation': 0.5352, 'total_loss': 33.5843}, LR: [0.000296, 0.000296], Avg. batch load time: 0.037, Elapsed time: 567.86
2024-08-07 15:15:51 - [34m[1mLOGS   [0m - Epoch:  17 [  134985/  200000], loss: {'classification': 33.0358, 'neural_augmentation': 0.5353, 'total_loss': 33.5711}, LR: [0.000296, 0.000296], Avg. batch load time: 0.029, Elapsed time: 691.83
2024-08-07 15:17:55 - [34m[1mLOGS   [0m - Epoch:  17 [  135048/  200000], loss: {'classification': 33.0212, 'neural_augmentation': 0.5354, 'total_loss': 33.5567}, LR: [0.000295, 0.000295], Avg. batch load time: 0.025, Elapsed time: 815.67
2024-08-07 15:19:59 - [34m[1mLOGS   [0m - Epoch:  17 [  135110/  200000], loss: {'classification': 33.022, 'neural_augmentation': 0.5355, 'total_loss': 33.5575}, LR: [0.000295, 0.000295], Avg. batch load time: 0.021, Elapsed time: 939.33
2024-08-07 15:22:02 - [34m[1mLOGS   [0m - Epoch:  17 [  135173/  200000], loss: {'classification': 33.0132, 'neural_augmentation': 0.5356, 'total_loss': 33.5488}, LR: [0.000294, 0.000294], Avg. batch load time: 0.019, Elapsed time: 1063.31
2024-08-07 15:24:06 - [34m[1mLOGS   [0m - Epoch:  17 [  135235/  200000], loss: {'classification': 33.0122, 'neural_augmentation': 0.5357, 'total_loss': 33.5479}, LR: [0.000294, 0.000294], Avg. batch load time: 0.017, Elapsed time: 1186.99
2024-08-07 15:26:10 - [34m[1mLOGS   [0m - Epoch:  17 [  135298/  200000], loss: {'classification': 33.0157, 'neural_augmentation': 0.5359, 'total_loss': 33.5516}, LR: [0.000293, 0.000293], Avg. batch load time: 0.015, Elapsed time: 1310.57
2024-08-07 15:28:14 - [34m[1mLOGS   [0m - Epoch:  17 [  135360/  200000], loss: {'classification': 33.0201, 'neural_augmentation': 0.536, 'total_loss': 33.5561}, LR: [0.000293, 0.000293], Avg. batch load time: 0.014, Elapsed time: 1434.37
2024-08-07 15:30:19 - [34m[1mLOGS   [0m - Epoch:  17 [  135423/  200000], loss: {'classification': 33.0138, 'neural_augmentation': 0.5362, 'total_loss': 33.55}, LR: [0.000293, 0.000293], Avg. batch load time: 0.013, Elapsed time: 1559.81
2024-08-07 15:32:24 - [34m[1mLOGS   [0m - Epoch:  17 [  135485/  200000], loss: {'classification': 33.0068, 'neural_augmentation': 0.5363, 'total_loss': 33.5431}, LR: [0.000292, 0.000292], Avg. batch load time: 0.012, Elapsed time: 1685.17
2024-08-07 15:34:28 - [34m[1mLOGS   [0m - Epoch:  17 [  135548/  200000], loss: {'classification': 33.0082, 'neural_augmentation': 0.5364, 'total_loss': 33.5446}, LR: [0.000292, 0.000292], Avg. batch load time: 0.011, Elapsed time: 1809.03
2024-08-07 15:36:32 - [34m[1mLOGS   [0m - Epoch:  17 [  135610/  200000], loss: {'classification': 33.0111, 'neural_augmentation': 0.5365, 'total_loss': 33.5476}, LR: [0.000291, 0.000291], Avg. batch load time: 0.010, Elapsed time: 1932.97
2024-08-07 15:38:36 - [34m[1mLOGS   [0m - Epoch:  17 [  135673/  200000], loss: {'classification': 33.008, 'neural_augmentation': 0.5366, 'total_loss': 33.5447}, LR: [0.000291, 0.000291], Avg. batch load time: 0.010, Elapsed time: 2056.64
2024-08-07 15:40:40 - [34m[1mLOGS   [0m - Epoch:  17 [  135735/  200000], loss: {'classification': 33.0159, 'neural_augmentation': 0.5368, 'total_loss': 33.5527}, LR: [0.00029, 0.00029], Avg. batch load time: 0.009, Elapsed time: 2180.63
2024-08-07 15:42:44 - [34m[1mLOGS   [0m - Epoch:  17 [  135798/  200000], loss: {'classification': 33.0154, 'neural_augmentation': 0.537, 'total_loss': 33.5523}, LR: [0.00029, 0.00029], Avg. batch load time: 0.009, Elapsed time: 2304.44
2024-08-07 15:44:48 - [34m[1mLOGS   [0m - Epoch:  17 [  135860/  200000], loss: {'classification': 33.0126, 'neural_augmentation': 0.5371, 'total_loss': 33.5497}, LR: [0.000289, 0.000289], Avg. batch load time: 0.008, Elapsed time: 2428.55
2024-08-07 15:46:52 - [34m[1mLOGS   [0m - Epoch:  17 [  135923/  200000], loss: {'classification': 33.011, 'neural_augmentation': 0.5372, 'total_loss': 33.5482}, LR: [0.000289, 0.000289], Avg. batch load time: 0.008, Elapsed time: 2552.42
2024-08-07 15:48:55 - [34m[1mLOGS   [0m - Epoch:  17 [  135985/  200000], loss: {'classification': 33.011, 'neural_augmentation': 0.5374, 'total_loss': 33.5484}, LR: [0.000288, 0.000288], Avg. batch load time: 0.008, Elapsed time: 2676.25
2024-08-07 15:50:59 - [34m[1mLOGS   [0m - Epoch:  17 [  136048/  200000], loss: {'classification': 33.0104, 'neural_augmentation': 0.5375, 'total_loss': 33.5479}, LR: [0.000288, 0.000288], Avg. batch load time: 0.007, Elapsed time: 2799.99
2024-08-07 15:53:03 - [34m[1mLOGS   [0m - Epoch:  17 [  136110/  200000], loss: {'classification': 33.0107, 'neural_augmentation': 0.5376, 'total_loss': 33.5483}, LR: [0.000287, 0.000287], Avg. batch load time: 0.007, Elapsed time: 2923.86
2024-08-07 15:55:07 - [34m[1mLOGS   [0m - Epoch:  17 [  136173/  200000], loss: {'classification': 33.0096, 'neural_augmentation': 0.5377, 'total_loss': 33.5474}, LR: [0.000287, 0.000287], Avg. batch load time: 0.007, Elapsed time: 3048.00
2024-08-07 15:57:17 - [34m[1mLOGS   [0m - Epoch:  17 [  136235/  200000], loss: {'classification': 33.0079, 'neural_augmentation': 0.5379, 'total_loss': 33.5458}, LR: [0.000286, 0.000286], Avg. batch load time: 0.007, Elapsed time: 3178.23
2024-08-07 15:59:21 - [34m[1mLOGS   [0m - Epoch:  17 [  136298/  200000], loss: {'classification': 33.0058, 'neural_augmentation': 0.538, 'total_loss': 33.5439}, LR: [0.000286, 0.000286], Avg. batch load time: 0.006, Elapsed time: 3301.94
2024-08-07 16:01:25 - [34m[1mLOGS   [0m - Epoch:  17 [  136360/  200000], loss: {'classification': 33.0057, 'neural_augmentation': 0.5382, 'total_loss': 33.5439}, LR: [0.000285, 0.000285], Avg. batch load time: 0.006, Elapsed time: 3425.80
2024-08-07 16:03:29 - [34m[1mLOGS   [0m - Epoch:  17 [  136423/  200000], loss: {'classification': 33.0064, 'neural_augmentation': 0.5383, 'total_loss': 33.5447}, LR: [0.000285, 0.000285], Avg. batch load time: 0.006, Elapsed time: 3549.47
2024-08-07 16:05:33 - [34m[1mLOGS   [0m - Epoch:  17 [  136485/  200000], loss: {'classification': 33.0063, 'neural_augmentation': 0.5385, 'total_loss': 33.5447}, LR: [0.000284, 0.000284], Avg. batch load time: 0.006, Elapsed time: 3673.48
2024-08-07 16:07:37 - [34m[1mLOGS   [0m - Epoch:  17 [  136548/  200000], loss: {'classification': 33.0066, 'neural_augmentation': 0.5386, 'total_loss': 33.5453}, LR: [0.000284, 0.000284], Avg. batch load time: 0.006, Elapsed time: 3797.42
2024-08-07 16:09:40 - [34m[1mLOGS   [0m - Epoch:  17 [  136610/  200000], loss: {'classification': 33.0086, 'neural_augmentation': 0.5387, 'total_loss': 33.5473}, LR: [0.000283, 0.000283], Avg. batch load time: 0.006, Elapsed time: 3921.26
2024-08-07 16:11:44 - [34m[1mLOGS   [0m - Epoch:  17 [  136673/  200000], loss: {'classification': 33.0059, 'neural_augmentation': 0.5389, 'total_loss': 33.5448}, LR: [0.000283, 0.000283], Avg. batch load time: 0.005, Elapsed time: 4044.89
2024-08-07 16:13:48 - [34m[1mLOGS   [0m - Epoch:  17 [  136735/  200000], loss: {'classification': 33.0034, 'neural_augmentation': 0.539, 'total_loss': 33.5424}, LR: [0.000282, 0.000282], Avg. batch load time: 0.005, Elapsed time: 4168.91
2024-08-07 16:15:52 - [34m[1mLOGS   [0m - Epoch:  17 [  136798/  200000], loss: {'classification': 33.0025, 'neural_augmentation': 0.5391, 'total_loss': 33.5416}, LR: [0.000282, 0.000282], Avg. batch load time: 0.005, Elapsed time: 4292.84
2024-08-07 16:17:56 - [34m[1mLOGS   [0m - Epoch:  17 [  136860/  200000], loss: {'classification': 33.0013, 'neural_augmentation': 0.5393, 'total_loss': 33.5406}, LR: [0.000281, 0.000281], Avg. batch load time: 0.005, Elapsed time: 4416.91
2024-08-07 16:20:00 - [34m[1mLOGS   [0m - Epoch:  17 [  136923/  200000], loss: {'classification': 33.0041, 'neural_augmentation': 0.5394, 'total_loss': 33.5435}, LR: [0.000281, 0.000281], Avg. batch load time: 0.005, Elapsed time: 4540.63
2024-08-07 16:22:11 - [34m[1mLOGS   [0m - Epoch:  17 [  136985/  200000], loss: {'classification': 33.0057, 'neural_augmentation': 0.5395, 'total_loss': 33.5453}, LR: [0.00028, 0.00028], Avg. batch load time: 0.005, Elapsed time: 4672.31
2024-08-07 16:24:15 - [34m[1mLOGS   [0m - Epoch:  17 [  137048/  200000], loss: {'classification': 33.007, 'neural_augmentation': 0.5397, 'total_loss': 33.5467}, LR: [0.00028, 0.00028], Avg. batch load time: 0.005, Elapsed time: 4795.93
2024-08-07 16:26:19 - [34m[1mLOGS   [0m - Epoch:  17 [  137110/  200000], loss: {'classification': 33.0057, 'neural_augmentation': 0.5398, 'total_loss': 33.5455}, LR: [0.000279, 0.000279], Avg. batch load time: 0.005, Elapsed time: 4919.59
2024-08-07 16:28:23 - [34m[1mLOGS   [0m - Epoch:  17 [  137173/  200000], loss: {'classification': 33.0064, 'neural_augmentation': 0.54, 'total_loss': 33.5463}, LR: [0.000279, 0.000279], Avg. batch load time: 0.005, Elapsed time: 5043.85
2024-08-07 16:30:27 - [34m[1mLOGS   [0m - Epoch:  17 [  137235/  200000], loss: {'classification': 33.0052, 'neural_augmentation': 0.5401, 'total_loss': 33.5453}, LR: [0.000278, 0.000278], Avg. batch load time: 0.004, Elapsed time: 5167.70
2024-08-07 16:32:31 - [34m[1mLOGS   [0m - Epoch:  17 [  137298/  200000], loss: {'classification': 33.009, 'neural_augmentation': 0.5402, 'total_loss': 33.5492}, LR: [0.000278, 0.000278], Avg. batch load time: 0.004, Elapsed time: 5291.47
2024-08-07 16:34:35 - [34m[1mLOGS   [0m - Epoch:  17 [  137360/  200000], loss: {'classification': 33.0075, 'neural_augmentation': 0.5404, 'total_loss': 33.5478}, LR: [0.000278, 0.000278], Avg. batch load time: 0.004, Elapsed time: 5415.43
2024-08-07 16:36:38 - [34m[1mLOGS   [0m - Epoch:  17 [  137423/  200000], loss: {'classification': 33.0081, 'neural_augmentation': 0.5405, 'total_loss': 33.5486}, LR: [0.000277, 0.000277], Avg. batch load time: 0.004, Elapsed time: 5539.22
2024-08-07 16:38:42 - [34m[1mLOGS   [0m - Epoch:  17 [  137485/  200000], loss: {'classification': 33.009, 'neural_augmentation': 0.5406, 'total_loss': 33.5497}, LR: [0.000277, 0.000277], Avg. batch load time: 0.004, Elapsed time: 5663.06
2024-08-07 16:40:46 - [34m[1mLOGS   [0m - Epoch:  17 [  137548/  200000], loss: {'classification': 33.0088, 'neural_augmentation': 0.5408, 'total_loss': 33.5496}, LR: [0.000276, 0.000276], Avg. batch load time: 0.004, Elapsed time: 5786.90
2024-08-07 16:42:50 - [34m[1mLOGS   [0m - Epoch:  17 [  137610/  200000], loss: {'classification': 33.0078, 'neural_augmentation': 0.5409, 'total_loss': 33.5488}, LR: [0.000276, 0.000276], Avg. batch load time: 0.004, Elapsed time: 5910.87
2024-08-07 16:44:54 - [34m[1mLOGS   [0m - Epoch:  17 [  137673/  200000], loss: {'classification': 33.0069, 'neural_augmentation': 0.5411, 'total_loss': 33.548}, LR: [0.000275, 0.000275], Avg. batch load time: 0.004, Elapsed time: 6035.07
2024-08-07 16:47:00 - [34m[1mLOGS   [0m - Epoch:  17 [  137735/  200000], loss: {'classification': 33.0086, 'neural_augmentation': 0.5412, 'total_loss': 33.5498}, LR: [0.000275, 0.000275], Avg. batch load time: 0.004, Elapsed time: 6160.34
2024-08-07 16:49:10 - [34m[1mLOGS   [0m - Epoch:  17 [  137798/  200000], loss: {'classification': 33.0086, 'neural_augmentation': 0.5414, 'total_loss': 33.55}, LR: [0.000274, 0.000274], Avg. batch load time: 0.004, Elapsed time: 6290.70
2024-08-07 16:51:14 - [34m[1mLOGS   [0m - Epoch:  17 [  137860/  200000], loss: {'classification': 33.0086, 'neural_augmentation': 0.5415, 'total_loss': 33.5501}, LR: [0.000274, 0.000274], Avg. batch load time: 0.004, Elapsed time: 6414.47
2024-08-07 16:53:17 - [34m[1mLOGS   [0m - Epoch:  17 [  137923/  200000], loss: {'classification': 33.0091, 'neural_augmentation': 0.5416, 'total_loss': 33.5508}, LR: [0.000273, 0.000273], Avg. batch load time: 0.004, Elapsed time: 6538.17
2024-08-07 16:55:21 - [34m[1mLOGS   [0m - Epoch:  17 [  137985/  200000], loss: {'classification': 33.0091, 'neural_augmentation': 0.5418, 'total_loss': 33.5509}, LR: [0.000273, 0.000273], Avg. batch load time: 0.004, Elapsed time: 6661.64
2024-08-07 16:57:24 - [34m[1mLOGS   [0m - Epoch:  17 [  138048/  200000], loss: {'classification': 33.0092, 'neural_augmentation': 0.5419, 'total_loss': 33.5511}, LR: [0.000272, 0.000272], Avg. batch load time: 0.004, Elapsed time: 6785.33
2024-08-07 16:59:28 - [34m[1mLOGS   [0m - Epoch:  17 [  138110/  200000], loss: {'classification': 33.0099, 'neural_augmentation': 0.542, 'total_loss': 33.5519}, LR: [0.000272, 0.000272], Avg. batch load time: 0.004, Elapsed time: 6909.28
2024-08-07 17:01:32 - [34m[1mLOGS   [0m - Epoch:  17 [  138173/  200000], loss: {'classification': 33.01, 'neural_augmentation': 0.5422, 'total_loss': 33.5521}, LR: [0.000271, 0.000271], Avg. batch load time: 0.004, Elapsed time: 7032.91
2024-08-07 17:03:36 - [34m[1mLOGS   [0m - Epoch:  17 [  138235/  200000], loss: {'classification': 33.0094, 'neural_augmentation': 0.5423, 'total_loss': 33.5517}, LR: [0.000271, 0.000271], Avg. batch load time: 0.004, Elapsed time: 7156.60
2024-08-07 17:05:39 - [34m[1mLOGS   [0m - Epoch:  17 [  138298/  200000], loss: {'classification': 33.0072, 'neural_augmentation': 0.5424, 'total_loss': 33.5496}, LR: [0.00027, 0.00027], Avg. batch load time: 0.003, Elapsed time: 7280.07
2024-08-07 17:07:43 - [34m[1mLOGS   [0m - Epoch:  17 [  138360/  200000], loss: {'classification': 33.0063, 'neural_augmentation': 0.5426, 'total_loss': 33.5488}, LR: [0.00027, 0.00027], Avg. batch load time: 0.003, Elapsed time: 7403.85
2024-08-07 17:09:47 - [34m[1mLOGS   [0m - Epoch:  17 [  138423/  200000], loss: {'classification': 33.0067, 'neural_augmentation': 0.5427, 'total_loss': 33.5494}, LR: [0.000269, 0.000269], Avg. batch load time: 0.003, Elapsed time: 7527.79
2024-08-07 17:11:51 - [34m[1mLOGS   [0m - Epoch:  17 [  138485/  200000], loss: {'classification': 33.0052, 'neural_augmentation': 0.5428, 'total_loss': 33.548}, LR: [0.000269, 0.000269], Avg. batch load time: 0.003, Elapsed time: 7652.04
2024-08-07 17:14:05 - [34m[1mLOGS   [0m - Epoch:  17 [  138548/  200000], loss: {'classification': 33.0053, 'neural_augmentation': 0.543, 'total_loss': 33.5483}, LR: [0.000268, 0.000268], Avg. batch load time: 0.003, Elapsed time: 7786.28
2024-08-07 17:16:09 - [34m[1mLOGS   [0m - Epoch:  17 [  138610/  200000], loss: {'classification': 33.0035, 'neural_augmentation': 0.5431, 'total_loss': 33.5466}, LR: [0.000268, 0.000268], Avg. batch load time: 0.003, Elapsed time: 7910.21
2024-08-07 17:18:13 - [34m[1mLOGS   [0m - Epoch:  17 [  138673/  200000], loss: {'classification': 33.0025, 'neural_augmentation': 0.5433, 'total_loss': 33.5457}, LR: [0.000267, 0.000267], Avg. batch load time: 0.003, Elapsed time: 8034.02
2024-08-07 17:20:17 - [34m[1mLOGS   [0m - Epoch:  17 [  138735/  200000], loss: {'classification': 33.0019, 'neural_augmentation': 0.5434, 'total_loss': 33.5453}, LR: [0.000267, 0.000267], Avg. batch load time: 0.003, Elapsed time: 8157.79
2024-08-07 17:22:21 - [34m[1mLOGS   [0m - Epoch:  17 [  138798/  200000], loss: {'classification': 33.0027, 'neural_augmentation': 0.5435, 'total_loss': 33.5462}, LR: [0.000267, 0.000267], Avg. batch load time: 0.003, Elapsed time: 8281.68
2024-08-07 17:24:24 - [34m[1mLOGS   [0m - Epoch:  17 [  138860/  200000], loss: {'classification': 33.0032, 'neural_augmentation': 0.5437, 'total_loss': 33.5469}, LR: [0.000266, 0.000266], Avg. batch load time: 0.003, Elapsed time: 8405.31
2024-08-07 17:26:28 - [34m[1mLOGS   [0m - Epoch:  17 [  138923/  200000], loss: {'classification': 33.0024, 'neural_augmentation': 0.5438, 'total_loss': 33.5462}, LR: [0.000266, 0.000266], Avg. batch load time: 0.003, Elapsed time: 8529.30
2024-08-07 17:28:32 - [34m[1mLOGS   [0m - Epoch:  17 [  138985/  200000], loss: {'classification': 33.0017, 'neural_augmentation': 0.544, 'total_loss': 33.5456}, LR: [0.000265, 0.000265], Avg. batch load time: 0.003, Elapsed time: 8653.20
2024-08-07 17:30:36 - [34m[1mLOGS   [0m - Epoch:  17 [  139048/  200000], loss: {'classification': 33.0003, 'neural_augmentation': 0.5441, 'total_loss': 33.5444}, LR: [0.000265, 0.000265], Avg. batch load time: 0.003, Elapsed time: 8776.96
2024-08-07 17:32:40 - [34m[1mLOGS   [0m - Epoch:  17 [  139110/  200000], loss: {'classification': 32.9997, 'neural_augmentation': 0.5442, 'total_loss': 33.5439}, LR: [0.000264, 0.000264], Avg. batch load time: 0.003, Elapsed time: 8900.72
2024-08-07 17:34:44 - [34m[1mLOGS   [0m - Epoch:  17 [  139173/  200000], loss: {'classification': 32.9991, 'neural_augmentation': 0.5444, 'total_loss': 33.5435}, LR: [0.000264, 0.000264], Avg. batch load time: 0.003, Elapsed time: 9024.51
2024-08-07 17:36:48 - [34m[1mLOGS   [0m - Epoch:  17 [  139235/  200000], loss: {'classification': 32.9983, 'neural_augmentation': 0.5445, 'total_loss': 33.5428}, LR: [0.000263, 0.000263], Avg. batch load time: 0.003, Elapsed time: 9148.40
2024-08-07 17:39:00 - [34m[1mLOGS   [0m - Epoch:  17 [  139298/  200000], loss: {'classification': 32.9984, 'neural_augmentation': 0.5446, 'total_loss': 33.5431}, LR: [0.000263, 0.000263], Avg. batch load time: 0.003, Elapsed time: 9280.64
2024-08-07 17:41:03 - [34m[1mLOGS   [0m - Epoch:  17 [  139360/  200000], loss: {'classification': 32.997, 'neural_augmentation': 0.5447, 'total_loss': 33.5418}, LR: [0.000262, 0.000262], Avg. batch load time: 0.003, Elapsed time: 9404.16
2024-08-07 17:43:07 - [34m[1mLOGS   [0m - Epoch:  17 [  139423/  200000], loss: {'classification': 32.9967, 'neural_augmentation': 0.5449, 'total_loss': 33.5416}, LR: [0.000262, 0.000262], Avg. batch load time: 0.003, Elapsed time: 9528.03
2024-08-07 17:45:11 - [34m[1mLOGS   [0m - Epoch:  17 [  139485/  200000], loss: {'classification': 32.9953, 'neural_augmentation': 0.545, 'total_loss': 33.5403}, LR: [0.000261, 0.000261], Avg. batch load time: 0.003, Elapsed time: 9651.84
2024-08-07 17:47:15 - [34m[1mLOGS   [0m - Epoch:  17 [  139548/  200000], loss: {'classification': 32.9952, 'neural_augmentation': 0.5451, 'total_loss': 33.5403}, LR: [0.000261, 0.000261], Avg. batch load time: 0.003, Elapsed time: 9775.76
2024-08-07 17:49:19 - [34m[1mLOGS   [0m - Epoch:  17 [  139610/  200000], loss: {'classification': 32.9956, 'neural_augmentation': 0.5453, 'total_loss': 33.5409}, LR: [0.00026, 0.00026], Avg. batch load time: 0.003, Elapsed time: 9899.58
2024-08-07 17:51:23 - [34m[1mLOGS   [0m - Epoch:  17 [  139673/  200000], loss: {'classification': 32.9946, 'neural_augmentation': 0.5454, 'total_loss': 33.54}, LR: [0.00026, 0.00026], Avg. batch load time: 0.003, Elapsed time: 10023.33
2024-08-07 17:53:26 - [34m[1mLOGS   [0m - Epoch:  17 [  139735/  200000], loss: {'classification': 32.9937, 'neural_augmentation': 0.5455, 'total_loss': 33.5393}, LR: [0.000259, 0.000259], Avg. batch load time: 0.003, Elapsed time: 10147.29
2024-08-07 17:55:30 - [34m[1mLOGS   [0m - Epoch:  17 [  139798/  200000], loss: {'classification': 32.9934, 'neural_augmentation': 0.5457, 'total_loss': 33.5391}, LR: [0.000259, 0.000259], Avg. batch load time: 0.003, Elapsed time: 10270.99
2024-08-07 17:57:34 - [34m[1mLOGS   [0m - Epoch:  17 [  139860/  200000], loss: {'classification': 32.9923, 'neural_augmentation': 0.5458, 'total_loss': 33.5381}, LR: [0.000259, 0.000259], Avg. batch load time: 0.003, Elapsed time: 10394.96
2024-08-07 17:59:38 - [34m[1mLOGS   [0m - Epoch:  17 [  139923/  200000], loss: {'classification': 32.992, 'neural_augmentation': 0.546, 'total_loss': 33.538}, LR: [0.000258, 0.000258], Avg. batch load time: 0.003, Elapsed time: 10518.84
2024-08-07 18:01:42 - [34m[1mLOGS   [0m - Epoch:  17 [  139985/  200000], loss: {'classification': 32.9901, 'neural_augmentation': 0.5461, 'total_loss': 33.5362}, LR: [0.000258, 0.000258], Avg. batch load time: 0.003, Elapsed time: 10642.63
2024-08-07 18:03:49 - [34m[1mLOGS   [0m - Epoch:  17 [  140048/  200000], loss: {'classification': 32.9902, 'neural_augmentation': 0.5462, 'total_loss': 33.5364}, LR: [0.000257, 0.000257], Avg. batch load time: 0.003, Elapsed time: 10770.08
2024-08-07 18:05:57 - [34m[1mLOGS   [0m - Epoch:  17 [  140110/  200000], loss: {'classification': 32.9881, 'neural_augmentation': 0.5464, 'total_loss': 33.5345}, LR: [0.000257, 0.000257], Avg. batch load time: 0.003, Elapsed time: 10897.55
2024-08-07 18:08:01 - [34m[1mLOGS   [0m - Epoch:  17 [  140173/  200000], loss: {'classification': 32.9876, 'neural_augmentation': 0.5465, 'total_loss': 33.5341}, LR: [0.000256, 0.000256], Avg. batch load time: 0.003, Elapsed time: 11021.38
2024-08-07 18:10:04 - [34m[1mLOGS   [0m - Epoch:  17 [  140235/  200000], loss: {'classification': 32.9867, 'neural_augmentation': 0.5466, 'total_loss': 33.5333}, LR: [0.000256, 0.000256], Avg. batch load time: 0.003, Elapsed time: 11145.23
2024-08-07 18:12:08 - [34m[1mLOGS   [0m - Epoch:  17 [  140298/  200000], loss: {'classification': 32.9865, 'neural_augmentation': 0.5468, 'total_loss': 33.5333}, LR: [0.000255, 0.000255], Avg. batch load time: 0.003, Elapsed time: 11269.04
2024-08-07 18:14:12 - [34m[1mLOGS   [0m - Epoch:  17 [  140360/  200000], loss: {'classification': 32.9858, 'neural_augmentation': 0.5469, 'total_loss': 33.5327}, LR: [0.000255, 0.000255], Avg. batch load time: 0.003, Elapsed time: 11392.84
2024-08-07 18:16:16 - [34m[1mLOGS   [0m - Epoch:  17 [  140423/  200000], loss: {'classification': 32.9855, 'neural_augmentation': 0.5471, 'total_loss': 33.5326}, LR: [0.000254, 0.000254], Avg. batch load time: 0.003, Elapsed time: 11516.73
2024-08-07 18:18:20 - [34m[1mLOGS   [0m - Epoch:  17 [  140485/  200000], loss: {'classification': 32.9845, 'neural_augmentation': 0.5472, 'total_loss': 33.5317}, LR: [0.000254, 0.000254], Avg. batch load time: 0.003, Elapsed time: 11640.60
2024-08-07 18:20:24 - [34m[1mLOGS   [0m - Epoch:  17 [  140548/  200000], loss: {'classification': 32.9824, 'neural_augmentation': 0.5473, 'total_loss': 33.5297}, LR: [0.000253, 0.000253], Avg. batch load time: 0.003, Elapsed time: 11764.46
2024-08-07 18:22:27 - [34m[1mLOGS   [0m - Epoch:  17 [  140610/  200000], loss: {'classification': 32.9795, 'neural_augmentation': 0.5475, 'total_loss': 33.5269}, LR: [0.000253, 0.000253], Avg. batch load time: 0.003, Elapsed time: 11888.19
2024-08-07 18:24:31 - [34m[1mLOGS   [0m - Epoch:  17 [  140673/  200000], loss: {'classification': 32.9789, 'neural_augmentation': 0.5476, 'total_loss': 33.5265}, LR: [0.000252, 0.000252], Avg. batch load time: 0.002, Elapsed time: 12011.98
2024-08-07 18:26:35 - [34m[1mLOGS   [0m - Epoch:  17 [  140735/  200000], loss: {'classification': 32.9776, 'neural_augmentation': 0.5477, 'total_loss': 33.5253}, LR: [0.000252, 0.000252], Avg. batch load time: 0.002, Elapsed time: 12135.86
2024-08-07 18:28:39 - [34m[1mLOGS   [0m - Epoch:  17 [  140798/  200000], loss: {'classification': 32.9766, 'neural_augmentation': 0.5479, 'total_loss': 33.5245}, LR: [0.000252, 0.000252], Avg. batch load time: 0.002, Elapsed time: 12259.35
2024-08-07 18:30:52 - [34m[1mLOGS   [0m - Epoch:  17 [  140860/  200000], loss: {'classification': 32.9765, 'neural_augmentation': 0.548, 'total_loss': 33.5246}, LR: [0.000251, 0.000251], Avg. batch load time: 0.002, Elapsed time: 12392.72
2024-08-07 18:32:55 - [34m[1mLOGS   [0m - Epoch:  17 [  140923/  200000], loss: {'classification': 32.9761, 'neural_augmentation': 0.5481, 'total_loss': 33.5243}, LR: [0.000251, 0.000251], Avg. batch load time: 0.002, Elapsed time: 12516.31
2024-08-07 18:34:59 - [34m[1mLOGS   [0m - Epoch:  17 [  140985/  200000], loss: {'classification': 32.9741, 'neural_augmentation': 0.5483, 'total_loss': 33.5223}, LR: [0.00025, 0.00025], Avg. batch load time: 0.002, Elapsed time: 12640.21
2024-08-07 18:37:03 - [34m[1mLOGS   [0m - Epoch:  17 [  141048/  200000], loss: {'classification': 32.9734, 'neural_augmentation': 0.5484, 'total_loss': 33.5218}, LR: [0.00025, 0.00025], Avg. batch load time: 0.002, Elapsed time: 12764.04
2024-08-07 18:39:07 - [34m[1mLOGS   [0m - Epoch:  17 [  141110/  200000], loss: {'classification': 32.9717, 'neural_augmentation': 0.5485, 'total_loss': 33.5203}, LR: [0.000249, 0.000249], Avg. batch load time: 0.002, Elapsed time: 12887.98
2024-08-07 18:41:11 - [34m[1mLOGS   [0m - Epoch:  17 [  141173/  200000], loss: {'classification': 32.9695, 'neural_augmentation': 0.5487, 'total_loss': 33.5182}, LR: [0.000249, 0.000249], Avg. batch load time: 0.002, Elapsed time: 13011.65
2024-08-07 18:43:15 - [34m[1mLOGS   [0m - Epoch:  17 [  141235/  200000], loss: {'classification': 32.9673, 'neural_augmentation': 0.5488, 'total_loss': 33.5161}, LR: [0.000248, 0.000248], Avg. batch load time: 0.002, Elapsed time: 13135.36
2024-08-07 18:45:18 - [34m[1mLOGS   [0m - Epoch:  17 [  141298/  200000], loss: {'classification': 32.9676, 'neural_augmentation': 0.549, 'total_loss': 33.5165}, LR: [0.000248, 0.000248], Avg. batch load time: 0.002, Elapsed time: 13259.17
2024-08-07 18:47:22 - [34m[1mLOGS   [0m - Epoch:  17 [  141360/  200000], loss: {'classification': 32.9673, 'neural_augmentation': 0.5491, 'total_loss': 33.5164}, LR: [0.000247, 0.000247], Avg. batch load time: 0.002, Elapsed time: 13382.77
2024-08-07 18:49:26 - [34m[1mLOGS   [0m - Epoch:  17 [  141423/  200000], loss: {'classification': 32.9667, 'neural_augmentation': 0.5492, 'total_loss': 33.5159}, LR: [0.000247, 0.000247], Avg. batch load time: 0.002, Elapsed time: 13507.01
2024-08-07 18:51:30 - [34m[1mLOGS   [0m - Epoch:  17 [  141485/  200000], loss: {'classification': 32.9663, 'neural_augmentation': 0.5494, 'total_loss': 33.5157}, LR: [0.000246, 0.000246], Avg. batch load time: 0.002, Elapsed time: 13630.59
2024-08-07 18:53:34 - [34m[1mLOGS   [0m - Epoch:  17 [  141548/  200000], loss: {'classification': 32.9658, 'neural_augmentation': 0.5495, 'total_loss': 33.5153}, LR: [0.000246, 0.000246], Avg. batch load time: 0.002, Elapsed time: 13754.53
2024-08-07 18:55:47 - [34m[1mLOGS   [0m - Epoch:  17 [  141610/  200000], loss: {'classification': 32.9647, 'neural_augmentation': 0.5496, 'total_loss': 33.5143}, LR: [0.000246, 0.000246], Avg. batch load time: 0.002, Elapsed time: 13888.28
2024-08-07 18:57:52 - [34m[1mLOGS   [0m - Epoch:  17 [  141673/  200000], loss: {'classification': 32.9639, 'neural_augmentation': 0.5498, 'total_loss': 33.5137}, LR: [0.000245, 0.000245], Avg. batch load time: 0.002, Elapsed time: 14012.34
2024-08-07 18:59:55 - [34m[1mLOGS   [0m - Epoch:  17 [  141735/  200000], loss: {'classification': 32.9624, 'neural_augmentation': 0.5499, 'total_loss': 33.5123}, LR: [0.000245, 0.000245], Avg. batch load time: 0.002, Elapsed time: 14136.09
2024-08-07 19:01:59 - [34m[1mLOGS   [0m - Epoch:  17 [  141798/  200000], loss: {'classification': 32.961, 'neural_augmentation': 0.55, 'total_loss': 33.5111}, LR: [0.000244, 0.000244], Avg. batch load time: 0.002, Elapsed time: 14259.73
2024-08-07 19:04:03 - [34m[1mLOGS   [0m - Epoch:  17 [  141860/  200000], loss: {'classification': 32.9598, 'neural_augmentation': 0.5502, 'total_loss': 33.51}, LR: [0.000244, 0.000244], Avg. batch load time: 0.002, Elapsed time: 14383.49
2024-08-07 19:06:06 - [34m[1mLOGS   [0m - Epoch:  17 [  141923/  200000], loss: {'classification': 32.959, 'neural_augmentation': 0.5503, 'total_loss': 33.5094}, LR: [0.000243, 0.000243], Avg. batch load time: 0.002, Elapsed time: 14507.17
2024-08-07 19:08:10 - [34m[1mLOGS   [0m - Epoch:  17 [  141985/  200000], loss: {'classification': 32.9576, 'neural_augmentation': 0.5505, 'total_loss': 33.508}, LR: [0.000243, 0.000243], Avg. batch load time: 0.002, Elapsed time: 14631.08
2024-08-07 19:10:14 - [34m[1mLOGS   [0m - Epoch:  17 [  142048/  200000], loss: {'classification': 32.9562, 'neural_augmentation': 0.5506, 'total_loss': 33.5068}, LR: [0.000242, 0.000242], Avg. batch load time: 0.002, Elapsed time: 14754.94
2024-08-07 19:12:18 - [34m[1mLOGS   [0m - Epoch:  17 [  142110/  200000], loss: {'classification': 32.9549, 'neural_augmentation': 0.5507, 'total_loss': 33.5056}, LR: [0.000242, 0.000242], Avg. batch load time: 0.002, Elapsed time: 14878.70
2024-08-07 19:14:22 - [34m[1mLOGS   [0m - Epoch:  17 [  142173/  200000], loss: {'classification': 32.9543, 'neural_augmentation': 0.5509, 'total_loss': 33.5052}, LR: [0.000241, 0.000241], Avg. batch load time: 0.002, Elapsed time: 15002.51
2024-08-07 19:16:26 - [34m[1mLOGS   [0m - Epoch:  17 [  142235/  200000], loss: {'classification': 32.954, 'neural_augmentation': 0.551, 'total_loss': 33.505}, LR: [0.000241, 0.000241], Avg. batch load time: 0.002, Elapsed time: 15126.52
2024-08-07 19:18:30 - [34m[1mLOGS   [0m - Epoch:  17 [  142298/  200000], loss: {'classification': 32.9533, 'neural_augmentation': 0.5511, 'total_loss': 33.5044}, LR: [0.000241, 0.000241], Avg. batch load time: 0.002, Elapsed time: 15250.49
2024-08-07 19:20:37 - [34m[1mLOGS   [0m - Epoch:  17 [  142360/  200000], loss: {'classification': 32.9527, 'neural_augmentation': 0.5513, 'total_loss': 33.5039}, LR: [0.00024, 0.00024], Avg. batch load time: 0.002, Elapsed time: 15377.79
2024-08-07 19:22:47 - [34m[1mLOGS   [0m - Epoch:  17 [  142423/  200000], loss: {'classification': 32.9516, 'neural_augmentation': 0.5514, 'total_loss': 33.503}, LR: [0.00024, 0.00024], Avg. batch load time: 0.002, Elapsed time: 15507.99
2024-08-07 19:24:51 - [34m[1mLOGS   [0m - Epoch:  17 [  142485/  200000], loss: {'classification': 32.951, 'neural_augmentation': 0.5515, 'total_loss': 33.5025}, LR: [0.000239, 0.000239], Avg. batch load time: 0.002, Elapsed time: 15631.58
2024-08-07 19:26:55 - [34m[1mLOGS   [0m - Epoch:  17 [  142548/  200000], loss: {'classification': 32.9493, 'neural_augmentation': 0.5517, 'total_loss': 33.501}, LR: [0.000239, 0.000239], Avg. batch load time: 0.002, Elapsed time: 15755.73
2024-08-07 19:28:59 - [34m[1mLOGS   [0m - Epoch:  17 [  142610/  200000], loss: {'classification': 32.9485, 'neural_augmentation': 0.5518, 'total_loss': 33.5003}, LR: [0.000238, 0.000238], Avg. batch load time: 0.002, Elapsed time: 15880.09
2024-08-07 19:29:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 32.9484, 'neural_augmentation': 0.5518, 'total_loss': 33.5002}
2024-08-07 19:29:19 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_best.pt
2024-08-07 19:29:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_last.pt
2024-08-07 19:29:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_last.pt
2024-08-07 19:29:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 142619 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_epoch_17_iter_142619.pt
2024-08-07 19:29:23 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 142619 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_epoch_17_iter_142619.pt
[31m===========================================================================[0m
2024-08-07 19:29:25 - [32m[1mINFO   [0m - Training epoch 18
2024-08-07 19:30:36 - [34m[1mLOGS   [0m - Epoch:  18 [  142619/  200000], loss: {'classification': 29.7602, 'neural_augmentation': 0.5728, 'total_loss': 30.333}, LR: [0.000238, 0.000238], Avg. batch load time: 71.125, Elapsed time: 71.37
2024-08-07 19:32:46 - [34m[1mLOGS   [0m - Epoch:  18 [  142681/  200000], loss: {'classification': 32.7376, 'neural_augmentation': 0.5685, 'total_loss': 33.306}, LR: [0.000238, 0.000238], Avg. batch load time: 0.156, Elapsed time: 201.58
2024-08-07 19:34:50 - [34m[1mLOGS   [0m - Epoch:  18 [  142744/  200000], loss: {'classification': 32.7823, 'neural_augmentation': 0.5687, 'total_loss': 33.351}, LR: [0.000237, 0.000237], Avg. batch load time: 0.079, Elapsed time: 325.55
2024-08-07 19:36:54 - [34m[1mLOGS   [0m - Epoch:  18 [  142806/  200000], loss: {'classification': 32.7799, 'neural_augmentation': 0.5689, 'total_loss': 33.3488}, LR: [0.000237, 0.000237], Avg. batch load time: 0.053, Elapsed time: 449.22
2024-08-07 19:38:58 - [34m[1mLOGS   [0m - Epoch:  18 [  142869/  200000], loss: {'classification': 32.7909, 'neural_augmentation': 0.569, 'total_loss': 33.36}, LR: [0.000236, 0.000236], Avg. batch load time: 0.040, Elapsed time: 572.89
2024-08-07 19:41:02 - [34m[1mLOGS   [0m - Epoch:  18 [  142931/  200000], loss: {'classification': 32.8139, 'neural_augmentation': 0.5691, 'total_loss': 33.383}, LR: [0.000236, 0.000236], Avg. batch load time: 0.032, Elapsed time: 696.86
2024-08-07 19:43:05 - [34m[1mLOGS   [0m - Epoch:  18 [  142994/  200000], loss: {'classification': 32.8128, 'neural_augmentation': 0.5692, 'total_loss': 33.382}, LR: [0.000235, 0.000235], Avg. batch load time: 0.027, Elapsed time: 820.75
2024-08-07 19:45:09 - [34m[1mLOGS   [0m - Epoch:  18 [  143056/  200000], loss: {'classification': 32.8015, 'neural_augmentation': 0.5693, 'total_loss': 33.3708}, LR: [0.000235, 0.000235], Avg. batch load time: 0.023, Elapsed time: 944.40
2024-08-07 19:47:13 - [34m[1mLOGS   [0m - Epoch:  18 [  143119/  200000], loss: {'classification': 32.7922, 'neural_augmentation': 0.5695, 'total_loss': 33.3617}, LR: [0.000235, 0.000235], Avg. batch load time: 0.020, Elapsed time: 1068.23
2024-08-07 19:49:16 - [34m[1mLOGS   [0m - Epoch:  18 [  143181/  200000], loss: {'classification': 32.7916, 'neural_augmentation': 0.5697, 'total_loss': 33.3613}, LR: [0.000234, 0.000234], Avg. batch load time: 0.018, Elapsed time: 1191.71
2024-08-07 19:51:20 - [34m[1mLOGS   [0m - Epoch:  18 [  143244/  200000], loss: {'classification': 32.7843, 'neural_augmentation': 0.5698, 'total_loss': 33.3542}, LR: [0.000234, 0.000234], Avg. batch load time: 0.017, Elapsed time: 1315.62
2024-08-07 19:53:24 - [34m[1mLOGS   [0m - Epoch:  18 [  143306/  200000], loss: {'classification': 32.7808, 'neural_augmentation': 0.57, 'total_loss': 33.3508}, LR: [0.000233, 0.000233], Avg. batch load time: 0.015, Elapsed time: 1439.23
2024-08-07 19:55:29 - [34m[1mLOGS   [0m - Epoch:  18 [  143369/  200000], loss: {'classification': 32.7772, 'neural_augmentation': 0.5701, 'total_loss': 33.3473}, LR: [0.000233, 0.000233], Avg. batch load time: 0.014, Elapsed time: 1564.70
2024-08-07 19:57:36 - [34m[1mLOGS   [0m - Epoch:  18 [  143431/  200000], loss: {'classification': 32.7719, 'neural_augmentation': 0.5703, 'total_loss': 33.3422}, LR: [0.000232, 0.000232], Avg. batch load time: 0.013, Elapsed time: 1691.71
2024-08-07 19:59:40 - [34m[1mLOGS   [0m - Epoch:  18 [  143494/  200000], loss: {'classification': 32.773, 'neural_augmentation': 0.5704, 'total_loss': 33.3434}, LR: [0.000232, 0.000232], Avg. batch load time: 0.012, Elapsed time: 1815.44
2024-08-07 20:01:44 - [34m[1mLOGS   [0m - Epoch:  18 [  143556/  200000], loss: {'classification': 32.7771, 'neural_augmentation': 0.5706, 'total_loss': 33.3477}, LR: [0.000231, 0.000231], Avg. batch load time: 0.011, Elapsed time: 1939.09
2024-08-07 20:03:47 - [34m[1mLOGS   [0m - Epoch:  18 [  143619/  200000], loss: {'classification': 32.7771, 'neural_augmentation': 0.5707, 'total_loss': 33.3478}, LR: [0.000231, 0.000231], Avg. batch load time: 0.011, Elapsed time: 2062.79
2024-08-07 20:05:51 - [34m[1mLOGS   [0m - Epoch:  18 [  143681/  200000], loss: {'classification': 32.7792, 'neural_augmentation': 0.5709, 'total_loss': 33.3501}, LR: [0.00023, 0.00023], Avg. batch load time: 0.010, Elapsed time: 2186.55
2024-08-07 20:07:55 - [34m[1mLOGS   [0m - Epoch:  18 [  143744/  200000], loss: {'classification': 32.777, 'neural_augmentation': 0.571, 'total_loss': 33.348}, LR: [0.00023, 0.00023], Avg. batch load time: 0.010, Elapsed time: 2310.30
2024-08-07 20:09:59 - [34m[1mLOGS   [0m - Epoch:  18 [  143806/  200000], loss: {'classification': 32.7802, 'neural_augmentation': 0.5712, 'total_loss': 33.3514}, LR: [0.00023, 0.00023], Avg. batch load time: 0.009, Elapsed time: 2434.21
2024-08-07 20:12:03 - [34m[1mLOGS   [0m - Epoch:  18 [  143869/  200000], loss: {'classification': 32.7757, 'neural_augmentation': 0.5713, 'total_loss': 33.3471}, LR: [0.000229, 0.000229], Avg. batch load time: 0.009, Elapsed time: 2558.11
2024-08-07 20:14:07 - [34m[1mLOGS   [0m - Epoch:  18 [  143931/  200000], loss: {'classification': 32.7771, 'neural_augmentation': 0.5715, 'total_loss': 33.3486}, LR: [0.000229, 0.000229], Avg. batch load time: 0.008, Elapsed time: 2681.95
2024-08-07 20:16:10 - [34m[1mLOGS   [0m - Epoch:  18 [  143994/  200000], loss: {'classification': 32.7779, 'neural_augmentation': 0.5716, 'total_loss': 33.3495}, LR: [0.000228, 0.000228], Avg. batch load time: 0.008, Elapsed time: 2805.75
2024-08-07 20:18:14 - [34m[1mLOGS   [0m - Epoch:  18 [  144056/  200000], loss: {'classification': 32.7775, 'neural_augmentation': 0.5717, 'total_loss': 33.3492}, LR: [0.000228, 0.000228], Avg. batch load time: 0.008, Elapsed time: 2929.42
2024-08-07 20:20:18 - [34m[1mLOGS   [0m - Epoch:  18 [  144119/  200000], loss: {'classification': 32.7798, 'neural_augmentation': 0.5718, 'total_loss': 33.3517}, LR: [0.000227, 0.000227], Avg. batch load time: 0.007, Elapsed time: 3053.03
2024-08-07 20:22:26 - [34m[1mLOGS   [0m - Epoch:  18 [  144181/  200000], loss: {'classification': 32.7782, 'neural_augmentation': 0.572, 'total_loss': 33.3501}, LR: [0.000227, 0.000227], Avg. batch load time: 0.007, Elapsed time: 3181.52
2024-08-07 20:24:30 - [34m[1mLOGS   [0m - Epoch:  18 [  144244/  200000], loss: {'classification': 32.7773, 'neural_augmentation': 0.5721, 'total_loss': 33.3493}, LR: [0.000226, 0.000226], Avg. batch load time: 0.007, Elapsed time: 3305.44
2024-08-07 20:26:34 - [34m[1mLOGS   [0m - Epoch:  18 [  144306/  200000], loss: {'classification': 32.778, 'neural_augmentation': 0.5722, 'total_loss': 33.3503}, LR: [0.000226, 0.000226], Avg. batch load time: 0.007, Elapsed time: 3429.34
2024-08-07 20:28:38 - [34m[1mLOGS   [0m - Epoch:  18 [  144369/  200000], loss: {'classification': 32.7778, 'neural_augmentation': 0.5723, 'total_loss': 33.3502}, LR: [0.000226, 0.000226], Avg. batch load time: 0.007, Elapsed time: 3553.16
2024-08-07 20:30:41 - [34m[1mLOGS   [0m - Epoch:  18 [  144431/  200000], loss: {'classification': 32.7774, 'neural_augmentation': 0.5725, 'total_loss': 33.3499}, LR: [0.000225, 0.000225], Avg. batch load time: 0.006, Elapsed time: 3676.81
2024-08-07 20:32:45 - [34m[1mLOGS   [0m - Epoch:  18 [  144494/  200000], loss: {'classification': 32.7751, 'neural_augmentation': 0.5726, 'total_loss': 33.3477}, LR: [0.000225, 0.000225], Avg. batch load time: 0.006, Elapsed time: 3800.51
2024-08-07 20:34:49 - [34m[1mLOGS   [0m - Epoch:  18 [  144556/  200000], loss: {'classification': 32.7763, 'neural_augmentation': 0.5727, 'total_loss': 33.349}, LR: [0.000224, 0.000224], Avg. batch load time: 0.006, Elapsed time: 3924.42
2024-08-07 20:36:53 - [34m[1mLOGS   [0m - Epoch:  18 [  144619/  200000], loss: {'classification': 32.7761, 'neural_augmentation': 0.5728, 'total_loss': 33.3489}, LR: [0.000224, 0.000224], Avg. batch load time: 0.006, Elapsed time: 4048.38
2024-08-07 20:38:57 - [34m[1mLOGS   [0m - Epoch:  18 [  144681/  200000], loss: {'classification': 32.775, 'neural_augmentation': 0.573, 'total_loss': 33.3479}, LR: [0.000223, 0.000223], Avg. batch load time: 0.006, Elapsed time: 4172.53
2024-08-07 20:41:01 - [34m[1mLOGS   [0m - Epoch:  18 [  144744/  200000], loss: {'classification': 32.7736, 'neural_augmentation': 0.5731, 'total_loss': 33.3467}, LR: [0.000223, 0.000223], Avg. batch load time: 0.006, Elapsed time: 4296.27
2024-08-07 20:43:05 - [34m[1mLOGS   [0m - Epoch:  18 [  144806/  200000], loss: {'classification': 32.7737, 'neural_augmentation': 0.5732, 'total_loss': 33.347}, LR: [0.000222, 0.000222], Avg. batch load time: 0.005, Elapsed time: 4420.04
2024-08-07 20:45:08 - [34m[1mLOGS   [0m - Epoch:  18 [  144869/  200000], loss: {'classification': 32.7722, 'neural_augmentation': 0.5734, 'total_loss': 33.3456}, LR: [0.000222, 0.000222], Avg. batch load time: 0.005, Elapsed time: 4543.71
2024-08-07 20:47:17 - [34m[1mLOGS   [0m - Epoch:  18 [  144931/  200000], loss: {'classification': 32.7718, 'neural_augmentation': 0.5735, 'total_loss': 33.3453}, LR: [0.000222, 0.000222], Avg. batch load time: 0.005, Elapsed time: 4672.21
2024-08-07 20:49:20 - [34m[1mLOGS   [0m - Epoch:  18 [  144994/  200000], loss: {'classification': 32.7708, 'neural_augmentation': 0.5736, 'total_loss': 33.3445}, LR: [0.000221, 0.000221], Avg. batch load time: 0.005, Elapsed time: 4795.67
2024-08-07 20:51:24 - [34m[1mLOGS   [0m - Epoch:  18 [  145056/  200000], loss: {'classification': 32.7698, 'neural_augmentation': 0.5737, 'total_loss': 33.3435}, LR: [0.000221, 0.000221], Avg. batch load time: 0.005, Elapsed time: 4919.11
2024-08-07 20:53:28 - [34m[1mLOGS   [0m - Epoch:  18 [  145119/  200000], loss: {'classification': 32.7716, 'neural_augmentation': 0.5739, 'total_loss': 33.3455}, LR: [0.00022, 0.00022], Avg. batch load time: 0.005, Elapsed time: 5043.08
2024-08-07 20:55:31 - [34m[1mLOGS   [0m - Epoch:  18 [  145181/  200000], loss: {'classification': 32.7694, 'neural_augmentation': 0.574, 'total_loss': 33.3435}, LR: [0.00022, 0.00022], Avg. batch load time: 0.005, Elapsed time: 5166.80
2024-08-07 20:57:35 - [34m[1mLOGS   [0m - Epoch:  18 [  145244/  200000], loss: {'classification': 32.7678, 'neural_augmentation': 0.5741, 'total_loss': 33.342}, LR: [0.000219, 0.000219], Avg. batch load time: 0.005, Elapsed time: 5290.59
2024-08-07 20:59:39 - [34m[1mLOGS   [0m - Epoch:  18 [  145306/  200000], loss: {'classification': 32.7677, 'neural_augmentation': 0.5743, 'total_loss': 33.3419}, LR: [0.000219, 0.000219], Avg. batch load time: 0.005, Elapsed time: 5414.49
2024-08-07 21:01:43 - [34m[1mLOGS   [0m - Epoch:  18 [  145369/  200000], loss: {'classification': 32.7667, 'neural_augmentation': 0.5744, 'total_loss': 33.3411}, LR: [0.000218, 0.000218], Avg. batch load time: 0.005, Elapsed time: 5538.23
2024-08-07 21:03:47 - [34m[1mLOGS   [0m - Epoch:  18 [  145431/  200000], loss: {'classification': 32.7644, 'neural_augmentation': 0.5745, 'total_loss': 33.3389}, LR: [0.000218, 0.000218], Avg. batch load time: 0.004, Elapsed time: 5661.91
2024-08-07 21:05:50 - [34m[1mLOGS   [0m - Epoch:  18 [  145494/  200000], loss: {'classification': 32.7631, 'neural_augmentation': 0.5747, 'total_loss': 33.3378}, LR: [0.000218, 0.000218], Avg. batch load time: 0.004, Elapsed time: 5785.56
2024-08-07 21:07:54 - [34m[1mLOGS   [0m - Epoch:  18 [  145556/  200000], loss: {'classification': 32.7615, 'neural_augmentation': 0.5748, 'total_loss': 33.3362}, LR: [0.000217, 0.000217], Avg. batch load time: 0.004, Elapsed time: 5909.23
2024-08-07 21:09:58 - [34m[1mLOGS   [0m - Epoch:  18 [  145619/  200000], loss: {'classification': 32.76, 'neural_augmentation': 0.5749, 'total_loss': 33.3349}, LR: [0.000217, 0.000217], Avg. batch load time: 0.004, Elapsed time: 6032.97
2024-08-07 21:12:01 - [34m[1mLOGS   [0m - Epoch:  18 [  145681/  200000], loss: {'classification': 32.7599, 'neural_augmentation': 0.575, 'total_loss': 33.335}, LR: [0.000216, 0.000216], Avg. batch load time: 0.004, Elapsed time: 6156.46
2024-08-07 21:14:10 - [34m[1mLOGS   [0m - Epoch:  18 [  145744/  200000], loss: {'classification': 32.7587, 'neural_augmentation': 0.5751, 'total_loss': 33.3339}, LR: [0.000216, 0.000216], Avg. batch load time: 0.004, Elapsed time: 6285.34
2024-08-07 21:16:14 - [34m[1mLOGS   [0m - Epoch:  18 [  145806/  200000], loss: {'classification': 32.7578, 'neural_augmentation': 0.5753, 'total_loss': 33.3331}, LR: [0.000215, 0.000215], Avg. batch load time: 0.004, Elapsed time: 6409.07
2024-08-07 21:18:17 - [34m[1mLOGS   [0m - Epoch:  18 [  145869/  200000], loss: {'classification': 32.7583, 'neural_augmentation': 0.5754, 'total_loss': 33.3337}, LR: [0.000215, 0.000215], Avg. batch load time: 0.004, Elapsed time: 6532.81
2024-08-07 21:20:21 - [34m[1mLOGS   [0m - Epoch:  18 [  145931/  200000], loss: {'classification': 32.7566, 'neural_augmentation': 0.5755, 'total_loss': 33.3321}, LR: [0.000215, 0.000215], Avg. batch load time: 0.004, Elapsed time: 6656.69
2024-08-07 21:22:26 - [34m[1mLOGS   [0m - Epoch:  18 [  145994/  200000], loss: {'classification': 32.7547, 'neural_augmentation': 0.5756, 'total_loss': 33.3304}, LR: [0.000214, 0.000214], Avg. batch load time: 0.004, Elapsed time: 6780.89
2024-08-07 21:24:29 - [34m[1mLOGS   [0m - Epoch:  18 [  146056/  200000], loss: {'classification': 32.7537, 'neural_augmentation': 0.5758, 'total_loss': 33.3294}, LR: [0.000214, 0.000214], Avg. batch load time: 0.004, Elapsed time: 6904.36
2024-08-07 21:26:33 - [34m[1mLOGS   [0m - Epoch:  18 [  146119/  200000], loss: {'classification': 32.752, 'neural_augmentation': 0.5759, 'total_loss': 33.3279}, LR: [0.000213, 0.000213], Avg. batch load time: 0.004, Elapsed time: 7028.42
2024-08-07 21:28:37 - [34m[1mLOGS   [0m - Epoch:  18 [  146181/  200000], loss: {'classification': 32.7511, 'neural_augmentation': 0.576, 'total_loss': 33.3271}, LR: [0.000213, 0.000213], Avg. batch load time: 0.004, Elapsed time: 7152.33
2024-08-07 21:30:41 - [34m[1mLOGS   [0m - Epoch:  18 [  146244/  200000], loss: {'classification': 32.7495, 'neural_augmentation': 0.5761, 'total_loss': 33.3256}, LR: [0.000212, 0.000212], Avg. batch load time: 0.004, Elapsed time: 7276.01
2024-08-07 21:32:44 - [34m[1mLOGS   [0m - Epoch:  18 [  146306/  200000], loss: {'classification': 32.7479, 'neural_augmentation': 0.5763, 'total_loss': 33.3241}, LR: [0.000212, 0.000212], Avg. batch load time: 0.004, Elapsed time: 7399.70
2024-08-07 21:34:48 - [34m[1mLOGS   [0m - Epoch:  18 [  146369/  200000], loss: {'classification': 32.7472, 'neural_augmentation': 0.5764, 'total_loss': 33.3236}, LR: [0.000211, 0.000211], Avg. batch load time: 0.004, Elapsed time: 7523.55
2024-08-07 21:36:52 - [34m[1mLOGS   [0m - Epoch:  18 [  146431/  200000], loss: {'classification': 32.7464, 'neural_augmentation': 0.5765, 'total_loss': 33.323}, LR: [0.000211, 0.000211], Avg. batch load time: 0.004, Elapsed time: 7647.30
2024-08-07 21:39:02 - [34m[1mLOGS   [0m - Epoch:  18 [  146494/  200000], loss: {'classification': 32.7457, 'neural_augmentation': 0.5766, 'total_loss': 33.3224}, LR: [0.000211, 0.000211], Avg. batch load time: 0.004, Elapsed time: 7777.65
2024-08-07 21:41:06 - [34m[1mLOGS   [0m - Epoch:  18 [  146556/  200000], loss: {'classification': 32.7459, 'neural_augmentation': 0.5768, 'total_loss': 33.3226}, LR: [0.00021, 0.00021], Avg. batch load time: 0.003, Elapsed time: 7901.31
2024-08-07 21:43:10 - [34m[1mLOGS   [0m - Epoch:  18 [  146619/  200000], loss: {'classification': 32.7449, 'neural_augmentation': 0.5769, 'total_loss': 33.3218}, LR: [0.00021, 0.00021], Avg. batch load time: 0.003, Elapsed time: 8025.16
2024-08-07 21:45:14 - [34m[1mLOGS   [0m - Epoch:  18 [  146681/  200000], loss: {'classification': 32.7441, 'neural_augmentation': 0.577, 'total_loss': 33.3211}, LR: [0.000209, 0.000209], Avg. batch load time: 0.003, Elapsed time: 8149.19
2024-08-07 21:47:18 - [34m[1mLOGS   [0m - Epoch:  18 [  146744/  200000], loss: {'classification': 32.7416, 'neural_augmentation': 0.5771, 'total_loss': 33.3187}, LR: [0.000209, 0.000209], Avg. batch load time: 0.003, Elapsed time: 8273.38
2024-08-07 21:49:22 - [34m[1mLOGS   [0m - Epoch:  18 [  146806/  200000], loss: {'classification': 32.7393, 'neural_augmentation': 0.5773, 'total_loss': 33.3166}, LR: [0.000208, 0.000208], Avg. batch load time: 0.003, Elapsed time: 8397.46
2024-08-07 21:51:26 - [34m[1mLOGS   [0m - Epoch:  18 [  146869/  200000], loss: {'classification': 32.7378, 'neural_augmentation': 0.5774, 'total_loss': 33.3152}, LR: [0.000208, 0.000208], Avg. batch load time: 0.003, Elapsed time: 8521.51
2024-08-07 21:53:30 - [34m[1mLOGS   [0m - Epoch:  18 [  146931/  200000], loss: {'classification': 32.7375, 'neural_augmentation': 0.5775, 'total_loss': 33.315}, LR: [0.000208, 0.000208], Avg. batch load time: 0.003, Elapsed time: 8645.49
2024-08-07 21:55:34 - [34m[1mLOGS   [0m - Epoch:  18 [  146994/  200000], loss: {'classification': 32.7351, 'neural_augmentation': 0.5776, 'total_loss': 33.3128}, LR: [0.000207, 0.000207], Avg. batch load time: 0.003, Elapsed time: 8769.21
2024-08-07 21:57:38 - [34m[1mLOGS   [0m - Epoch:  18 [  147056/  200000], loss: {'classification': 32.7354, 'neural_augmentation': 0.5778, 'total_loss': 33.3131}, LR: [0.000207, 0.000207], Avg. batch load time: 0.003, Elapsed time: 8893.31
2024-08-07 21:59:42 - [34m[1mLOGS   [0m - Epoch:  18 [  147119/  200000], loss: {'classification': 32.7347, 'neural_augmentation': 0.5779, 'total_loss': 33.3125}, LR: [0.000206, 0.000206], Avg. batch load time: 0.003, Elapsed time: 9017.18
2024-08-07 22:01:46 - [34m[1mLOGS   [0m - Epoch:  18 [  147181/  200000], loss: {'classification': 32.7345, 'neural_augmentation': 0.578, 'total_loss': 33.3125}, LR: [0.000206, 0.000206], Avg. batch load time: 0.003, Elapsed time: 9141.28
2024-08-07 22:03:55 - [34m[1mLOGS   [0m - Epoch:  18 [  147244/  200000], loss: {'classification': 32.7334, 'neural_augmentation': 0.5781, 'total_loss': 33.3115}, LR: [0.000205, 0.000205], Avg. batch load time: 0.003, Elapsed time: 9270.01
2024-08-07 22:05:59 - [34m[1mLOGS   [0m - Epoch:  18 [  147306/  200000], loss: {'classification': 32.7343, 'neural_augmentation': 0.5782, 'total_loss': 33.3126}, LR: [0.000205, 0.000205], Avg. batch load time: 0.003, Elapsed time: 9394.18
2024-08-07 22:08:03 - [34m[1mLOGS   [0m - Epoch:  18 [  147369/  200000], loss: {'classification': 32.7336, 'neural_augmentation': 0.5784, 'total_loss': 33.3119}, LR: [0.000205, 0.000205], Avg. batch load time: 0.003, Elapsed time: 9517.84
2024-08-07 22:10:06 - [34m[1mLOGS   [0m - Epoch:  18 [  147431/  200000], loss: {'classification': 32.7324, 'neural_augmentation': 0.5785, 'total_loss': 33.3109}, LR: [0.000204, 0.000204], Avg. batch load time: 0.003, Elapsed time: 9641.71
2024-08-07 22:12:10 - [34m[1mLOGS   [0m - Epoch:  18 [  147494/  200000], loss: {'classification': 32.7314, 'neural_augmentation': 0.5786, 'total_loss': 33.31}, LR: [0.000204, 0.000204], Avg. batch load time: 0.003, Elapsed time: 9765.46
2024-08-07 22:14:14 - [34m[1mLOGS   [0m - Epoch:  18 [  147556/  200000], loss: {'classification': 32.7313, 'neural_augmentation': 0.5787, 'total_loss': 33.31}, LR: [0.000203, 0.000203], Avg. batch load time: 0.003, Elapsed time: 9889.28
2024-08-07 22:16:18 - [34m[1mLOGS   [0m - Epoch:  18 [  147619/  200000], loss: {'classification': 32.7301, 'neural_augmentation': 0.5788, 'total_loss': 33.309}, LR: [0.000203, 0.000203], Avg. batch load time: 0.003, Elapsed time: 10012.94
2024-08-07 22:18:21 - [34m[1mLOGS   [0m - Epoch:  18 [  147681/  200000], loss: {'classification': 32.7293, 'neural_augmentation': 0.579, 'total_loss': 33.3082}, LR: [0.000202, 0.000202], Avg. batch load time: 0.003, Elapsed time: 10136.73
2024-08-07 22:20:25 - [34m[1mLOGS   [0m - Epoch:  18 [  147744/  200000], loss: {'classification': 32.7295, 'neural_augmentation': 0.5791, 'total_loss': 33.3086}, LR: [0.000202, 0.000202], Avg. batch load time: 0.003, Elapsed time: 10260.69
2024-08-07 22:22:29 - [34m[1mLOGS   [0m - Epoch:  18 [  147806/  200000], loss: {'classification': 32.7285, 'neural_augmentation': 0.5792, 'total_loss': 33.3078}, LR: [0.000202, 0.000202], Avg. batch load time: 0.003, Elapsed time: 10384.42
2024-08-07 22:24:33 - [34m[1mLOGS   [0m - Epoch:  18 [  147869/  200000], loss: {'classification': 32.7277, 'neural_augmentation': 0.5793, 'total_loss': 33.307}, LR: [0.000201, 0.000201], Avg. batch load time: 0.003, Elapsed time: 10508.11
2024-08-07 22:26:36 - [34m[1mLOGS   [0m - Epoch:  18 [  147931/  200000], loss: {'classification': 32.7253, 'neural_augmentation': 0.5795, 'total_loss': 33.3048}, LR: [0.000201, 0.000201], Avg. batch load time: 0.003, Elapsed time: 10631.75
2024-08-07 22:28:40 - [34m[1mLOGS   [0m - Epoch:  18 [  147994/  200000], loss: {'classification': 32.7242, 'neural_augmentation': 0.5796, 'total_loss': 33.3038}, LR: [0.0002, 0.0002], Avg. batch load time: 0.003, Elapsed time: 10755.64
2024-08-07 22:30:49 - [34m[1mLOGS   [0m - Epoch:  18 [  148056/  200000], loss: {'classification': 32.7233, 'neural_augmentation': 0.5797, 'total_loss': 33.303}, LR: [0.0002, 0.0002], Avg. batch load time: 0.003, Elapsed time: 10884.44
2024-08-07 22:32:53 - [34m[1mLOGS   [0m - Epoch:  18 [  148119/  200000], loss: {'classification': 32.7231, 'neural_augmentation': 0.5798, 'total_loss': 33.3029}, LR: [0.000199, 0.000199], Avg. batch load time: 0.003, Elapsed time: 11008.17
2024-08-07 22:34:57 - [34m[1mLOGS   [0m - Epoch:  18 [  148181/  200000], loss: {'classification': 32.7233, 'neural_augmentation': 0.5799, 'total_loss': 33.3033}, LR: [0.000199, 0.000199], Avg. batch load time: 0.003, Elapsed time: 11132.07
2024-08-07 22:37:00 - [34m[1mLOGS   [0m - Epoch:  18 [  148244/  200000], loss: {'classification': 32.7229, 'neural_augmentation': 0.5801, 'total_loss': 33.303}, LR: [0.000199, 0.000199], Avg. batch load time: 0.003, Elapsed time: 11255.76
2024-08-07 22:39:04 - [34m[1mLOGS   [0m - Epoch:  18 [  148306/  200000], loss: {'classification': 32.7224, 'neural_augmentation': 0.5802, 'total_loss': 33.3026}, LR: [0.000198, 0.000198], Avg. batch load time: 0.003, Elapsed time: 11379.60
2024-08-07 22:41:08 - [34m[1mLOGS   [0m - Epoch:  18 [  148369/  200000], loss: {'classification': 32.7217, 'neural_augmentation': 0.5803, 'total_loss': 33.302}, LR: [0.000198, 0.000198], Avg. batch load time: 0.003, Elapsed time: 11503.31
2024-08-07 22:43:12 - [34m[1mLOGS   [0m - Epoch:  18 [  148431/  200000], loss: {'classification': 32.7205, 'neural_augmentation': 0.5804, 'total_loss': 33.3009}, LR: [0.000197, 0.000197], Avg. batch load time: 0.003, Elapsed time: 11627.19
2024-08-07 22:45:16 - [34m[1mLOGS   [0m - Epoch:  18 [  148494/  200000], loss: {'classification': 32.7192, 'neural_augmentation': 0.5806, 'total_loss': 33.2998}, LR: [0.000197, 0.000197], Avg. batch load time: 0.003, Elapsed time: 11750.85
2024-08-07 22:47:19 - [34m[1mLOGS   [0m - Epoch:  18 [  148556/  200000], loss: {'classification': 32.7195, 'neural_augmentation': 0.5807, 'total_loss': 33.3002}, LR: [0.000196, 0.000196], Avg. batch load time: 0.003, Elapsed time: 11874.75
2024-08-07 22:49:23 - [34m[1mLOGS   [0m - Epoch:  18 [  148619/  200000], loss: {'classification': 32.7183, 'neural_augmentation': 0.5808, 'total_loss': 33.2992}, LR: [0.000196, 0.000196], Avg. batch load time: 0.003, Elapsed time: 11998.64
2024-08-07 22:51:27 - [34m[1mLOGS   [0m - Epoch:  18 [  148681/  200000], loss: {'classification': 32.7175, 'neural_augmentation': 0.5809, 'total_loss': 33.2984}, LR: [0.000196, 0.000196], Avg. batch load time: 0.003, Elapsed time: 12122.28
2024-08-07 22:53:31 - [34m[1mLOGS   [0m - Epoch:  18 [  148744/  200000], loss: {'classification': 32.717, 'neural_augmentation': 0.5811, 'total_loss': 33.2981}, LR: [0.000195, 0.000195], Avg. batch load time: 0.003, Elapsed time: 12246.44
2024-08-07 22:55:41 - [34m[1mLOGS   [0m - Epoch:  18 [  148806/  200000], loss: {'classification': 32.7158, 'neural_augmentation': 0.5812, 'total_loss': 33.2969}, LR: [0.000195, 0.000195], Avg. batch load time: 0.003, Elapsed time: 12376.41
2024-08-07 22:57:45 - [34m[1mLOGS   [0m - Epoch:  18 [  148869/  200000], loss: {'classification': 32.7144, 'neural_augmentation': 0.5813, 'total_loss': 33.2957}, LR: [0.000194, 0.000194], Avg. batch load time: 0.003, Elapsed time: 12500.31
2024-08-07 22:59:49 - [34m[1mLOGS   [0m - Epoch:  18 [  148931/  200000], loss: {'classification': 32.7143, 'neural_augmentation': 0.5814, 'total_loss': 33.2957}, LR: [0.000194, 0.000194], Avg. batch load time: 0.003, Elapsed time: 12624.15
2024-08-07 23:01:53 - [34m[1mLOGS   [0m - Epoch:  18 [  148994/  200000], loss: {'classification': 32.7137, 'neural_augmentation': 0.5815, 'total_loss': 33.2952}, LR: [0.000194, 0.000194], Avg. batch load time: 0.003, Elapsed time: 12747.84
2024-08-07 23:03:56 - [34m[1mLOGS   [0m - Epoch:  18 [  149056/  200000], loss: {'classification': 32.7124, 'neural_augmentation': 0.5817, 'total_loss': 33.2941}, LR: [0.000193, 0.000193], Avg. batch load time: 0.003, Elapsed time: 12871.51
2024-08-07 23:06:00 - [34m[1mLOGS   [0m - Epoch:  18 [  149119/  200000], loss: {'classification': 32.7119, 'neural_augmentation': 0.5818, 'total_loss': 33.2937}, LR: [0.000193, 0.000193], Avg. batch load time: 0.003, Elapsed time: 12995.30
2024-08-07 23:08:04 - [34m[1mLOGS   [0m - Epoch:  18 [  149181/  200000], loss: {'classification': 32.7121, 'neural_augmentation': 0.5819, 'total_loss': 33.294}, LR: [0.000192, 0.000192], Avg. batch load time: 0.002, Elapsed time: 13119.30
2024-08-07 23:10:08 - [34m[1mLOGS   [0m - Epoch:  18 [  149244/  200000], loss: {'classification': 32.7122, 'neural_augmentation': 0.582, 'total_loss': 33.2942}, LR: [0.000192, 0.000192], Avg. batch load time: 0.002, Elapsed time: 13243.39
2024-08-07 23:12:12 - [34m[1mLOGS   [0m - Epoch:  18 [  149306/  200000], loss: {'classification': 32.7102, 'neural_augmentation': 0.5822, 'total_loss': 33.2923}, LR: [0.000191, 0.000191], Avg. batch load time: 0.002, Elapsed time: 13367.24
2024-08-07 23:14:16 - [34m[1mLOGS   [0m - Epoch:  18 [  149369/  200000], loss: {'classification': 32.709, 'neural_augmentation': 0.5823, 'total_loss': 33.2912}, LR: [0.000191, 0.000191], Avg. batch load time: 0.002, Elapsed time: 13491.05
2024-08-07 23:16:19 - [34m[1mLOGS   [0m - Epoch:  18 [  149431/  200000], loss: {'classification': 32.7073, 'neural_augmentation': 0.5824, 'total_loss': 33.2897}, LR: [0.000191, 0.000191], Avg. batch load time: 0.002, Elapsed time: 13614.55
2024-08-07 23:18:23 - [34m[1mLOGS   [0m - Epoch:  18 [  149494/  200000], loss: {'classification': 32.7064, 'neural_augmentation': 0.5825, 'total_loss': 33.2889}, LR: [0.00019, 0.00019], Avg. batch load time: 0.002, Elapsed time: 13737.94
2024-08-07 23:20:33 - [34m[1mLOGS   [0m - Epoch:  18 [  149556/  200000], loss: {'classification': 32.705, 'neural_augmentation': 0.5826, 'total_loss': 33.2876}, LR: [0.00019, 0.00019], Avg. batch load time: 0.002, Elapsed time: 13868.20
2024-08-07 23:22:37 - [34m[1mLOGS   [0m - Epoch:  18 [  149619/  200000], loss: {'classification': 32.7031, 'neural_augmentation': 0.5827, 'total_loss': 33.2858}, LR: [0.000189, 0.000189], Avg. batch load time: 0.002, Elapsed time: 13991.91
2024-08-07 23:24:41 - [34m[1mLOGS   [0m - Epoch:  18 [  149681/  200000], loss: {'classification': 32.7017, 'neural_augmentation': 0.5828, 'total_loss': 33.2845}, LR: [0.000189, 0.000189], Avg. batch load time: 0.002, Elapsed time: 14115.92
2024-08-07 23:26:45 - [34m[1mLOGS   [0m - Epoch:  18 [  149744/  200000], loss: {'classification': 32.7004, 'neural_augmentation': 0.583, 'total_loss': 33.2834}, LR: [0.000189, 0.000189], Avg. batch load time: 0.002, Elapsed time: 14239.88
2024-08-07 23:28:48 - [34m[1mLOGS   [0m - Epoch:  18 [  149806/  200000], loss: {'classification': 32.6991, 'neural_augmentation': 0.5831, 'total_loss': 33.2822}, LR: [0.000188, 0.000188], Avg. batch load time: 0.002, Elapsed time: 14363.79
2024-08-07 23:30:52 - [34m[1mLOGS   [0m - Epoch:  18 [  149869/  200000], loss: {'classification': 32.6979, 'neural_augmentation': 0.5832, 'total_loss': 33.2811}, LR: [0.000188, 0.000188], Avg. batch load time: 0.002, Elapsed time: 14487.59
2024-08-07 23:32:56 - [34m[1mLOGS   [0m - Epoch:  18 [  149931/  200000], loss: {'classification': 32.6966, 'neural_augmentation': 0.5833, 'total_loss': 33.2799}, LR: [0.000187, 0.000187], Avg. batch load time: 0.002, Elapsed time: 14611.43
2024-08-07 23:35:00 - [34m[1mLOGS   [0m - Epoch:  18 [  149994/  200000], loss: {'classification': 32.6951, 'neural_augmentation': 0.5834, 'total_loss': 33.2785}, LR: [0.000187, 0.000187], Avg. batch load time: 0.002, Elapsed time: 14734.95
2024-08-07 23:37:03 - [34m[1mLOGS   [0m - Epoch:  18 [  150056/  200000], loss: {'classification': 32.6935, 'neural_augmentation': 0.5836, 'total_loss': 33.2771}, LR: [0.000186, 0.000186], Avg. batch load time: 0.002, Elapsed time: 14858.67
2024-08-07 23:39:07 - [34m[1mLOGS   [0m - Epoch:  18 [  150119/  200000], loss: {'classification': 32.6926, 'neural_augmentation': 0.5837, 'total_loss': 33.2763}, LR: [0.000186, 0.000186], Avg. batch load time: 0.002, Elapsed time: 14982.63
2024-08-07 23:41:11 - [34m[1mLOGS   [0m - Epoch:  18 [  150181/  200000], loss: {'classification': 32.6919, 'neural_augmentation': 0.5838, 'total_loss': 33.2757}, LR: [0.000186, 0.000186], Avg. batch load time: 0.002, Elapsed time: 15106.45
2024-08-07 23:43:15 - [34m[1mLOGS   [0m - Epoch:  18 [  150244/  200000], loss: {'classification': 32.6904, 'neural_augmentation': 0.5839, 'total_loss': 33.2743}, LR: [0.000185, 0.000185], Avg. batch load time: 0.002, Elapsed time: 15230.24
2024-08-07 23:45:22 - [34m[1mLOGS   [0m - Epoch:  18 [  150306/  200000], loss: {'classification': 32.6891, 'neural_augmentation': 0.584, 'total_loss': 33.2731}, LR: [0.000185, 0.000185], Avg. batch load time: 0.002, Elapsed time: 15357.40
2024-08-07 23:47:31 - [34m[1mLOGS   [0m - Epoch:  18 [  150369/  200000], loss: {'classification': 32.6882, 'neural_augmentation': 0.5841, 'total_loss': 33.2724}, LR: [0.000184, 0.000184], Avg. batch load time: 0.002, Elapsed time: 15486.55
2024-08-07 23:49:35 - [34m[1mLOGS   [0m - Epoch:  18 [  150431/  200000], loss: {'classification': 32.6871, 'neural_augmentation': 0.5843, 'total_loss': 33.2713}, LR: [0.000184, 0.000184], Avg. batch load time: 0.002, Elapsed time: 15610.33
2024-08-07 23:51:39 - [34m[1mLOGS   [0m - Epoch:  18 [  150494/  200000], loss: {'classification': 32.6864, 'neural_augmentation': 0.5844, 'total_loss': 33.2707}, LR: [0.000184, 0.000184], Avg. batch load time: 0.002, Elapsed time: 15734.04
2024-08-07 23:53:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 32.6852, 'neural_augmentation': 0.5845, 'total_loss': 33.2697}
2024-08-07 23:53:34 - [34m[1mLOGS   [0m - Best checkpoint with score 0.00 saved at /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_best.pt
2024-08-07 23:53:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_last.pt
2024-08-07 23:53:36 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_last.pt
2024-08-07 23:53:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 150550 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/training_checkpoint_epoch_18_iter_150550.pt
2024-08-07 23:53:38 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 150550 is saved at: /ML-A100/team/mm/models/catlip_data/results_base_noc/train/checkpoint_epoch_18_iter_150550.pt
[31m===========================================================================[0m
2024-08-07 23:53:40 - [32m[1mINFO   [0m - Training epoch 19
2024-08-07 23:54:54 - [34m[1mLOGS   [0m - Epoch:  19 [  150550/  200000], loss: {'classification': 33.1531, 'neural_augmentation': 0.6132, 'total_loss': 33.7663}, LR: [0.000183, 0.000183], Avg. batch load time: 74.127, Elapsed time: 74.37
2024-08-07 23:57:00 - [34m[1mLOGS   [0m - Epoch:  19 [  150612/  200000], loss: {'classification': 32.4808, 'neural_augmentation': 0.5997, 'total_loss': 33.0805}, LR: [0.000183, 0.000183], Avg. batch load time: 0.153, Elapsed time: 199.89
2024-08-07 23:59:04 - [34m[1mLOGS   [0m - Epoch:  19 [  150675/  200000], loss: {'classification': 32.5048, 'neural_augmentation': 0.5999, 'total_loss': 33.1047}, LR: [0.000182, 0.000182], Avg. batch load time: 0.077, Elapsed time: 323.92
2024-08-08 00:01:07 - [34m[1mLOGS   [0m - Epoch:  19 [  150737/  200000], loss: {'classification': 32.4607, 'neural_augmentation': 0.6, 'total_loss': 33.0607}, LR: [0.000182, 0.000182], Avg. batch load time: 0.052, Elapsed time: 447.55
2024-08-08 00:03:11 - [34m[1mLOGS   [0m - Epoch:  19 [  150800/  200000], loss: {'classification': 32.4641, 'neural_augmentation': 0.6001, 'total_loss': 33.0642}, LR: [0.000182, 0.000182], Avg. batch load time: 0.039, Elapsed time: 571.57
2024-08-08 00:05:15 - [34m[1mLOGS   [0m - Epoch:  19 [  150862/  200000], loss: {'classification': 32.4555, 'neural_augmentation': 0.6003, 'total_loss': 33.0558}, LR: [0.000181, 0.000181], Avg. batch load time: 0.031, Elapsed time: 695.30
2024-08-08 00:07:19 - [34m[1mLOGS   [0m - Epoch:  19 [  150925/  200000], loss: {'classification': 32.4659, 'neural_augmentation': 0.6004, 'total_loss': 33.0662}, LR: [0.000181, 0.000181], Avg. batch load time: 0.026, Elapsed time: 818.93
2024-08-08 00:09:23 - [34m[1mLOGS   [0m - Epoch:  19 [  150987/  200000], loss: {'classification': 32.4651, 'neural_augmentation': 0.6005, 'total_loss': 33.0656}, LR: [0.00018, 0.00018], Avg. batch load time: 0.023, Elapsed time: 942.89
2024-08-08 00:11:27 - [34m[1mLOGS   [0m - Epoch:  19 [  151050/  200000], loss: {'classification': 32.4741, 'neural_augmentation': 0.6006, 'total_loss': 33.0747}, LR: [0.00018, 0.00018], Avg. batch load time: 0.020, Elapsed time: 1066.76
2024-08-08 00:13:30 - [34m[1mLOGS   [0m - Epoch:  19 [  151112/  200000], loss: {'classification': 32.471, 'neural_augmentation': 0.6008, 'total_loss': 33.0718}, LR: [0.00018, 0.00018], Avg. batch load time: 0.018, Elapsed time: 1190.65
2024-08-08 00:15:34 - [34m[1mLOGS   [0m - Epoch:  19 [  151175/  200000], loss: {'classification': 32.4676, 'neural_augmentation': 0.6009, 'total_loss': 33.0684}, LR: [0.000179, 0.000179], Avg. batch load time: 0.016, Elapsed time: 1314.66
2024-08-08 00:17:38 - [34m[1mLOGS   [0m - Epoch:  19 [  151237/  200000], loss: {'classification': 32.4708, 'neural_augmentation': 0.601, 'total_loss': 33.0718}, LR: [0.000179, 0.000179], Avg. batch load time: 0.015, Elapsed time: 1438.68
2024-08-08 00:19:46 - [34m[1mLOGS   [0m - Epoch:  19 [  151300/  200000], loss: {'classification': 32.4669, 'neural_augmentation': 0.6012, 'total_loss': 33.068}, LR: [0.000178, 0.000178], Avg. batch load time: 0.014, Elapsed time: 1565.87
2024-08-08 00:21:53 - [34m[1mLOGS   [0m - Epoch:  19 [  151362/  200000], loss: {'classification': 32.4679, 'neural_augmentation': 0.6013, 'total_loss': 33.0692}, LR: [0.000178, 0.000178], Avg. batch load time: 0.013, Elapsed time: 1692.89
2024-08-08 00:23:56 - [34m[1mLOGS   [0m - Epoch:  19 [  151425/  200000], loss: {'classification': 32.4761, 'neural_augmentation': 0.6014, 'total_loss': 33.0775}, LR: [0.000177, 0.000177], Avg. batch load time: 0.012, Elapsed time: 1816.46
2024-08-08 00:26:00 - [34m[1mLOGS   [0m - Epoch:  19 [  151487/  200000], loss: {'classification': 32.4763, 'neural_augmentation': 0.6015, 'total_loss': 33.0778}, LR: [0.000177, 0.000177], Avg. batch load time: 0.011, Elapsed time: 1940.11
2024-08-08 00:28:04 - [34m[1mLOGS   [0m - Epoch:  19 [  151550/  200000], loss: {'classification': 32.4771, 'neural_augmentation': 0.6016, 'total_loss': 33.0787}, LR: [0.000177, 0.000177], Avg. batch load time: 0.010, Elapsed time: 2063.84
2024-08-08 00:30:08 - [34m[1mLOGS   [0m - Epoch:  19 [  151612/  200000], loss: {'classification': 32.4779, 'neural_augmentation': 0.6016, 'total_loss': 33.0796}, LR: [0.000176, 0.000176], Avg. batch load time: 0.010, Elapsed time: 2187.80
2024-08-08 00:32:12 - [34m[1mLOGS   [0m - Epoch:  19 [  151675/  200000], loss: {'classification': 32.4783, 'neural_augmentation': 0.6018, 'total_loss': 33.08}, LR: [0.000176, 0.000176], Avg. batch load time: 0.009, Elapsed time: 2311.72
2024-08-08 00:34:16 - [34m[1mLOGS   [0m - Epoch:  19 [  151737/  200000], loss: {'classification': 32.4804, 'neural_augmentation': 0.6019, 'total_loss': 33.0823}, LR: [0.000175, 0.000175], Avg. batch load time: 0.009, Elapsed time: 2435.81
2024-08-08 00:36:19 - [34m[1mLOGS   [0m - Epoch:  19 [  151800/  200000], loss: {'classification': 32.4756, 'neural_augmentation': 0.602, 'total_loss': 33.0776}, LR: [0.000175, 0.000175], Avg. batch load time: 0.009, Elapsed time: 2559.69
2024-08-08 00:38:23 - [34m[1mLOGS   [0m - Epoch:  19 [  151862/  200000], loss: {'classification': 32.4782, 'neural_augmentation': 0.6021, 'total_loss': 33.0803}, LR: [0.000175, 0.000175], Avg. batch load time: 0.008, Elapsed time: 2683.56
2024-08-08 00:40:27 - [34m[1mLOGS   [0m - Epoch:  19 [  151925/  200000], loss: {'classification': 32.4796, 'neural_augmentation': 0.6022, 'total_loss': 33.0818}, LR: [0.000174, 0.000174], Avg. batch load time: 0.008, Elapsed time: 2807.40
2024-08-08 00:42:31 - [34m[1mLOGS   [0m - Epoch:  19 [  151987/  200000], loss: {'classification': 32.479, 'neural_augmentation': 0.6023, 'total_loss': 33.0813}, LR: [0.000174, 0.000174], Avg. batch load time: 0.008, Elapsed time: 2930.92
2024-08-08 00:44:34 - [34m[1mLOGS   [0m - Epoch:  19 [  152050/  200000], loss: {'classification': 32.4789, 'neural_augmentation': 0.6025, 'total_loss': 33.0814}, LR: [0.000173, 0.000173], Avg. batch load time: 0.007, Elapsed time: 3054.70
2024-08-08 00:46:47 - [34m[1mLOGS   [0m - Epoch:  19 [  152112/  200000], loss: {'classification': 32.4743, 'neural_augmentation': 0.6026, 'total_loss': 33.0769}, LR: [0.000173, 0.000173], Avg. batch load time: 0.007, Elapsed time: 3186.96
2024-08-08 00:48:51 - [34m[1mLOGS   [0m - Epoch:  19 [  152175/  200000], loss: {'classification': 32.4757, 'neural_augmentation': 0.6027, 'total_loss': 33.0784}, LR: [0.000173, 0.000173], Avg. batch load time: 0.007, Elapsed time: 3310.91
2024-08-08 00:50:55 - [34m[1mLOGS   [0m - Epoch:  19 [  152237/  200000], loss: {'classification': 32.4759, 'neural_augmentation': 0.6028, 'total_loss': 33.0787}, LR: [0.000172, 0.000172], Avg. batch load time: 0.007, Elapsed time: 3434.94
2024-08-08 00:52:59 - [34m[1mLOGS   [0m - Epoch:  19 [  152300/  200000], loss: {'classification': 32.4782, 'neural_augmentation': 0.6029, 'total_loss': 33.0811}, LR: [0.000172, 0.000172], Avg. batch load time: 0.006, Elapsed time: 3558.92
2024-08-08 00:55:03 - [34m[1mLOGS   [0m - Epoch:  19 [  152362/  200000], loss: {'classification': 32.4791, 'neural_augmentation': 0.603, 'total_loss': 33.0821}, LR: [0.000171, 0.000171], Avg. batch load time: 0.006, Elapsed time: 3682.91
2024-08-08 00:57:06 - [34m[1mLOGS   [0m - Epoch:  19 [  152425/  200000], loss: {'classification': 32.4793, 'neural_augmentation': 0.6032, 'total_loss': 33.0825}, LR: [0.000171, 0.000171], Avg. batch load time: 0.006, Elapsed time: 3806.67
2024-08-08 00:59:10 - [34m[1mLOGS   [0m - Epoch:  19 [  152487/  200000], loss: {'classification': 32.4797, 'neural_augmentation': 0.6033, 'total_loss': 33.083}, LR: [0.000171, 0.000171], Avg. batch load time: 0.006, Elapsed time: 3930.62
2024-08-08 01:01:14 - [34m[1mLOGS   [0m - Epoch:  19 [  152550/  200000], loss: {'classification': 32.4774, 'neural_augmentation': 0.6034, 'total_loss': 33.0808}, LR: [0.00017, 0.00017], Avg. batch load time: 0.006, Elapsed time: 4054.56
2024-08-08 01:03:18 - [34m[1mLOGS   [0m - Epoch:  19 [  152612/  200000], loss: {'classification': 32.4761, 'neural_augmentation': 0.6035, 'total_loss': 33.0796}, LR: [0.00017, 0.00017], Avg. batch load time: 0.006, Elapsed time: 4178.29
2024-08-08 01:05:22 - [34m[1mLOGS   [0m - Epoch:  19 [  152675/  200000], loss: {'classification': 32.4764, 'neural_augmentation': 0.6036, 'total_loss': 33.0801}, LR: [0.000169, 0.000169], Avg. batch load time: 0.005, Elapsed time: 4301.95
2024-08-08 01:07:25 - [34m[1mLOGS   [0m - Epoch:  19 [  152737/  200000], loss: {'classification': 32.4737, 'neural_augmentation': 0.6037, 'total_loss': 33.0774}, LR: [0.000169, 0.000169], Avg. batch load time: 0.005, Elapsed time: 4425.64
2024-08-08 01:09:29 - [34m[1mLOGS   [0m - Epoch:  19 [  152800/  200000], loss: {'classification': 32.4724, 'neural_augmentation': 0.6039, 'total_loss': 33.0762}, LR: [0.000169, 0.000169], Avg. batch load time: 0.005, Elapsed time: 4549.43
2024-08-08 01:11:41 - [34m[1mLOGS   [0m - Epoch:  19 [  152862/  200000], loss: {'classification': 32.471, 'neural_augmentation': 0.604, 'total_loss': 33.075}, LR: [0.000168, 0.000168], Avg. batch load time: 0.005, Elapsed time: 4681.50
2024-08-08 01:13:45 - [34m[1mLOGS   [0m - Epoch:  19 [  152925/  200000], loss: {'classification': 32.4723, 'neural_augmentation': 0.6041, 'total_loss': 33.0764}, LR: [0.000168, 0.000168], Avg. batch load time: 0.005, Elapsed time: 4805.50
2024-08-08 01:15:49 - [34m[1mLOGS   [0m - Epoch:  19 [  152987/  200000], loss: {'classification': 32.4708, 'neural_augmentation': 0.6042, 'total_loss': 33.075}, LR: [0.000168, 0.000168], Avg. batch load time: 0.005, Elapsed time: 4929.34
2024-08-08 01:17:53 - [34m[1mLOGS   [0m - Epoch:  19 [  153050/  200000], loss: {'classification': 32.4681, 'neural_augmentation': 0.6043, 'total_loss': 33.0724}, LR: [0.000167, 0.000167], Avg. batch load time: 0.005, Elapsed time: 5053.01
2024-08-08 01:19:57 - [34m[1mLOGS   [0m - Epoch:  19 [  153112/  200000], loss: {'classification': 32.4671, 'neural_augmentation': 0.6044, 'total_loss': 33.0715}, LR: [0.000167, 0.000167], Avg. batch load time: 0.005, Elapsed time: 5176.79
2024-08-08 01:22:00 - [34m[1mLOGS   [0m - Epoch:  19 [  153175/  200000], loss: {'classification': 32.466, 'neural_augmentation': 0.6045, 'total_loss': 33.0705}, LR: [0.000166, 0.000166], Avg. batch load time: 0.005, Elapsed time: 5300.56
2024-08-08 01:24:04 - [34m[1mLOGS   [0m - Epoch:  19 [  153237/  200000], loss: {'classification': 32.4672, 'neural_augmentation': 0.6046, 'total_loss': 33.0719}, LR: [0.000166, 0.000166], Avg. batch load time: 0.005, Elapsed time: 5424.45
2024-08-08 01:26:08 - [34m[1mLOGS   [0m - Epoch:  19 [  153300/  200000], loss: {'classification': 32.4666, 'neural_augmentation': 0.6047, 'total_loss': 33.0713}, LR: [0.000166, 0.000166], Avg. batch load time: 0.004, Elapsed time: 5548.12
2024-08-08 01:28:12 - [34m[1mLOGS   [0m - Epoch:  19 [  153362/  200000], loss: {'classification': 32.4638, 'neural_augmentation': 0.6049, 'total_loss': 33.0686}, LR: [0.000165, 0.000165], Avg. batch load time: 0.004, Elapsed time: 5671.75
2024-08-08 01:30:15 - [34m[1mLOGS   [0m - Epoch:  19 [  153425/  200000], loss: {'classification': 32.4612, 'neural_augmentation': 0.605, 'total_loss': 33.0661}, LR: [0.000165, 0.000165], Avg. batch load time: 0.004, Elapsed time: 5795.61
2024-08-08 01:32:19 - [34m[1mLOGS   [0m - Epoch:  19 [  153487/  200000], loss: {'classification': 32.4599, 'neural_augmentation': 0.6051, 'total_loss': 33.065}, LR: [0.000164, 0.000164], Avg. batch load time: 0.004, Elapsed time: 5919.53
2024-08-08 01:34:23 - [34m[1mLOGS   [0m - Epoch:  19 [  153550/  200000], loss: {'classification': 32.4574, 'neural_augmentation': 0.6052, 'total_loss': 33.0626}, LR: [0.000164, 0.000164], Avg. batch load time: 0.004, Elapsed time: 6043.32
2024-08-08 01:36:28 - [34m[1mLOGS   [0m - Epoch:  19 [  153612/  200000], loss: {'classification': 32.456, 'neural_augmentation': 0.6053, 'total_loss': 33.0613}, LR: [0.000164, 0.000164], Avg. batch load time: 0.004, Elapsed time: 6168.47
2024-08-08 01:38:40 - [34m[1mLOGS   [0m - Epoch:  19 [  153675/  200000], loss: {'classification': 32.4557, 'neural_augmentation': 0.6054, 'total_loss': 33.0611}, LR: [0.000163, 0.000163], Avg. batch load time: 0.004, Elapsed time: 6300.25
2024-08-08 01:40:44 - [34m[1mLOGS   [0m - Epoch:  19 [  153737/  200000], loss: {'classification': 32.4559, 'neural_augmentation': 0.6055, 'total_loss': 33.0614}, LR: [0.000163, 0.000163], Avg. batch load time: 0.004, Elapsed time: 6424.00
2024-08-08 01:42:48 - [34m[1mLOGS   [0m - Epoch:  19 [  153800/  200000], loss: {'classification': 32.4564, 'neural_augmentation': 0.6056, 'total_loss': 33.062}, LR: [0.000162, 0.000162], Avg. batch load time: 0.004, Elapsed time: 6548.21
2024-08-08 01:44:52 - [34m[1mLOGS   [0m - Epoch:  19 [  153862/  200000], loss: {'classification': 32.457, 'neural_augmentation': 0.6057, 'total_loss': 33.0628}, LR: [0.000162, 0.000162], Avg. batch load time: 0.004, Elapsed time: 6672.07
2024-08-08 01:46:56 - [34m[1mLOGS   [0m - Epoch:  19 [  153925/  200000], loss: {'classification': 32.4555, 'neural_augmentation': 0.6059, 'total_loss': 33.0613}, LR: [0.000162, 0.000162], Avg. batch load time: 0.004, Elapsed time: 6796.28
2024-08-08 01:49:00 - [34m[1mLOGS   [0m - Epoch:  19 [  153987/  200000], loss: {'classification': 32.4554, 'neural_augmentation': 0.606, 'total_loss': 33.0613}, LR: [0.000161, 0.000161], Avg. batch load time: 0.004, Elapsed time: 6920.05
2024-08-08 01:51:04 - [34m[1mLOGS   [0m - Epoch:  19 [  154050/  200000], loss: {'classification': 32.4548, 'neural_augmentation': 0.6061, 'total_loss': 33.0608}, LR: [0.000161, 0.000161], Avg. batch load time: 0.004, Elapsed time: 7043.89
2024-08-08 01:53:08 - [34m[1mLOGS   [0m - Epoch:  19 [  154112/  200000], loss: {'classification': 32.4533, 'neural_augmentation': 0.6062, 'total_loss': 33.0595}, LR: [0.00016, 0.00016], Avg. batch load time: 0.004, Elapsed time: 7167.81
2024-08-08 01:55:12 - [34m[1mLOGS   [0m - Epoch:  19 [  154175/  200000], loss: {'classification': 32.4542, 'neural_augmentation': 0.6063, 'total_loss': 33.0605}, LR: [0.00016, 0.00016], Avg. batch load time: 0.004, Elapsed time: 7291.72
2024-08-08 01:57:15 - [34m[1mLOGS   [0m - Epoch:  19 [  154237/  200000], loss: {'classification': 32.4535, 'neural_augmentation': 0.6064, 'total_loss': 33.0599}, LR: [0.00016, 0.00016], Avg. batch load time: 0.004, Elapsed time: 7415.36
2024-08-08 01:59:19 - [34m[1mLOGS   [0m - Epoch:  19 [  154300/  200000], loss: {'classification': 32.4523, 'neural_augmentation': 0.6065, 'total_loss': 33.0588}, LR: [0.000159, 0.000159], Avg. batch load time: 0.004, Elapsed time: 7539.03
2024-08-08 02:01:22 - [34m[1mLOGS   [0m - Epoch:  19 [  154362/  200000], loss: {'classification': 32.4527, 'neural_augmentation': 0.6066, 'total_loss': 33.0593}, LR: [0.000159, 0.000159], Avg. batch load time: 0.003, Elapsed time: 7662.67
