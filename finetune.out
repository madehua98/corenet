nohup: ignoring input
2024-07-17 04:37:12 - [93m[1mDEBUG   [0m - Cannot load internal arguments, skipping.
base
sci
2024-07-17 04:37:14 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base500/train/checkpoint_last.pt
2024-07-17 04:37:14 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-17 04:37:14 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(768, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=768, out_features=1024, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =  171.790 M
Total trainable parameters =  171.790 M

2024-07-17 04:37:15 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.172G                 | 29.646G    |
|  pos_embed                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  4.243M                |  7.361G    |
|   patch_embed.backbone.stem          |   0.151M               |   2.483G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    56.623M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    10.486M |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    2.416G  |
|   patch_embed.backbone.stages        |   2.321M               |   4.424G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.93G   |
|    patch_embed.backbone.stages.1     |    2.047M              |    2.494G  |
|   patch_embed.backbone.pool          |   1.771M               |   0.454G   |
|    patch_embed.backbone.pool.proj    |    1.77M               |    0.453G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.311M  |
|  blocks                              |  56.703M               |  14.511G   |
|   blocks.0                           |   7.088M               |   1.814G   |
|    blocks.0.norm1                    |    1.536K              |    0.983M  |
|    blocks.0.attn                     |    2.362M              |    0.604G  |
|    blocks.0.norm2                    |    1.536K              |    0.983M  |
|    blocks.0.mlp                      |    4.722M              |    1.208G  |
|   blocks.1                           |   7.088M               |   1.814G   |
|    blocks.1.norm1                    |    1.536K              |    0.983M  |
|    blocks.1.attn                     |    2.362M              |    0.604G  |
|    blocks.1.norm2                    |    1.536K              |    0.983M  |
|    blocks.1.mlp                      |    4.722M              |    1.208G  |
|   blocks.2                           |   7.088M               |   1.814G   |
|    blocks.2.norm1                    |    1.536K              |    0.983M  |
|    blocks.2.attn                     |    2.362M              |    0.604G  |
|    blocks.2.norm2                    |    1.536K              |    0.983M  |
|    blocks.2.mlp                      |    4.722M              |    1.208G  |
|   blocks.3                           |   7.088M               |   1.814G   |
|    blocks.3.norm1                    |    1.536K              |    0.983M  |
|    blocks.3.attn                     |    2.362M              |    0.604G  |
|    blocks.3.norm2                    |    1.536K              |    0.983M  |
|    blocks.3.mlp                      |    4.722M              |    1.208G  |
|   blocks.4                           |   7.088M               |   1.814G   |
|    blocks.4.norm1                    |    1.536K              |    0.983M  |
|    blocks.4.attn                     |    2.362M              |    0.604G  |
|    blocks.4.norm2                    |    1.536K              |    0.983M  |
|    blocks.4.mlp                      |    4.722M              |    1.208G  |
|   blocks.5                           |   7.088M               |   1.814G   |
|    blocks.5.norm1                    |    1.536K              |    0.983M  |
|    blocks.5.attn                     |    2.362M              |    0.604G  |
|    blocks.5.norm2                    |    1.536K              |    0.983M  |
|    blocks.5.mlp                      |    4.722M              |    1.208G  |
|   blocks.6                           |   7.088M               |   1.814G   |
|    blocks.6.norm1                    |    1.536K              |    0.983M  |
|    blocks.6.attn                     |    2.362M              |    0.604G  |
|    blocks.6.norm2                    |    1.536K              |    0.983M  |
|    blocks.6.mlp                      |    4.722M              |    1.208G  |
|   blocks.7                           |   7.088M               |   1.814G   |
|    blocks.7.norm1                    |    1.536K              |    0.983M  |
|    blocks.7.attn                     |    2.362M              |    0.604G  |
|    blocks.7.norm2                    |    1.536K              |    0.983M  |
|    blocks.7.mlp                      |    4.722M              |    1.208G  |
|  pool                                |  7.08M                 |  0.454G    |
|   pool.proj                          |   7.079M               |   0.453G   |
|    pool.proj.weight                  |    (1024, 768, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.536K               |   0.983M   |
|    pool.norm.weight                  |    (768,)              |            |
|    pool.norm.bias                    |    (768,)              |            |
|  blocks1                             |  0.101G                |  6.448G    |
|   blocks1.0                          |   12.596M              |   0.806G   |
|    blocks1.0.norm1                   |    2.048K              |    0.328M  |
|    blocks1.0.attn                    |    4.198M              |    0.268G  |
|    blocks1.0.norm2                   |    2.048K              |    0.328M  |
|    blocks1.0.mlp                     |    8.394M              |    0.537G  |
|   blocks1.1                          |   12.596M              |   0.806G   |
|    blocks1.1.norm1                   |    2.048K              |    0.328M  |
|    blocks1.1.attn                    |    4.198M              |    0.268G  |
|    blocks1.1.norm2                   |    2.048K              |    0.328M  |
|    blocks1.1.mlp                     |    8.394M              |    0.537G  |
|   blocks1.2                          |   12.596M              |   0.806G   |
|    blocks1.2.norm1                   |    2.048K              |    0.328M  |
|    blocks1.2.attn                    |    4.198M              |    0.268G  |
|    blocks1.2.norm2                   |    2.048K              |    0.328M  |
|    blocks1.2.mlp                     |    8.394M              |    0.537G  |
|   blocks1.3                          |   12.596M              |   0.806G   |
|    blocks1.3.norm1                   |    2.048K              |    0.328M  |
|    blocks1.3.attn                    |    4.198M              |    0.268G  |
|    blocks1.3.norm2                   |    2.048K              |    0.328M  |
|    blocks1.3.mlp                     |    8.394M              |    0.537G  |
|   blocks1.4                          |   12.596M              |   0.806G   |
|    blocks1.4.norm1                   |    2.048K              |    0.328M  |
|    blocks1.4.attn                    |    4.198M              |    0.268G  |
|    blocks1.4.norm2                   |    2.048K              |    0.328M  |
|    blocks1.4.mlp                     |    8.394M              |    0.537G  |
|   blocks1.5                          |   12.596M              |   0.806G   |
|    blocks1.5.norm1                   |    2.048K              |    0.328M  |
|    blocks1.5.attn                    |    4.198M              |    0.268G  |
|    blocks1.5.norm2                   |    2.048K              |    0.328M  |
|    blocks1.5.mlp                     |    8.394M              |    0.537G  |
|   blocks1.6                          |   12.596M              |   0.806G   |
|    blocks1.6.norm1                   |    2.048K              |    0.328M  |
|    blocks1.6.attn                    |    4.198M              |    0.268G  |
|    blocks1.6.norm2                   |    2.048K              |    0.328M  |
|    blocks1.6.mlp                     |    8.394M              |    0.537G  |
|   blocks1.7                          |   12.596M              |   0.806G   |
|    blocks1.7.norm1                   |    2.048K              |    0.328M  |
|    blocks1.7.attn                    |    4.198M              |    0.268G  |
|    blocks1.7.norm2                   |    2.048K              |    0.328M  |
|    blocks1.7.mlp                     |    8.394M              |    0.537G  |
|  block_to_block1                     |  0.787M                |  0.201G    |
|   block_to_block1.weight             |   (1024, 768)          |            |
|   block_to_block1.bias               |   (1024,)              |            |
|  mlp                                 |  2.099M                |  0.671G    |
|   mlp.0                              |   1.05M                |   0.336G   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   0.336G   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  0.104M                |  0.103M    |
|   classifier.weight                  |   (101, 1024)          |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-17 04:37:15 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-17 04:37:15 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks.2.attn.q_norm', 'blocks.6.drop_path2', 'neural_augmentor.noise', 'blocks.0.attn.q_norm', 'blocks1.3.mlp.norm', 'blocks1.7.attn.attn_drop', 'patch_embed.backbone.stem.norm1.drop', 'blocks.7.drop_path2', 'blocks.3.attn.attn_drop', 'blocks1.0.attn.k_norm', 'patch_embed.backbone.stages.1.0.down', 'blocks1.4.ls1', 'blocks1.5.mlp.norm', 'blocks.4.attn.attn_drop', 'blocks1.7.drop_path2', 'blocks.7.mlp.norm', 'blocks.3.ls2', 'blocks1.2.mlp.norm', 'blocks.0.drop_path2', 'patch_drop', 'blocks.5.ls2', 'blocks.4.drop_path1', 'blocks.0.attn.attn_drop', 'patch_embed.backbone.stages.1.2.down', 'blocks1.6.ls1', 'blocks1.4.ls2', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks1.6.drop_path1', 'blocks1.6.mlp.norm', 'blocks.7.ls1', 'blocks1.5.attn.q_norm', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks.1.attn.attn_drop', 'blocks1.7.attn.k_norm', 'blocks1.6.attn.q_norm', 'blocks.3.drop_path2', 'blocks1.0.drop_path1', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks1.7.ls2', 'blocks1.5.drop_path1', 'blocks1.3.drop_path1', 'blocks1.3.attn.attn_drop', 'norm', 'neural_augmentor', 'blocks.2.attn.k_norm', 'blocks1.5.attn.attn_drop', 'blocks1.2.attn.k_norm', 'blocks1.7.drop_path1', 'blocks1.0.ls2', 'blocks.2.attn.attn_drop', 'blocks1.4.attn.q_norm', 'blocks1.4.mlp.norm', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks1.2.attn.attn_drop', 'blocks.7.ls2', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.1.attn.attn_drop', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.1.ls1', 'blocks1.7.mlp.norm', 'blocks.6.attn.attn_drop', 'neural_augmentor.brightness.min_fn', 'blocks1.0.mlp.norm', 'blocks1.4.drop_path1', 'blocks1.6.attn.attn_drop', 'blocks1.1.attn.k_norm', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks.4.ls1', 'blocks1.2.drop_path1', 'blocks1.3.drop_path2', 'blocks1.2.attn.q_norm', 'blocks1.4.attn.attn_drop', 'blocks.4.mlp.norm', 'blocks.2.drop_path2', 'blocks.0.ls1', 'blocks1.7.attn.q_norm', 'blocks.5.attn.q_norm', 'blocks.5.attn.attn_drop', 'blocks.7.drop_path1', 'neural_augmentor.contrast', 'blocks.3.attn.q_norm', 'blocks.7.attn.q_norm', 'blocks.1.mlp.norm', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'patch_embed.proj', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks1.1.ls2', 'blocks.2.ls2', 'blocks.5.attn.k_norm', 'blocks1.7.ls1', 'blocks1.1.mlp.norm', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks.7.attn.attn_drop', 'blocks.0.ls2', 'blocks.4.drop_path2', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks1.2.ls2', 'blocks.1.drop_path1', 'blocks.4.attn.k_norm', 'neural_augmentor.brightness.max_fn', 'blocks1.5.drop_path2', 'neural_augmentor.noise.max_fn', 'blocks.2.ls1', 'blocks.0.mlp.norm', 'blocks1.5.attn.k_norm', 'blocks.5.ls1', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks.6.ls1', 'blocks1.1.ls1', 'blocks.0.attn.k_norm', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks1.0.ls1', 'blocks.1.ls2', 'blocks1.0.attn.attn_drop', 'blocks.3.attn.k_norm', 'blocks1.6.ls2', 'blocks.0.drop_path1', 'blocks1.2.drop_path2', 'blocks.6.drop_path1', 'blocks.4.ls2', 'blocks.3.drop_path1', 'neural_augmentor.contrast.max_fn', 'blocks1.2.ls1', 'blocks1.3.ls1', 'blocks1.3.attn.q_norm', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks.5.mlp.norm', 'patch_embed.backbone.stages.1.3.down', 'blocks.2.drop_path1', 'blocks1.5.ls1', 'blocks.1.drop_path2', 'blocks.4.attn.q_norm', 'blocks1.3.attn.k_norm', 'blocks1.5.ls2', 'patch_embed.backbone.stages.1.3.shortcut', 'patch_embed.backbone.stages.1.1.shortcut', 'norm_pre', 'blocks.7.attn.k_norm', 'blocks1.3.ls2', 'blocks1.0.drop_path2', 'blocks1.4.drop_path2', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks.5.drop_path2', 'blocks.1.attn.k_norm', 'patch_embed.backbone.stages.0.1.shortcut', 'patch_embed.backbone.stages.1.1.down', 'patch_embed.backbone.stages.0.1.down', 'patch_embed.backbone.stages.0.0.down', 'blocks.6.ls2', 'blocks1.1.drop_path2', 'neural_augmentor.contrast.min_fn', 'neural_augmentor.brightness', 'blocks1.1.drop_path1', 'blocks1.6.attn.k_norm', 'blocks1.0.attn.q_norm', 'blocks.1.attn.q_norm', 'blocks.6.mlp.norm', 'neural_augmentor.noise.min_fn', 'blocks.3.mlp.norm', 'blocks.2.mlp.norm', 'blocks.3.ls1', 'blocks.6.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks1.1.attn.q_norm', 'blocks.6.attn.q_norm', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.5.drop_path1', 'blocks1.6.drop_path2'}
2024-07-17 04:37:15 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - Random seeds are set to 0
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - Using PyTorch version 2.2.1+cu121
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - Available GPUs: 8
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - CUDNN is enabled
2024-07-17 04:37:15 - [34m[1mLOGS   [0m - Directory exists at: /ML-A100/team/mm/models/catlip_data/single_base_500/train
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 3): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 0): tcp://di-20240206174114-98czq:30786
2024-07-17 04:37:22 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-17 04:37:22 - [34m[1mLOGS   [0m - Total number of samples: 75750
2024-07-17 04:37:22 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-17 04:37:22 - [34m[1mLOGS   [0m - Training dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/train_images 
	is_training=True 
	num_samples=75750
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), size=(224, 224), interpolation=bilinear), 
			RandomHorizontalFlip(p=0.5), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Number of categories: 101
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Total number of samples: 25250
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Using all samples in the dataset.
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Validation dataset details are given below
ImageNetDataset(
	root=/ML-A100/team/mm/models/food101/food101/test_images 
	is_training=False 
	num_samples=25250
	transforms=Compose(
			Resize(size=232, interpolation=bilinear, maintain_aspect_ratio=True), 
			CenterCrop(size=(h=224, w=224)), 
			ToTensor(dtype=torch.float32, norm_factor=255)
		)
	 num_classes=101
)
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Training sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=64
	 scales=[(128, 128, 196), (160, 160, 125), (192, 192, 87), (224, 224, 64), (256, 256, 49), (288, 288, 38), (320, 320, 31)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Validation sampler details: VariableBatchSamplerDDP(
	 num_repeat=1
	 trunc_rep_aug=False
	 sharding=False
	 disable_shuffle_sharding=False
	 base_im_size=(h=224, w=224)
	 base_batch_size=50
	 scales=[(224, 224, 50)]
	 scale_inc=False
	 min_scale_inc_factor=1.0
	 max_scale_inc_factor=1.0
	 ep_intervals=[40]
)
2024-07-17 04:37:23 - [34m[1mLOGS   [0m - Number of data workers: 64
base
sci
2024-07-17 04:37:30 - [34m[1mLOGS   [0m - Pretrained weights are loaded from /ML-A100/team/mm/models/catlip_data/results_base500/train/checkpoint_last.pt
2024-07-17 04:37:30 - [32m[1mINFO   [0m - Trainable parameters: ['pos_embed', 'neural_augmentor.brightness._low', 'neural_augmentor.brightness._high', 'neural_augmentor.contrast._low', 'neural_augmentor.contrast._high', 'neural_augmentor.noise._low', 'neural_augmentor.noise._high', 'patch_embed.backbone.stem.conv1.weight', 'patch_embed.backbone.stem.conv1.bias', 'patch_embed.backbone.stem.norm1.weight', 'patch_embed.backbone.stem.norm1.bias', 'patch_embed.backbone.stem.conv2.weight', 'patch_embed.backbone.stem.conv2.bias', 'patch_embed.backbone.stages.0.0.pre_norm.weight', 'patch_embed.backbone.stages.0.0.pre_norm.bias', 'patch_embed.backbone.stages.0.0.conv1_1x1.weight', 'patch_embed.backbone.stages.0.0.conv1_1x1.bias', 'patch_embed.backbone.stages.0.0.conv2_kxk.weight', 'patch_embed.backbone.stages.0.0.conv2_kxk.bias', 'patch_embed.backbone.stages.0.0.conv3_1x1.weight', 'patch_embed.backbone.stages.0.0.conv3_1x1.bias', 'patch_embed.backbone.stages.0.1.pre_norm.weight', 'patch_embed.backbone.stages.0.1.pre_norm.bias', 'patch_embed.backbone.stages.0.1.conv1_1x1.weight', 'patch_embed.backbone.stages.0.1.conv1_1x1.bias', 'patch_embed.backbone.stages.0.1.conv2_kxk.weight', 'patch_embed.backbone.stages.0.1.conv2_kxk.bias', 'patch_embed.backbone.stages.0.1.conv3_1x1.weight', 'patch_embed.backbone.stages.0.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.0.shortcut.expand.weight', 'patch_embed.backbone.stages.1.0.shortcut.expand.bias', 'patch_embed.backbone.stages.1.0.pre_norm.weight', 'patch_embed.backbone.stages.1.0.pre_norm.bias', 'patch_embed.backbone.stages.1.0.conv1_1x1.weight', 'patch_embed.backbone.stages.1.0.conv1_1x1.bias', 'patch_embed.backbone.stages.1.0.conv2_kxk.weight', 'patch_embed.backbone.stages.1.0.conv2_kxk.bias', 'patch_embed.backbone.stages.1.0.conv3_1x1.weight', 'patch_embed.backbone.stages.1.0.conv3_1x1.bias', 'patch_embed.backbone.stages.1.1.pre_norm.weight', 'patch_embed.backbone.stages.1.1.pre_norm.bias', 'patch_embed.backbone.stages.1.1.conv1_1x1.weight', 'patch_embed.backbone.stages.1.1.conv1_1x1.bias', 'patch_embed.backbone.stages.1.1.conv2_kxk.weight', 'patch_embed.backbone.stages.1.1.conv2_kxk.bias', 'patch_embed.backbone.stages.1.1.conv3_1x1.weight', 'patch_embed.backbone.stages.1.1.conv3_1x1.bias', 'patch_embed.backbone.stages.1.2.pre_norm.weight', 'patch_embed.backbone.stages.1.2.pre_norm.bias', 'patch_embed.backbone.stages.1.2.conv1_1x1.weight', 'patch_embed.backbone.stages.1.2.conv1_1x1.bias', 'patch_embed.backbone.stages.1.2.conv2_kxk.weight', 'patch_embed.backbone.stages.1.2.conv2_kxk.bias', 'patch_embed.backbone.stages.1.2.conv3_1x1.weight', 'patch_embed.backbone.stages.1.2.conv3_1x1.bias', 'patch_embed.backbone.stages.1.3.pre_norm.weight', 'patch_embed.backbone.stages.1.3.pre_norm.bias', 'patch_embed.backbone.stages.1.3.conv1_1x1.weight', 'patch_embed.backbone.stages.1.3.conv1_1x1.bias', 'patch_embed.backbone.stages.1.3.conv2_kxk.weight', 'patch_embed.backbone.stages.1.3.conv2_kxk.bias', 'patch_embed.backbone.stages.1.3.conv3_1x1.weight', 'patch_embed.backbone.stages.1.3.conv3_1x1.bias', 'patch_embed.backbone.pool.proj.weight', 'patch_embed.backbone.pool.proj.bias', 'patch_embed.backbone.pool.norm.weight', 'patch_embed.backbone.pool.norm.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'pool.proj.weight', 'pool.proj.bias', 'pool.norm.weight', 'pool.norm.bias', 'blocks1.0.norm1.weight', 'blocks1.0.norm1.bias', 'blocks1.0.attn.qkv.weight', 'blocks1.0.attn.qkv.bias', 'blocks1.0.attn.proj.weight', 'blocks1.0.attn.proj.bias', 'blocks1.0.norm2.weight', 'blocks1.0.norm2.bias', 'blocks1.0.mlp.fc1.weight', 'blocks1.0.mlp.fc1.bias', 'blocks1.0.mlp.fc2.weight', 'blocks1.0.mlp.fc2.bias', 'blocks1.1.norm1.weight', 'blocks1.1.norm1.bias', 'blocks1.1.attn.qkv.weight', 'blocks1.1.attn.qkv.bias', 'blocks1.1.attn.proj.weight', 'blocks1.1.attn.proj.bias', 'blocks1.1.norm2.weight', 'blocks1.1.norm2.bias', 'blocks1.1.mlp.fc1.weight', 'blocks1.1.mlp.fc1.bias', 'blocks1.1.mlp.fc2.weight', 'blocks1.1.mlp.fc2.bias', 'blocks1.2.norm1.weight', 'blocks1.2.norm1.bias', 'blocks1.2.attn.qkv.weight', 'blocks1.2.attn.qkv.bias', 'blocks1.2.attn.proj.weight', 'blocks1.2.attn.proj.bias', 'blocks1.2.norm2.weight', 'blocks1.2.norm2.bias', 'blocks1.2.mlp.fc1.weight', 'blocks1.2.mlp.fc1.bias', 'blocks1.2.mlp.fc2.weight', 'blocks1.2.mlp.fc2.bias', 'blocks1.3.norm1.weight', 'blocks1.3.norm1.bias', 'blocks1.3.attn.qkv.weight', 'blocks1.3.attn.qkv.bias', 'blocks1.3.attn.proj.weight', 'blocks1.3.attn.proj.bias', 'blocks1.3.norm2.weight', 'blocks1.3.norm2.bias', 'blocks1.3.mlp.fc1.weight', 'blocks1.3.mlp.fc1.bias', 'blocks1.3.mlp.fc2.weight', 'blocks1.3.mlp.fc2.bias', 'blocks1.4.norm1.weight', 'blocks1.4.norm1.bias', 'blocks1.4.attn.qkv.weight', 'blocks1.4.attn.qkv.bias', 'blocks1.4.attn.proj.weight', 'blocks1.4.attn.proj.bias', 'blocks1.4.norm2.weight', 'blocks1.4.norm2.bias', 'blocks1.4.mlp.fc1.weight', 'blocks1.4.mlp.fc1.bias', 'blocks1.4.mlp.fc2.weight', 'blocks1.4.mlp.fc2.bias', 'blocks1.5.norm1.weight', 'blocks1.5.norm1.bias', 'blocks1.5.attn.qkv.weight', 'blocks1.5.attn.qkv.bias', 'blocks1.5.attn.proj.weight', 'blocks1.5.attn.proj.bias', 'blocks1.5.norm2.weight', 'blocks1.5.norm2.bias', 'blocks1.5.mlp.fc1.weight', 'blocks1.5.mlp.fc1.bias', 'blocks1.5.mlp.fc2.weight', 'blocks1.5.mlp.fc2.bias', 'blocks1.6.norm1.weight', 'blocks1.6.norm1.bias', 'blocks1.6.attn.qkv.weight', 'blocks1.6.attn.qkv.bias', 'blocks1.6.attn.proj.weight', 'blocks1.6.attn.proj.bias', 'blocks1.6.norm2.weight', 'blocks1.6.norm2.bias', 'blocks1.6.mlp.fc1.weight', 'blocks1.6.mlp.fc1.bias', 'blocks1.6.mlp.fc2.weight', 'blocks1.6.mlp.fc2.bias', 'blocks1.7.norm1.weight', 'blocks1.7.norm1.bias', 'blocks1.7.attn.qkv.weight', 'blocks1.7.attn.qkv.bias', 'blocks1.7.attn.proj.weight', 'blocks1.7.attn.proj.bias', 'blocks1.7.norm2.weight', 'blocks1.7.norm2.bias', 'blocks1.7.mlp.fc1.weight', 'blocks1.7.mlp.fc1.bias', 'blocks1.7.mlp.fc2.weight', 'blocks1.7.mlp.fc2.bias', 'block_to_block1.weight', 'block_to_block1.bias', 'mlp.0.weight', 'mlp.0.bias', 'mlp.2.weight', 'mlp.2.bias', 'fc_norm.weight', 'fc_norm.bias', 'classifier.weight', 'classifier.bias']
2024-07-17 04:37:30 - [34m[1mLOGS   [0m - [36mModel[0m
ViTamin(
  (neural_augmentor): DistributionNeuralAugmentor(
  	Brightness=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Contrast=UniformSampler(min_fn=Clip(min=0.1, max=0.9, clipping=soft), max_fn=Clip(min=1.1, max=10.0, clipping=soft)), 
  	Noise=UniformSampler(min_fn=Clip(min=0.0, max=5e-05, clipping=soft), max_fn=Clip(min=0.0001, max=1.0, clipping=soft)), )
  (patch_embed): HybridEmbed(
    (backbone): MbConvStages(
      (stem): Stem(
        (conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm1): LayerNormAct2d(
          (128,), eps=1e-06, elementwise_affine=True
          (drop): Identity()
          (act): GELU()
        )
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Identity()
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): MbConvLNBlock(
            (shortcut): Downsample2d(
              (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)
              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (pre_norm): LayerNormAct2d(
              (128,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (1): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (2): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
          (3): MbConvLNBlock(
            (shortcut): Identity()
            (pre_norm): LayerNormAct2d(
              (256,), eps=1e-06, elementwise_affine=True
              (drop): Identity()
              (act): Identity()
            )
            (down): Identity()
            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
            (act1): GELU()
            (act2): GELU()
            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
            (drop_path): Identity()
          )
        )
      )
      (pool): StridedConv(
        (proj): Conv2d(256, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)
      )
    )
    (proj): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (pool): StridedConv(
    (proj): Conv2d(768, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)
  )
  (blocks1): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): Identity()
  (block_to_block1): LinearLayer(in_features=768, out_features=1024, bias=True, channel_first=False)
  (mlp): Sequential(
    (0): Linear(in_features=1024, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (classifier_drop): Dropout(p=0.0, inplace=False)
  (classifier): LinearLayer(in_features=1024, out_features=101, bias=True, channel_first=False)
)
[31m=================================================================[0m
                            ViTamin Summary
[31m=================================================================[0m
Total parameters     =  171.790 M
Total trainable parameters =  171.790 M

2024-07-17 04:37:30 - [34m[1mLOGS   [0m - FVCore Analysis:
2024-07-17 04:37:30 - [34m[1mLOGS   [0m - Input sizes: [1, 3, 256, 256]
| module                               | #parameters or shape   | #flops     |
|:-------------------------------------|:-----------------------|:-----------|
| model                                | 0.172G                 | 29.646G    |
|  pos_embed                           |  (1, 1, 768)           |            |
|  neural_augmentor                    |  6                     |            |
|   neural_augmentor.brightness        |   2                    |            |
|    neural_augmentor.brightness._low  |    ()                  |            |
|    neural_augmentor.brightness._high |    ()                  |            |
|   neural_augmentor.contrast          |   2                    |            |
|    neural_augmentor.contrast._low    |    ()                  |            |
|    neural_augmentor.contrast._high   |    ()                  |            |
|   neural_augmentor.noise             |   2                    |            |
|    neural_augmentor.noise._low       |    ()                  |            |
|    neural_augmentor.noise._high      |    ()                  |            |
|  patch_embed.backbone                |  4.243M                |  7.361G    |
|   patch_embed.backbone.stem          |   0.151M               |   2.483G   |
|    patch_embed.backbone.stem.conv1   |    3.584K              |    56.623M |
|    patch_embed.backbone.stem.norm1   |    0.256K              |    10.486M |
|    patch_embed.backbone.stem.conv2   |    0.148M              |    2.416G  |
|   patch_embed.backbone.stages        |   2.321M               |   4.424G   |
|    patch_embed.backbone.stages.0     |    0.274M              |    1.93G   |
|    patch_embed.backbone.stages.1     |    2.047M              |    2.494G  |
|   patch_embed.backbone.pool          |   1.771M               |   0.454G   |
|    patch_embed.backbone.pool.proj    |    1.77M               |    0.453G  |
|    patch_embed.backbone.pool.norm    |    0.512K              |    1.311M  |
|  blocks                              |  56.703M               |  14.511G   |
|   blocks.0                           |   7.088M               |   1.814G   |
|    blocks.0.norm1                    |    1.536K              |    0.983M  |
|    blocks.0.attn                     |    2.362M              |    0.604G  |
|    blocks.0.norm2                    |    1.536K              |    0.983M  |
|    blocks.0.mlp                      |    4.722M              |    1.208G  |
|   blocks.1                           |   7.088M               |   1.814G   |
|    blocks.1.norm1                    |    1.536K              |    0.983M  |
|    blocks.1.attn                     |    2.362M              |    0.604G  |
|    blocks.1.norm2                    |    1.536K              |    0.983M  |
|    blocks.1.mlp                      |    4.722M              |    1.208G  |
|   blocks.2                           |   7.088M               |   1.814G   |
|    blocks.2.norm1                    |    1.536K              |    0.983M  |
|    blocks.2.attn                     |    2.362M              |    0.604G  |
|    blocks.2.norm2                    |    1.536K              |    0.983M  |
|    blocks.2.mlp                      |    4.722M              |    1.208G  |
|   blocks.3                           |   7.088M               |   1.814G   |
|    blocks.3.norm1                    |    1.536K              |    0.983M  |
|    blocks.3.attn                     |    2.362M              |    0.604G  |
|    blocks.3.norm2                    |    1.536K              |    0.983M  |
|    blocks.3.mlp                      |    4.722M              |    1.208G  |
|   blocks.4                           |   7.088M               |   1.814G   |
|    blocks.4.norm1                    |    1.536K              |    0.983M  |
|    blocks.4.attn                     |    2.362M              |    0.604G  |
|    blocks.4.norm2                    |    1.536K              |    0.983M  |
|    blocks.4.mlp                      |    4.722M              |    1.208G  |
|   blocks.5                           |   7.088M               |   1.814G   |
|    blocks.5.norm1                    |    1.536K              |    0.983M  |
|    blocks.5.attn                     |    2.362M              |    0.604G  |
|    blocks.5.norm2                    |    1.536K              |    0.983M  |
|    blocks.5.mlp                      |    4.722M              |    1.208G  |
|   blocks.6                           |   7.088M               |   1.814G   |
|    blocks.6.norm1                    |    1.536K              |    0.983M  |
|    blocks.6.attn                     |    2.362M              |    0.604G  |
|    blocks.6.norm2                    |    1.536K              |    0.983M  |
|    blocks.6.mlp                      |    4.722M              |    1.208G  |
|   blocks.7                           |   7.088M               |   1.814G   |
|    blocks.7.norm1                    |    1.536K              |    0.983M  |
|    blocks.7.attn                     |    2.362M              |    0.604G  |
|    blocks.7.norm2                    |    1.536K              |    0.983M  |
|    blocks.7.mlp                      |    4.722M              |    1.208G  |
|  pool                                |  7.08M                 |  0.454G    |
|   pool.proj                          |   7.079M               |   0.453G   |
|    pool.proj.weight                  |    (1024, 768, 3, 3)   |            |
|    pool.proj.bias                    |    (1024,)             |            |
|   pool.norm                          |   1.536K               |   0.983M   |
|    pool.norm.weight                  |    (768,)              |            |
|    pool.norm.bias                    |    (768,)              |            |
|  blocks1                             |  0.101G                |  6.448G    |
|   blocks1.0                          |   12.596M              |   0.806G   |
|    blocks1.0.norm1                   |    2.048K              |    0.328M  |
|    blocks1.0.attn                    |    4.198M              |    0.268G  |
|    blocks1.0.norm2                   |    2.048K              |    0.328M  |
|    blocks1.0.mlp                     |    8.394M              |    0.537G  |
|   blocks1.1                          |   12.596M              |   0.806G   |
|    blocks1.1.norm1                   |    2.048K              |    0.328M  |
|    blocks1.1.attn                    |    4.198M              |    0.268G  |
|    blocks1.1.norm2                   |    2.048K              |    0.328M  |
|    blocks1.1.mlp                     |    8.394M              |    0.537G  |
|   blocks1.2                          |   12.596M              |   0.806G   |
|    blocks1.2.norm1                   |    2.048K              |    0.328M  |
|    blocks1.2.attn                    |    4.198M              |    0.268G  |
|    blocks1.2.norm2                   |    2.048K              |    0.328M  |
|    blocks1.2.mlp                     |    8.394M              |    0.537G  |
|   blocks1.3                          |   12.596M              |   0.806G   |
|    blocks1.3.norm1                   |    2.048K              |    0.328M  |
|    blocks1.3.attn                    |    4.198M              |    0.268G  |
|    blocks1.3.norm2                   |    2.048K              |    0.328M  |
|    blocks1.3.mlp                     |    8.394M              |    0.537G  |
|   blocks1.4                          |   12.596M              |   0.806G   |
|    blocks1.4.norm1                   |    2.048K              |    0.328M  |
|    blocks1.4.attn                    |    4.198M              |    0.268G  |
|    blocks1.4.norm2                   |    2.048K              |    0.328M  |
|    blocks1.4.mlp                     |    8.394M              |    0.537G  |
|   blocks1.5                          |   12.596M              |   0.806G   |
|    blocks1.5.norm1                   |    2.048K              |    0.328M  |
|    blocks1.5.attn                    |    4.198M              |    0.268G  |
|    blocks1.5.norm2                   |    2.048K              |    0.328M  |
|    blocks1.5.mlp                     |    8.394M              |    0.537G  |
|   blocks1.6                          |   12.596M              |   0.806G   |
|    blocks1.6.norm1                   |    2.048K              |    0.328M  |
|    blocks1.6.attn                    |    4.198M              |    0.268G  |
|    blocks1.6.norm2                   |    2.048K              |    0.328M  |
|    blocks1.6.mlp                     |    8.394M              |    0.537G  |
|   blocks1.7                          |   12.596M              |   0.806G   |
|    blocks1.7.norm1                   |    2.048K              |    0.328M  |
|    blocks1.7.attn                    |    4.198M              |    0.268G  |
|    blocks1.7.norm2                   |    2.048K              |    0.328M  |
|    blocks1.7.mlp                     |    8.394M              |    0.537G  |
|  block_to_block1                     |  0.787M                |  0.201G    |
|   block_to_block1.weight             |   (1024, 768)          |            |
|   block_to_block1.bias               |   (1024,)              |            |
|  mlp                                 |  2.099M                |  0.671G    |
|   mlp.0                              |   1.05M                |   0.336G   |
|    mlp.0.weight                      |    (1024, 1024)        |            |
|    mlp.0.bias                        |    (1024,)             |            |
|   mlp.2                              |   1.05M                |   0.336G   |
|    mlp.2.weight                      |    (1024, 1024)        |            |
|    mlp.2.bias                        |    (1024,)             |            |
|  fc_norm                             |  2.048K                |  5.12K     |
|   fc_norm.weight                     |   (1024,)              |            |
|   fc_norm.bias                       |   (1024,)              |            |
|  classifier                          |  0.104M                |  0.103M    |
|   classifier.weight                  |   (101, 1024)          |            |
|   classifier.bias                    |   (101,)               |            |
2024-07-17 04:37:31 - [33m[1mWARNING[0m - 
** Please be cautious when using the results in papers. Certain operations may or may not be accounted in FLOP computation in FVCore. Therefore, you want to manually ensure that FLOP computation is correct.
2024-07-17 04:37:31 - [33m[1mWARNING[0m - Uncalled Modules:
{'blocks1.2.attn.attn_drop', 'patch_embed.backbone.stages.0.0.pre_norm.drop', 'blocks.5.attn.attn_drop', 'blocks1.1.attn.k_norm', 'blocks.0.ls1', 'blocks1.7.attn.attn_drop', 'blocks.5.drop_path1', 'blocks1.0.ls1', 'neural_augmentor.brightness.min_fn', 'blocks.4.ls2', 'blocks.7.attn.q_norm', 'blocks1.1.mlp.norm', 'blocks1.6.ls2', 'blocks.4.attn.attn_drop', 'blocks1.5.drop_path1', 'blocks.1.attn.k_norm', 'blocks1.0.attn.attn_drop', 'blocks1.6.attn.q_norm', 'patch_embed.backbone.stages.0.1.pre_norm.drop', 'blocks.6.drop_path1', 'blocks.1.drop_path2', 'norm_pre', 'blocks.4.drop_path2', 'patch_drop', 'blocks.0.drop_path2', 'blocks.4.drop_path1', 'blocks1.6.mlp.norm', 'patch_embed.backbone.stages.0.1.down', 'patch_embed.backbone.stages.1.0.pre_norm.drop', 'blocks.4.attn.k_norm', 'blocks1.3.attn.attn_drop', 'blocks1.3.drop_path1', 'blocks1.4.attn.k_norm', 'patch_embed.backbone.stages.1.2.pre_norm.act', 'blocks.1.attn.q_norm', 'patch_embed.backbone.stages.1.3.shortcut', 'blocks1.6.drop_path2', 'blocks.2.ls1', 'blocks.5.ls2', 'patch_embed.backbone.stages.1.0.down', 'blocks.7.ls2', 'blocks1.2.ls1', 'blocks.6.attn.attn_drop', 'blocks.6.mlp.norm', 'blocks.3.attn.q_norm', 'blocks1.4.ls1', 'patch_embed.backbone.stages.1.3.pre_norm.act', 'blocks1.5.mlp.norm', 'blocks1.3.attn.q_norm', 'blocks.5.attn.q_norm', 'neural_augmentor.contrast.min_fn', 'blocks.5.attn.k_norm', 'blocks1.0.drop_path1', 'blocks1.6.ls1', 'blocks.6.attn.k_norm', 'blocks.4.mlp.norm', 'blocks1.4.drop_path1', 'blocks1.6.attn.k_norm', 'patch_embed.backbone.stages.0.0.shortcut.expand', 'blocks1.5.attn.k_norm', 'blocks.3.ls2', 'patch_embed.backbone.stages.0.1.drop_path', 'blocks.7.ls1', 'blocks.3.drop_path2', 'blocks1.1.drop_path2', 'neural_augmentor.contrast', 'blocks1.3.ls2', 'blocks1.7.mlp.norm', 'patch_embed.backbone.stages.1.3.down', 'blocks1.3.mlp.norm', 'neural_augmentor', 'blocks.4.attn.q_norm', 'blocks.7.drop_path1', 'blocks1.0.mlp.norm', 'blocks1.6.attn.attn_drop', 'blocks1.7.drop_path1', 'blocks.0.drop_path1', 'patch_embed.backbone.stages.0.1.shortcut', 'blocks.3.drop_path1', 'blocks.6.ls2', 'patch_embed.backbone.stem.norm1.drop', 'blocks1.0.drop_path2', 'blocks1.2.mlp.norm', 'patch_embed.backbone.stages.0.0.pre_norm.act', 'neural_augmentor.brightness', 'blocks.1.attn.attn_drop', 'patch_embed.backbone.stages.1.1.pre_norm.act', 'blocks1.4.ls2', 'blocks.7.drop_path2', 'blocks.0.ls2', 'patch_embed.backbone.stages.1.1.shortcut', 'blocks.3.attn.k_norm', 'blocks.2.attn.q_norm', 'blocks1.4.drop_path2', 'blocks.5.ls1', 'blocks.6.ls1', 'blocks.0.attn.q_norm', 'blocks1.5.ls1', 'blocks1.1.ls1', 'patch_embed.backbone.stages.1.2.shortcut', 'blocks.7.attn.attn_drop', 'blocks.2.drop_path1', 'blocks1.5.ls2', 'blocks.3.mlp.norm', 'blocks1.3.attn.k_norm', 'blocks1.2.drop_path1', 'blocks1.0.attn.q_norm', 'blocks.6.drop_path2', 'neural_augmentor.contrast.max_fn', 'blocks.0.attn.attn_drop', 'blocks.0.attn.k_norm', 'neural_augmentor.noise.min_fn', 'blocks1.2.attn.k_norm', 'blocks1.6.drop_path1', 'blocks.7.attn.k_norm', 'patch_embed.proj', 'neural_augmentor.noise', 'blocks.0.mlp.norm', 'patch_embed.backbone.stages.1.2.down', 'blocks.2.attn.attn_drop', 'blocks1.4.attn.attn_drop', 'blocks1.5.attn.q_norm', 'blocks.1.ls2', 'blocks1.0.attn.k_norm', 'blocks.5.mlp.norm', 'blocks1.1.drop_path1', 'norm', 'blocks.7.mlp.norm', 'neural_augmentor.noise.max_fn', 'blocks.6.attn.q_norm', 'blocks.2.ls2', 'patch_embed.backbone.stages.1.0.drop_path', 'blocks1.2.ls2', 'patch_embed.backbone.stages.0.0.down', 'blocks1.7.ls2', 'blocks1.5.drop_path2', 'blocks1.7.attn.k_norm', 'patch_embed.backbone.stages.1.3.pre_norm.drop', 'blocks.5.drop_path2', 'blocks.3.ls1', 'blocks1.7.attn.q_norm', 'blocks1.4.mlp.norm', 'blocks1.2.attn.q_norm', 'neural_augmentor.brightness.max_fn', 'patch_embed.backbone.stages.1.3.drop_path', 'blocks1.1.attn.q_norm', 'blocks1.7.drop_path2', 'blocks.1.drop_path1', 'patch_embed.backbone.stages.1.0.pre_norm.act', 'blocks1.7.ls1', 'patch_embed.backbone.stages.1.2.pre_norm.drop', 'blocks.2.mlp.norm', 'blocks1.1.attn.attn_drop', 'blocks.3.attn.attn_drop', 'patch_embed.backbone.stages.1.1.down', 'patch_embed.backbone.stages.1.1.drop_path', 'blocks.1.mlp.norm', 'patch_embed.backbone.stages.0.0.drop_path', 'blocks1.3.drop_path2', 'blocks.1.ls1', 'patch_embed.backbone.stages.1.1.pre_norm.drop', 'blocks1.2.drop_path2', 'blocks.4.ls1', 'blocks1.0.ls2', 'blocks.2.attn.k_norm', 'patch_embed.backbone.stages.1.2.drop_path', 'blocks.2.drop_path2', 'patch_embed.backbone.stages.0.1.pre_norm.act', 'blocks1.1.ls2', 'blocks1.5.attn.attn_drop', 'blocks1.4.attn.q_norm', 'blocks1.3.ls1'}
2024-07-17 04:37:31 - [33m[1mWARNING[0m - Unsupported Ops:
Counter({'aten::add': 39, 'aten::gelu': 30, 'aten::scaled_dot_product_attention': 16, 'aten::avg_pool2d': 2, 'aten::mean': 1})
[31m=================================================================[0m
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - Using DistributedDataParallel.
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - [36mLoss function[0m
CompositeLoss(
	CrossEntropy(  ignore_idx=-1  class_weighting=False  label_smoothing=0.1 loss_wt=1.0)
	NeuralAugmentation(  target_metric=psnr  target_value=[40, 20]  curriculum_learning=True  alpha=0.0015378700499807767 loss_wt=1.0)
	
)
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - [36mOptimizer[0m
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - Max. epochs for training: 120
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - [36mLearning rate scheduler[0m
CosineScheduler(
 	 min_lr=3e-06
 	 max_lr=3e-05
 	 period=120
 	 warmup_init_lr=1e-06
 	 warmup_iters=500
 )
2024-07-17 04:37:31 - [34m[1mLOGS   [0m - No checkpoint found at '/ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt'
2024-07-17 04:37:31 - [32m[1mINFO   [0m - Configuration file is stored here: [36m/ML-A100/team/mm/models/catlip_data/single_base_500/train/config.yaml[0m
[31m===========================================================================[0m
2024-07-17 04:37:33 - [32m[1mINFO   [0m - Training epoch 0
2024-07-17 04:37:18 - [32m[1mINFO   [0m - distributed init (rank 6): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 7): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 4): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 5): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 2): tcp://di-20240206174114-98czq:30786
base
sci
2024-07-17 04:37:19 - [32m[1mINFO   [0m - distributed init (rank 1): tcp://di-20240206174114-98czq:30786
base
sci
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/ML-A800/home/guoshuyue/anaconda3/envs/corenet/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]
bucket_view.sizes() = [256, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2024-07-17 04:40:34 - [34m[1mLOGS   [0m - Epoch:   0 [       1/10000000], loss: {'classification': 4.7298, 'neural_augmentation': 0.083, 'total_loss': 4.8128}, LR: [1e-06, 1e-06], Avg. batch load time: 165.919, Elapsed time: 180.42
2024-07-17 04:40:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 0
	 loss={'classification': 4.7194, 'neural_augmentation': 0.0826, 'total_loss': 4.802}
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:43:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 0
	 loss={'classification': 4.6967, 'neural_augmentation': 0.0, 'total_loss': 4.6967} || top1={'logits': 0.9766} || top5={'logits': 4.8828} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0388, 0.0416, 0.0277, 0.0204, 0.0193, 0.0199, 0.0193, 0.0193, 0.0197, 0.0255, 0.0194, 0.0213, 0.0275, 0.0195, 0.0193, 0.0193, 0.0194, 0.0193, 0.0193, 0.0218, 0.0273, 0.027, 0.0193, 0.0211, 0.0193, 0.02, 0.0194, 0.0266, 0.0214, 0.0214, 0.0214, 0.02, 0.0193, 0.0194, 0.0265, 0.0205, 0.0232, 0.0193, 0.0194, 0.0404, 0.0194, 0.0197, 0.0221, 0.0193, 0.0263, 0.0193, 0.0193, 0.0245, 0.0223, 0.0209, 0.0199, 0.0197, 0.0217, 0.0193, 0.0193, 0.0235, 0.0194, 0.02, 0.0194, 0.0194, 0.0195, 0.0193, 0.0198, 0.0389, 0.0288, 0.0193, 0.0256, 0.023, 0.0193, 0.0201, 0.0213, 0.0193, 0.0198, 0.0264, 0.0215, 0.0237, 0.0194, 0.0218, 0.0194, 0.0197, 0.0208, 0.0193, 0.0194, 0.0193, 0.0193, 0.0214, 0.0219, 0.0219, 0.0223, 0.0193, 0.0193, 0.0193, 0.0193, 0.024, 0.025, 0.0193, 0.0193, 0.0206, 0.0235, 0.02, 0.0202], 'AP': [0.0176, 0.017, 0.0117, 0.0102, 0.0098, 0.0091, 0.008, 0.0088, 0.0099, 0.0123, 0.0093, 0.0103, 0.0121, 0.0098, 0.0097, 0.0096, 0.0094, 0.0093, 0.0097, 0.0105, 0.0123, 0.0106, 0.0085, 0.0105, 0.0098, 0.0097, 0.0099, 0.0107, 0.0105, 0.01, 0.0106, 0.0098, 0.0085, 0.008, 0.0109, 0.0097, 0.0114, 0.0084, 0.0098, 0.0139, 0.0086, 0.01, 0.0109, 0.0092, 0.0109, 0.0098, 0.0095, 0.0107, 0.0107, 0.0101, 0.01, 0.0099, 0.0095, 0.0097, 0.0089, 0.011, 0.0089, 0.0089, 0.0095, 0.009, 0.0089, 0.009, 0.01, 0.0117, 0.0114, 0.0092, 0.011, 0.0106, 0.0095, 0.01, 0.0095, 0.0098, 0.01, 0.0104, 0.0103, 0.0106, 0.0082, 0.0094, 0.0096, 0.0101, 0.0099, 0.0078, 0.0092, 0.0098, 0.0083, 0.0104, 0.0103, 0.0105, 0.0112, 0.0097, 0.0097, 0.0075, 0.01, 0.0112, 0.0111, 0.0098, 0.0098, 0.0095, 0.0111, 0.01, 0.0097], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0101, 'weighted': 0.0102}
2024-07-17 04:43:59 - [34m[1mLOGS   [0m - Best checkpoint with score 0.98 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:44:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:44:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:44:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 0/iteration 115 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_0_iter_115.pt
2024-07-17 04:44:06 - [34m[1mLOGS   [0m - Model state for epoch 0/iteration 115 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_0_iter_115.pt
[31m===========================================================================[0m
2024-07-17 04:44:08 - [32m[1mINFO   [0m - Training epoch 1
2024-07-17 04:44:09 - [34m[1mLOGS   [0m - Epoch:   1 [     116/10000000], loss: {'classification': 4.7202, 'neural_augmentation': 0.0763, 'total_loss': 4.7965}, LR: [8e-06, 8e-06], Avg. batch load time: 0.951, Elapsed time:  1.26
2024-07-17 04:44:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 1
	 loss={'classification': 4.6781, 'neural_augmentation': 0.0824, 'total_loss': 4.7606}
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:44:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 1
	 loss={'classification': 4.6487, 'neural_augmentation': 0.0, 'total_loss': 4.6487} || top1={'logits': 0.9766} || top5={'logits': 4.8828} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0388, 0.0383, 0.0193, 0.0196, 0.0303, 0.0207, 0.0194, 0.0193, 0.0193, 0.0202, 0.0214, 0.0261, 0.0435, 0.0193, 0.0193, 0.0215, 0.0201, 0.0389, 0.0193, 0.0194, 0.0236, 0.0239, 0.0194, 0.0193, 0.0215, 0.0194, 0.0195, 0.0208, 0.0193, 0.0194, 0.0215, 0.0204, 0.0194, 0.0228, 0.0194, 0.0195, 0.0212, 0.0216, 0.0193, 0.0193, 0.0196, 0.0193, 0.0193, 0.0194, 0.0194, 0.0193, 0.0249, 0.0259, 0.0211, 0.0221, 0.0208, 0.0204, 0.0194, 0.02, 0.0194, 0.0244, 0.0194, 0.0194, 0.0205, 0.0238, 0.0193, 0.0194, 0.0204, 0.0266, 0.0193, 0.0193, 0.0248, 0.0199, 0.024, 0.0251, 0.0222, 0.0226, 0.0195, 0.0195, 0.0198, 0.0218, 0.0193, 0.0193, 0.0223, 0.0253, 0.0193, 0.0193, 0.0224, 0.0193, 0.0194, 0.0195, 0.0194, 0.022, 0.0193, 0.0195, 0.0195, 0.0193, 0.0215, 0.0302, 0.0193, 0.0196, 0.0196, 0.0243, 0.0193, 0.0193, 0.02], 'AP': [0.0178, 0.0188, 0.0089, 0.0096, 0.0117, 0.0095, 0.0092, 0.0086, 0.0097, 0.01, 0.0098, 0.0113, 0.0155, 0.0093, 0.0097, 0.0105, 0.0097, 0.0118, 0.0083, 0.0086, 0.0115, 0.0106, 0.0093, 0.0093, 0.0109, 0.0081, 0.0096, 0.0099, 0.0092, 0.0094, 0.0101, 0.0101, 0.0084, 0.0115, 0.0082, 0.0088, 0.0097, 0.01, 0.0092, 0.0087, 0.0095, 0.009, 0.0091, 0.0098, 0.0086, 0.0096, 0.0102, 0.0113, 0.0105, 0.0105, 0.0101, 0.0098, 0.0093, 0.0097, 0.0081, 0.0119, 0.0078, 0.0108, 0.01, 0.0107, 0.0081, 0.0088, 0.01, 0.0118, 0.0097, 0.0088, 0.0116, 0.0094, 0.0115, 0.0112, 0.0107, 0.0108, 0.0096, 0.0097, 0.0094, 0.0108, 0.0089, 0.0084, 0.0141, 0.0117, 0.0093, 0.0092, 0.0112, 0.0097, 0.0097, 0.0094, 0.0092, 0.0099, 0.008, 0.0099, 0.0098, 0.0073, 0.0099, 0.0125, 0.0086, 0.0099, 0.01, 0.0117, 0.0097, 0.0094, 0.0098], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0101, 'weighted': 0.0102}
2024-07-17 04:44:46 - [34m[1mLOGS   [0m - Best checkpoint with score 0.98 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:44:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:44:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:44:54 - [34m[1mLOGS   [0m - Training checkpoint for epoch 1/iteration 234 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_1_iter_234.pt
2024-07-17 04:44:55 - [34m[1mLOGS   [0m - Model state for epoch 1/iteration 234 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_1_iter_234.pt
[31m===========================================================================[0m
2024-07-17 04:44:57 - [32m[1mINFO   [0m - Training epoch 2
2024-07-17 04:44:58 - [34m[1mLOGS   [0m - Epoch:   2 [     235/10000000], loss: {'classification': 4.647, 'neural_augmentation': 0.0866, 'total_loss': 4.7336}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 0.659, Elapsed time:  0.87
2024-07-17 04:45:22 - [34m[1mLOGS   [0m - *** Training summary for epoch 2
	 loss={'classification': 4.6346, 'neural_augmentation': 0.0813, 'total_loss': 4.716}
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:45:33 - [34m[1mLOGS   [0m - *** Validation summary for epoch 2
	 loss={'classification': 4.6208, 'neural_augmentation': 0.0, 'total_loss': 4.6208} || top1={'logits': 0.9766} || top5={'logits': 4.8828} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0413, 0.0267, 0.02, 0.0255, 0.0233, 0.0194, 0.0254, 0.0404, 0.0233, 0.0206, 0.0195, 0.0317, 0.0196, 0.0193, 0.0194, 0.0214, 0.02, 0.0216, 0.0195, 0.0204, 0.0243, 0.0193, 0.021, 0.0194, 0.0201, 0.0219, 0.0217, 0.0232, 0.0194, 0.0216, 0.02, 0.0207, 0.0195, 0.0206, 0.0199, 0.0238, 0.021, 0.0236, 0.0222, 0.0221, 0.0204, 0.0219, 0.0213, 0.0206, 0.02, 0.0194, 0.0234, 0.0198, 0.0291, 0.0206, 0.0194, 0.0225, 0.02, 0.0255, 0.0211, 0.0249, 0.0229, 0.0219, 0.02, 0.0196, 0.0199, 0.0287, 0.0194, 0.0208, 0.0198, 0.0209, 0.0236, 0.0206, 0.0193, 0.0201, 0.0205, 0.0193, 0.0226, 0.0223, 0.0201, 0.0194, 0.0201, 0.0217, 0.0203, 0.0226, 0.0197, 0.023, 0.0203, 0.0194, 0.0305, 0.0218, 0.0225, 0.0195, 0.021, 0.0196, 0.0243, 0.0203, 0.0212, 0.0214, 0.0254, 0.0199, 0.0216, 0.02, 0.02, 0.0195, 0.0197], 'AP': [0.021, 0.0124, 0.0098, 0.01, 0.011, 0.0095, 0.0116, 0.0127, 0.0106, 0.0099, 0.0091, 0.0125, 0.0094, 0.0091, 0.0096, 0.0107, 0.009, 0.0097, 0.009, 0.0098, 0.0108, 0.0094, 0.0103, 0.0096, 0.0098, 0.0106, 0.0116, 0.0112, 0.0088, 0.0104, 0.01, 0.0098, 0.0095, 0.0098, 0.0099, 0.0113, 0.0101, 0.0105, 0.0102, 0.0101, 0.0101, 0.0096, 0.01, 0.01, 0.01, 0.0091, 0.0109, 0.0091, 0.0113, 0.01, 0.0093, 0.0103, 0.0094, 0.0102, 0.0098, 0.0112, 0.0104, 0.0099, 0.0099, 0.0097, 0.0099, 0.011, 0.0096, 0.0098, 0.0097, 0.01, 0.0107, 0.0099, 0.0091, 0.0101, 0.0096, 0.009, 0.0104, 0.0107, 0.0093, 0.0095, 0.0092, 0.0113, 0.0097, 0.0118, 0.0089, 0.0108, 0.0099, 0.0096, 0.012, 0.0102, 0.0103, 0.0093, 0.0099, 0.0096, 0.0102, 0.0095, 0.01, 0.0103, 0.0113, 0.0097, 0.0104, 0.0093, 0.0098, 0.0102, 0.0094], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0102, 'weighted': 0.0103}
2024-07-17 04:45:36 - [34m[1mLOGS   [0m - Best checkpoint with score 0.98 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:45:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:45:40 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:45:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 2/iteration 354 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_2_iter_354.pt
2024-07-17 04:45:43 - [34m[1mLOGS   [0m - Model state for epoch 2/iteration 354 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_2_iter_354.pt
[31m===========================================================================[0m
2024-07-17 04:45:45 - [32m[1mINFO   [0m - Training epoch 3
2024-07-17 04:45:46 - [34m[1mLOGS   [0m - Epoch:   3 [     355/10000000], loss: {'classification': 4.6204, 'neural_augmentation': 0.0872, 'total_loss': 4.7076}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 0.714, Elapsed time:  0.93
2024-07-17 04:46:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 3
	 loss={'classification': 4.6173, 'neural_augmentation': 0.0805, 'total_loss': 4.6978}
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:46:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 3
	 loss={'classification': 4.6159, 'neural_augmentation': 0.0, 'total_loss': 4.6159} || top1={'logits': 0.9766} || top5={'logits': 4.8242} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0421, 0.0268, 0.0246, 0.0194, 0.0239, 0.021, 0.0224, 0.029, 0.0259, 0.0199, 0.0214, 0.0199, 0.0223, 0.0248, 0.02, 0.0196, 0.0242, 0.0202, 0.025, 0.0195, 0.0194, 0.0196, 0.0272, 0.0199, 0.0446, 0.0197, 0.0226, 0.0196, 0.0196, 0.0194, 0.0197, 0.0195, 0.0202, 0.0193, 0.0236, 0.0282, 0.0221, 0.0241, 0.0198, 0.0194, 0.0209, 0.0202, 0.0195, 0.0234, 0.0194, 0.0268, 0.0194, 0.0213, 0.02, 0.0222, 0.0225, 0.0196, 0.0225, 0.0204, 0.0209, 0.0279, 0.0194, 0.0194, 0.0201, 0.0195, 0.0211, 0.0234, 0.02, 0.0219, 0.0543, 0.0538, 0.0196, 0.0198, 0.0255, 0.0194, 0.0195, 0.0196, 0.0206, 0.0351, 0.021, 0.0195, 0.0255, 0.0196, 0.0222, 0.0196, 0.0216, 0.0245, 0.0203, 0.0237, 0.0223, 0.0209, 0.0193, 0.0211, 0.0292, 0.0196, 0.0211, 0.0282, 0.0195, 0.021, 0.0224, 0.0215, 0.0215, 0.02, 0.0193, 0.0208, 0.02], 'AP': [0.0203, 0.0126, 0.0116, 0.0093, 0.01, 0.0099, 0.0104, 0.0125, 0.0103, 0.009, 0.0101, 0.0091, 0.0095, 0.0102, 0.0092, 0.0089, 0.0109, 0.0099, 0.0105, 0.0093, 0.0092, 0.009, 0.012, 0.0092, 0.0143, 0.0094, 0.0102, 0.0087, 0.0097, 0.0092, 0.0088, 0.0088, 0.01, 0.0084, 0.011, 0.0113, 0.0104, 0.0111, 0.0094, 0.009, 0.0103, 0.0096, 0.0094, 0.0109, 0.0093, 0.0113, 0.0095, 0.0103, 0.0097, 0.0103, 0.01, 0.0093, 0.0099, 0.0099, 0.0101, 0.0109, 0.0096, 0.009, 0.0098, 0.0093, 0.01, 0.0108, 0.01, 0.0101, 0.0144, 0.0158, 0.0084, 0.0089, 0.0102, 0.0088, 0.0098, 0.0095, 0.0102, 0.0118, 0.0096, 0.0085, 0.0098, 0.0097, 0.0105, 0.0094, 0.0101, 0.0111, 0.0105, 0.01, 0.0103, 0.0099, 0.009, 0.0105, 0.0114, 0.0091, 0.0105, 0.0108, 0.0093, 0.01, 0.0105, 0.0099, 0.0101, 0.0097, 0.0092, 0.0104, 0.0095], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0102, 'weighted': 0.0103}
2024-07-17 04:46:21 - [34m[1mLOGS   [0m - Best checkpoint with score 0.98 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:46:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:46:27 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:46:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 3/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_3_iter_465.pt
2024-07-17 04:46:29 - [34m[1mLOGS   [0m - Model state for epoch 3/iteration 465 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_3_iter_465.pt
[31m===========================================================================[0m
2024-07-17 04:46:31 - [32m[1mINFO   [0m - Training epoch 4
2024-07-17 04:46:32 - [34m[1mLOGS   [0m - Epoch:   4 [     466/10000000], loss: {'classification': 4.6164, 'neural_augmentation': 0.0766, 'total_loss': 4.693}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 0.322, Elapsed time:  0.54
2024-07-17 04:46:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 4
	 loss={'classification': 4.6162, 'neural_augmentation': 0.0805, 'total_loss': 4.6967}
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 4
	 loss={'classification': 4.6158, 'neural_augmentation': 0.0, 'total_loss': 4.6158} || top1={'logits': 1.3086} || top5={'logits': 4.8516} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.056, 0.0269, 0.0319, 0.023, 0.02, 0.0195, 0.0233, 0.0587, 0.0206, 0.0213, 0.0267, 0.0207, 0.0195, 0.0202, 0.02, 0.0195, 0.0237, 0.0194, 0.0211, 0.0338, 0.0194, 0.0204, 0.02, 0.021, 0.0369, 0.02, 0.0195, 0.0279, 0.0193, 0.0199, 0.0206, 0.0194, 0.0273, 0.0229, 0.0204, 0.0321, 0.0234, 0.0325, 0.0285, 0.0199, 0.0209, 0.0215, 0.0216, 0.022, 0.0207, 0.0259, 0.0201, 0.0224, 0.0198, 0.0251, 0.0226, 0.0291, 0.023, 0.0204, 0.0206, 0.0204, 0.0193, 0.0223, 0.0251, 0.0199, 0.021, 0.0214, 0.0199, 0.0198, 0.0574, 0.0642, 0.0195, 0.0222, 0.0211, 0.0203, 0.0233, 0.0194, 0.0237, 0.0258, 0.0227, 0.0198, 0.0237, 0.0272, 0.0312, 0.0197, 0.0211, 0.0238, 0.02, 0.022, 0.0257, 0.0331, 0.023, 0.0207, 0.0339, 0.0237, 0.0229, 0.0374, 0.0196, 0.0194, 0.0215, 0.0194, 0.0206, 0.0194, 0.0194, 0.0237, 0.02], 'AP': [0.0235, 0.0115, 0.013, 0.0111, 0.0094, 0.0088, 0.0113, 0.0234, 0.0098, 0.0097, 0.0116, 0.0094, 0.0088, 0.0098, 0.0098, 0.0096, 0.0103, 0.009, 0.01, 0.0149, 0.0078, 0.0098, 0.0094, 0.0097, 0.0144, 0.0097, 0.0094, 0.0115, 0.0091, 0.0088, 0.0102, 0.0089, 0.0114, 0.0102, 0.0097, 0.0117, 0.0097, 0.0115, 0.0114, 0.0097, 0.0101, 0.0102, 0.0103, 0.0105, 0.0097, 0.0115, 0.0097, 0.0099, 0.0093, 0.0114, 0.0102, 0.0127, 0.0103, 0.0097, 0.0102, 0.0101, 0.0093, 0.01, 0.0109, 0.0093, 0.0098, 0.0102, 0.01, 0.0096, 0.0217, 0.0232, 0.0086, 0.0103, 0.0103, 0.0093, 0.0101, 0.0089, 0.0107, 0.0115, 0.0105, 0.0089, 0.0105, 0.0121, 0.0111, 0.0083, 0.01, 0.0113, 0.009, 0.0102, 0.0116, 0.0111, 0.0101, 0.0099, 0.0154, 0.0105, 0.0106, 0.0159, 0.0094, 0.009, 0.01, 0.009, 0.01, 0.0092, 0.0095, 0.0102, 0.0094], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0099, 'macro': 0.0108, 'weighted': 0.0109}
2024-07-17 04:47:07 - [34m[1mLOGS   [0m - Best checkpoint with score 1.31 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:47:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:47:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:47:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 4/iteration 568 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_4_iter_568.pt
2024-07-17 04:47:14 - [34m[1mLOGS   [0m - Model state for epoch 4/iteration 568 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_4_iter_568.pt
[31m===========================================================================[0m
2024-07-17 04:47:16 - [32m[1mINFO   [0m - Training epoch 5
2024-07-17 04:47:18 - [34m[1mLOGS   [0m - Epoch:   5 [     569/10000000], loss: {'classification': 4.6144, 'neural_augmentation': 0.0788, 'total_loss': 4.6933}, LR: [3e-05, 3e-05], Avg. batch load time: 1.748, Elapsed time:  1.96
2024-07-17 04:47:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 5
	 loss={'classification': 4.6159, 'neural_augmentation': 0.0802, 'total_loss': 4.6962}
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:47:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 5
	 loss={'classification': 4.6169, 'neural_augmentation': 0.0, 'total_loss': 4.6169} || top1={'logits': 0.9766} || top5={'logits': 4.8867} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0477, 0.0271, 0.0316, 0.0223, 0.0233, 0.0194, 0.0217, 0.0414, 0.0235, 0.0196, 0.0215, 0.0194, 0.0193, 0.0271, 0.025, 0.0195, 0.0196, 0.0203, 0.0247, 0.0221, 0.0195, 0.0204, 0.0206, 0.0251, 0.0221, 0.0308, 0.0199, 0.0207, 0.0194, 0.0194, 0.0195, 0.0261, 0.0264, 0.0194, 0.0202, 0.0213, 0.0236, 0.0321, 0.0212, 0.0194, 0.0245, 0.0242, 0.0203, 0.0235, 0.0206, 0.0293, 0.0227, 0.0249, 0.0205, 0.0259, 0.0213, 0.0316, 0.0203, 0.0194, 0.0268, 0.0201, 0.0214, 0.0235, 0.0194, 0.0228, 0.0245, 0.0292, 0.0196, 0.0194, 0.0495, 0.0597, 0.0197, 0.0193, 0.0255, 0.0195, 0.0197, 0.0194, 0.0217, 0.0194, 0.0205, 0.0202, 0.0194, 0.0222, 0.0196, 0.0194, 0.0198, 0.0234, 0.0307, 0.0258, 0.0322, 0.0242, 0.0222, 0.0216, 0.0283, 0.0209, 0.0239, 0.0524, 0.0197, 0.0223, 0.0245, 0.0194, 0.0211, 0.0194, 0.0207, 0.0198, 0.0199], 'AP': [0.0238, 0.013, 0.0123, 0.0099, 0.0096, 0.0086, 0.0102, 0.0168, 0.0104, 0.0092, 0.0101, 0.0092, 0.0089, 0.0113, 0.0105, 0.0094, 0.0094, 0.0092, 0.0114, 0.0107, 0.008, 0.0097, 0.0098, 0.0104, 0.0102, 0.0117, 0.0094, 0.0101, 0.0091, 0.0091, 0.0096, 0.011, 0.0117, 0.0102, 0.0096, 0.0103, 0.0106, 0.0124, 0.0103, 0.0093, 0.0101, 0.0107, 0.0095, 0.0104, 0.01, 0.0105, 0.0104, 0.011, 0.0093, 0.011, 0.0099, 0.0129, 0.01, 0.0089, 0.0105, 0.0095, 0.0101, 0.0086, 0.0091, 0.0105, 0.0107, 0.0119, 0.0095, 0.0091, 0.0208, 0.0272, 0.0093, 0.0089, 0.0099, 0.0095, 0.0094, 0.0077, 0.0108, 0.0091, 0.0096, 0.0093, 0.0088, 0.0108, 0.0089, 0.0082, 0.0098, 0.0099, 0.0118, 0.011, 0.0122, 0.0108, 0.0101, 0.0109, 0.0131, 0.0101, 0.0109, 0.0168, 0.0097, 0.0097, 0.0108, 0.0087, 0.01, 0.0092, 0.0099, 0.0094, 0.0097], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0098, 'macro': 0.0106, 'weighted': 0.0108}
2024-07-17 04:47:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:47:59 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:48:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 5/iteration 684 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_5_iter_684.pt
2024-07-17 04:48:02 - [34m[1mLOGS   [0m - Model state for epoch 5/iteration 684 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_5_iter_684.pt
[31m===========================================================================[0m
2024-07-17 04:48:04 - [32m[1mINFO   [0m - Training epoch 6
2024-07-17 04:48:06 - [34m[1mLOGS   [0m - Epoch:   6 [     685/10000000], loss: {'classification': 4.6164, 'neural_augmentation': 0.0797, 'total_loss': 4.6961}, LR: [3e-05, 3e-05], Avg. batch load time: 1.946, Elapsed time:  2.16
2024-07-17 04:48:30 - [34m[1mLOGS   [0m - *** Training summary for epoch 6
	 loss={'classification': 4.6166, 'neural_augmentation': 0.0805, 'total_loss': 4.697}
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:38 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:48:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 6
	 loss={'classification': 4.6166, 'neural_augmentation': 0.0, 'total_loss': 4.6166} || top1={'logits': 0.9766} || top5={'logits': 4.832} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.051, 0.0267, 0.0256, 0.0249, 0.0197, 0.0209, 0.0214, 0.0426, 0.0197, 0.0204, 0.0204, 0.0195, 0.0194, 0.0224, 0.0239, 0.021, 0.022, 0.0198, 0.0202, 0.0214, 0.0194, 0.0194, 0.0196, 0.0269, 0.0219, 0.0215, 0.0194, 0.0218, 0.0212, 0.0198, 0.0198, 0.0194, 0.0304, 0.0208, 0.0222, 0.0297, 0.0211, 0.0245, 0.0231, 0.0311, 0.0196, 0.0233, 0.0281, 0.0202, 0.0268, 0.0274, 0.023, 0.0194, 0.0204, 0.0213, 0.0207, 0.023, 0.0241, 0.0226, 0.0206, 0.0217, 0.0206, 0.0204, 0.0195, 0.0298, 0.0281, 0.0212, 0.0215, 0.0193, 0.0633, 0.0814, 0.0194, 0.0194, 0.0269, 0.021, 0.0195, 0.0194, 0.0219, 0.0214, 0.023, 0.0251, 0.0233, 0.0276, 0.0195, 0.0354, 0.0196, 0.0327, 0.0237, 0.0268, 0.0347, 0.0226, 0.0244, 0.0251, 0.023, 0.0266, 0.0238, 0.037, 0.0194, 0.0194, 0.0259, 0.022, 0.0233, 0.0197, 0.0213, 0.0222, 0.021], 'AP': [0.0265, 0.0109, 0.0116, 0.0111, 0.0092, 0.0098, 0.0098, 0.0186, 0.009, 0.0096, 0.0098, 0.0086, 0.0089, 0.0104, 0.0108, 0.0097, 0.0107, 0.0093, 0.0098, 0.0103, 0.0077, 0.0081, 0.0097, 0.0116, 0.0106, 0.0099, 0.009, 0.0111, 0.0096, 0.009, 0.0097, 0.0084, 0.0123, 0.0096, 0.0099, 0.0117, 0.0093, 0.0113, 0.0108, 0.0117, 0.0096, 0.0107, 0.0118, 0.0095, 0.0116, 0.0111, 0.0108, 0.0088, 0.0092, 0.0096, 0.0095, 0.0105, 0.0107, 0.0101, 0.0096, 0.0105, 0.0101, 0.0096, 0.0093, 0.0111, 0.0117, 0.0102, 0.0105, 0.0088, 0.0215, 0.0392, 0.0089, 0.0087, 0.0109, 0.0098, 0.0086, 0.0078, 0.0101, 0.0101, 0.011, 0.0104, 0.0101, 0.012, 0.0093, 0.0119, 0.0098, 0.0114, 0.0107, 0.0108, 0.0114, 0.0107, 0.0108, 0.0108, 0.0111, 0.0107, 0.0117, 0.0175, 0.0092, 0.0077, 0.0109, 0.0099, 0.0108, 0.0088, 0.01, 0.0105, 0.0099], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0098, 'macro': 0.0109, 'weighted': 0.011}
2024-07-17 04:48:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:48:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:48:48 - [34m[1mLOGS   [0m - Training checkpoint for epoch 6/iteration 798 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_6_iter_798.pt
2024-07-17 04:48:49 - [34m[1mLOGS   [0m - Model state for epoch 6/iteration 798 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_6_iter_798.pt
[31m===========================================================================[0m
2024-07-17 04:48:51 - [32m[1mINFO   [0m - Training epoch 7
2024-07-17 04:48:53 - [34m[1mLOGS   [0m - Epoch:   7 [     799/10000000], loss: {'classification': 4.615, 'neural_augmentation': 0.0819, 'total_loss': 4.6969}, LR: [3e-05, 3e-05], Avg. batch load time: 1.860, Elapsed time:  2.07
2024-07-17 04:49:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 7
	 loss={'classification': 4.616, 'neural_augmentation': 0.0794, 'total_loss': 4.6954}
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:49:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 7
	 loss={'classification': 4.615, 'neural_augmentation': 0.0, 'total_loss': 4.615} || top1={'logits': 0.9766} || top5={'logits': 5.0898} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0561, 0.0266, 0.035, 0.022, 0.0195, 0.0194, 0.0226, 0.0755, 0.0201, 0.0199, 0.0209, 0.0196, 0.0194, 0.0241, 0.0221, 0.0194, 0.0279, 0.0233, 0.0226, 0.0215, 0.0194, 0.0194, 0.0241, 0.0241, 0.052, 0.0218, 0.0194, 0.0271, 0.0206, 0.0201, 0.0309, 0.0216, 0.0278, 0.0214, 0.0194, 0.0296, 0.0199, 0.0366, 0.0224, 0.0194, 0.0211, 0.0204, 0.0225, 0.0223, 0.0216, 0.0204, 0.0274, 0.0207, 0.02, 0.0232, 0.0216, 0.03, 0.0315, 0.0226, 0.0229, 0.0271, 0.0246, 0.0198, 0.021, 0.0199, 0.0257, 0.0222, 0.0273, 0.0194, 0.0573, 0.1034, 0.0194, 0.0194, 0.0203, 0.0201, 0.0195, 0.0194, 0.0287, 0.0201, 0.0204, 0.0206, 0.0226, 0.0352, 0.0229, 0.0194, 0.0202, 0.023, 0.0229, 0.0343, 0.0374, 0.0194, 0.0194, 0.0249, 0.0306, 0.0232, 0.0285, 0.0657, 0.0195, 0.0194, 0.0237, 0.0194, 0.0282, 0.0194, 0.0206, 0.0211, 0.0243], 'AP': [0.0258, 0.0121, 0.0151, 0.0105, 0.0091, 0.0086, 0.0112, 0.0273, 0.0096, 0.0093, 0.0097, 0.0088, 0.0077, 0.0104, 0.0101, 0.0089, 0.013, 0.0103, 0.0102, 0.0102, 0.0074, 0.0078, 0.0104, 0.0118, 0.0168, 0.0105, 0.0089, 0.0112, 0.0087, 0.0093, 0.0125, 0.0098, 0.0124, 0.0086, 0.0085, 0.0127, 0.0093, 0.0126, 0.0107, 0.0098, 0.0103, 0.0099, 0.0101, 0.0103, 0.0102, 0.0095, 0.0119, 0.009, 0.0083, 0.011, 0.0105, 0.0117, 0.0131, 0.0104, 0.01, 0.0101, 0.0096, 0.0088, 0.0096, 0.0093, 0.0118, 0.0106, 0.0116, 0.0087, 0.022, 0.0493, 0.009, 0.0079, 0.0101, 0.0094, 0.0093, 0.0079, 0.0118, 0.0094, 0.0095, 0.0095, 0.0101, 0.013, 0.0095, 0.0075, 0.0091, 0.0113, 0.0106, 0.0143, 0.0166, 0.0096, 0.0091, 0.0106, 0.014, 0.0109, 0.012, 0.027, 0.0092, 0.0082, 0.0105, 0.0083, 0.0114, 0.0087, 0.0106, 0.0102, 0.0118], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0099, 'macro': 0.0113, 'weighted': 0.0115}
2024-07-17 04:49:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:49:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:49:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 7/iteration 919 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_7_iter_919.pt
2024-07-17 04:49:37 - [34m[1mLOGS   [0m - Model state for epoch 7/iteration 919 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_7_iter_919.pt
[31m===========================================================================[0m
2024-07-17 04:49:39 - [32m[1mINFO   [0m - Training epoch 8
2024-07-17 04:49:40 - [34m[1mLOGS   [0m - Epoch:   8 [     920/10000000], loss: {'classification': 4.6127, 'neural_augmentation': 0.0761, 'total_loss': 4.6887}, LR: [3e-05, 3e-05], Avg. batch load time: 0.487, Elapsed time:  0.70
2024-07-17 04:50:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 8
	 loss={'classification': 4.616, 'neural_augmentation': 0.0779, 'total_loss': 4.6939}
2024-07-17 04:50:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 8
	 loss={'classification': 4.6164, 'neural_augmentation': 0.0, 'total_loss': 4.6164} || top1={'logits': 0.9727} || top5={'logits': 4.6914} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0409, 0.0265, 0.021, 0.0233, 0.02, 0.0193, 0.0257, 0.0407, 0.0254, 0.0235, 0.0206, 0.0197, 0.0208, 0.0322, 0.0209, 0.0281, 0.0194, 0.0211, 0.0208, 0.02, 0.0249, 0.0288, 0.029, 0.0193, 0.0262, 0.0194, 0.0219, 0.025, 0.0259, 0.0256, 0.0465, 0.0247, 0.0193, 0.0201, 0.022, 0.0312, 0.0194, 0.0201, 0.0217, 0.0385, 0.0231, 0.0229, 0.0201, 0.0206, 0.0201, 0.0196, 0.0238, 0.0219, 0.0194, 0.0211, 0.0201, 0.0193, 0.0248, 0.0249, 0.0201, 0.0196, 0.0206, 0.0194, 0.0311, 0.0261, 0.0209, 0.0198, 0.0307, 0.0196, 0.0249, 0.0678, 0.0294, 0.0228, 0.0219, 0.026, 0.0228, 0.0223, 0.0207, 0.0196, 0.0237, 0.0202, 0.022, 0.0333, 0.0217, 0.0253, 0.0198, 0.027, 0.0219, 0.0317, 0.0214, 0.0196, 0.0252, 0.0197, 0.0477, 0.0218, 0.0203, 0.0235, 0.0198, 0.0227, 0.0264, 0.0254, 0.0209, 0.0194, 0.0196, 0.0313, 0.028], 'AP': [0.0196, 0.0125, 0.0096, 0.0106, 0.0099, 0.0085, 0.0121, 0.0179, 0.0116, 0.0109, 0.0098, 0.0094, 0.0094, 0.0129, 0.0101, 0.0104, 0.0076, 0.0097, 0.0096, 0.0092, 0.0102, 0.0139, 0.0125, 0.0088, 0.012, 0.0088, 0.0104, 0.01, 0.0108, 0.011, 0.0159, 0.0115, 0.0085, 0.0096, 0.0102, 0.012, 0.0093, 0.0089, 0.0122, 0.0127, 0.01, 0.0098, 0.0098, 0.0098, 0.0089, 0.0095, 0.0109, 0.0101, 0.0074, 0.0097, 0.0095, 0.0086, 0.0115, 0.0113, 0.0091, 0.0085, 0.0093, 0.0085, 0.0114, 0.0109, 0.0096, 0.0091, 0.0127, 0.0095, 0.0091, 0.0204, 0.0122, 0.0109, 0.0121, 0.0099, 0.0108, 0.0099, 0.0095, 0.0091, 0.0105, 0.0086, 0.0096, 0.0127, 0.0098, 0.0113, 0.0094, 0.0122, 0.0104, 0.0119, 0.0097, 0.0087, 0.0106, 0.0089, 0.0151, 0.0098, 0.0088, 0.0096, 0.0092, 0.0112, 0.0118, 0.0111, 0.0092, 0.0087, 0.0095, 0.0122, 0.0122], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0098, 'macro': 0.0106, 'weighted': 0.0107}
2024-07-17 04:50:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:50:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:50:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 8/iteration 1028 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_8_iter_1028.pt
2024-07-17 04:50:21 - [34m[1mLOGS   [0m - Model state for epoch 8/iteration 1028 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_8_iter_1028.pt
[31m===========================================================================[0m
2024-07-17 04:50:24 - [32m[1mINFO   [0m - Training epoch 9
2024-07-17 04:50:25 - [34m[1mLOGS   [0m - Epoch:   9 [    1029/10000000], loss: {'classification': 4.6161, 'neural_augmentation': 0.0863, 'total_loss': 4.7024}, LR: [3e-05, 3e-05], Avg. batch load time: 0.826, Elapsed time:  1.04
2024-07-17 04:50:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 9
	 loss={'classification': 4.6161, 'neural_augmentation': 0.0778, 'total_loss': 4.6939}
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:50:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 9
	 loss={'classification': 4.6152, 'neural_augmentation': 0.0, 'total_loss': 4.6152} || top1={'logits': 0.9766} || top5={'logits': 5.0391} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0514, 0.0266, 0.0261, 0.0209, 0.0203, 0.0221, 0.0319, 0.0709, 0.0345, 0.0199, 0.0196, 0.0203, 0.0194, 0.0232, 0.0222, 0.0218, 0.0295, 0.024, 0.0194, 0.0195, 0.0197, 0.0193, 0.0307, 0.022, 0.0251, 0.0202, 0.0195, 0.0229, 0.0199, 0.0228, 0.0385, 0.0208, 0.0246, 0.0202, 0.0199, 0.0263, 0.0197, 0.0296, 0.0194, 0.0268, 0.0201, 0.027, 0.0229, 0.0252, 0.0196, 0.0213, 0.0251, 0.0199, 0.0197, 0.0211, 0.0217, 0.0244, 0.0279, 0.0277, 0.0194, 0.0204, 0.0195, 0.0201, 0.0234, 0.0211, 0.0218, 0.0242, 0.0281, 0.0194, 0.0428, 0.1284, 0.0196, 0.0214, 0.0235, 0.023, 0.0252, 0.0194, 0.0224, 0.0241, 0.0201, 0.0214, 0.0252, 0.037, 0.02, 0.0194, 0.0195, 0.0304, 0.0226, 0.0384, 0.024, 0.0207, 0.0279, 0.0195, 0.0326, 0.0264, 0.0257, 0.0325, 0.0204, 0.0193, 0.0258, 0.0262, 0.0284, 0.032, 0.02, 0.03, 0.0211], 'AP': [0.0259, 0.0109, 0.0112, 0.0101, 0.0092, 0.0102, 0.0113, 0.0271, 0.0124, 0.0093, 0.0091, 0.01, 0.0086, 0.0101, 0.01, 0.0095, 0.0119, 0.0109, 0.0089, 0.0091, 0.009, 0.0078, 0.0127, 0.0098, 0.0122, 0.0097, 0.0088, 0.0106, 0.0088, 0.0108, 0.0131, 0.0099, 0.0109, 0.0094, 0.0083, 0.0108, 0.0092, 0.0125, 0.0093, 0.0109, 0.0088, 0.0107, 0.0108, 0.0101, 0.0089, 0.0104, 0.0129, 0.009, 0.0081, 0.0105, 0.0103, 0.0146, 0.0109, 0.0107, 0.0086, 0.0094, 0.0091, 0.01, 0.0111, 0.01, 0.0104, 0.011, 0.0117, 0.0091, 0.0152, 0.05, 0.0083, 0.0099, 0.0104, 0.0101, 0.0112, 0.0085, 0.0101, 0.0105, 0.0095, 0.0099, 0.0109, 0.0156, 0.0112, 0.0092, 0.0093, 0.0114, 0.0103, 0.0165, 0.0113, 0.0098, 0.0106, 0.0094, 0.0136, 0.0118, 0.0118, 0.0149, 0.0094, 0.0087, 0.0113, 0.0095, 0.0108, 0.0113, 0.0098, 0.0118, 0.0128], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0112, 'weighted': 0.0114}
2024-07-17 04:51:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:51:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:51:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 9/iteration 1140 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_9_iter_1140.pt
2024-07-17 04:51:07 - [34m[1mLOGS   [0m - Model state for epoch 9/iteration 1140 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_9_iter_1140.pt
[31m===========================================================================[0m
2024-07-17 04:51:09 - [32m[1mINFO   [0m - Training epoch 10
2024-07-17 04:51:10 - [34m[1mLOGS   [0m - Epoch:  10 [    1141/10000000], loss: {'classification': 4.615, 'neural_augmentation': 0.088, 'total_loss': 4.703}, LR: [3e-05, 3e-05], Avg. batch load time: 0.860, Elapsed time:  1.07
2024-07-17 04:51:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 10
	 loss={'classification': 4.6159, 'neural_augmentation': 0.077, 'total_loss': 4.6929}
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:51:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 10
	 loss={'classification': 4.6146, 'neural_augmentation': 0.0, 'total_loss': 4.6146} || top1={'logits': 1.0391} || top5={'logits': 5.0078} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.054, 0.0265, 0.0278, 0.0255, 0.0198, 0.0194, 0.0207, 0.0948, 0.0239, 0.0194, 0.0195, 0.0195, 0.0196, 0.0256, 0.0237, 0.0196, 0.0317, 0.0274, 0.0195, 0.037, 0.0194, 0.0193, 0.0285, 0.0219, 0.0303, 0.0239, 0.0198, 0.0223, 0.0194, 0.023, 0.0317, 0.0198, 0.0287, 0.0199, 0.02, 0.0403, 0.0203, 0.0417, 0.0199, 0.0209, 0.0196, 0.026, 0.0228, 0.0218, 0.0199, 0.0207, 0.0261, 0.0194, 0.0209, 0.0278, 0.0211, 0.0288, 0.03, 0.0233, 0.0197, 0.0199, 0.0194, 0.0196, 0.0194, 0.0217, 0.0195, 0.0376, 0.0306, 0.0194, 0.05, 0.1117, 0.0194, 0.0211, 0.0194, 0.0212, 0.0287, 0.0196, 0.02, 0.0196, 0.02, 0.024, 0.0199, 0.0326, 0.0333, 0.0194, 0.0203, 0.0284, 0.0286, 0.0418, 0.0313, 0.0205, 0.0276, 0.0215, 0.0447, 0.0258, 0.0312, 0.0713, 0.02, 0.0193, 0.0227, 0.0194, 0.0251, 0.0226, 0.0214, 0.0224, 0.0235], 'AP': [0.0246, 0.0105, 0.0127, 0.0099, 0.0092, 0.0085, 0.0096, 0.0338, 0.0107, 0.0088, 0.0092, 0.0094, 0.0079, 0.0113, 0.0104, 0.0091, 0.0138, 0.0123, 0.0086, 0.0123, 0.0078, 0.011, 0.0125, 0.0099, 0.013, 0.0106, 0.0093, 0.011, 0.0089, 0.0108, 0.0117, 0.009, 0.0128, 0.0085, 0.0093, 0.0128, 0.0096, 0.0166, 0.0096, 0.0101, 0.0088, 0.0121, 0.0102, 0.0097, 0.0091, 0.0096, 0.0114, 0.0086, 0.0088, 0.0118, 0.0101, 0.0129, 0.0111, 0.0116, 0.0085, 0.0092, 0.0087, 0.0091, 0.0084, 0.0105, 0.0094, 0.0153, 0.0123, 0.0087, 0.0178, 0.0369, 0.0086, 0.0094, 0.0089, 0.0103, 0.012, 0.0089, 0.0096, 0.0097, 0.0096, 0.0107, 0.0091, 0.0133, 0.0127, 0.0075, 0.0098, 0.0117, 0.0124, 0.0159, 0.0135, 0.0097, 0.0104, 0.0094, 0.0191, 0.0116, 0.0146, 0.028, 0.0094, 0.0078, 0.0103, 0.0077, 0.0114, 0.0108, 0.0105, 0.0104, 0.011], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0114, 'weighted': 0.0116}
2024-07-17 04:51:50 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:51:51 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:51:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 10/iteration 1254 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_10_iter_1254.pt
2024-07-17 04:51:53 - [34m[1mLOGS   [0m - Model state for epoch 10/iteration 1254 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_10_iter_1254.pt
[31m===========================================================================[0m
2024-07-17 04:51:55 - [32m[1mINFO   [0m - Training epoch 11
2024-07-17 04:51:56 - [34m[1mLOGS   [0m - Epoch:  11 [    1255/10000000], loss: {'classification': 4.6118, 'neural_augmentation': 0.0799, 'total_loss': 4.6917}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.578, Elapsed time:  0.79
2024-07-17 04:52:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 11
	 loss={'classification': 4.6161, 'neural_augmentation': 0.0772, 'total_loss': 4.6933}
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:26 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:52:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 11
	 loss={'classification': 4.6142, 'neural_augmentation': 0.0, 'total_loss': 4.6142} || top1={'logits': 1.1133} || top5={'logits': 5.0586} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0601, 0.0267, 0.0243, 0.0196, 0.0195, 0.0195, 0.0199, 0.0706, 0.0265, 0.02, 0.0198, 0.0223, 0.0202, 0.0237, 0.0254, 0.0197, 0.0311, 0.0319, 0.0194, 0.0251, 0.0195, 0.0194, 0.0321, 0.0219, 0.0243, 0.0258, 0.0212, 0.0217, 0.0204, 0.0246, 0.0311, 0.0195, 0.0276, 0.0194, 0.0198, 0.0286, 0.0206, 0.0309, 0.0194, 0.0197, 0.0204, 0.0219, 0.022, 0.0212, 0.02, 0.0195, 0.0258, 0.0194, 0.0203, 0.0216, 0.026, 0.0293, 0.0204, 0.0219, 0.0194, 0.0203, 0.0194, 0.0213, 0.0194, 0.0209, 0.0236, 0.0271, 0.0233, 0.0195, 0.0801, 0.1319, 0.0194, 0.0214, 0.0195, 0.0226, 0.0293, 0.0194, 0.0219, 0.0194, 0.0206, 0.0224, 0.0285, 0.029, 0.023, 0.0232, 0.0202, 0.0324, 0.0237, 0.0358, 0.0247, 0.02, 0.0196, 0.0215, 0.0355, 0.0273, 0.0288, 0.0394, 0.0194, 0.0194, 0.0207, 0.0299, 0.0215, 0.0219, 0.0275, 0.0288, 0.0216], 'AP': [0.0271, 0.0104, 0.0113, 0.0094, 0.0094, 0.0094, 0.0094, 0.0267, 0.0111, 0.0095, 0.0088, 0.0102, 0.0087, 0.011, 0.0115, 0.0092, 0.0133, 0.0125, 0.0081, 0.0111, 0.0085, 0.0079, 0.0123, 0.0104, 0.0113, 0.0114, 0.0096, 0.0105, 0.0093, 0.0103, 0.011, 0.0087, 0.0124, 0.0086, 0.0095, 0.0114, 0.0098, 0.0133, 0.009, 0.0091, 0.0095, 0.0102, 0.0099, 0.0099, 0.0091, 0.0089, 0.0113, 0.0083, 0.0084, 0.0103, 0.0109, 0.0117, 0.0103, 0.0125, 0.0081, 0.0092, 0.0084, 0.0094, 0.0085, 0.0095, 0.0103, 0.0119, 0.0109, 0.009, 0.0241, 0.0628, 0.0088, 0.0101, 0.0091, 0.0108, 0.014, 0.0087, 0.0101, 0.0085, 0.0095, 0.0112, 0.0114, 0.013, 0.0103, 0.0096, 0.0095, 0.0129, 0.0114, 0.0142, 0.0123, 0.0095, 0.0092, 0.0094, 0.0144, 0.0122, 0.0134, 0.0175, 0.0091, 0.0085, 0.0096, 0.0091, 0.0102, 0.0095, 0.0104, 0.0109, 0.0105], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.01, 'macro': 0.0113, 'weighted': 0.0115}
2024-07-17 04:52:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:52:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:52:36 - [34m[1mLOGS   [0m - Training checkpoint for epoch 11/iteration 1357 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_11_iter_1357.pt
2024-07-17 04:52:37 - [34m[1mLOGS   [0m - Model state for epoch 11/iteration 1357 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_11_iter_1357.pt
[31m===========================================================================[0m
2024-07-17 04:52:39 - [32m[1mINFO   [0m - Training epoch 12
2024-07-17 04:52:40 - [34m[1mLOGS   [0m - Epoch:  12 [    1358/10000000], loss: {'classification': 4.6139, 'neural_augmentation': 0.0797, 'total_loss': 4.6936}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.624, Elapsed time:  0.84
2024-07-17 04:53:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 12
	 loss={'classification': 4.6159, 'neural_augmentation': 0.0769, 'total_loss': 4.6928}
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:12 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:13 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:13 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:13 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:13 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 12
	 loss={'classification': 4.6151, 'neural_augmentation': 0.0, 'total_loss': 4.6151} || top1={'logits': 1.0547} || top5={'logits': 5.2656} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0515, 0.0265, 0.0404, 0.021, 0.02, 0.0195, 0.0211, 0.0887, 0.0241, 0.0194, 0.0202, 0.0207, 0.0196, 0.0225, 0.0248, 0.0208, 0.0345, 0.0292, 0.0195, 0.0221, 0.0194, 0.0193, 0.031, 0.0267, 0.0334, 0.0247, 0.0204, 0.0218, 0.0209, 0.0236, 0.0249, 0.02, 0.0263, 0.0218, 0.0218, 0.0304, 0.0207, 0.0459, 0.0204, 0.0206, 0.0234, 0.0235, 0.0227, 0.0202, 0.021, 0.0198, 0.045, 0.0204, 0.021, 0.0232, 0.0236, 0.03, 0.0222, 0.02, 0.0194, 0.0195, 0.0197, 0.0207, 0.0194, 0.021, 0.0245, 0.0233, 0.035, 0.0198, 0.068, 0.1279, 0.0196, 0.0213, 0.0195, 0.0228, 0.0316, 0.0194, 0.0334, 0.0194, 0.0201, 0.0237, 0.024, 0.0322, 0.0254, 0.0193, 0.0212, 0.0321, 0.0299, 0.0373, 0.0277, 0.0206, 0.0261, 0.0203, 0.0299, 0.0249, 0.0333, 0.0586, 0.0253, 0.0193, 0.0195, 0.0194, 0.0227, 0.0197, 0.0196, 0.0195, 0.0308], 'AP': [0.0238, 0.0102, 0.0159, 0.0096, 0.0091, 0.0084, 0.0098, 0.0279, 0.0112, 0.0083, 0.0089, 0.0096, 0.0078, 0.0108, 0.0107, 0.0097, 0.0141, 0.0124, 0.0086, 0.0102, 0.0077, 0.0067, 0.0124, 0.0111, 0.0139, 0.0111, 0.0094, 0.0103, 0.0092, 0.0109, 0.0102, 0.0089, 0.0128, 0.0099, 0.0105, 0.0121, 0.0096, 0.0166, 0.0095, 0.0097, 0.011, 0.0109, 0.0103, 0.0094, 0.0097, 0.0092, 0.0155, 0.0095, 0.0087, 0.011, 0.0107, 0.0147, 0.0103, 0.0096, 0.0083, 0.0091, 0.0086, 0.0104, 0.0084, 0.0103, 0.0113, 0.0111, 0.0127, 0.0091, 0.0223, 0.0481, 0.0083, 0.0097, 0.0095, 0.0102, 0.0129, 0.0082, 0.0144, 0.0094, 0.0095, 0.0111, 0.0105, 0.0126, 0.0127, 0.0079, 0.0095, 0.0124, 0.0131, 0.0155, 0.0131, 0.0099, 0.0103, 0.0097, 0.0141, 0.0114, 0.0151, 0.0269, 0.0103, 0.0076, 0.009, 0.008, 0.0108, 0.0118, 0.0099, 0.0096, 0.0123], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0], 'micro': 0.0103, 'macro': 0.0116, 'weighted': 0.0117}
2024-07-17 04:53:20 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:53:21 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:53:22 - [34m[1mLOGS   [0m - Training checkpoint for epoch 12/iteration 1473 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_12_iter_1473.pt
2024-07-17 04:53:23 - [34m[1mLOGS   [0m - Model state for epoch 12/iteration 1473 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_12_iter_1473.pt
[31m===========================================================================[0m
2024-07-17 04:53:25 - [32m[1mINFO   [0m - Training epoch 13
2024-07-17 04:53:26 - [34m[1mLOGS   [0m - Epoch:  13 [    1474/10000000], loss: {'classification': 4.6128, 'neural_augmentation': 0.0697, 'total_loss': 4.6824}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.715, Elapsed time:  0.93
2024-07-17 04:53:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 13
	 loss={'classification': 4.6149, 'neural_augmentation': 0.0778, 'total_loss': 4.6926}
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:53:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 13
	 loss={'classification': 4.6114, 'neural_augmentation': 0.0, 'total_loss': 4.6114} || top1={'logits': 1.1719} || top5={'logits': 6.8438} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0582, 0.0333, 0.0403, 0.0355, 0.0195, 0.0383, 0.0205, 0.0713, 0.022, 0.0194, 0.0204, 0.0226, 0.0195, 0.0234, 0.0227, 0.0194, 0.0285, 0.0262, 0.0198, 0.0241, 0.0194, 0.0195, 0.0327, 0.0244, 0.0355, 0.0257, 0.0204, 0.0235, 0.0213, 0.0246, 0.0301, 0.0202, 0.039, 0.0337, 0.0237, 0.0341, 0.022, 0.036, 0.0208, 0.0215, 0.024, 0.0228, 0.0201, 0.024, 0.0283, 0.0203, 0.0436, 0.0194, 0.0216, 0.0231, 0.0234, 0.0258, 0.0279, 0.0195, 0.0215, 0.0195, 0.0212, 0.0197, 0.02, 0.0282, 0.0379, 0.0264, 0.0312, 0.0194, 0.0408, 0.0908, 0.0194, 0.0195, 0.0216, 0.0232, 0.0351, 0.0194, 0.0276, 0.0197, 0.0231, 0.0268, 0.0198, 0.0394, 0.0278, 0.0194, 0.033, 0.0261, 0.043, 0.0361, 0.0427, 0.0195, 0.0198, 0.0225, 0.0354, 0.0291, 0.03, 0.0993, 0.02, 0.0246, 0.0197, 0.0195, 0.0245, 0.0197, 0.02, 0.0243, 0.0225], 'AP': [0.0263, 0.0126, 0.017, 0.0114, 0.0095, 0.0146, 0.0094, 0.0271, 0.0106, 0.0077, 0.0101, 0.0102, 0.0077, 0.0106, 0.0101, 0.009, 0.0124, 0.0152, 0.0087, 0.0116, 0.0074, 0.0075, 0.0144, 0.0111, 0.0137, 0.012, 0.0091, 0.0103, 0.0091, 0.0111, 0.0115, 0.0094, 0.0153, 0.0101, 0.0114, 0.0133, 0.0101, 0.0161, 0.0101, 0.0098, 0.0106, 0.0108, 0.0093, 0.0103, 0.0124, 0.0099, 0.0153, 0.0075, 0.0091, 0.0112, 0.011, 0.0118, 0.0118, 0.0094, 0.009, 0.008, 0.0095, 0.0094, 0.0089, 0.0125, 0.0156, 0.0118, 0.0117, 0.0083, 0.0176, 0.0353, 0.008, 0.009, 0.0102, 0.0108, 0.015, 0.0078, 0.0117, 0.0093, 0.0108, 0.0111, 0.0093, 0.0162, 0.0112, 0.0096, 0.0104, 0.0113, 0.0169, 0.0152, 0.0176, 0.0089, 0.0094, 0.0101, 0.016, 0.0143, 0.0138, 0.0399, 0.0093, 0.0084, 0.008, 0.0084, 0.0115, 0.0087, 0.0099, 0.0103, 0.0105], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0113, 'macro': 0.0119, 'weighted': 0.012}
2024-07-17 04:54:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:54:05 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:54:07 - [34m[1mLOGS   [0m - Training checkpoint for epoch 13/iteration 1579 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_13_iter_1579.pt
2024-07-17 04:54:07 - [34m[1mLOGS   [0m - Model state for epoch 13/iteration 1579 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_13_iter_1579.pt
[31m===========================================================================[0m
2024-07-17 04:54:09 - [32m[1mINFO   [0m - Training epoch 14
2024-07-17 04:54:11 - [34m[1mLOGS   [0m - Epoch:  14 [    1580/10000000], loss: {'classification': 4.6129, 'neural_augmentation': 0.0819, 'total_loss': 4.6948}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.325, Elapsed time:  1.54
2024-07-17 04:54:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 14
	 loss={'classification': 4.6142, 'neural_augmentation': 0.0774, 'total_loss': 4.6916}
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:43 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:54:44 - [34m[1mLOGS   [0m - *** Validation summary for epoch 14
	 loss={'classification': 4.6128, 'neural_augmentation': 0.0, 'total_loss': 4.6128} || top1={'logits': 0.9727} || top5={'logits': 5.332} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0505, 0.0516, 0.0344, 0.0311, 0.0202, 0.03, 0.0211, 0.0812, 0.0268, 0.02, 0.025, 0.0224, 0.0268, 0.0211, 0.0238, 0.0203, 0.0295, 0.0283, 0.0196, 0.0232, 0.0203, 0.0483, 0.0356, 0.0238, 0.0289, 0.024, 0.0199, 0.0254, 0.0212, 0.0243, 0.0215, 0.0194, 0.0321, 0.0359, 0.0294, 0.0454, 0.0242, 0.0395, 0.024, 0.0194, 0.0228, 0.0304, 0.0203, 0.0209, 0.0479, 0.0205, 0.0489, 0.0338, 0.0214, 0.0217, 0.0271, 0.0258, 0.0244, 0.0197, 0.0195, 0.0198, 0.0212, 0.0228, 0.0194, 0.0293, 0.0673, 0.0247, 0.0246, 0.0194, 0.0497, 0.1214, 0.0194, 0.0271, 0.0202, 0.0226, 0.0362, 0.0194, 0.0265, 0.0255, 0.0209, 0.0252, 0.0229, 0.0412, 0.0235, 0.0194, 0.0202, 0.027, 0.0441, 0.0414, 0.036, 0.0204, 0.0197, 0.0213, 0.0314, 0.0297, 0.0362, 0.113, 0.022, 0.0247, 0.02, 0.0196, 0.0237, 0.0195, 0.02, 0.0293, 0.022], 'AP': [0.0251, 0.0224, 0.0161, 0.0107, 0.0092, 0.0131, 0.0094, 0.0288, 0.011, 0.0079, 0.0102, 0.0099, 0.0122, 0.0103, 0.0105, 0.0092, 0.013, 0.0122, 0.0087, 0.0111, 0.0083, 0.0193, 0.0147, 0.011, 0.0127, 0.0109, 0.009, 0.0107, 0.0093, 0.0108, 0.0094, 0.009, 0.0138, 0.0119, 0.016, 0.0179, 0.0112, 0.0167, 0.0104, 0.0089, 0.0108, 0.0118, 0.0095, 0.0099, 0.0171, 0.0098, 0.0163, 0.0157, 0.009, 0.0105, 0.0117, 0.0119, 0.0109, 0.0094, 0.0086, 0.0083, 0.009, 0.0106, 0.0083, 0.0127, 0.0238, 0.0112, 0.0103, 0.0088, 0.019, 0.0439, 0.0078, 0.0119, 0.0106, 0.0104, 0.0148, 0.0087, 0.0111, 0.0108, 0.0097, 0.011, 0.0106, 0.0145, 0.0104, 0.0094, 0.0088, 0.0118, 0.0176, 0.0151, 0.0154, 0.01, 0.0089, 0.0101, 0.0132, 0.0118, 0.0156, 0.0428, 0.0097, 0.0122, 0.0088, 0.0081, 0.0111, 0.0084, 0.0098, 0.0109, 0.0104], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0109, 'macro': 0.0125, 'weighted': 0.0127}
2024-07-17 04:54:50 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:54:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:54:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 14/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_14_iter_1692.pt
2024-07-17 04:54:53 - [34m[1mLOGS   [0m - Model state for epoch 14/iteration 1692 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_14_iter_1692.pt
[31m===========================================================================[0m
2024-07-17 04:54:55 - [32m[1mINFO   [0m - Training epoch 15
2024-07-17 04:54:56 - [34m[1mLOGS   [0m - Epoch:  15 [    1693/10000000], loss: {'classification': 4.6157, 'neural_augmentation': 0.0737, 'total_loss': 4.6893}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.305, Elapsed time:  0.52
2024-07-17 04:55:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 15
	 loss={'classification': 4.6052, 'neural_augmentation': 0.0783, 'total_loss': 4.6835}
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:55:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 15
	 loss={'classification': 4.5911, 'neural_augmentation': 0.0, 'total_loss': 4.5911} || top1={'logits': 1.5898} || top5={'logits': 7.3242} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0522, 0.0677, 0.0365, 0.022, 0.0226, 0.0341, 0.0199, 0.0763, 0.0234, 0.025, 0.021, 0.0312, 0.0308, 0.0212, 0.0249, 0.029, 0.0308, 0.0258, 0.026, 0.0245, 0.0371, 0.052, 0.0345, 0.0226, 0.0383, 0.0277, 0.0205, 0.0199, 0.0243, 0.0239, 0.0278, 0.0206, 0.0269, 0.0294, 0.0251, 0.035, 0.0257, 0.0426, 0.0228, 0.0232, 0.036, 0.0263, 0.0205, 0.02, 0.0387, 0.0205, 0.0433, 0.0474, 0.0223, 0.0281, 0.0198, 0.0249, 0.0232, 0.0203, 0.0243, 0.0195, 0.0334, 0.025, 0.0195, 0.0264, 0.0441, 0.0255, 0.0372, 0.0288, 0.05, 0.1087, 0.0193, 0.0255, 0.0214, 0.0232, 0.0372, 0.0194, 0.0266, 0.023, 0.0219, 0.0266, 0.0256, 0.0473, 0.0311, 0.034, 0.0196, 0.0259, 0.0395, 0.0404, 0.0399, 0.0218, 0.0211, 0.0239, 0.0423, 0.0315, 0.0337, 0.0713, 0.024, 0.0494, 0.0195, 0.0203, 0.0346, 0.0274, 0.0225, 0.0194, 0.0235], 'AP': [0.0261, 0.0286, 0.0149, 0.0095, 0.01, 0.0152, 0.0097, 0.0278, 0.011, 0.0118, 0.0092, 0.0139, 0.0135, 0.0109, 0.0109, 0.0122, 0.0123, 0.0116, 0.011, 0.0118, 0.0154, 0.023, 0.0146, 0.0108, 0.0133, 0.0123, 0.0096, 0.0089, 0.0115, 0.011, 0.0107, 0.0097, 0.0128, 0.0131, 0.0117, 0.0123, 0.0117, 0.0184, 0.0101, 0.011, 0.014, 0.0128, 0.0099, 0.0094, 0.0158, 0.0092, 0.0152, 0.017, 0.0095, 0.0113, 0.0095, 0.0117, 0.0115, 0.0094, 0.0097, 0.0084, 0.012, 0.0117, 0.0093, 0.0119, 0.0181, 0.0121, 0.0134, 0.0121, 0.0207, 0.0449, 0.0083, 0.0121, 0.0099, 0.0108, 0.0163, 0.0091, 0.0119, 0.0101, 0.0105, 0.0118, 0.0122, 0.0169, 0.0117, 0.0157, 0.0084, 0.0123, 0.017, 0.017, 0.016, 0.0101, 0.01, 0.0145, 0.0183, 0.0179, 0.0152, 0.0309, 0.0103, 0.0197, 0.0082, 0.0086, 0.0125, 0.0106, 0.0105, 0.0093, 0.0115], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0128, 'macro': 0.0133, 'weighted': 0.0135}
2024-07-17 04:55:32 - [34m[1mLOGS   [0m - Best checkpoint with score 1.59 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:55:36 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:55:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:55:39 - [34m[1mLOGS   [0m - Training checkpoint for epoch 15/iteration 1803 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_15_iter_1803.pt
2024-07-17 04:55:39 - [34m[1mLOGS   [0m - Model state for epoch 15/iteration 1803 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_15_iter_1803.pt
[31m===========================================================================[0m
2024-07-17 04:55:41 - [32m[1mINFO   [0m - Training epoch 16
2024-07-17 04:55:43 - [34m[1mLOGS   [0m - Epoch:  16 [    1804/10000000], loss: {'classification': 4.5951, 'neural_augmentation': 0.0821, 'total_loss': 4.6772}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.656, Elapsed time:  1.87
2024-07-17 04:56:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 16
	 loss={'classification': 4.5909, 'neural_augmentation': 0.0787, 'total_loss': 4.6696}
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:56:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 16
	 loss={'classification': 4.5619, 'neural_augmentation': 0.0, 'total_loss': 4.5619} || top1={'logits': 1.8711} || top5={'logits': 8.1094} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0527, 0.0681, 0.04, 0.0238, 0.0199, 0.0431, 0.0201, 0.0824, 0.0234, 0.0237, 0.0201, 0.0276, 0.0253, 0.0234, 0.0239, 0.0244, 0.0269, 0.0286, 0.0383, 0.0263, 0.0363, 0.0607, 0.0348, 0.0232, 0.0255, 0.027, 0.0207, 0.0198, 0.0285, 0.0292, 0.0204, 0.0292, 0.0294, 0.0326, 0.0231, 0.0327, 0.0269, 0.0428, 0.0223, 0.0227, 0.0281, 0.0255, 0.0201, 0.0197, 0.0352, 0.0198, 0.0302, 0.0375, 0.0209, 0.0246, 0.0206, 0.0258, 0.0243, 0.0216, 0.0303, 0.0289, 0.0227, 0.0262, 0.0194, 0.0275, 0.0429, 0.0271, 0.0275, 0.0245, 0.052, 0.1411, 0.0241, 0.0253, 0.0263, 0.0252, 0.0386, 0.0247, 0.0248, 0.0231, 0.0238, 0.0271, 0.0276, 0.0441, 0.02, 0.035, 0.0194, 0.0249, 0.0396, 0.0497, 0.036, 0.0236, 0.0249, 0.0244, 0.0447, 0.0262, 0.0395, 0.0681, 0.0223, 0.0446, 0.0229, 0.0287, 0.0232, 0.0249, 0.0204, 0.0199, 0.0227], 'AP': [0.0293, 0.0302, 0.0164, 0.0106, 0.0094, 0.0183, 0.0096, 0.0329, 0.0106, 0.0112, 0.009, 0.0129, 0.0119, 0.0111, 0.0104, 0.0113, 0.0119, 0.0133, 0.014, 0.0118, 0.0139, 0.0278, 0.0145, 0.0106, 0.012, 0.0121, 0.0094, 0.0085, 0.012, 0.0126, 0.0099, 0.0133, 0.0135, 0.0139, 0.0107, 0.0134, 0.0125, 0.0179, 0.0106, 0.0103, 0.0131, 0.0116, 0.0098, 0.0088, 0.016, 0.0084, 0.0138, 0.0155, 0.0088, 0.0116, 0.0098, 0.0118, 0.0117, 0.0096, 0.0135, 0.0119, 0.0103, 0.012, 0.0085, 0.0125, 0.018, 0.0126, 0.013, 0.011, 0.0198, 0.0688, 0.0108, 0.0116, 0.0119, 0.0118, 0.0173, 0.0102, 0.0117, 0.0102, 0.011, 0.0119, 0.0139, 0.0161, 0.0096, 0.0151, 0.0095, 0.0114, 0.0173, 0.0204, 0.0161, 0.0118, 0.011, 0.0111, 0.0198, 0.0125, 0.0171, 0.0278, 0.0106, 0.0197, 0.0107, 0.0102, 0.0116, 0.0111, 0.01, 0.0095, 0.0108], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0145, 'macro': 0.0138, 'weighted': 0.014}
2024-07-17 04:56:21 - [34m[1mLOGS   [0m - Best checkpoint with score 1.87 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:56:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:56:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:56:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 16/iteration 1925 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_16_iter_1925.pt
2024-07-17 04:56:29 - [34m[1mLOGS   [0m - Model state for epoch 16/iteration 1925 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_16_iter_1925.pt
[31m===========================================================================[0m
2024-07-17 04:56:31 - [32m[1mINFO   [0m - Training epoch 17
2024-07-17 04:56:31 - [34m[1mLOGS   [0m - Epoch:  17 [    1926/10000000], loss: {'classification': 4.5945, 'neural_augmentation': 0.0724, 'total_loss': 4.6669}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 0.356, Elapsed time:  0.57
2024-07-17 04:56:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 17
	 loss={'classification': 4.5728, 'neural_augmentation': 0.0796, 'total_loss': 4.6523}
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 17
	 loss={'classification': 4.5421, 'neural_augmentation': 0.0, 'total_loss': 4.5421} || top1={'logits': 2.0781} || top5={'logits': 9.0938} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0557, 0.0792, 0.0355, 0.0312, 0.0208, 0.0671, 0.02, 0.0833, 0.0219, 0.0236, 0.0202, 0.0226, 0.0288, 0.0288, 0.024, 0.0288, 0.0236, 0.0318, 0.0382, 0.0259, 0.0275, 0.0737, 0.0351, 0.02, 0.0267, 0.0244, 0.0209, 0.0234, 0.0349, 0.0368, 0.0204, 0.0291, 0.0372, 0.0445, 0.0221, 0.0356, 0.0292, 0.0356, 0.0272, 0.0217, 0.0362, 0.022, 0.0204, 0.0234, 0.0544, 0.0422, 0.0352, 0.0414, 0.0562, 0.0288, 0.0201, 0.0305, 0.029, 0.0218, 0.0394, 0.0225, 0.0274, 0.0262, 0.0351, 0.0326, 0.0583, 0.0279, 0.0411, 0.0257, 0.03, 0.1809, 0.0216, 0.0297, 0.0295, 0.0379, 0.048, 0.0284, 0.0277, 0.0229, 0.0254, 0.0207, 0.0297, 0.0327, 0.0204, 0.0289, 0.0229, 0.0222, 0.0541, 0.069, 0.038, 0.03, 0.0235, 0.0216, 0.0785, 0.0303, 0.0377, 0.0778, 0.024, 0.0431, 0.0243, 0.029, 0.0244, 0.0241, 0.0209, 0.0195, 0.023], 'AP': [0.0275, 0.0349, 0.0164, 0.0152, 0.0094, 0.0262, 0.0088, 0.033, 0.0097, 0.0113, 0.0093, 0.0145, 0.0122, 0.0151, 0.0111, 0.0119, 0.0114, 0.0143, 0.0155, 0.0124, 0.0118, 0.0326, 0.0144, 0.0094, 0.0119, 0.0111, 0.009, 0.0105, 0.0143, 0.017, 0.0099, 0.0126, 0.0151, 0.0199, 0.0103, 0.0152, 0.0129, 0.0162, 0.0117, 0.0105, 0.0155, 0.011, 0.0095, 0.0108, 0.0202, 0.0157, 0.0155, 0.0158, 0.022, 0.0125, 0.0092, 0.0123, 0.0121, 0.0099, 0.0161, 0.0108, 0.0123, 0.0123, 0.0145, 0.0141, 0.0241, 0.0129, 0.0159, 0.0116, 0.0129, 0.0952, 0.0105, 0.0126, 0.012, 0.0147, 0.0197, 0.0122, 0.0131, 0.0107, 0.0121, 0.0102, 0.0136, 0.0145, 0.0092, 0.0132, 0.01, 0.0099, 0.0224, 0.0291, 0.016, 0.0129, 0.0108, 0.0106, 0.035, 0.0137, 0.0166, 0.0314, 0.0111, 0.0195, 0.0108, 0.0125, 0.0109, 0.011, 0.0101, 0.0086, 0.0119], 'Recall@P=50': [0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0161, 'macro': 0.0153, 'weighted': 0.0155}
2024-07-17 04:57:10 - [34m[1mLOGS   [0m - Best checkpoint with score 2.08 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:57:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:57:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:57:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 17/iteration 2039 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_17_iter_2039.pt
2024-07-17 04:57:17 - [34m[1mLOGS   [0m - Model state for epoch 17/iteration 2039 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_17_iter_2039.pt
[31m===========================================================================[0m
2024-07-17 04:57:19 - [32m[1mINFO   [0m - Training epoch 18
2024-07-17 04:57:20 - [34m[1mLOGS   [0m - Epoch:  18 [    2040/10000000], loss: {'classification': 4.5711, 'neural_augmentation': 0.074, 'total_loss': 4.6451}, LR: [2.9e-05, 2.9e-05], Avg. batch load time: 1.256, Elapsed time:  1.47
2024-07-17 04:57:43 - [34m[1mLOGS   [0m - *** Training summary for epoch 18
	 loss={'classification': 4.5567, 'neural_augmentation': 0.0811, 'total_loss': 4.6379}
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:57:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 18
	 loss={'classification': 4.5255, 'neural_augmentation': 0.0, 'total_loss': 4.5255} || top1={'logits': 2.0039} || top5={'logits': 8.8477} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0659, 0.073, 0.0353, 0.0273, 0.0216, 0.0744, 0.0212, 0.0782, 0.0201, 0.0252, 0.0231, 0.0213, 0.0329, 0.0332, 0.0207, 0.0249, 0.0224, 0.0392, 0.0399, 0.0265, 0.0254, 0.0735, 0.03, 0.0219, 0.0321, 0.0249, 0.0223, 0.0265, 0.023, 0.042, 0.0202, 0.0236, 0.0421, 0.0941, 0.022, 0.0411, 0.0271, 0.0356, 0.0305, 0.0228, 0.0386, 0.0235, 0.0215, 0.0262, 0.0464, 0.0408, 0.0339, 0.0406, 0.0692, 0.0323, 0.0237, 0.032, 0.0268, 0.022, 0.0438, 0.0249, 0.0269, 0.0275, 0.0304, 0.0304, 0.0612, 0.0281, 0.0369, 0.0239, 0.0414, 0.1739, 0.0278, 0.0241, 0.0333, 0.0291, 0.0465, 0.0256, 0.028, 0.0242, 0.0271, 0.0201, 0.0305, 0.032, 0.0297, 0.0279, 0.0219, 0.022, 0.0551, 0.0648, 0.0355, 0.0325, 0.0203, 0.02, 0.1331, 0.0303, 0.0432, 0.0781, 0.0245, 0.0414, 0.024, 0.0257, 0.0217, 0.0229, 0.0202, 0.0209, 0.0209], 'AP': [0.0312, 0.0331, 0.0156, 0.0121, 0.0097, 0.0312, 0.0093, 0.0338, 0.009, 0.0117, 0.0106, 0.0088, 0.0128, 0.0155, 0.0097, 0.0114, 0.01, 0.0162, 0.0173, 0.0123, 0.0112, 0.0321, 0.014, 0.0099, 0.0131, 0.011, 0.0102, 0.0121, 0.0104, 0.0171, 0.0095, 0.011, 0.0171, 0.0427, 0.0101, 0.0152, 0.0127, 0.0165, 0.0124, 0.0112, 0.0178, 0.0105, 0.0095, 0.0114, 0.0183, 0.0163, 0.0157, 0.0157, 0.0264, 0.014, 0.0107, 0.014, 0.0118, 0.0095, 0.0191, 0.0117, 0.0119, 0.0128, 0.0131, 0.0142, 0.0255, 0.0136, 0.0158, 0.011, 0.0155, 0.1004, 0.0111, 0.0113, 0.0143, 0.0131, 0.0191, 0.0101, 0.013, 0.011, 0.0121, 0.0092, 0.0137, 0.0146, 0.0118, 0.013, 0.0095, 0.0097, 0.0225, 0.0266, 0.0146, 0.0138, 0.0096, 0.01, 0.06, 0.0142, 0.018, 0.0304, 0.0116, 0.0197, 0.0107, 0.0116, 0.0107, 0.0108, 0.0097, 0.0095, 0.0099], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0169, 'macro': 0.0159, 'weighted': 0.0161}
2024-07-17 04:57:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:58:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:58:02 - [34m[1mLOGS   [0m - Training checkpoint for epoch 18/iteration 2152 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_18_iter_2152.pt
2024-07-17 04:58:02 - [34m[1mLOGS   [0m - Model state for epoch 18/iteration 2152 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_18_iter_2152.pt
[31m===========================================================================[0m
2024-07-17 04:58:04 - [32m[1mINFO   [0m - Training epoch 19
2024-07-17 04:58:05 - [34m[1mLOGS   [0m - Epoch:  19 [    2153/10000000], loss: {'classification': 4.5499, 'neural_augmentation': 0.0851, 'total_loss': 4.6349}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 0.712, Elapsed time:  0.92
2024-07-17 04:58:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 19
	 loss={'classification': 4.5446, 'neural_augmentation': 0.0829, 'total_loss': 4.6276}
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:37 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:58:39 - [34m[1mLOGS   [0m - *** Validation summary for epoch 19
	 loss={'classification': 4.5154, 'neural_augmentation': 0.0, 'total_loss': 4.5154} || top1={'logits': 2.1523} || top5={'logits': 9.5625} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0646, 0.0644, 0.0341, 0.0328, 0.0228, 0.0961, 0.0213, 0.0545, 0.0207, 0.0248, 0.0211, 0.0346, 0.0377, 0.037, 0.021, 0.0247, 0.022, 0.0322, 0.037, 0.0274, 0.0228, 0.0746, 0.0299, 0.022, 0.0302, 0.0257, 0.0208, 0.0257, 0.0275, 0.0354, 0.0207, 0.0234, 0.043, 0.2632, 0.0226, 0.0427, 0.0307, 0.0352, 0.0304, 0.0234, 0.0471, 0.025, 0.0221, 0.0272, 0.045, 0.034, 0.0374, 0.0476, 0.0581, 0.0348, 0.021, 0.0494, 0.029, 0.0225, 0.0445, 0.0256, 0.025, 0.0292, 0.0335, 0.0323, 0.0619, 0.0284, 0.0406, 0.0232, 0.0268, 0.1587, 0.0232, 0.0249, 0.0358, 0.0284, 0.0423, 0.0211, 0.0298, 0.0228, 0.0256, 0.0196, 0.0334, 0.0317, 0.027, 0.0276, 0.022, 0.0223, 0.0525, 0.0649, 0.0275, 0.0295, 0.0202, 0.0232, 0.1885, 0.0299, 0.043, 0.0858, 0.0245, 0.0431, 0.0235, 0.0241, 0.0209, 0.0225, 0.0202, 0.0204, 0.0219], 'AP': [0.0321, 0.0291, 0.015, 0.0146, 0.01, 0.0384, 0.0094, 0.0238, 0.0097, 0.0117, 0.0105, 0.0146, 0.0143, 0.0162, 0.0095, 0.0111, 0.0099, 0.0134, 0.0167, 0.0127, 0.0112, 0.0307, 0.0134, 0.0104, 0.0139, 0.0116, 0.0096, 0.0123, 0.0124, 0.016, 0.0095, 0.0106, 0.0183, 0.1521, 0.0108, 0.0162, 0.0138, 0.0162, 0.0131, 0.0107, 0.0204, 0.0114, 0.0103, 0.0122, 0.0182, 0.0158, 0.0169, 0.0166, 0.0249, 0.0148, 0.01, 0.018, 0.0129, 0.0095, 0.0185, 0.0123, 0.0115, 0.0133, 0.014, 0.0147, 0.0263, 0.0131, 0.018, 0.0106, 0.0116, 0.0771, 0.011, 0.0116, 0.0157, 0.0129, 0.0182, 0.0094, 0.0134, 0.0107, 0.0114, 0.0079, 0.0146, 0.0138, 0.0122, 0.013, 0.0095, 0.0099, 0.0209, 0.0261, 0.0127, 0.0136, 0.0088, 0.0098, 0.1058, 0.0139, 0.0182, 0.0322, 0.0114, 0.0192, 0.0102, 0.0112, 0.0097, 0.0105, 0.0097, 0.0094, 0.01], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.018, 'macro': 0.0173, 'weighted': 0.0175}
2024-07-17 04:58:42 - [34m[1mLOGS   [0m - Best checkpoint with score 2.15 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:58:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_0.9766.pt
2024-07-17 04:58:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_1.3086.pt', 'checkpoint_score_1.5898.pt', 'checkpoint_score_1.8711.pt', 'checkpoint_score_2.0781.pt', 'checkpoint_score_2.1523.pt']
2024-07-17 04:58:50 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 04:58:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:58:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:58:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 19/iteration 2262 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_19_iter_2262.pt
2024-07-17 04:58:56 - [34m[1mLOGS   [0m - Model state for epoch 19/iteration 2262 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_19_iter_2262.pt
[31m===========================================================================[0m
2024-07-17 04:58:58 - [32m[1mINFO   [0m - Training epoch 20
2024-07-17 04:58:59 - [34m[1mLOGS   [0m - Epoch:  20 [    2263/10000000], loss: {'classification': 4.5146, 'neural_augmentation': 0.078, 'total_loss': 4.5926}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 0.914, Elapsed time:  1.13
2024-07-17 04:59:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 20
	 loss={'classification': 4.5297, 'neural_augmentation': 0.085, 'total_loss': 4.6147}
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:31 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 04:59:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 20
	 loss={'classification': 4.5029, 'neural_augmentation': 0.0, 'total_loss': 4.5029} || top1={'logits': 2.1836} || top5={'logits': 9.3555} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0735, 0.0593, 0.0338, 0.0437, 0.0238, 0.0956, 0.0515, 0.0495, 0.0201, 0.0232, 0.0273, 0.0404, 0.0539, 0.0563, 0.0239, 0.0292, 0.0299, 0.0439, 0.0584, 0.0279, 0.0226, 0.0744, 0.0341, 0.0224, 0.0231, 0.025, 0.0221, 0.0316, 0.022, 0.0509, 0.0209, 0.0245, 0.033, 0.3114, 0.0225, 0.0455, 0.0327, 0.0391, 0.0381, 0.0369, 0.0613, 0.0284, 0.0226, 0.0337, 0.0471, 0.048, 0.0596, 0.0474, 0.0788, 0.0466, 0.0232, 0.0471, 0.0316, 0.0235, 0.0618, 0.0255, 0.0235, 0.0268, 0.032, 0.0326, 0.0787, 0.0266, 0.0563, 0.0379, 0.0427, 0.1592, 0.0259, 0.0264, 0.0471, 0.039, 0.0547, 0.0293, 0.0347, 0.0683, 0.0317, 0.0293, 0.0385, 0.0357, 0.033, 0.0304, 0.0235, 0.0212, 0.0567, 0.0621, 0.0234, 0.0343, 0.0204, 0.0195, 0.2048, 0.0324, 0.0496, 0.0629, 0.0246, 0.0449, 0.0293, 0.0251, 0.0248, 0.0253, 0.0231, 0.0232, 0.0236], 'AP': [0.0332, 0.0259, 0.0148, 0.0185, 0.0106, 0.039, 0.0187, 0.0203, 0.0089, 0.0109, 0.0125, 0.0183, 0.0184, 0.0228, 0.0113, 0.0115, 0.012, 0.0165, 0.0244, 0.0125, 0.0102, 0.0305, 0.0145, 0.0104, 0.0106, 0.0113, 0.0104, 0.0144, 0.0104, 0.0214, 0.0102, 0.0115, 0.0143, 0.2162, 0.0104, 0.0166, 0.0147, 0.0169, 0.0164, 0.0152, 0.0268, 0.013, 0.0105, 0.0139, 0.019, 0.0194, 0.021, 0.0159, 0.0337, 0.0178, 0.011, 0.0179, 0.0142, 0.0102, 0.0249, 0.0119, 0.0106, 0.0135, 0.0151, 0.0146, 0.0338, 0.0127, 0.0238, 0.0162, 0.0169, 0.0707, 0.0121, 0.0118, 0.0202, 0.0174, 0.0215, 0.0119, 0.0139, 0.0224, 0.0128, 0.014, 0.0154, 0.014, 0.0144, 0.0136, 0.0108, 0.009, 0.0206, 0.0254, 0.0111, 0.0151, 0.0096, 0.0094, 0.1208, 0.0152, 0.0196, 0.0246, 0.0113, 0.0198, 0.0134, 0.0111, 0.0112, 0.0115, 0.0114, 0.0101, 0.0107], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.019, 'macro': 0.0195, 'weighted': 0.0197}
2024-07-17 04:59:37 - [34m[1mLOGS   [0m - Best checkpoint with score 2.18 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 04:59:39 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_1.3086.pt
2024-07-17 04:59:39 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_1.5898.pt', 'checkpoint_score_1.8711.pt', 'checkpoint_score_2.0781.pt', 'checkpoint_score_2.1523.pt', 'checkpoint_score_2.1836.pt']
2024-07-17 04:59:44 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 04:59:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 04:59:47 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 04:59:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 20/iteration 2381 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_20_iter_2381.pt
2024-07-17 04:59:49 - [34m[1mLOGS   [0m - Model state for epoch 20/iteration 2381 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_20_iter_2381.pt
[31m===========================================================================[0m
2024-07-17 04:59:51 - [32m[1mINFO   [0m - Training epoch 21
2024-07-17 04:59:53 - [34m[1mLOGS   [0m - Epoch:  21 [    2382/10000000], loss: {'classification': 4.5434, 'neural_augmentation': 0.0863, 'total_loss': 4.6297}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.014, Elapsed time:  1.25
2024-07-17 05:00:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 21
	 loss={'classification': 4.5121, 'neural_augmentation': 0.0876, 'total_loss': 4.5997}
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:00:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 21
	 loss={'classification': 4.4562, 'neural_augmentation': 0.0, 'total_loss': 4.4562} || top1={'logits': 2.3984} || top5={'logits': 11.0898} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0692, 0.0608, 0.032, 0.0693, 0.0247, 0.1077, 0.0433, 0.0505, 0.0215, 0.0243, 0.0311, 0.0539, 0.0415, 0.0614, 0.0224, 0.0336, 0.0239, 0.0317, 0.0508, 0.0275, 0.0227, 0.0616, 0.0304, 0.025, 0.0249, 0.0249, 0.0231, 0.0304, 0.0232, 0.0331, 0.0226, 0.0233, 0.0326, 0.3758, 0.0229, 0.0517, 0.0387, 0.0438, 0.0387, 0.0349, 0.0706, 0.0307, 0.0234, 0.0333, 0.0484, 0.0398, 0.0555, 0.0413, 0.1075, 0.0485, 0.0241, 0.0632, 0.036, 0.0226, 0.0612, 0.0272, 0.0249, 0.0286, 0.0287, 0.032, 0.0725, 0.0269, 0.066, 0.0302, 0.0618, 0.1438, 0.0282, 0.026, 0.0481, 0.0328, 0.0487, 0.0248, 0.0318, 0.0612, 0.0327, 0.0369, 0.0393, 0.0391, 0.0357, 0.0301, 0.0249, 0.0228, 0.0575, 0.0515, 0.0226, 0.0336, 0.0292, 0.0195, 0.2388, 0.0297, 0.0458, 0.068, 0.0247, 0.0519, 0.0258, 0.0236, 0.0289, 0.0242, 0.0276, 0.0236, 0.025], 'AP': [0.0343, 0.0276, 0.0143, 0.0276, 0.0113, 0.0439, 0.018, 0.0206, 0.0097, 0.0113, 0.0133, 0.0235, 0.0166, 0.0261, 0.0108, 0.0124, 0.0113, 0.0139, 0.0224, 0.0129, 0.0106, 0.0269, 0.013, 0.0115, 0.0117, 0.0117, 0.0103, 0.0141, 0.0102, 0.0168, 0.0101, 0.0113, 0.015, 0.2866, 0.0108, 0.0184, 0.0171, 0.0183, 0.0166, 0.0148, 0.0289, 0.0137, 0.0108, 0.0145, 0.0195, 0.0167, 0.0229, 0.0148, 0.0454, 0.0192, 0.011, 0.0234, 0.0151, 0.0104, 0.0229, 0.0123, 0.0109, 0.0132, 0.014, 0.014, 0.0316, 0.0131, 0.0276, 0.0135, 0.0241, 0.058, 0.012, 0.0123, 0.0208, 0.015, 0.0206, 0.0111, 0.0144, 0.0193, 0.0141, 0.0158, 0.0154, 0.0156, 0.0152, 0.0138, 0.0115, 0.0097, 0.0203, 0.0213, 0.0111, 0.0156, 0.0135, 0.0093, 0.1425, 0.0142, 0.0189, 0.0263, 0.0114, 0.0224, 0.0118, 0.0106, 0.0122, 0.0109, 0.0114, 0.0105, 0.0111], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.022, 'macro': 0.0208, 'weighted': 0.021}
2024-07-17 05:00:30 - [34m[1mLOGS   [0m - Best checkpoint with score 2.40 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:00:31 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_1.5898.pt
2024-07-17 05:00:31 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_1.8711.pt', 'checkpoint_score_2.0781.pt', 'checkpoint_score_2.1523.pt', 'checkpoint_score_2.1836.pt', 'checkpoint_score_2.3984.pt']
2024-07-17 05:00:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:00:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:00:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:00:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 21/iteration 2490 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_21_iter_2490.pt
2024-07-17 05:00:41 - [34m[1mLOGS   [0m - Model state for epoch 21/iteration 2490 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_21_iter_2490.pt
[31m===========================================================================[0m
2024-07-17 05:00:43 - [32m[1mINFO   [0m - Training epoch 22
2024-07-17 05:00:45 - [34m[1mLOGS   [0m - Epoch:  22 [    2491/10000000], loss: {'classification': 4.5028, 'neural_augmentation': 0.0913, 'total_loss': 4.5941}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 1.149, Elapsed time:  1.36
2024-07-17 05:01:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 22
	 loss={'classification': 4.4931, 'neural_augmentation': 0.0899, 'total_loss': 4.583}
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:01:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 22
	 loss={'classification': 4.4301, 'neural_augmentation': 0.0, 'total_loss': 4.4301} || top1={'logits': 2.6328} || top5={'logits': 11.957} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0681, 0.0617, 0.035, 0.1064, 0.0277, 0.1124, 0.0543, 0.0536, 0.0208, 0.0242, 0.0341, 0.0452, 0.0481, 0.0755, 0.0247, 0.0273, 0.0304, 0.0416, 0.0488, 0.0281, 0.0223, 0.0757, 0.0326, 0.0253, 0.0692, 0.0265, 0.0215, 0.0284, 0.0229, 0.048, 0.0227, 0.0276, 0.0289, 0.3956, 0.0252, 0.0485, 0.0438, 0.0481, 0.0374, 0.0298, 0.0664, 0.0296, 0.0233, 0.0333, 0.0599, 0.0478, 0.0623, 0.0409, 0.0937, 0.0452, 0.0229, 0.0688, 0.0375, 0.0224, 0.0539, 0.0274, 0.0247, 0.0287, 0.0347, 0.0318, 0.0706, 0.027, 0.0637, 0.0368, 0.0605, 0.1372, 0.0243, 0.0304, 0.0478, 0.0362, 0.0537, 0.0266, 0.0319, 0.0743, 0.0468, 0.0332, 0.033, 0.0409, 0.0365, 0.0305, 0.0273, 0.0236, 0.0479, 0.0593, 0.0241, 0.0317, 0.0357, 0.0218, 0.2537, 0.0313, 0.0467, 0.0845, 0.0245, 0.0568, 0.0338, 0.0262, 0.0243, 0.0285, 0.0367, 0.025, 0.0274], 'AP': [0.0353, 0.0274, 0.0153, 0.0426, 0.0125, 0.0449, 0.0212, 0.0229, 0.0093, 0.0114, 0.0144, 0.0197, 0.0189, 0.0298, 0.0114, 0.012, 0.0138, 0.0194, 0.021, 0.0133, 0.0102, 0.0315, 0.014, 0.0111, 0.023, 0.012, 0.01, 0.0131, 0.0102, 0.0195, 0.0102, 0.0124, 0.0136, 0.3042, 0.0119, 0.018, 0.0175, 0.0204, 0.0164, 0.0134, 0.0279, 0.0136, 0.0108, 0.0151, 0.0248, 0.0187, 0.0247, 0.0146, 0.0405, 0.0193, 0.011, 0.0238, 0.016, 0.0104, 0.0219, 0.0123, 0.011, 0.0133, 0.02, 0.0141, 0.0302, 0.0125, 0.0275, 0.0147, 0.0194, 0.0569, 0.0113, 0.0142, 0.0206, 0.016, 0.0221, 0.0117, 0.0143, 0.0255, 0.0167, 0.0144, 0.0169, 0.0155, 0.0162, 0.0141, 0.0122, 0.0098, 0.0188, 0.0289, 0.0114, 0.0147, 0.0138, 0.0099, 0.1563, 0.0148, 0.0192, 0.0377, 0.0108, 0.0229, 0.0156, 0.0119, 0.0115, 0.0123, 0.0138, 0.0111, 0.0124], 'Recall@P=50': [0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0234, 'macro': 0.0221, 'weighted': 0.0223}
2024-07-17 05:01:22 - [34m[1mLOGS   [0m - Best checkpoint with score 2.63 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:01:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_1.8711.pt
2024-07-17 05:01:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_2.0781.pt', 'checkpoint_score_2.1523.pt', 'checkpoint_score_2.1836.pt', 'checkpoint_score_2.3984.pt', 'checkpoint_score_2.6328.pt']
2024-07-17 05:01:30 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:01:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:01:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:01:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 22/iteration 2607 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_22_iter_2607.pt
2024-07-17 05:01:35 - [34m[1mLOGS   [0m - Model state for epoch 22/iteration 2607 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_22_iter_2607.pt
[31m===========================================================================[0m
2024-07-17 05:01:37 - [32m[1mINFO   [0m - Training epoch 23
2024-07-17 05:01:38 - [34m[1mLOGS   [0m - Epoch:  23 [    2608/10000000], loss: {'classification': 4.4865, 'neural_augmentation': 0.086, 'total_loss': 4.5725}, LR: [2.8e-05, 2.8e-05], Avg. batch load time: 0.802, Elapsed time:  1.02
2024-07-17 05:02:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 23
	 loss={'classification': 4.4788, 'neural_augmentation': 0.0928, 'total_loss': 4.5715}
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:02:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 23
	 loss={'classification': 4.4271, 'neural_augmentation': 0.0, 'total_loss': 4.4271} || top1={'logits': 3.0078} || top5={'logits': 11.5781} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0639, 0.0589, 0.0323, 0.109, 0.0285, 0.1191, 0.0532, 0.0531, 0.0211, 0.0239, 0.0351, 0.0677, 0.0457, 0.0793, 0.0231, 0.0331, 0.0307, 0.0564, 0.0615, 0.0281, 0.0337, 0.0734, 0.0317, 0.0282, 0.056, 0.0263, 0.0226, 0.0301, 0.0252, 0.0445, 0.0217, 0.0333, 0.0287, 0.4241, 0.0227, 0.0533, 0.0363, 0.0502, 0.0443, 0.0369, 0.0682, 0.0318, 0.0252, 0.0416, 0.0679, 0.0502, 0.0626, 0.0436, 0.1091, 0.0584, 0.0281, 0.0839, 0.038, 0.0227, 0.0524, 0.0274, 0.0224, 0.0247, 0.042, 0.0351, 0.0539, 0.0288, 0.0676, 0.0622, 0.057, 0.1304, 0.0263, 0.0311, 0.058, 0.046, 0.0651, 0.0314, 0.0307, 0.0736, 0.0408, 0.0424, 0.0423, 0.0401, 0.0467, 0.0296, 0.0295, 0.0257, 0.0476, 0.0795, 0.023, 0.0326, 0.0293, 0.0217, 0.2732, 0.0319, 0.0609, 0.0715, 0.0241, 0.059, 0.046, 0.0287, 0.0297, 0.0308, 0.035, 0.0328, 0.0258], 'AP': [0.0329, 0.0267, 0.0154, 0.0454, 0.0134, 0.0461, 0.0216, 0.0219, 0.0096, 0.0112, 0.015, 0.0282, 0.0194, 0.0313, 0.0108, 0.0135, 0.0139, 0.0211, 0.0244, 0.0131, 0.013, 0.0299, 0.0135, 0.0123, 0.0239, 0.0121, 0.0097, 0.0141, 0.0107, 0.0188, 0.0095, 0.0126, 0.0125, 0.3311, 0.0109, 0.0197, 0.0157, 0.0207, 0.019, 0.0154, 0.0317, 0.0144, 0.0116, 0.0171, 0.027, 0.0204, 0.0259, 0.0144, 0.0528, 0.0212, 0.0122, 0.0311, 0.0165, 0.0109, 0.0227, 0.0123, 0.0101, 0.0119, 0.0161, 0.0149, 0.0227, 0.0131, 0.0284, 0.0205, 0.0181, 0.0533, 0.0121, 0.0139, 0.0252, 0.0207, 0.0261, 0.0141, 0.0138, 0.0264, 0.0155, 0.0188, 0.0176, 0.0159, 0.0184, 0.0133, 0.0119, 0.0109, 0.0165, 0.0341, 0.0108, 0.0144, 0.0132, 0.0097, 0.1611, 0.0149, 0.0238, 0.0289, 0.0105, 0.0239, 0.0183, 0.0126, 0.0123, 0.0123, 0.0152, 0.0126, 0.0123], 'Recall@P=50': [0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0242, 'macro': 0.0232, 'weighted': 0.0233}
2024-07-17 05:02:15 - [34m[1mLOGS   [0m - Best checkpoint with score 3.01 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:02:17 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_2.0781.pt
2024-07-17 05:02:17 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_2.1523.pt', 'checkpoint_score_2.1836.pt', 'checkpoint_score_2.3984.pt', 'checkpoint_score_2.6328.pt', 'checkpoint_score_3.0078.pt']
2024-07-17 05:02:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:02:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:02:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:02:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 23/iteration 2722 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_23_iter_2722.pt
2024-07-17 05:02:28 - [34m[1mLOGS   [0m - Model state for epoch 23/iteration 2722 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_23_iter_2722.pt
[31m===========================================================================[0m
2024-07-17 05:02:30 - [32m[1mINFO   [0m - Training epoch 24
2024-07-17 05:02:31 - [34m[1mLOGS   [0m - Epoch:  24 [    2723/10000000], loss: {'classification': 4.4658, 'neural_augmentation': 0.1019, 'total_loss': 4.5678}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.301, Elapsed time:  0.56
2024-07-17 05:02:54 - [34m[1mLOGS   [0m - *** Training summary for epoch 24
	 loss={'classification': 4.4662, 'neural_augmentation': 0.097, 'total_loss': 4.5632}
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:04 - [34m[1mLOGS   [0m - *** Validation summary for epoch 24
	 loss={'classification': 4.3913, 'neural_augmentation': 0.0, 'total_loss': 4.3913} || top1={'logits': 3.1328} || top5={'logits': 12.9062} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0603, 0.0548, 0.032, 0.124, 0.0385, 0.1345, 0.0574, 0.0532, 0.0212, 0.0242, 0.0305, 0.0644, 0.047, 0.0825, 0.0237, 0.0312, 0.0331, 0.0622, 0.0633, 0.0277, 0.0322, 0.0819, 0.0357, 0.0275, 0.0894, 0.0275, 0.0219, 0.0305, 0.0243, 0.0591, 0.0218, 0.0344, 0.028, 0.44, 0.0232, 0.0553, 0.0348, 0.0537, 0.0427, 0.0344, 0.0685, 0.0324, 0.0244, 0.0385, 0.0715, 0.0535, 0.0666, 0.0384, 0.1123, 0.052, 0.0249, 0.0794, 0.0363, 0.0269, 0.0459, 0.0302, 0.0214, 0.0288, 0.0482, 0.0399, 0.0432, 0.0292, 0.0659, 0.07, 0.0542, 0.1138, 0.0272, 0.0357, 0.0562, 0.0437, 0.0636, 0.0337, 0.0292, 0.0722, 0.0358, 0.0541, 0.0442, 0.04, 0.0469, 0.0309, 0.0254, 0.0305, 0.0455, 0.0885, 0.0229, 0.0294, 0.0309, 0.0233, 0.3158, 0.0315, 0.0667, 0.0736, 0.0235, 0.0555, 0.0478, 0.0261, 0.0293, 0.0316, 0.0433, 0.0325, 0.0291], 'AP': [0.0312, 0.024, 0.0141, 0.0556, 0.0142, 0.0501, 0.0217, 0.0217, 0.0093, 0.0118, 0.0143, 0.0269, 0.0191, 0.0325, 0.0107, 0.013, 0.0148, 0.0244, 0.0254, 0.0135, 0.0132, 0.0335, 0.0154, 0.012, 0.0417, 0.0121, 0.0096, 0.0141, 0.0103, 0.0223, 0.0098, 0.0125, 0.0125, 0.3657, 0.0113, 0.0189, 0.0151, 0.0211, 0.0183, 0.0149, 0.0296, 0.0145, 0.0111, 0.017, 0.0288, 0.0219, 0.0257, 0.014, 0.0514, 0.0216, 0.0109, 0.0282, 0.0163, 0.0115, 0.0193, 0.0144, 0.0096, 0.0125, 0.0182, 0.0168, 0.0193, 0.0138, 0.0281, 0.0214, 0.0171, 0.0495, 0.0126, 0.0159, 0.0253, 0.0205, 0.028, 0.0152, 0.0135, 0.0284, 0.0149, 0.0228, 0.0206, 0.0154, 0.0195, 0.0139, 0.0124, 0.0129, 0.0161, 0.043, 0.0102, 0.0131, 0.0138, 0.0102, 0.1926, 0.015, 0.0259, 0.0292, 0.0101, 0.0226, 0.0194, 0.0124, 0.0121, 0.0132, 0.0181, 0.0131, 0.0131], 'Recall@P=50': [0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0264, 'macro': 0.0245, 'weighted': 0.0245}
2024-07-17 05:03:08 - [34m[1mLOGS   [0m - Best checkpoint with score 3.13 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:03:09 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_2.1523.pt
2024-07-17 05:03:09 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_2.1836.pt', 'checkpoint_score_2.3984.pt', 'checkpoint_score_2.6328.pt', 'checkpoint_score_3.0078.pt', 'checkpoint_score_3.1328.pt']
2024-07-17 05:03:14 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:03:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:03:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:03:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 24/iteration 2831 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_24_iter_2831.pt
2024-07-17 05:03:19 - [34m[1mLOGS   [0m - Model state for epoch 24/iteration 2831 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_24_iter_2831.pt
[31m===========================================================================[0m
2024-07-17 05:03:21 - [32m[1mINFO   [0m - Training epoch 25
2024-07-17 05:03:22 - [34m[1mLOGS   [0m - Epoch:  25 [    2832/10000000], loss: {'classification': 4.4702, 'neural_augmentation': 0.1041, 'total_loss': 4.5743}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.750, Elapsed time:  0.96
2024-07-17 05:03:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 25
	 loss={'classification': 4.4517, 'neural_augmentation': 0.1005, 'total_loss': 4.5521}
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:53 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:03:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 25
	 loss={'classification': 4.3704, 'neural_augmentation': 0.0, 'total_loss': 4.3704} || top1={'logits': 3.3828} || top5={'logits': 14.2539} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0654, 0.0584, 0.0317, 0.1585, 0.0314, 0.1408, 0.054, 0.0574, 0.0222, 0.025, 0.0323, 0.0709, 0.0453, 0.0836, 0.0217, 0.0316, 0.034, 0.0604, 0.0548, 0.0291, 0.0327, 0.0944, 0.0392, 0.0273, 0.0918, 0.0284, 0.0217, 0.0281, 0.0253, 0.0511, 0.0221, 0.0292, 0.09, 0.4374, 0.0238, 0.0537, 0.0331, 0.0573, 0.0435, 0.0383, 0.0622, 0.0315, 0.0257, 0.0418, 0.0903, 0.0557, 0.0665, 0.0421, 0.1216, 0.0539, 0.02, 0.0745, 0.0365, 0.0263, 0.0442, 0.0342, 0.0209, 0.0316, 0.0415, 0.0391, 0.036, 0.033, 0.067, 0.0635, 0.0515, 0.1329, 0.0319, 0.0379, 0.0537, 0.0419, 0.0751, 0.035, 0.0295, 0.0755, 0.0369, 0.0635, 0.0443, 0.0409, 0.05, 0.0324, 0.0249, 0.0273, 0.0427, 0.0755, 0.0251, 0.0272, 0.0339, 0.022, 0.3242, 0.0318, 0.0736, 0.0793, 0.0237, 0.0594, 0.0487, 0.0257, 0.027, 0.03, 0.0438, 0.029, 0.0307], 'AP': [0.0316, 0.0263, 0.0142, 0.0722, 0.0144, 0.0553, 0.0218, 0.0243, 0.01, 0.0122, 0.0147, 0.0246, 0.0186, 0.0362, 0.0104, 0.0137, 0.0158, 0.026, 0.0226, 0.0142, 0.0138, 0.0442, 0.0171, 0.012, 0.0403, 0.015, 0.0094, 0.0128, 0.0108, 0.0212, 0.0105, 0.0125, 0.032, 0.3607, 0.0117, 0.0196, 0.0149, 0.0232, 0.0187, 0.0154, 0.0309, 0.0145, 0.0119, 0.0175, 0.0348, 0.0219, 0.0254, 0.0145, 0.0542, 0.0218, 0.0091, 0.0279, 0.0165, 0.0114, 0.0204, 0.0153, 0.0091, 0.0134, 0.0176, 0.0168, 0.0173, 0.0161, 0.0288, 0.0204, 0.0184, 0.0579, 0.0133, 0.0164, 0.0248, 0.0188, 0.0314, 0.0159, 0.014, 0.0309, 0.0149, 0.0224, 0.0183, 0.0164, 0.0206, 0.0141, 0.0121, 0.0117, 0.0161, 0.0378, 0.0118, 0.0127, 0.0142, 0.0101, 0.1988, 0.015, 0.0277, 0.0322, 0.01, 0.0245, 0.0204, 0.0124, 0.0117, 0.0132, 0.0184, 0.0136, 0.0143], 'Recall@P=50': [0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0278, 'macro': 0.0254, 'weighted': 0.0255}
2024-07-17 05:03:59 - [34m[1mLOGS   [0m - Best checkpoint with score 3.38 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:04:00 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_2.1836.pt
2024-07-17 05:04:00 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_2.3984.pt', 'checkpoint_score_2.6328.pt', 'checkpoint_score_3.0078.pt', 'checkpoint_score_3.1328.pt', 'checkpoint_score_3.3828.pt']
2024-07-17 05:04:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:04:07 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:04:08 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:04:10 - [34m[1mLOGS   [0m - Training checkpoint for epoch 25/iteration 2937 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_25_iter_2937.pt
2024-07-17 05:04:11 - [34m[1mLOGS   [0m - Model state for epoch 25/iteration 2937 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_25_iter_2937.pt
[31m===========================================================================[0m
2024-07-17 05:04:13 - [32m[1mINFO   [0m - Training epoch 26
2024-07-17 05:04:14 - [34m[1mLOGS   [0m - Epoch:  26 [    2938/10000000], loss: {'classification': 4.435, 'neural_augmentation': 0.1027, 'total_loss': 4.5377}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.955, Elapsed time:  1.17
2024-07-17 05:04:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 26
	 loss={'classification': 4.4406, 'neural_augmentation': 0.1042, 'total_loss': 4.5448}
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:04:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 26
	 loss={'classification': 4.3602, 'neural_augmentation': 0.0, 'total_loss': 4.3602} || top1={'logits': 3.5664} || top5={'logits': 14.4375} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0741, 0.0532, 0.0343, 0.184, 0.0354, 0.1231, 0.0625, 0.0614, 0.029, 0.0258, 0.0354, 0.0846, 0.0517, 0.1215, 0.0225, 0.0314, 0.0328, 0.0625, 0.0436, 0.0274, 0.0292, 0.0615, 0.0372, 0.0313, 0.0982, 0.0264, 0.0219, 0.0285, 0.0249, 0.054, 0.0198, 0.0302, 0.0811, 0.4591, 0.0227, 0.0522, 0.0374, 0.0461, 0.0444, 0.0437, 0.0618, 0.0345, 0.0269, 0.038, 0.0639, 0.0588, 0.0629, 0.0495, 0.1375, 0.0551, 0.0229, 0.1089, 0.0478, 0.0246, 0.0461, 0.0383, 0.0213, 0.0263, 0.046, 0.0406, 0.0491, 0.0396, 0.0837, 0.0753, 0.0377, 0.1053, 0.0312, 0.0326, 0.069, 0.0464, 0.0666, 0.0654, 0.0419, 0.0975, 0.0459, 0.063, 0.0409, 0.0364, 0.0465, 0.0311, 0.0261, 0.0284, 0.041, 0.0685, 0.0228, 0.0318, 0.0353, 0.0229, 0.2757, 0.0354, 0.0699, 0.0693, 0.0255, 0.05, 0.066, 0.0261, 0.0224, 0.0316, 0.0424, 0.0391, 0.0372], 'AP': [0.036, 0.024, 0.0142, 0.0944, 0.0162, 0.0472, 0.0262, 0.0262, 0.012, 0.0123, 0.015, 0.0333, 0.021, 0.044, 0.0107, 0.0143, 0.0156, 0.0253, 0.0197, 0.0127, 0.0122, 0.0265, 0.0171, 0.014, 0.037, 0.0118, 0.0097, 0.013, 0.0116, 0.0217, 0.0092, 0.013, 0.031, 0.3591, 0.01, 0.0208, 0.0159, 0.02, 0.02, 0.019, 0.0359, 0.0159, 0.0121, 0.0171, 0.0244, 0.0242, 0.0253, 0.0152, 0.0629, 0.023, 0.0102, 0.0437, 0.0187, 0.0113, 0.0208, 0.0161, 0.0089, 0.0127, 0.0176, 0.0179, 0.024, 0.018, 0.0329, 0.0249, 0.0141, 0.045, 0.0143, 0.0143, 0.0307, 0.0211, 0.0256, 0.0209, 0.0169, 0.0386, 0.0159, 0.028, 0.0178, 0.0155, 0.0205, 0.0135, 0.0124, 0.013, 0.0161, 0.0391, 0.0108, 0.0144, 0.0184, 0.0106, 0.1703, 0.0153, 0.0258, 0.026, 0.0124, 0.0212, 0.0257, 0.0123, 0.0105, 0.014, 0.0176, 0.0174, 0.0158], 'Recall@P=50': [0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0276, 'macro': 0.0259, 'weighted': 0.026}
2024-07-17 05:04:52 - [34m[1mLOGS   [0m - Best checkpoint with score 3.57 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:04:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_2.3984.pt
2024-07-17 05:04:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_2.6328.pt', 'checkpoint_score_3.0078.pt', 'checkpoint_score_3.1328.pt', 'checkpoint_score_3.3828.pt', 'checkpoint_score_3.5664.pt']
2024-07-17 05:04:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:05:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:05:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:05:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 26/iteration 3051 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_26_iter_3051.pt
2024-07-17 05:05:04 - [34m[1mLOGS   [0m - Model state for epoch 26/iteration 3051 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_26_iter_3051.pt
[31m===========================================================================[0m
2024-07-17 05:05:06 - [32m[1mINFO   [0m - Training epoch 27
2024-07-17 05:05:07 - [34m[1mLOGS   [0m - Epoch:  27 [    3052/10000000], loss: {'classification': 4.3836, 'neural_augmentation': 0.107, 'total_loss': 4.4906}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 0.853, Elapsed time:  1.13
2024-07-17 05:05:33 - [34m[1mLOGS   [0m - *** Training summary for epoch 27
	 loss={'classification': 4.4296, 'neural_augmentation': 0.1085, 'total_loss': 4.538}
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:42 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:05:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 27
	 loss={'classification': 4.3307, 'neural_augmentation': 0.0, 'total_loss': 4.3307} || top1={'logits': 4.043} || top5={'logits': 15.7812} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0742, 0.0668, 0.0303, 0.1785, 0.0392, 0.1256, 0.0616, 0.0767, 0.0293, 0.0269, 0.033, 0.1067, 0.0529, 0.091, 0.0228, 0.0361, 0.0355, 0.0657, 0.051, 0.0284, 0.0389, 0.1464, 0.0618, 0.0296, 0.1021, 0.0272, 0.0214, 0.0291, 0.0242, 0.0531, 0.0202, 0.0297, 0.0752, 0.4526, 0.0234, 0.0586, 0.0385, 0.049, 0.0453, 0.0396, 0.0728, 0.0321, 0.0266, 0.0403, 0.0739, 0.0569, 0.0633, 0.0511, 0.147, 0.0651, 0.023, 0.0981, 0.0403, 0.0254, 0.0511, 0.0461, 0.0209, 0.031, 0.0475, 0.0422, 0.0623, 0.0371, 0.0775, 0.0757, 0.0372, 0.1494, 0.0289, 0.0311, 0.0679, 0.0482, 0.0604, 0.0331, 0.0372, 0.1007, 0.0425, 0.0795, 0.0423, 0.0418, 0.0503, 0.0315, 0.0267, 0.0279, 0.036, 0.0757, 0.0249, 0.0303, 0.0375, 0.0232, 0.2873, 0.0366, 0.0722, 0.0787, 0.0271, 0.0544, 0.0608, 0.0274, 0.0268, 0.0394, 0.0488, 0.0329, 0.0369], 'AP': [0.0359, 0.0297, 0.0134, 0.0987, 0.0171, 0.0529, 0.0268, 0.0315, 0.0135, 0.0122, 0.0141, 0.0418, 0.0213, 0.0378, 0.0111, 0.0156, 0.017, 0.0263, 0.0228, 0.0138, 0.0153, 0.0686, 0.0262, 0.0136, 0.0427, 0.0119, 0.0092, 0.0133, 0.011, 0.0224, 0.0092, 0.0126, 0.0299, 0.3369, 0.011, 0.0219, 0.0158, 0.0218, 0.0197, 0.0175, 0.0329, 0.0153, 0.012, 0.0174, 0.0298, 0.0251, 0.0247, 0.0155, 0.0709, 0.0242, 0.0101, 0.0434, 0.0175, 0.0115, 0.0224, 0.0171, 0.0093, 0.0136, 0.019, 0.0176, 0.0257, 0.0165, 0.0337, 0.0271, 0.0145, 0.0717, 0.0128, 0.014, 0.0302, 0.0213, 0.0262, 0.015, 0.0162, 0.0449, 0.0153, 0.0282, 0.0175, 0.0172, 0.0216, 0.0143, 0.0125, 0.0126, 0.0157, 0.0479, 0.0118, 0.0145, 0.0151, 0.0106, 0.1838, 0.0157, 0.0282, 0.032, 0.0128, 0.0237, 0.0254, 0.0136, 0.0123, 0.0157, 0.0198, 0.0153, 0.016], 'Recall@P=50': [0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0293, 'macro': 0.0274, 'weighted': 0.0275}
2024-07-17 05:05:47 - [34m[1mLOGS   [0m - Best checkpoint with score 4.04 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:05:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_2.6328.pt
2024-07-17 05:05:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_3.0078.pt', 'checkpoint_score_3.1328.pt', 'checkpoint_score_3.3828.pt', 'checkpoint_score_3.5664.pt', 'checkpoint_score_4.0430.pt']
2024-07-17 05:05:53 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:05:56 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:05:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:05:58 - [34m[1mLOGS   [0m - Training checkpoint for epoch 27/iteration 3177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_27_iter_3177.pt
2024-07-17 05:05:59 - [34m[1mLOGS   [0m - Model state for epoch 27/iteration 3177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_27_iter_3177.pt
[31m===========================================================================[0m
2024-07-17 05:06:01 - [32m[1mINFO   [0m - Training epoch 28
2024-07-17 05:06:03 - [34m[1mLOGS   [0m - Epoch:  28 [    3178/10000000], loss: {'classification': 4.4136, 'neural_augmentation': 0.1129, 'total_loss': 4.5264}, LR: [2.7e-05, 2.7e-05], Avg. batch load time: 1.794, Elapsed time:  2.01
2024-07-17 05:06:24 - [34m[1mLOGS   [0m - *** Training summary for epoch 28
	 loss={'classification': 4.4143, 'neural_augmentation': 0.1137, 'total_loss': 4.528}
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:32 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:06:35 - [34m[1mLOGS   [0m - *** Validation summary for epoch 28
	 loss={'classification': 4.3088, 'neural_augmentation': 0.0, 'total_loss': 4.3088} || top1={'logits': 4.4453} || top5={'logits': 16.6758} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0741, 0.1352, 0.0303, 0.1528, 0.0412, 0.1528, 0.0664, 0.0769, 0.0306, 0.0284, 0.0279, 0.1102, 0.0548, 0.086, 0.025, 0.0429, 0.0389, 0.0735, 0.0537, 0.0292, 0.0323, 0.1308, 0.0532, 0.0319, 0.1359, 0.0284, 0.0228, 0.0279, 0.0233, 0.0622, 0.0272, 0.0274, 0.0808, 0.4408, 0.0267, 0.0618, 0.0443, 0.0703, 0.0469, 0.0375, 0.0687, 0.0342, 0.0282, 0.0421, 0.0786, 0.0623, 0.0623, 0.0548, 0.1296, 0.0563, 0.0279, 0.0814, 0.0421, 0.0222, 0.0522, 0.0408, 0.0207, 0.0338, 0.0508, 0.0437, 0.0467, 0.0331, 0.0796, 0.0787, 0.0231, 0.158, 0.0324, 0.0314, 0.075, 0.0469, 0.0759, 0.0395, 0.046, 0.1046, 0.0349, 0.0835, 0.0483, 0.0636, 0.0557, 0.0356, 0.0256, 0.0302, 0.0356, 0.0743, 0.0246, 0.0286, 0.0484, 0.0261, 0.3343, 0.0345, 0.0847, 0.0796, 0.032, 0.0871, 0.0705, 0.0259, 0.0291, 0.0345, 0.0503, 0.0345, 0.0368], 'AP': [0.036, 0.0593, 0.0135, 0.0749, 0.0174, 0.063, 0.0298, 0.0343, 0.0136, 0.0132, 0.0126, 0.0437, 0.0208, 0.0361, 0.0115, 0.0172, 0.0182, 0.0314, 0.022, 0.0146, 0.0147, 0.0598, 0.0232, 0.0147, 0.0725, 0.0121, 0.0102, 0.0131, 0.0108, 0.0237, 0.0119, 0.0131, 0.0345, 0.3625, 0.0112, 0.0249, 0.0173, 0.0298, 0.0206, 0.0166, 0.032, 0.0153, 0.0122, 0.0186, 0.0308, 0.0266, 0.0248, 0.0171, 0.0605, 0.0231, 0.0129, 0.0347, 0.0181, 0.0104, 0.0229, 0.018, 0.0084, 0.0148, 0.0214, 0.0168, 0.0235, 0.0159, 0.0325, 0.0289, 0.0097, 0.073, 0.0134, 0.0143, 0.0348, 0.0203, 0.031, 0.0187, 0.0165, 0.0486, 0.0144, 0.0322, 0.019, 0.0259, 0.0235, 0.0156, 0.0113, 0.0134, 0.0155, 0.0387, 0.0114, 0.0141, 0.0188, 0.0116, 0.222, 0.0148, 0.0303, 0.0323, 0.0149, 0.0389, 0.0309, 0.0119, 0.0126, 0.0145, 0.0212, 0.0158, 0.0156], 'Recall@P=50': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0313, 'macro': 0.0291, 'weighted': 0.0293}
2024-07-17 05:06:39 - [34m[1mLOGS   [0m - Best checkpoint with score 4.45 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:06:40 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_3.0078.pt
2024-07-17 05:06:40 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_3.1328.pt', 'checkpoint_score_3.3828.pt', 'checkpoint_score_3.5664.pt', 'checkpoint_score_4.0430.pt', 'checkpoint_score_4.4453.pt']
2024-07-17 05:06:45 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:06:47 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:06:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:06:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 28/iteration 3282 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_28_iter_3282.pt
2024-07-17 05:06:50 - [34m[1mLOGS   [0m - Model state for epoch 28/iteration 3282 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_28_iter_3282.pt
[31m===========================================================================[0m
2024-07-17 05:06:52 - [32m[1mINFO   [0m - Training epoch 29
2024-07-17 05:06:53 - [34m[1mLOGS   [0m - Epoch:  29 [    3283/10000000], loss: {'classification': 4.4322, 'neural_augmentation': 0.1157, 'total_loss': 4.5479}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 0.332, Elapsed time:  0.55
2024-07-17 05:07:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 29
	 loss={'classification': 4.3981, 'neural_augmentation': 0.1186, 'total_loss': 4.5167}
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:25 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:07:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 29
	 loss={'classification': 4.3074, 'neural_augmentation': 0.0, 'total_loss': 4.3074} || top1={'logits': 4.9023} || top5={'logits': 17.4609} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0744, 0.1078, 0.0304, 0.1536, 0.0434, 0.156, 0.0764, 0.0669, 0.0383, 0.0291, 0.0272, 0.1097, 0.0595, 0.087, 0.0451, 0.0455, 0.0379, 0.0794, 0.0495, 0.0305, 0.0372, 0.1656, 0.0873, 0.0301, 0.1595, 0.0282, 0.0235, 0.0272, 0.0245, 0.0616, 0.0317, 0.029, 0.0852, 0.4665, 0.0275, 0.0479, 0.0397, 0.0822, 0.0461, 0.0427, 0.0659, 0.0329, 0.0277, 0.0414, 0.0993, 0.0551, 0.0641, 0.0403, 0.1224, 0.0619, 0.0253, 0.0736, 0.0421, 0.0259, 0.0548, 0.037, 0.0205, 0.0363, 0.0503, 0.0428, 0.045, 0.0335, 0.0794, 0.0854, 0.0315, 0.2015, 0.0326, 0.0349, 0.059, 0.0412, 0.0768, 0.0512, 0.0391, 0.1223, 0.0396, 0.085, 0.051, 0.0622, 0.0506, 0.0357, 0.03, 0.0289, 0.0343, 0.0871, 0.0307, 0.0282, 0.0404, 0.0276, 0.3197, 0.0317, 0.0904, 0.0999, 0.0305, 0.0745, 0.0639, 0.0264, 0.0331, 0.0346, 0.0516, 0.0364, 0.0413], 'AP': [0.0355, 0.0489, 0.0143, 0.0874, 0.017, 0.0832, 0.0343, 0.0275, 0.0149, 0.0132, 0.0125, 0.0462, 0.0232, 0.0403, 0.0197, 0.0191, 0.0186, 0.0316, 0.0225, 0.0146, 0.0163, 0.0787, 0.0331, 0.0142, 0.083, 0.0125, 0.0106, 0.0126, 0.011, 0.0248, 0.0135, 0.0132, 0.0374, 0.3792, 0.012, 0.0197, 0.018, 0.0311, 0.0206, 0.0181, 0.0324, 0.015, 0.0127, 0.018, 0.0403, 0.0253, 0.0265, 0.0146, 0.0544, 0.0238, 0.0115, 0.0304, 0.0181, 0.0124, 0.0227, 0.0171, 0.0091, 0.0158, 0.0208, 0.0174, 0.0222, 0.0157, 0.0364, 0.038, 0.0145, 0.1056, 0.0142, 0.0158, 0.029, 0.0173, 0.0319, 0.0216, 0.0161, 0.0505, 0.0157, 0.0328, 0.021, 0.0248, 0.0214, 0.017, 0.0141, 0.0123, 0.0157, 0.0423, 0.0147, 0.0138, 0.0162, 0.0122, 0.2188, 0.0146, 0.0357, 0.0431, 0.0139, 0.0349, 0.028, 0.0117, 0.014, 0.0155, 0.0216, 0.018, 0.0159], 'Recall@P=50': [0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0317, 'macro': 0.0308, 'weighted': 0.0309}
2024-07-17 05:07:31 - [34m[1mLOGS   [0m - Best checkpoint with score 4.90 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:07:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_3.1328.pt
2024-07-17 05:07:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_3.3828.pt', 'checkpoint_score_3.5664.pt', 'checkpoint_score_4.0430.pt', 'checkpoint_score_4.4453.pt', 'checkpoint_score_4.9023.pt']
2024-07-17 05:07:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:07:39 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:07:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:07:41 - [34m[1mLOGS   [0m - Training checkpoint for epoch 29/iteration 3388 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_29_iter_3388.pt
2024-07-17 05:07:42 - [34m[1mLOGS   [0m - Model state for epoch 29/iteration 3388 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_29_iter_3388.pt
[31m===========================================================================[0m
2024-07-17 05:07:44 - [32m[1mINFO   [0m - Training epoch 30
2024-07-17 05:07:46 - [34m[1mLOGS   [0m - Epoch:  30 [    3389/10000000], loss: {'classification': 4.4013, 'neural_augmentation': 0.1255, 'total_loss': 4.5268}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.329, Elapsed time:  1.54
2024-07-17 05:08:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 30
	 loss={'classification': 4.3876, 'neural_augmentation': 0.1239, 'total_loss': 4.5114}
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:08:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 30
	 loss={'classification': 4.2614, 'neural_augmentation': 0.0, 'total_loss': 4.2614} || top1={'logits': 5.1523} || top5={'logits': 19.0234} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0744, 0.1644, 0.0318, 0.1916, 0.0406, 0.1398, 0.0916, 0.0887, 0.0358, 0.0287, 0.0298, 0.1063, 0.056, 0.1142, 0.0541, 0.0459, 0.0428, 0.098, 0.0494, 0.0311, 0.058, 0.1659, 0.0882, 0.0347, 0.1542, 0.029, 0.0273, 0.0305, 0.0262, 0.0825, 0.035, 0.0297, 0.095, 0.468, 0.0262, 0.0461, 0.0734, 0.0686, 0.0482, 0.0352, 0.0686, 0.0348, 0.0288, 0.0416, 0.0986, 0.0656, 0.0605, 0.0391, 0.1205, 0.0649, 0.0292, 0.0628, 0.0444, 0.0279, 0.0519, 0.0387, 0.0209, 0.0348, 0.0559, 0.0502, 0.1092, 0.0345, 0.0764, 0.0791, 0.0412, 0.1931, 0.0363, 0.036, 0.073, 0.0499, 0.0861, 0.0755, 0.0428, 0.1178, 0.046, 0.0966, 0.05, 0.0796, 0.0529, 0.0573, 0.0346, 0.0326, 0.034, 0.1465, 0.0409, 0.0324, 0.0614, 0.03, 0.3354, 0.0311, 0.0731, 0.0946, 0.0401, 0.121, 0.0771, 0.027, 0.0328, 0.0482, 0.0556, 0.0454, 0.0507], 'AP': [0.0373, 0.079, 0.0144, 0.1119, 0.0181, 0.0715, 0.0407, 0.0357, 0.0156, 0.0132, 0.0136, 0.0459, 0.0229, 0.0497, 0.0203, 0.0197, 0.0196, 0.0356, 0.023, 0.015, 0.022, 0.0839, 0.036, 0.0156, 0.0799, 0.0135, 0.0123, 0.014, 0.0129, 0.0305, 0.0146, 0.0135, 0.0389, 0.3795, 0.0116, 0.0219, 0.025, 0.032, 0.0219, 0.0159, 0.031, 0.0158, 0.0135, 0.0186, 0.0429, 0.0283, 0.0279, 0.0145, 0.0543, 0.0238, 0.0144, 0.027, 0.0196, 0.0124, 0.0232, 0.0175, 0.0097, 0.015, 0.0238, 0.0174, 0.0529, 0.0154, 0.0323, 0.0315, 0.0178, 0.0892, 0.0166, 0.0163, 0.0353, 0.0206, 0.0345, 0.0304, 0.0176, 0.052, 0.0186, 0.0406, 0.0202, 0.0315, 0.0241, 0.0242, 0.016, 0.0135, 0.016, 0.071, 0.0144, 0.0148, 0.0218, 0.0129, 0.2183, 0.014, 0.0299, 0.0407, 0.0176, 0.0541, 0.0337, 0.0119, 0.0141, 0.019, 0.0242, 0.0198, 0.0177], 'Recall@P=50': [0.0, 0.0, 0.0, 0.024, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0341, 'macro': 0.0333, 'weighted': 0.0335}
2024-07-17 05:08:23 - [34m[1mLOGS   [0m - Best checkpoint with score 5.15 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:08:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_3.3828.pt
2024-07-17 05:08:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_3.5664.pt', 'checkpoint_score_4.0430.pt', 'checkpoint_score_4.4453.pt', 'checkpoint_score_4.9023.pt', 'checkpoint_score_5.1523.pt']
2024-07-17 05:08:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:08:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:08:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:08:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 30/iteration 3501 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_30_iter_3501.pt
2024-07-17 05:08:35 - [34m[1mLOGS   [0m - Model state for epoch 30/iteration 3501 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_30_iter_3501.pt
[31m===========================================================================[0m
2024-07-17 05:08:37 - [32m[1mINFO   [0m - Training epoch 31
2024-07-17 05:08:38 - [34m[1mLOGS   [0m - Epoch:  31 [    3502/10000000], loss: {'classification': 4.3974, 'neural_augmentation': 0.1339, 'total_loss': 4.5313}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 0.821, Elapsed time:  1.03
2024-07-17 05:08:59 - [34m[1mLOGS   [0m - *** Training summary for epoch 31
	 loss={'classification': 4.3626, 'neural_augmentation': 0.13, 'total_loss': 4.4927}
2024-07-17 05:09:06 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 0.52 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:07 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 31
	 loss={'classification': 4.2393, 'neural_augmentation': 0.0, 'total_loss': 4.2393} || top1={'logits': 5.5859} || top5={'logits': 19.7773} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0876, 0.1269, 0.0308, 0.1599, 0.0413, 0.1512, 0.0929, 0.0952, 0.036, 0.0293, 0.0278, 0.1427, 0.0668, 0.0772, 0.0413, 0.0547, 0.0377, 0.0831, 0.0504, 0.0356, 0.0654, 0.1797, 0.0861, 0.034, 0.1443, 0.0284, 0.0266, 0.0314, 0.0265, 0.0773, 0.0413, 0.029, 0.0866, 0.4473, 0.0262, 0.0531, 0.0606, 0.0728, 0.0514, 0.0367, 0.0733, 0.0341, 0.0317, 0.0474, 0.0932, 0.0589, 0.051, 0.0366, 0.1393, 0.0726, 0.0312, 0.1186, 0.0428, 0.0282, 0.0636, 0.0365, 0.0228, 0.0371, 0.0532, 0.048, 0.1289, 0.0321, 0.0765, 0.0818, 0.0377, 0.2181, 0.0364, 0.0341, 0.0808, 0.0452, 0.0968, 0.0876, 0.0548, 0.123, 0.0428, 0.0924, 0.0577, 0.0666, 0.0575, 0.0535, 0.0464, 0.0353, 0.0343, 0.1357, 0.0459, 0.0332, 0.0496, 0.0278, 0.3148, 0.032, 0.0828, 0.0948, 0.0416, 0.0984, 0.0744, 0.0259, 0.0356, 0.0545, 0.0691, 0.0399, 0.049], 'AP': [0.0406, 0.0602, 0.0141, 0.1079, 0.0183, 0.0615, 0.0429, 0.0421, 0.0163, 0.0143, 0.0125, 0.0626, 0.0263, 0.0352, 0.0181, 0.0273, 0.0182, 0.0338, 0.0235, 0.0165, 0.0257, 0.0922, 0.0356, 0.0159, 0.0747, 0.0132, 0.0116, 0.0149, 0.0119, 0.0306, 0.0151, 0.0147, 0.0399, 0.3678, 0.012, 0.022, 0.0223, 0.0295, 0.0232, 0.0177, 0.0333, 0.016, 0.0148, 0.02, 0.045, 0.0266, 0.0259, 0.0147, 0.0638, 0.0245, 0.0135, 0.047, 0.0187, 0.013, 0.0288, 0.0172, 0.0109, 0.0164, 0.022, 0.0176, 0.0584, 0.0154, 0.0325, 0.0308, 0.0163, 0.1112, 0.0157, 0.0154, 0.0372, 0.0191, 0.0383, 0.0334, 0.0198, 0.0555, 0.0181, 0.0413, 0.021, 0.0258, 0.0252, 0.0224, 0.0188, 0.0148, 0.0171, 0.0776, 0.0163, 0.0155, 0.0208, 0.0126, 0.2066, 0.0146, 0.0322, 0.0372, 0.0175, 0.0453, 0.0337, 0.012, 0.0159, 0.0216, 0.0272, 0.0182, 0.0189], 'Recall@P=50': [0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.012, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0357, 'macro': 0.0339, 'weighted': 0.034}
2024-07-17 05:09:12 - [34m[1mLOGS   [0m - Best checkpoint with score 5.59 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:09:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_3.5664.pt
2024-07-17 05:09:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_4.0430.pt', 'checkpoint_score_4.4453.pt', 'checkpoint_score_4.9023.pt', 'checkpoint_score_5.1523.pt', 'checkpoint_score_5.5859.pt']
2024-07-17 05:09:19 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:09:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:09:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:09:24 - [34m[1mLOGS   [0m - Training checkpoint for epoch 31/iteration 3601 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_31_iter_3601.pt
2024-07-17 05:09:24 - [34m[1mLOGS   [0m - Model state for epoch 31/iteration 3601 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_31_iter_3601.pt
[31m===========================================================================[0m
2024-07-17 05:09:26 - [32m[1mINFO   [0m - Training epoch 32
2024-07-17 05:09:28 - [34m[1mLOGS   [0m - Epoch:  32 [    3602/10000000], loss: {'classification': 4.3209, 'neural_augmentation': 0.1354, 'total_loss': 4.4563}, LR: [2.6e-05, 2.6e-05], Avg. batch load time: 1.566, Elapsed time:  1.78
2024-07-17 05:09:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 32
	 loss={'classification': 4.3381, 'neural_augmentation': 0.1358, 'total_loss': 4.4739}
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 0.5357142857142857 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:09:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 32
	 loss={'classification': 4.1801, 'neural_augmentation': 0.0, 'total_loss': 4.1801} || top1={'logits': 6.332} || top5={'logits': 21.5391} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0879, 0.1843, 0.0303, 0.2083, 0.0423, 0.1565, 0.1301, 0.0763, 0.038, 0.0307, 0.0316, 0.1298, 0.0659, 0.1166, 0.047, 0.0478, 0.0441, 0.093, 0.0438, 0.0447, 0.0747, 0.2382, 0.0937, 0.0409, 0.1844, 0.0342, 0.0312, 0.029, 0.0324, 0.0952, 0.0372, 0.0338, 0.1124, 0.444, 0.0287, 0.0541, 0.0667, 0.0862, 0.0496, 0.0407, 0.072, 0.036, 0.041, 0.0484, 0.1189, 0.0728, 0.0567, 0.0316, 0.1456, 0.0651, 0.0382, 0.1022, 0.0469, 0.0362, 0.0463, 0.0368, 0.0289, 0.0434, 0.062, 0.0473, 0.1635, 0.0321, 0.0719, 0.0847, 0.0638, 0.1719, 0.0434, 0.0393, 0.0777, 0.0413, 0.1119, 0.0927, 0.0426, 0.134, 0.0562, 0.0915, 0.0598, 0.0752, 0.0607, 0.0565, 0.0675, 0.0406, 0.0368, 0.1808, 0.0563, 0.0346, 0.0635, 0.0291, 0.3372, 0.0308, 0.0934, 0.1051, 0.046, 0.1325, 0.0853, 0.0282, 0.0379, 0.0478, 0.0612, 0.0503, 0.0477], 'AP': [0.0432, 0.0918, 0.0141, 0.1437, 0.0183, 0.0814, 0.0623, 0.0327, 0.0172, 0.0151, 0.0179, 0.0589, 0.0256, 0.0497, 0.0201, 0.0219, 0.0187, 0.0376, 0.0205, 0.0202, 0.0318, 0.1536, 0.0362, 0.0187, 0.1069, 0.0159, 0.0136, 0.0138, 0.0134, 0.0355, 0.0158, 0.0158, 0.0502, 0.3596, 0.0134, 0.0231, 0.0243, 0.0359, 0.0233, 0.0185, 0.036, 0.0165, 0.0183, 0.0208, 0.0557, 0.0306, 0.0255, 0.0138, 0.0779, 0.0269, 0.0168, 0.0448, 0.0202, 0.0151, 0.023, 0.0163, 0.0126, 0.018, 0.0248, 0.0182, 0.0731, 0.0153, 0.0334, 0.0354, 0.0239, 0.0924, 0.018, 0.0174, 0.0353, 0.0184, 0.0501, 0.0382, 0.0189, 0.0566, 0.0216, 0.0431, 0.0227, 0.0303, 0.0272, 0.0243, 0.0247, 0.0166, 0.0164, 0.112, 0.019, 0.0149, 0.0279, 0.0129, 0.2318, 0.0144, 0.0401, 0.0532, 0.0202, 0.0589, 0.0377, 0.0134, 0.0161, 0.0206, 0.0255, 0.0211, 0.0207], 'Recall@P=50': [0.0, 0.0, 0.0, 0.06, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0388, 'macro': 0.0384, 'weighted': 0.0386}
2024-07-17 05:10:03 - [34m[1mLOGS   [0m - Best checkpoint with score 6.33 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:10:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_4.0430.pt
2024-07-17 05:10:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_4.4453.pt', 'checkpoint_score_4.9023.pt', 'checkpoint_score_5.1523.pt', 'checkpoint_score_5.5859.pt', 'checkpoint_score_6.3320.pt']
2024-07-17 05:10:10 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:10:12 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:10:13 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:10:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 32/iteration 3708 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_32_iter_3708.pt
2024-07-17 05:10:15 - [34m[1mLOGS   [0m - Model state for epoch 32/iteration 3708 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_32_iter_3708.pt
[31m===========================================================================[0m
2024-07-17 05:10:17 - [32m[1mINFO   [0m - Training epoch 33
2024-07-17 05:10:19 - [34m[1mLOGS   [0m - Epoch:  33 [    3709/10000000], loss: {'classification': 4.3009, 'neural_augmentation': 0.1455, 'total_loss': 4.4464}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 1.345, Elapsed time:  1.56
2024-07-17 05:10:39 - [34m[1mLOGS   [0m - *** Training summary for epoch 33
	 loss={'classification': 4.3135, 'neural_augmentation': 0.142, 'total_loss': 4.4556}
2024-07-17 05:10:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:10:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 33
	 loss={'classification': 4.1345, 'neural_augmentation': 0.0, 'total_loss': 4.1345} || top1={'logits': 6.793} || top5={'logits': 22.8867} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.0966, 0.18, 0.0305, 0.2155, 0.0399, 0.1663, 0.171, 0.0904, 0.043, 0.0307, 0.0306, 0.1482, 0.0676, 0.1284, 0.0593, 0.0567, 0.0447, 0.0936, 0.0422, 0.0579, 0.0645, 0.281, 0.0918, 0.0475, 0.1878, 0.0384, 0.0329, 0.0298, 0.0348, 0.0997, 0.039, 0.0364, 0.1274, 0.463, 0.0294, 0.0606, 0.067, 0.0843, 0.0526, 0.0447, 0.0816, 0.0384, 0.0491, 0.0512, 0.1407, 0.0718, 0.0548, 0.0323, 0.16, 0.0781, 0.0425, 0.1109, 0.0491, 0.0347, 0.0457, 0.0362, 0.0316, 0.0403, 0.0637, 0.0454, 0.1663, 0.0331, 0.0775, 0.0807, 0.0637, 0.2317, 0.0458, 0.0432, 0.0887, 0.0581, 0.1189, 0.0933, 0.0419, 0.129, 0.0537, 0.1236, 0.0625, 0.0799, 0.061, 0.0482, 0.0634, 0.0419, 0.0492, 0.2056, 0.0475, 0.0348, 0.062, 0.0272, 0.3561, 0.0352, 0.1048, 0.1054, 0.0494, 0.1334, 0.0827, 0.0362, 0.0379, 0.0514, 0.0682, 0.0497, 0.062], 'AP': [0.0453, 0.0898, 0.0146, 0.1514, 0.0177, 0.0826, 0.0928, 0.0413, 0.0192, 0.0141, 0.0159, 0.0685, 0.0266, 0.0559, 0.0251, 0.0288, 0.0206, 0.0378, 0.0195, 0.0225, 0.0256, 0.1774, 0.0365, 0.0222, 0.112, 0.0172, 0.014, 0.0136, 0.0137, 0.0372, 0.0161, 0.0172, 0.0539, 0.3855, 0.0135, 0.0252, 0.0254, 0.0353, 0.0242, 0.0193, 0.0392, 0.0174, 0.022, 0.0223, 0.0718, 0.0291, 0.0293, 0.0138, 0.0871, 0.0344, 0.0174, 0.0471, 0.0209, 0.0146, 0.0205, 0.0166, 0.0137, 0.0194, 0.0253, 0.0192, 0.083, 0.0164, 0.0389, 0.0337, 0.0254, 0.1368, 0.0197, 0.0193, 0.0427, 0.0242, 0.055, 0.0425, 0.0194, 0.0579, 0.0217, 0.0574, 0.0231, 0.0317, 0.0275, 0.0222, 0.0249, 0.0174, 0.0182, 0.1468, 0.0181, 0.0154, 0.0278, 0.0125, 0.2434, 0.0157, 0.0439, 0.0471, 0.0218, 0.0597, 0.0365, 0.0165, 0.0184, 0.0213, 0.0285, 0.0213, 0.0242], 'Recall@P=50': [0.0, 0.0, 0.0, 0.06, 0.0, 0.004, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0428, 'macro': 0.0419, 'weighted': 0.0421}
2024-07-17 05:10:53 - [34m[1mLOGS   [0m - Best checkpoint with score 6.79 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:10:55 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_4.4453.pt
2024-07-17 05:10:55 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_4.9023.pt', 'checkpoint_score_5.1523.pt', 'checkpoint_score_5.5859.pt', 'checkpoint_score_6.3320.pt', 'checkpoint_score_6.7930.pt']
2024-07-17 05:11:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:11:02 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:11:03 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:11:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 33/iteration 3809 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_33_iter_3809.pt
2024-07-17 05:11:06 - [34m[1mLOGS   [0m - Model state for epoch 33/iteration 3809 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_33_iter_3809.pt
[31m===========================================================================[0m
2024-07-17 05:11:08 - [32m[1mINFO   [0m - Training epoch 34
2024-07-17 05:11:09 - [34m[1mLOGS   [0m - Epoch:  34 [    3810/10000000], loss: {'classification': 4.2792, 'neural_augmentation': 0.1513, 'total_loss': 4.4305}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 1.136, Elapsed time:  1.35
2024-07-17 05:11:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 34
	 loss={'classification': 4.289, 'neural_augmentation': 0.1492, 'total_loss': 4.4381}
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:11:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 34
	 loss={'classification': 4.117, 'neural_augmentation': 0.0, 'total_loss': 4.117} || top1={'logits': 7.2852} || top5={'logits': 23.418} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.095, 0.1712, 0.0293, 0.205, 0.0408, 0.1513, 0.1975, 0.0983, 0.0444, 0.0308, 0.0293, 0.1459, 0.0891, 0.1174, 0.0614, 0.0657, 0.0462, 0.1062, 0.0484, 0.0484, 0.0745, 0.2766, 0.086, 0.0487, 0.1852, 0.0408, 0.0353, 0.0315, 0.0294, 0.1074, 0.0437, 0.0369, 0.1246, 0.4626, 0.0313, 0.0638, 0.0716, 0.0888, 0.0499, 0.0441, 0.1022, 0.0371, 0.056, 0.0484, 0.1454, 0.0728, 0.0533, 0.0383, 0.1472, 0.0732, 0.0479, 0.112, 0.0477, 0.0357, 0.0587, 0.0396, 0.044, 0.0442, 0.0599, 0.044, 0.1744, 0.0365, 0.0738, 0.0872, 0.0723, 0.243, 0.0485, 0.0378, 0.1087, 0.0504, 0.1306, 0.0797, 0.0484, 0.1475, 0.053, 0.1328, 0.0664, 0.074, 0.063, 0.0506, 0.0649, 0.0429, 0.0646, 0.2328, 0.0502, 0.0463, 0.0594, 0.029, 0.376, 0.0407, 0.0973, 0.0969, 0.0518, 0.1312, 0.0861, 0.0377, 0.0436, 0.0543, 0.0706, 0.0516, 0.0548], 'AP': [0.0454, 0.0866, 0.0144, 0.1466, 0.0175, 0.0813, 0.1278, 0.0445, 0.0201, 0.0142, 0.0151, 0.072, 0.0345, 0.054, 0.0255, 0.0337, 0.0216, 0.0448, 0.0223, 0.0198, 0.0282, 0.1611, 0.0368, 0.0238, 0.1207, 0.0179, 0.0149, 0.0143, 0.0134, 0.0434, 0.0164, 0.0193, 0.0564, 0.3899, 0.014, 0.025, 0.0251, 0.0339, 0.0243, 0.019, 0.0471, 0.0167, 0.0247, 0.0216, 0.0794, 0.0316, 0.0279, 0.0152, 0.0775, 0.03, 0.0237, 0.0475, 0.0198, 0.0158, 0.0258, 0.0178, 0.0153, 0.0218, 0.0244, 0.019, 0.0825, 0.0168, 0.0333, 0.0355, 0.0303, 0.1387, 0.0203, 0.017, 0.0486, 0.021, 0.062, 0.0399, 0.0214, 0.0654, 0.0219, 0.0649, 0.0244, 0.0311, 0.0277, 0.0214, 0.0266, 0.0179, 0.0217, 0.1463, 0.0187, 0.0184, 0.0278, 0.0131, 0.2573, 0.0174, 0.0429, 0.0441, 0.0231, 0.0594, 0.0384, 0.0161, 0.0203, 0.0234, 0.032, 0.0215, 0.0237], 'Recall@P=50': [0.0, 0.0, 0.0, 0.06, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0], 'micro': 0.0435, 'macro': 0.0433, 'weighted': 0.0435}
2024-07-17 05:11:46 - [34m[1mLOGS   [0m - Best checkpoint with score 7.29 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:11:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_4.9023.pt
2024-07-17 05:11:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_5.1523.pt', 'checkpoint_score_5.5859.pt', 'checkpoint_score_6.3320.pt', 'checkpoint_score_6.7930.pt', 'checkpoint_score_7.2852.pt']
2024-07-17 05:11:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:11:54 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:11:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:11:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 34/iteration 3914 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_34_iter_3914.pt
2024-07-17 05:11:58 - [34m[1mLOGS   [0m - Model state for epoch 34/iteration 3914 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_34_iter_3914.pt
[31m===========================================================================[0m
2024-07-17 05:12:00 - [32m[1mINFO   [0m - Training epoch 35
2024-07-17 05:12:02 - [34m[1mLOGS   [0m - Epoch:  35 [    3915/10000000], loss: {'classification': 4.2896, 'neural_augmentation': 0.1576, 'total_loss': 4.4472}, LR: [2.5e-05, 2.5e-05], Avg. batch load time: 2.026, Elapsed time:  2.24
2024-07-17 05:12:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 35
	 loss={'classification': 4.2796, 'neural_augmentation': 0.1563, 'total_loss': 4.4359}
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 0.5714285714285714 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:12:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 35
	 loss={'classification': 4.0675, 'neural_augmentation': 0.0, 'total_loss': 4.0675} || top1={'logits': 7.418} || top5={'logits': 24.7812} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1012, 0.209, 0.03, 0.2369, 0.0459, 0.1483, 0.2105, 0.1011, 0.0472, 0.0298, 0.0343, 0.1567, 0.0975, 0.1391, 0.0786, 0.0595, 0.0466, 0.1244, 0.0577, 0.053, 0.0688, 0.2936, 0.0904, 0.0557, 0.1992, 0.0416, 0.0351, 0.0374, 0.0315, 0.1187, 0.0444, 0.0398, 0.1411, 0.4571, 0.0403, 0.0611, 0.0806, 0.0924, 0.0555, 0.0465, 0.1303, 0.0386, 0.0531, 0.0498, 0.1477, 0.0803, 0.0613, 0.0439, 0.1794, 0.0707, 0.0543, 0.1111, 0.054, 0.0482, 0.0646, 0.0397, 0.0331, 0.0597, 0.0646, 0.0411, 0.1929, 0.0315, 0.0849, 0.0918, 0.0845, 0.2197, 0.0559, 0.0384, 0.1045, 0.0513, 0.1528, 0.0956, 0.0467, 0.1548, 0.0677, 0.1466, 0.0533, 0.0834, 0.0629, 0.0583, 0.0655, 0.0445, 0.0642, 0.2218, 0.0514, 0.046, 0.0752, 0.0297, 0.3642, 0.0516, 0.096, 0.0985, 0.0622, 0.1509, 0.0883, 0.0435, 0.0504, 0.0522, 0.0837, 0.0552, 0.0497], 'AP': [0.0464, 0.1043, 0.0148, 0.1667, 0.0199, 0.0949, 0.1517, 0.0461, 0.0211, 0.0142, 0.0162, 0.0773, 0.0391, 0.0639, 0.0355, 0.03, 0.0233, 0.0518, 0.0248, 0.0222, 0.0279, 0.1758, 0.0373, 0.0282, 0.1307, 0.0196, 0.0155, 0.0169, 0.0149, 0.0466, 0.0177, 0.0186, 0.0614, 0.3571, 0.0163, 0.0266, 0.031, 0.0355, 0.0267, 0.0205, 0.0569, 0.0174, 0.024, 0.0219, 0.0755, 0.0339, 0.0286, 0.0156, 0.1045, 0.0285, 0.0238, 0.0456, 0.0219, 0.0183, 0.0285, 0.0176, 0.015, 0.0241, 0.0261, 0.0181, 0.1112, 0.0149, 0.0362, 0.0369, 0.0348, 0.1256, 0.0236, 0.0177, 0.0496, 0.022, 0.0747, 0.0429, 0.0209, 0.071, 0.025, 0.0747, 0.0216, 0.0366, 0.0282, 0.0257, 0.0262, 0.0185, 0.0221, 0.1551, 0.0197, 0.0203, 0.0345, 0.0135, 0.2704, 0.0224, 0.0381, 0.0436, 0.026, 0.0726, 0.0407, 0.0196, 0.0228, 0.0218, 0.034, 0.0226, 0.0218], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.076, 0.0, 0.004, 0.056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0462, 'macro': 0.0465, 'weighted': 0.0467}
2024-07-17 05:12:40 - [34m[1mLOGS   [0m - Best checkpoint with score 7.42 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:12:40 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_5.1523.pt
2024-07-17 05:12:40 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_5.5859.pt', 'checkpoint_score_6.3320.pt', 'checkpoint_score_6.7930.pt', 'checkpoint_score_7.2852.pt', 'checkpoint_score_7.4180.pt']
2024-07-17 05:12:45 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:12:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:12:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:12:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 35/iteration 4026 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_35_iter_4026.pt
2024-07-17 05:12:51 - [34m[1mLOGS   [0m - Model state for epoch 35/iteration 4026 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_35_iter_4026.pt
[31m===========================================================================[0m
2024-07-17 05:12:53 - [32m[1mINFO   [0m - Training epoch 36
2024-07-17 05:12:54 - [34m[1mLOGS   [0m - Epoch:  36 [    4027/10000000], loss: {'classification': 4.2736, 'neural_augmentation': 0.1648, 'total_loss': 4.4384}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 0.778, Elapsed time:  1.00
2024-07-17 05:13:15 - [34m[1mLOGS   [0m - *** Training summary for epoch 36
	 loss={'classification': 4.2531, 'neural_augmentation': 0.1631, 'total_loss': 4.4162}
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 0.5151515151515151 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:23 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:24 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:13:26 - [34m[1mLOGS   [0m - *** Validation summary for epoch 36
	 loss={'classification': 4.0458, 'neural_augmentation': 0.0, 'total_loss': 4.0458} || top1={'logits': 7.4648} || top5={'logits': 25.0039} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1054, 0.1996, 0.0308, 0.2362, 0.0408, 0.2082, 0.2972, 0.121, 0.0521, 0.0297, 0.0467, 0.1567, 0.0938, 0.1425, 0.0925, 0.0551, 0.051, 0.1035, 0.048, 0.0562, 0.0724, 0.3084, 0.0967, 0.0728, 0.195, 0.0511, 0.0384, 0.041, 0.0387, 0.1033, 0.0405, 0.0439, 0.168, 0.4413, 0.0368, 0.0672, 0.0837, 0.0961, 0.0573, 0.049, 0.1141, 0.0418, 0.0634, 0.0576, 0.16, 0.0708, 0.0576, 0.0362, 0.2043, 0.0798, 0.0656, 0.1177, 0.0531, 0.0421, 0.0513, 0.0377, 0.0386, 0.0522, 0.0654, 0.0435, 0.1932, 0.0325, 0.0905, 0.0775, 0.0908, 0.2489, 0.0519, 0.0411, 0.1071, 0.0659, 0.1575, 0.0933, 0.0486, 0.1527, 0.0677, 0.1254, 0.0598, 0.0924, 0.07, 0.0577, 0.0586, 0.0427, 0.0671, 0.2257, 0.0623, 0.0464, 0.0849, 0.0299, 0.3911, 0.0557, 0.114, 0.0847, 0.06, 0.1588, 0.0893, 0.0541, 0.0539, 0.0422, 0.0938, 0.0526, 0.0562], 'AP': [0.0494, 0.1035, 0.0149, 0.161, 0.0188, 0.1075, 0.2071, 0.0542, 0.0233, 0.014, 0.0195, 0.0754, 0.0381, 0.0715, 0.041, 0.0253, 0.0228, 0.0437, 0.021, 0.0241, 0.0281, 0.1777, 0.0398, 0.0296, 0.1321, 0.0213, 0.0175, 0.0183, 0.0165, 0.0438, 0.0164, 0.0196, 0.073, 0.3326, 0.0154, 0.029, 0.0312, 0.0418, 0.0273, 0.0196, 0.0563, 0.0185, 0.0267, 0.0244, 0.0925, 0.0331, 0.0269, 0.0149, 0.1317, 0.0301, 0.0283, 0.0526, 0.022, 0.0176, 0.0256, 0.017, 0.0163, 0.0225, 0.0284, 0.0189, 0.1136, 0.0153, 0.0362, 0.0372, 0.0382, 0.1579, 0.022, 0.0185, 0.0506, 0.0291, 0.0847, 0.0424, 0.0217, 0.0735, 0.0273, 0.0718, 0.0235, 0.0388, 0.0317, 0.0239, 0.0237, 0.0181, 0.0234, 0.1573, 0.0204, 0.0197, 0.0361, 0.0135, 0.3071, 0.0229, 0.0472, 0.0428, 0.0248, 0.0718, 0.0414, 0.0274, 0.0227, 0.0177, 0.044, 0.0228, 0.0258], 'Recall@P=50': [0.0, 0.0, 0.0, 0.068, 0.0, 0.008, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056, 0.004, 0.0, 0.0, 0.024, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0487, 'macro': 0.0491, 'weighted': 0.0493}
2024-07-17 05:13:29 - [34m[1mLOGS   [0m - Best checkpoint with score 7.46 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:13:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_5.5859.pt
2024-07-17 05:13:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_6.3320.pt', 'checkpoint_score_6.7930.pt', 'checkpoint_score_7.2852.pt', 'checkpoint_score_7.4180.pt', 'checkpoint_score_7.4648.pt']
2024-07-17 05:13:36 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:13:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:13:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:13:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 36/iteration 4128 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_36_iter_4128.pt
2024-07-17 05:13:41 - [34m[1mLOGS   [0m - Model state for epoch 36/iteration 4128 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_36_iter_4128.pt
[31m===========================================================================[0m
2024-07-17 05:13:43 - [32m[1mINFO   [0m - Training epoch 37
2024-07-17 05:13:44 - [34m[1mLOGS   [0m - Epoch:  37 [    4129/10000000], loss: {'classification': 4.2012, 'neural_augmentation': 0.1757, 'total_loss': 4.3769}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 1.047, Elapsed time:  1.27
2024-07-17 05:14:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 37
	 loss={'classification': 4.2368, 'neural_augmentation': 0.1712, 'total_loss': 4.408}
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 0.5476190476190477 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 0.5263157894736842 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:14:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 37
	 loss={'classification': 4.0396, 'neural_augmentation': 0.0, 'total_loss': 4.0396} || top1={'logits': 8.0547} || top5={'logits': 26.3711} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1126, 0.1842, 0.0362, 0.2008, 0.0411, 0.1631, 0.2448, 0.117, 0.0583, 0.0301, 0.041, 0.1787, 0.1417, 0.1245, 0.0845, 0.064, 0.0531, 0.1441, 0.0591, 0.0746, 0.0809, 0.2881, 0.0841, 0.0682, 0.2265, 0.0589, 0.0355, 0.0515, 0.0321, 0.1176, 0.0439, 0.0468, 0.1584, 0.4463, 0.0452, 0.0606, 0.084, 0.1077, 0.0608, 0.0466, 0.1248, 0.0408, 0.0821, 0.0555, 0.1886, 0.0853, 0.0608, 0.0481, 0.173, 0.0697, 0.0588, 0.1121, 0.053, 0.041, 0.0662, 0.0385, 0.0366, 0.0687, 0.0675, 0.0439, 0.2384, 0.0334, 0.086, 0.0881, 0.1033, 0.2519, 0.0749, 0.0397, 0.1168, 0.0588, 0.1801, 0.1107, 0.062, 0.1671, 0.0633, 0.1372, 0.0686, 0.103, 0.0649, 0.0563, 0.0483, 0.0415, 0.0698, 0.2287, 0.067, 0.0575, 0.0819, 0.0315, 0.3995, 0.0904, 0.109, 0.0947, 0.0642, 0.1544, 0.0747, 0.0576, 0.0607, 0.0457, 0.0893, 0.0483, 0.052], 'AP': [0.0594, 0.0952, 0.0167, 0.1577, 0.0184, 0.0945, 0.1619, 0.0537, 0.0243, 0.0154, 0.0175, 0.0881, 0.0541, 0.0592, 0.0353, 0.0307, 0.0267, 0.0625, 0.0241, 0.0295, 0.033, 0.1932, 0.0362, 0.0303, 0.1507, 0.0252, 0.0165, 0.0207, 0.0158, 0.0506, 0.018, 0.0206, 0.0685, 0.3355, 0.0183, 0.0256, 0.032, 0.0409, 0.0293, 0.0208, 0.0636, 0.019, 0.0397, 0.0247, 0.1159, 0.0359, 0.0275, 0.0174, 0.1067, 0.0272, 0.0262, 0.0479, 0.0228, 0.0182, 0.0294, 0.0178, 0.0165, 0.0247, 0.0286, 0.0197, 0.1488, 0.0151, 0.0398, 0.0402, 0.0476, 0.1515, 0.0316, 0.0184, 0.0542, 0.0295, 0.087, 0.0561, 0.0247, 0.0859, 0.0257, 0.0839, 0.0278, 0.0431, 0.0284, 0.0271, 0.0207, 0.018, 0.0249, 0.1455, 0.0236, 0.0248, 0.0382, 0.0137, 0.3085, 0.0336, 0.0474, 0.0449, 0.0276, 0.0703, 0.0355, 0.0249, 0.0266, 0.019, 0.0387, 0.0218, 0.0233], 'Recall@P=50': [0.004, 0.0, 0.0, 0.092, 0.0, 0.004, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.004, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0488, 'macro': 0.0508, 'weighted': 0.0511}
2024-07-17 05:14:23 - [34m[1mLOGS   [0m - Best checkpoint with score 8.05 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:14:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_6.3320.pt
2024-07-17 05:14:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_6.7930.pt', 'checkpoint_score_7.2852.pt', 'checkpoint_score_7.4180.pt', 'checkpoint_score_7.4648.pt', 'checkpoint_score_8.0547.pt']
2024-07-17 05:14:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:14:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:14:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:14:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 37/iteration 4248 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_37_iter_4248.pt
2024-07-17 05:14:35 - [34m[1mLOGS   [0m - Model state for epoch 37/iteration 4248 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_37_iter_4248.pt
[31m===========================================================================[0m
2024-07-17 05:14:37 - [32m[1mINFO   [0m - Training epoch 38
2024-07-17 05:14:39 - [34m[1mLOGS   [0m - Epoch:  38 [    4249/10000000], loss: {'classification': 4.2274, 'neural_augmentation': 0.1788, 'total_loss': 4.4062}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 1.790, Elapsed time:  2.01
2024-07-17 05:15:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 38
	 loss={'classification': 4.1951, 'neural_augmentation': 0.1793, 'total_loss': 4.3744}
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 0.8333333333333334 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 0.5416666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:15:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 38
	 loss={'classification': 3.9755, 'neural_augmentation': 0.0, 'total_loss': 3.9755} || top1={'logits': 8.1836} || top5={'logits': 26.9492} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1263, 0.2008, 0.0426, 0.254, 0.0584, 0.1914, 0.3828, 0.1398, 0.0581, 0.0345, 0.0532, 0.222, 0.1483, 0.1621, 0.0964, 0.095, 0.0575, 0.1306, 0.0591, 0.0789, 0.1009, 0.3096, 0.0855, 0.0947, 0.2371, 0.074, 0.0385, 0.0545, 0.0292, 0.1212, 0.0511, 0.0541, 0.1703, 0.4508, 0.0346, 0.0734, 0.1029, 0.101, 0.0721, 0.0671, 0.1523, 0.0511, 0.1536, 0.0554, 0.2058, 0.0747, 0.066, 0.0459, 0.2544, 0.0686, 0.0617, 0.1594, 0.0584, 0.0381, 0.0549, 0.0339, 0.0366, 0.051, 0.0694, 0.0473, 0.2455, 0.0356, 0.1313, 0.1119, 0.1423, 0.2876, 0.0802, 0.0389, 0.1215, 0.1174, 0.1609, 0.1116, 0.0598, 0.1712, 0.0784, 0.1816, 0.0774, 0.0985, 0.0733, 0.0753, 0.0447, 0.041, 0.0707, 0.2091, 0.0712, 0.0561, 0.0895, 0.032, 0.4021, 0.0751, 0.1404, 0.0954, 0.0727, 0.1646, 0.0963, 0.0812, 0.0668, 0.0611, 0.1317, 0.0611, 0.0724], 'AP': [0.0676, 0.1046, 0.0177, 0.1725, 0.0297, 0.1101, 0.2734, 0.0672, 0.0246, 0.0154, 0.0237, 0.1285, 0.0744, 0.0807, 0.0441, 0.0383, 0.0261, 0.0595, 0.0236, 0.0314, 0.0461, 0.1897, 0.041, 0.0398, 0.1559, 0.032, 0.0173, 0.0228, 0.0145, 0.0505, 0.0241, 0.0231, 0.0772, 0.3567, 0.0151, 0.0304, 0.0387, 0.0448, 0.0323, 0.0319, 0.0766, 0.022, 0.0719, 0.0246, 0.1214, 0.0339, 0.0301, 0.0172, 0.1514, 0.0294, 0.0272, 0.091, 0.0245, 0.0169, 0.0272, 0.0153, 0.0165, 0.021, 0.0286, 0.0208, 0.1507, 0.0156, 0.0572, 0.0457, 0.0747, 0.1895, 0.0341, 0.0181, 0.0689, 0.0522, 0.0739, 0.05, 0.0274, 0.0913, 0.0339, 0.11, 0.0327, 0.0467, 0.0307, 0.0312, 0.0203, 0.0184, 0.0242, 0.1479, 0.0267, 0.0231, 0.0392, 0.0142, 0.2963, 0.0307, 0.0611, 0.0456, 0.0284, 0.0786, 0.0431, 0.0334, 0.0309, 0.0247, 0.0581, 0.0286, 0.0309], 'Recall@P=50': [0.004, 0.0029, 0.0, 0.004, 0.004, 0.028, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.0545, 'macro': 0.0584, 'weighted': 0.0587}
2024-07-17 05:15:16 - [34m[1mLOGS   [0m - Best checkpoint with score 8.18 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:15:18 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_6.7930.pt
2024-07-17 05:15:18 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_7.2852.pt', 'checkpoint_score_7.4180.pt', 'checkpoint_score_7.4648.pt', 'checkpoint_score_8.0547.pt', 'checkpoint_score_8.1836.pt']
2024-07-17 05:15:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:15:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:15:26 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:15:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 38/iteration 4362 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_38_iter_4362.pt
2024-07-17 05:15:28 - [34m[1mLOGS   [0m - Model state for epoch 38/iteration 4362 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_38_iter_4362.pt
[31m===========================================================================[0m
2024-07-17 05:15:30 - [32m[1mINFO   [0m - Training epoch 39
2024-07-17 05:15:32 - [34m[1mLOGS   [0m - Epoch:  39 [    4363/10000000], loss: {'classification': 4.1834, 'neural_augmentation': 0.1878, 'total_loss': 4.3712}, LR: [2.4e-05, 2.4e-05], Avg. batch load time: 1.281, Elapsed time:  1.49
2024-07-17 05:15:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 39
	 loss={'classification': 4.1707, 'neural_augmentation': 0.1873, 'total_loss': 4.358}
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 0.5714285714285714 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:03 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 39
	 loss={'classification': 3.9477, 'neural_augmentation': 0.0, 'total_loss': 3.9477} || top1={'logits': 9.2266} || top5={'logits': 29.5312} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1262, 0.1923, 0.0574, 0.2594, 0.0466, 0.1754, 0.3364, 0.1315, 0.0638, 0.0313, 0.0639, 0.2082, 0.1326, 0.1667, 0.1004, 0.0761, 0.0596, 0.1515, 0.0669, 0.07, 0.1159, 0.2955, 0.09, 0.0951, 0.2456, 0.0731, 0.0367, 0.0513, 0.0288, 0.13, 0.0461, 0.0529, 0.1826, 0.4695, 0.0342, 0.0788, 0.1213, 0.1117, 0.0696, 0.0639, 0.16, 0.0576, 0.128, 0.0663, 0.2078, 0.0779, 0.073, 0.0477, 0.2059, 0.0699, 0.0618, 0.1383, 0.0537, 0.038, 0.0606, 0.0327, 0.0372, 0.0517, 0.0678, 0.0572, 0.2788, 0.0521, 0.132, 0.0918, 0.1383, 0.2796, 0.0823, 0.0455, 0.1354, 0.0772, 0.202, 0.119, 0.0552, 0.2076, 0.0836, 0.1505, 0.0937, 0.1103, 0.0805, 0.0791, 0.0416, 0.0421, 0.0604, 0.2519, 0.0649, 0.0622, 0.1179, 0.0345, 0.405, 0.0922, 0.1369, 0.1111, 0.0702, 0.1676, 0.109, 0.0576, 0.0674, 0.0524, 0.1169, 0.0591, 0.0758], 'AP': [0.0615, 0.0995, 0.0214, 0.1938, 0.0219, 0.1032, 0.2122, 0.0618, 0.0274, 0.0141, 0.0273, 0.1122, 0.0604, 0.0793, 0.0444, 0.0355, 0.0305, 0.0699, 0.0222, 0.0278, 0.0467, 0.2178, 0.0406, 0.0437, 0.1608, 0.0311, 0.0173, 0.0214, 0.014, 0.0572, 0.0181, 0.0226, 0.0845, 0.3731, 0.0153, 0.0315, 0.042, 0.0499, 0.0316, 0.029, 0.0772, 0.0233, 0.0583, 0.0286, 0.1186, 0.0349, 0.034, 0.0183, 0.1185, 0.0287, 0.0266, 0.0704, 0.0236, 0.0171, 0.0275, 0.0144, 0.0166, 0.0213, 0.0287, 0.0232, 0.1635, 0.0228, 0.0623, 0.04, 0.069, 0.1799, 0.034, 0.0195, 0.0666, 0.0394, 0.1071, 0.0626, 0.0243, 0.1108, 0.0338, 0.0933, 0.0365, 0.0502, 0.0335, 0.0352, 0.0187, 0.0181, 0.0228, 0.1901, 0.0247, 0.0233, 0.0537, 0.015, 0.2987, 0.0376, 0.0728, 0.0575, 0.0282, 0.0824, 0.0499, 0.0264, 0.0292, 0.0241, 0.0511, 0.0273, 0.0299], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.06, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.056, 0.0, 0.004, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.008, 0.004, 0.008, 0.004, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0], 'micro': 0.0575, 'macro': 0.0589, 'weighted': 0.0591}
2024-07-17 05:16:10 - [34m[1mLOGS   [0m - Best checkpoint with score 9.23 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:16:11 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_7.2852.pt
2024-07-17 05:16:11 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_7.4180.pt', 'checkpoint_score_7.4648.pt', 'checkpoint_score_8.0547.pt', 'checkpoint_score_8.1836.pt', 'checkpoint_score_9.2266.pt']
2024-07-17 05:16:16 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:16:18 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:16:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:16:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 39/iteration 4475 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_39_iter_4475.pt
2024-07-17 05:16:21 - [34m[1mLOGS   [0m - Model state for epoch 39/iteration 4475 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_39_iter_4475.pt
[31m===========================================================================[0m
2024-07-17 05:16:23 - [32m[1mINFO   [0m - Training epoch 40
2024-07-17 05:16:25 - [34m[1mLOGS   [0m - Epoch:  40 [    4476/10000000], loss: {'classification': 4.2016, 'neural_augmentation': 0.1956, 'total_loss': 4.3972}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 1.813, Elapsed time:  2.03
2024-07-17 05:16:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 40
	 loss={'classification': 4.1523, 'neural_augmentation': 0.1961, 'total_loss': 4.3484}
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:56 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:57 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:16:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 40
	 loss={'classification': 3.9128, 'neural_augmentation': 0.0, 'total_loss': 3.9128} || top1={'logits': 9.7734} || top5={'logits': 30.6055} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1257, 0.1917, 0.0647, 0.2612, 0.0548, 0.1735, 0.3765, 0.1394, 0.065, 0.0323, 0.0528, 0.2189, 0.132, 0.1551, 0.1006, 0.0842, 0.0542, 0.1373, 0.0608, 0.0713, 0.1269, 0.3008, 0.0854, 0.0995, 0.227, 0.0795, 0.0399, 0.0667, 0.0379, 0.1216, 0.0546, 0.0606, 0.1855, 0.454, 0.045, 0.0912, 0.1174, 0.1075, 0.0787, 0.0684, 0.174, 0.0613, 0.1473, 0.0576, 0.2326, 0.0785, 0.0654, 0.0509, 0.2172, 0.0749, 0.0661, 0.156, 0.0554, 0.0433, 0.0668, 0.0354, 0.0372, 0.0641, 0.0762, 0.0603, 0.276, 0.0486, 0.1465, 0.0988, 0.1509, 0.266, 0.1128, 0.0436, 0.1399, 0.1417, 0.1725, 0.1369, 0.0643, 0.1897, 0.1061, 0.1401, 0.1104, 0.1063, 0.0758, 0.0848, 0.0404, 0.0452, 0.0619, 0.2877, 0.0663, 0.0632, 0.0759, 0.0349, 0.3648, 0.1054, 0.152, 0.1256, 0.0688, 0.1665, 0.0931, 0.0761, 0.064, 0.06, 0.1357, 0.061, 0.0803], 'AP': [0.067, 0.1026, 0.0232, 0.2006, 0.0252, 0.1117, 0.2888, 0.071, 0.0285, 0.0149, 0.0231, 0.1201, 0.0636, 0.0766, 0.0444, 0.0384, 0.0248, 0.0633, 0.0236, 0.0302, 0.0633, 0.2164, 0.0414, 0.0436, 0.1543, 0.0335, 0.0191, 0.0276, 0.0164, 0.0508, 0.021, 0.0244, 0.0947, 0.3456, 0.0191, 0.0334, 0.0463, 0.0481, 0.0349, 0.0303, 0.0846, 0.0238, 0.0687, 0.0255, 0.1445, 0.0332, 0.0332, 0.0229, 0.1342, 0.0298, 0.0294, 0.0815, 0.0257, 0.0181, 0.0283, 0.0152, 0.0161, 0.0249, 0.0327, 0.0264, 0.1733, 0.0217, 0.0658, 0.0435, 0.0782, 0.1619, 0.0477, 0.02, 0.0662, 0.0724, 0.0854, 0.0705, 0.0295, 0.0988, 0.0454, 0.0783, 0.047, 0.0509, 0.0314, 0.038, 0.0188, 0.0203, 0.0232, 0.2072, 0.0277, 0.0267, 0.0335, 0.0166, 0.2809, 0.0423, 0.0715, 0.0561, 0.0282, 0.0835, 0.0439, 0.031, 0.0295, 0.0253, 0.0638, 0.027, 0.0333], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.144, 0.0, 0.024, 0.06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.072, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004], 'micro': 0.0606, 'macro': 0.0616, 'weighted': 0.0618}
2024-07-17 05:17:01 - [34m[1mLOGS   [0m - Best checkpoint with score 9.77 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:17:03 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_7.4180.pt
2024-07-17 05:17:03 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_7.4648.pt', 'checkpoint_score_8.0547.pt', 'checkpoint_score_8.1836.pt', 'checkpoint_score_9.2266.pt', 'checkpoint_score_9.7734.pt']
2024-07-17 05:17:09 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:17:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:17:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:17:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 40/iteration 4586 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_40_iter_4586.pt
2024-07-17 05:17:14 - [34m[1mLOGS   [0m - Model state for epoch 40/iteration 4586 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_40_iter_4586.pt
[31m===========================================================================[0m
2024-07-17 05:17:16 - [32m[1mINFO   [0m - Training epoch 41
2024-07-17 05:17:17 - [34m[1mLOGS   [0m - Epoch:  41 [    4587/10000000], loss: {'classification': 4.1259, 'neural_augmentation': 0.2056, 'total_loss': 4.3315}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 1.333, Elapsed time:  1.59
2024-07-17 05:17:38 - [34m[1mLOGS   [0m - *** Training summary for epoch 41
	 loss={'classification': 4.1222, 'neural_augmentation': 0.2049, 'total_loss': 4.3271}
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:47 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:17:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 41
	 loss={'classification': 3.8674, 'neural_augmentation': 0.0, 'total_loss': 3.8674} || top1={'logits': 10.2812} || top5={'logits': 31.1875} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1358, 0.2065, 0.0674, 0.2387, 0.0776, 0.1495, 0.3822, 0.1419, 0.0755, 0.0372, 0.0553, 0.3079, 0.1387, 0.1359, 0.1051, 0.098, 0.0682, 0.167, 0.0444, 0.0758, 0.1385, 0.3104, 0.1016, 0.1054, 0.2364, 0.0838, 0.0479, 0.0681, 0.032, 0.1245, 0.0491, 0.0632, 0.2248, 0.4441, 0.0484, 0.0947, 0.1186, 0.117, 0.0761, 0.0902, 0.1612, 0.0558, 0.1525, 0.0643, 0.2575, 0.0896, 0.0705, 0.0554, 0.2077, 0.0731, 0.0634, 0.1888, 0.0595, 0.0473, 0.0684, 0.0366, 0.0375, 0.0581, 0.0854, 0.062, 0.2928, 0.0657, 0.1461, 0.1217, 0.178, 0.3448, 0.0867, 0.0425, 0.1489, 0.2625, 0.1661, 0.0907, 0.0735, 0.2051, 0.111, 0.1937, 0.1048, 0.113, 0.0842, 0.0997, 0.0446, 0.0439, 0.0723, 0.2845, 0.0836, 0.0635, 0.1261, 0.035, 0.4227, 0.0822, 0.1716, 0.1469, 0.076, 0.1843, 0.1016, 0.0829, 0.0733, 0.0657, 0.1427, 0.0529, 0.0832], 'AP': [0.0701, 0.1137, 0.0229, 0.1647, 0.0341, 0.0784, 0.3038, 0.0697, 0.032, 0.016, 0.0234, 0.2, 0.0694, 0.0673, 0.0505, 0.0421, 0.031, 0.0817, 0.0196, 0.0312, 0.0662, 0.2485, 0.0492, 0.0521, 0.1478, 0.0357, 0.0208, 0.0281, 0.0145, 0.0634, 0.0199, 0.0253, 0.1143, 0.3621, 0.02, 0.0394, 0.0502, 0.0514, 0.0347, 0.0455, 0.084, 0.0235, 0.0704, 0.0279, 0.17, 0.0389, 0.0309, 0.0234, 0.1219, 0.0314, 0.0276, 0.1199, 0.0257, 0.0196, 0.0268, 0.0161, 0.017, 0.026, 0.0344, 0.0287, 0.2052, 0.0284, 0.071, 0.0488, 0.1021, 0.2388, 0.032, 0.0191, 0.0752, 0.1351, 0.0833, 0.0519, 0.0324, 0.1201, 0.0494, 0.1126, 0.05, 0.0519, 0.0334, 0.0427, 0.0206, 0.0187, 0.0258, 0.2018, 0.0335, 0.0236, 0.0531, 0.016, 0.3088, 0.0364, 0.0925, 0.0672, 0.0291, 0.0947, 0.0484, 0.0353, 0.0337, 0.0263, 0.07, 0.0237, 0.0445], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.044, 0.0, 0.004, 0.1, 0.004, 0.0, 0.0, 0.0, 0.044, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.092, 0.0, 0.012, 0.02, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.224, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064, 0.0, 0.004, 0.0, 0.004, 0.028, 0.0, 0.0, 0.008, 0.0, 0.004, 0.0, 0.0, 0.016, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.012], 'micro': 0.0649, 'macro': 0.0679, 'weighted': 0.0681}
2024-07-17 05:17:52 - [34m[1mLOGS   [0m - Best checkpoint with score 10.28 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:17:54 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_7.4648.pt
2024-07-17 05:17:54 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_8.0547.pt', 'checkpoint_score_8.1836.pt', 'checkpoint_score_9.2266.pt', 'checkpoint_score_9.7734.pt', 'checkpoint_score_10.2812.pt']
2024-07-17 05:17:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:18:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:18:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:18:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 41/iteration 4685 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_41_iter_4685.pt
2024-07-17 05:18:04 - [34m[1mLOGS   [0m - Model state for epoch 41/iteration 4685 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_41_iter_4685.pt
[31m===========================================================================[0m
2024-07-17 05:18:06 - [32m[1mINFO   [0m - Training epoch 42
2024-07-17 05:18:07 - [34m[1mLOGS   [0m - Epoch:  42 [    4686/10000000], loss: {'classification': 4.182, 'neural_augmentation': 0.2131, 'total_loss': 4.3951}, LR: [2.3e-05, 2.3e-05], Avg. batch load time: 0.760, Elapsed time:  0.97
2024-07-17 05:18:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 42
	 loss={'classification': 4.1056, 'neural_augmentation': 0.2141, 'total_loss': 4.3197}
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 0.5862068965517241 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:41 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:18:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 42
	 loss={'classification': 3.8631, 'neural_augmentation': 0.0, 'total_loss': 3.8631} || top1={'logits': 10.6133} || top5={'logits': 31.4922} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.126, 0.2, 0.0502, 0.287, 0.0637, 0.1672, 0.4167, 0.2027, 0.0634, 0.033, 0.0639, 0.2928, 0.1408, 0.1623, 0.1199, 0.0953, 0.0617, 0.1507, 0.0593, 0.0814, 0.1107, 0.349, 0.0899, 0.1002, 0.2302, 0.0962, 0.0487, 0.056, 0.0289, 0.1292, 0.0473, 0.0726, 0.2262, 0.4667, 0.0439, 0.0931, 0.1373, 0.119, 0.0689, 0.072, 0.1597, 0.0685, 0.1466, 0.0644, 0.2733, 0.0837, 0.0714, 0.0483, 0.2169, 0.0738, 0.0671, 0.1722, 0.0556, 0.0551, 0.0748, 0.0374, 0.0393, 0.0538, 0.073, 0.0647, 0.2849, 0.125, 0.1193, 0.103, 0.1674, 0.3758, 0.0847, 0.0397, 0.1591, 0.1846, 0.1935, 0.093, 0.0652, 0.2069, 0.0928, 0.1931, 0.1066, 0.12, 0.0817, 0.0852, 0.0475, 0.0458, 0.0879, 0.2447, 0.0843, 0.0597, 0.102, 0.0414, 0.4211, 0.0862, 0.1842, 0.12, 0.0544, 0.1868, 0.1056, 0.0709, 0.0927, 0.0688, 0.1441, 0.0609, 0.09], 'AP': [0.0636, 0.1076, 0.0209, 0.2047, 0.0292, 0.077, 0.3222, 0.1081, 0.0283, 0.0157, 0.0266, 0.1933, 0.0692, 0.0777, 0.0564, 0.0478, 0.0322, 0.0754, 0.0241, 0.0306, 0.0471, 0.2834, 0.0423, 0.044, 0.1639, 0.0432, 0.0222, 0.0275, 0.0124, 0.0602, 0.0193, 0.0267, 0.1167, 0.3655, 0.0185, 0.0376, 0.0519, 0.0564, 0.0321, 0.035, 0.0932, 0.0262, 0.0683, 0.0276, 0.1982, 0.0351, 0.0308, 0.0204, 0.1286, 0.0305, 0.0359, 0.1072, 0.0243, 0.0225, 0.0328, 0.0164, 0.0185, 0.0232, 0.0325, 0.0268, 0.1862, 0.0529, 0.0556, 0.0468, 0.0906, 0.2704, 0.0357, 0.0179, 0.0765, 0.0961, 0.1088, 0.0428, 0.0291, 0.1097, 0.0364, 0.1251, 0.057, 0.0541, 0.0336, 0.0341, 0.0203, 0.0204, 0.0308, 0.1553, 0.0355, 0.0256, 0.0493, 0.0169, 0.3197, 0.0369, 0.1027, 0.0581, 0.0242, 0.0963, 0.0492, 0.0301, 0.0386, 0.0298, 0.0678, 0.0281, 0.0398], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.096, 0.0, 0.0, 0.228, 0.02, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.004, 0.0, 0.0, 0.0, 0.0, 0.148, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.004, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.004, 0.004, 0.0, 0.024, 0.204, 0.0, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.016, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008], 'micro': 0.0647, 'macro': 0.0688, 'weighted': 0.0689}
2024-07-17 05:18:45 - [34m[1mLOGS   [0m - Best checkpoint with score 10.61 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:18:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_8.0547.pt
2024-07-17 05:18:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_8.1836.pt', 'checkpoint_score_9.2266.pt', 'checkpoint_score_9.7734.pt', 'checkpoint_score_10.2812.pt', 'checkpoint_score_10.6133.pt']
2024-07-17 05:18:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:18:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:18:55 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:18:57 - [34m[1mLOGS   [0m - Training checkpoint for epoch 42/iteration 4803 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_42_iter_4803.pt
2024-07-17 05:18:58 - [34m[1mLOGS   [0m - Model state for epoch 42/iteration 4803 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_42_iter_4803.pt
[31m===========================================================================[0m
2024-07-17 05:19:00 - [32m[1mINFO   [0m - Training epoch 43
2024-07-17 05:19:02 - [34m[1mLOGS   [0m - Epoch:  43 [    4804/10000000], loss: {'classification': 4.1435, 'neural_augmentation': 0.2253, 'total_loss': 4.3688}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 1.965, Elapsed time:  2.18
2024-07-17 05:19:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 43
	 loss={'classification': 4.0771, 'neural_augmentation': 0.2234, 'total_loss': 4.3005}
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 0.5294117647058824 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 0.5384615384615384 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:35 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:36 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:36 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:36 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:36 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:19:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 43
	 loss={'classification': 3.771, 'neural_augmentation': 0.0, 'total_loss': 3.771} || top1={'logits': 12.4023} || top5={'logits': 35.1055} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1327, 0.2323, 0.067, 0.3299, 0.0831, 0.1899, 0.4383, 0.2016, 0.0695, 0.0351, 0.1115, 0.321, 0.1408, 0.1896, 0.1261, 0.1236, 0.0716, 0.1526, 0.0579, 0.0846, 0.1603, 0.3513, 0.0843, 0.1047, 0.2474, 0.0925, 0.0648, 0.0848, 0.033, 0.122, 0.0483, 0.0775, 0.2547, 0.4464, 0.0562, 0.13, 0.1288, 0.139, 0.0847, 0.1113, 0.1871, 0.064, 0.1618, 0.0731, 0.25, 0.0864, 0.0659, 0.0596, 0.2505, 0.0766, 0.0763, 0.2138, 0.059, 0.0594, 0.0752, 0.0393, 0.0406, 0.0599, 0.0919, 0.0798, 0.3264, 0.1333, 0.1279, 0.1145, 0.1818, 0.4079, 0.0826, 0.0377, 0.1855, 0.3491, 0.192, 0.1083, 0.0902, 0.1988, 0.1242, 0.1788, 0.1443, 0.1191, 0.0944, 0.0969, 0.0489, 0.0507, 0.0783, 0.3005, 0.0846, 0.0653, 0.1301, 0.0542, 0.4146, 0.1101, 0.2072, 0.1455, 0.0745, 0.2015, 0.1511, 0.0831, 0.0841, 0.0568, 0.1491, 0.0754, 0.0852], 'AP': [0.0667, 0.1308, 0.0261, 0.2687, 0.0484, 0.0974, 0.3863, 0.105, 0.0304, 0.0161, 0.0511, 0.2125, 0.0659, 0.0929, 0.0558, 0.051, 0.0314, 0.0768, 0.0222, 0.0343, 0.0726, 0.2817, 0.0409, 0.0478, 0.1693, 0.0428, 0.0278, 0.0346, 0.015, 0.0621, 0.0197, 0.0294, 0.141, 0.385, 0.0256, 0.0557, 0.0613, 0.0639, 0.0396, 0.0594, 0.0957, 0.026, 0.0861, 0.0299, 0.1682, 0.0382, 0.0308, 0.0268, 0.1494, 0.0322, 0.0361, 0.1387, 0.0265, 0.0264, 0.032, 0.0168, 0.0195, 0.0262, 0.0383, 0.0344, 0.2525, 0.0717, 0.0598, 0.0475, 0.0948, 0.3231, 0.0355, 0.0174, 0.0898, 0.2161, 0.1008, 0.056, 0.036, 0.1191, 0.0513, 0.0891, 0.0709, 0.056, 0.0369, 0.0402, 0.0224, 0.0227, 0.0306, 0.243, 0.0371, 0.0286, 0.063, 0.0237, 0.3059, 0.0501, 0.1157, 0.0693, 0.0302, 0.1131, 0.0738, 0.039, 0.0368, 0.0285, 0.0782, 0.0319, 0.0442], 'Recall@P=50': [0.0, 0.0029, 0.0, 0.184, 0.012, 0.0, 0.34, 0.004, 0.0, 0.0, 0.004, 0.076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.14, 0.0, 0.0, 0.072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.284, 0.0, 0.0, 0.004, 0.0, 0.0, 0.008, 0.004, 0.0, 0.004, 0.0, 0.06, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.004, 0.012, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.008, 0.0, 0.0, 0.0, 0.004, 0.004, 0.0, 0.008], 'micro': 0.0758, 'macro': 0.079, 'weighted': 0.079}
2024-07-17 05:19:40 - [34m[1mLOGS   [0m - Best checkpoint with score 12.40 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:19:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_8.1836.pt
2024-07-17 05:19:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_9.2266.pt', 'checkpoint_score_9.7734.pt', 'checkpoint_score_10.2812.pt', 'checkpoint_score_10.6133.pt', 'checkpoint_score_12.4023.pt']
2024-07-17 05:19:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:19:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:19:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:19:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 43/iteration 4923 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_43_iter_4923.pt
2024-07-17 05:19:52 - [34m[1mLOGS   [0m - Model state for epoch 43/iteration 4923 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_43_iter_4923.pt
[31m===========================================================================[0m
2024-07-17 05:19:54 - [32m[1mINFO   [0m - Training epoch 44
2024-07-17 05:19:56 - [34m[1mLOGS   [0m - Epoch:  44 [    4924/10000000], loss: {'classification': 4.0572, 'neural_augmentation': 0.2324, 'total_loss': 4.2896}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 1.278, Elapsed time:  1.50
2024-07-17 05:20:19 - [34m[1mLOGS   [0m - *** Training summary for epoch 44
	 loss={'classification': 4.0533, 'neural_augmentation': 0.233, 'total_loss': 4.2863}
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 0.5151515151515151 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 0.625 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:27 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:20:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 44
	 loss={'classification': 3.7131, 'neural_augmentation': 0.0, 'total_loss': 3.7131} || top1={'logits': 13.3477} || top5={'logits': 37.0938} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1348, 0.2375, 0.0549, 0.3858, 0.103, 0.1857, 0.4733, 0.2174, 0.0711, 0.043, 0.1397, 0.2997, 0.1557, 0.2263, 0.1439, 0.1225, 0.078, 0.1517, 0.0554, 0.0726, 0.1667, 0.3552, 0.0911, 0.1061, 0.2302, 0.1134, 0.0858, 0.0738, 0.0366, 0.1277, 0.0444, 0.0715, 0.3134, 0.5085, 0.0597, 0.1526, 0.1636, 0.1525, 0.0934, 0.1023, 0.1845, 0.0644, 0.1627, 0.0675, 0.3167, 0.0845, 0.0701, 0.0575, 0.2994, 0.0793, 0.0797, 0.2062, 0.0631, 0.0582, 0.0612, 0.0442, 0.0435, 0.0624, 0.0997, 0.0901, 0.3122, 0.172, 0.1346, 0.1106, 0.2453, 0.4381, 0.0912, 0.0448, 0.1881, 0.3793, 0.1916, 0.1199, 0.0853, 0.1955, 0.136, 0.2236, 0.16, 0.117, 0.1011, 0.109, 0.0616, 0.0475, 0.0778, 0.3464, 0.1089, 0.064, 0.1669, 0.0608, 0.4525, 0.1015, 0.2497, 0.1763, 0.0749, 0.208, 0.161, 0.089, 0.1004, 0.0685, 0.1574, 0.0909, 0.0912], 'AP': [0.0693, 0.1363, 0.0241, 0.3078, 0.0504, 0.1157, 0.417, 0.1215, 0.0314, 0.0178, 0.0576, 0.198, 0.0713, 0.1106, 0.067, 0.0538, 0.0344, 0.0792, 0.021, 0.0314, 0.0735, 0.2918, 0.0454, 0.0476, 0.135, 0.0454, 0.0343, 0.0304, 0.0162, 0.0725, 0.0194, 0.0288, 0.2013, 0.4491, 0.027, 0.0785, 0.0761, 0.0746, 0.0415, 0.05, 0.0928, 0.0261, 0.0832, 0.0299, 0.246, 0.0368, 0.0335, 0.0198, 0.2046, 0.0358, 0.0384, 0.1294, 0.028, 0.0239, 0.0292, 0.0192, 0.021, 0.0267, 0.0412, 0.0397, 0.2248, 0.0838, 0.0618, 0.0483, 0.1302, 0.3864, 0.0375, 0.0204, 0.0989, 0.2649, 0.1004, 0.0646, 0.0364, 0.1235, 0.0561, 0.1531, 0.0897, 0.0593, 0.0425, 0.0465, 0.0266, 0.0213, 0.0311, 0.2961, 0.0447, 0.025, 0.0937, 0.0233, 0.3236, 0.0428, 0.1511, 0.0877, 0.031, 0.1248, 0.0853, 0.0418, 0.0424, 0.0336, 0.0833, 0.0385, 0.0488], 'Recall@P=50': [0.0, 0.0, 0.0, 0.264, 0.0, 0.016, 0.372, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.168, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.032, 0.5, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.196, 0.0, 0.004, 0.0, 0.016, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.38, 0.0, 0.0, 0.004, 0.068, 0.0, 0.0, 0.0, 0.02, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.0, 0.004, 0.0, 0.008, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.008, 0.0, 0.004], 'micro': 0.0822, 'macro': 0.088, 'weighted': 0.088}
2024-07-17 05:20:32 - [34m[1mLOGS   [0m - Best checkpoint with score 13.35 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:20:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_9.2266.pt
2024-07-17 05:20:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_9.7734.pt', 'checkpoint_score_10.2812.pt', 'checkpoint_score_10.6133.pt', 'checkpoint_score_12.4023.pt', 'checkpoint_score_13.3477.pt']
2024-07-17 05:20:39 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:20:41 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:20:42 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:20:43 - [34m[1mLOGS   [0m - Training checkpoint for epoch 44/iteration 5034 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_44_iter_5034.pt
2024-07-17 05:20:44 - [34m[1mLOGS   [0m - Model state for epoch 44/iteration 5034 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_44_iter_5034.pt
[31m===========================================================================[0m
2024-07-17 05:20:46 - [32m[1mINFO   [0m - Training epoch 45
2024-07-17 05:20:47 - [34m[1mLOGS   [0m - Epoch:  45 [    5035/10000000], loss: {'classification': 4.0066, 'neural_augmentation': 0.2413, 'total_loss': 4.2479}, LR: [2.2e-05, 2.2e-05], Avg. batch load time: 0.951, Elapsed time:  1.17
2024-07-17 05:21:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 45
	 loss={'classification': 4.0066, 'neural_augmentation': 0.2429, 'total_loss': 4.2495}
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 0.5161290322580645 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 0.5714285714285714 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:17 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:18 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:21:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 45
	 loss={'classification': 3.6665, 'neural_augmentation': 0.0, 'total_loss': 3.6665} || top1={'logits': 13.9023} || top5={'logits': 38.9766} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1471, 0.2468, 0.062, 0.3764, 0.1207, 0.1856, 0.4613, 0.2288, 0.0709, 0.0541, 0.1278, 0.317, 0.151, 0.2074, 0.1251, 0.1235, 0.0773, 0.1629, 0.062, 0.077, 0.1797, 0.3697, 0.0934, 0.1157, 0.251, 0.1111, 0.0827, 0.0963, 0.0383, 0.1295, 0.0492, 0.0775, 0.3302, 0.5044, 0.0685, 0.1465, 0.1647, 0.1481, 0.0962, 0.0996, 0.1973, 0.0628, 0.1677, 0.0743, 0.3279, 0.0912, 0.0698, 0.0647, 0.2957, 0.081, 0.0835, 0.2022, 0.0645, 0.0633, 0.077, 0.0518, 0.0567, 0.0699, 0.1019, 0.1113, 0.3333, 0.1887, 0.1269, 0.1192, 0.2273, 0.4837, 0.0996, 0.0428, 0.2065, 0.3973, 0.2022, 0.1623, 0.107, 0.206, 0.1429, 0.2441, 0.2118, 0.1257, 0.1008, 0.1029, 0.0782, 0.0553, 0.088, 0.3957, 0.12, 0.0714, 0.1779, 0.0668, 0.4462, 0.1232, 0.2606, 0.1848, 0.0831, 0.2061, 0.1653, 0.1087, 0.1051, 0.0825, 0.1646, 0.107, 0.0798], 'AP': [0.0734, 0.148, 0.0295, 0.3388, 0.054, 0.1139, 0.416, 0.1307, 0.0318, 0.0197, 0.0551, 0.228, 0.0753, 0.1068, 0.0607, 0.0515, 0.0364, 0.0896, 0.0251, 0.0331, 0.0898, 0.3043, 0.0445, 0.0543, 0.1696, 0.0474, 0.034, 0.0412, 0.0176, 0.0682, 0.0213, 0.0306, 0.2211, 0.4744, 0.0336, 0.0819, 0.0723, 0.0741, 0.0422, 0.0568, 0.1089, 0.0271, 0.089, 0.0314, 0.2532, 0.0411, 0.033, 0.0236, 0.2073, 0.037, 0.0407, 0.1384, 0.0285, 0.0269, 0.0353, 0.023, 0.0254, 0.0325, 0.0422, 0.0522, 0.264, 0.0997, 0.0575, 0.0556, 0.1348, 0.4353, 0.0419, 0.019, 0.1114, 0.3345, 0.1172, 0.0846, 0.0405, 0.1289, 0.0574, 0.1657, 0.1209, 0.0634, 0.0417, 0.0454, 0.0325, 0.0246, 0.034, 0.3348, 0.0509, 0.0305, 0.0927, 0.0267, 0.3427, 0.0549, 0.1665, 0.0956, 0.0331, 0.119, 0.0932, 0.0583, 0.045, 0.036, 0.0846, 0.0445, 0.0437], 'Recall@P=50': [0.0, 0.0058, 0.0, 0.276, 0.0, 0.016, 0.372, 0.0, 0.0, 0.0, 0.004, 0.064, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.0, 0.004, 0.172, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.024, 0.42, 0.004, 0.012, 0.0, 0.0, 0.0, 0.008, 0.004, 0.0, 0.004, 0.0, 0.208, 0.0, 0.004, 0.0, 0.008, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.092, 0.004, 0.0, 0.0, 0.016, 0.444, 0.0, 0.0, 0.008, 0.264, 0.004, 0.0, 0.0, 0.016, 0.0, 0.024, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.084, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.004, 0.008, 0.0, 0.0], 'micro': 0.0879, 'macro': 0.0956, 'weighted': 0.0956}
2024-07-17 05:21:23 - [34m[1mLOGS   [0m - Best checkpoint with score 13.90 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:21:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_9.7734.pt
2024-07-17 05:21:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_10.2812.pt', 'checkpoint_score_10.6133.pt', 'checkpoint_score_12.4023.pt', 'checkpoint_score_13.3477.pt', 'checkpoint_score_13.9023.pt']
2024-07-17 05:21:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:21:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:21:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:21:34 - [34m[1mLOGS   [0m - Training checkpoint for epoch 45/iteration 5138 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_45_iter_5138.pt
2024-07-17 05:21:35 - [34m[1mLOGS   [0m - Model state for epoch 45/iteration 5138 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_45_iter_5138.pt
[31m===========================================================================[0m
2024-07-17 05:21:37 - [32m[1mINFO   [0m - Training epoch 46
2024-07-17 05:21:38 - [34m[1mLOGS   [0m - Epoch:  46 [    5139/10000000], loss: {'classification': 4.0378, 'neural_augmentation': 0.2548, 'total_loss': 4.2926}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 0.848, Elapsed time:  1.06
2024-07-17 05:22:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 46
	 loss={'classification': 3.9718, 'neural_augmentation': 0.2534, 'total_loss': 4.2251}
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 0.5454545454545454 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:11 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:22:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 46
	 loss={'classification': 3.583, 'neural_augmentation': 0.0, 'total_loss': 3.583} || top1={'logits': 15.8438} || top5={'logits': 41.9375} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1515, 0.2737, 0.0864, 0.3873, 0.1404, 0.2103, 0.4749, 0.2358, 0.0876, 0.055, 0.1582, 0.3725, 0.1524, 0.222, 0.1507, 0.1238, 0.0879, 0.1673, 0.0697, 0.0832, 0.2003, 0.3947, 0.1092, 0.1229, 0.2535, 0.1287, 0.0969, 0.1051, 0.05, 0.1451, 0.0576, 0.0839, 0.3607, 0.5047, 0.0738, 0.18, 0.1624, 0.1671, 0.1122, 0.1212, 0.2123, 0.0693, 0.175, 0.077, 0.3445, 0.0918, 0.0793, 0.0736, 0.3307, 0.0935, 0.0992, 0.2494, 0.0637, 0.0692, 0.0893, 0.0804, 0.0639, 0.0768, 0.1056, 0.1308, 0.3499, 0.2164, 0.1536, 0.125, 0.2545, 0.4944, 0.1103, 0.0589, 0.2408, 0.441, 0.1948, 0.1902, 0.109, 0.2209, 0.1766, 0.2669, 0.2487, 0.126, 0.1135, 0.1066, 0.1023, 0.062, 0.0847, 0.4487, 0.1465, 0.0816, 0.2132, 0.0882, 0.4579, 0.1277, 0.2523, 0.2387, 0.091, 0.2142, 0.2293, 0.1166, 0.1115, 0.077, 0.172, 0.1199, 0.0829], 'AP': [0.0768, 0.1574, 0.042, 0.3536, 0.0672, 0.1231, 0.4389, 0.1377, 0.0365, 0.0224, 0.0731, 0.2752, 0.081, 0.104, 0.0698, 0.0571, 0.0398, 0.0884, 0.0254, 0.0352, 0.1029, 0.3318, 0.0496, 0.0689, 0.1853, 0.0607, 0.0427, 0.0513, 0.0272, 0.08, 0.0267, 0.0325, 0.2695, 0.4867, 0.0392, 0.1051, 0.077, 0.0853, 0.0511, 0.0627, 0.1343, 0.0311, 0.0997, 0.032, 0.2501, 0.0425, 0.0365, 0.0273, 0.2141, 0.0398, 0.0497, 0.1809, 0.0288, 0.0312, 0.0435, 0.032, 0.0285, 0.0335, 0.0459, 0.0628, 0.3089, 0.1272, 0.0729, 0.0598, 0.1459, 0.4488, 0.0481, 0.0221, 0.128, 0.4024, 0.1103, 0.1003, 0.0447, 0.1344, 0.0735, 0.1811, 0.1607, 0.0718, 0.0478, 0.0513, 0.0454, 0.0282, 0.0347, 0.4053, 0.0679, 0.0351, 0.1376, 0.0338, 0.3502, 0.0618, 0.1798, 0.1436, 0.0365, 0.1271, 0.1308, 0.073, 0.0501, 0.0334, 0.0929, 0.0518, 0.0399], 'Recall@P=50': [0.0, 0.0087, 0.0, 0.288, 0.0, 0.012, 0.416, 0.0, 0.0, 0.0, 0.004, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.004, 0.028, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.228, 0.404, 0.004, 0.012, 0.0, 0.0, 0.0, 0.008, 0.024, 0.0, 0.004, 0.0, 0.2, 0.0, 0.004, 0.004, 0.0, 0.0, 0.004, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.232, 0.004, 0.0, 0.0, 0.004, 0.448, 0.0, 0.0, 0.004, 0.384, 0.0, 0.0, 0.0, 0.012, 0.0, 0.024, 0.032, 0.008, 0.0, 0.008, 0.0, 0.0, 0.0, 0.4, 0.004, 0.0, 0.008, 0.0, 0.056, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.1012, 'macro': 0.1078, 'weighted': 0.1076}
2024-07-17 05:22:15 - [34m[1mLOGS   [0m - Best checkpoint with score 15.84 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:22:18 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_10.2812.pt
2024-07-17 05:22:18 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_10.6133.pt', 'checkpoint_score_12.4023.pt', 'checkpoint_score_13.3477.pt', 'checkpoint_score_13.9023.pt', 'checkpoint_score_15.8438.pt']
2024-07-17 05:22:23 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:22:25 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:22:25 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:22:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 46/iteration 5250 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_46_iter_5250.pt
2024-07-17 05:22:29 - [34m[1mLOGS   [0m - Model state for epoch 46/iteration 5250 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_46_iter_5250.pt
[31m===========================================================================[0m
2024-07-17 05:22:31 - [32m[1mINFO   [0m - Training epoch 47
2024-07-17 05:22:32 - [34m[1mLOGS   [0m - Epoch:  47 [    5251/10000000], loss: {'classification': 3.9979, 'neural_augmentation': 0.2691, 'total_loss': 4.267}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 0.510, Elapsed time:  0.84
2024-07-17 05:22:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 47
	 loss={'classification': 3.9132, 'neural_augmentation': 0.2634, 'total_loss': 4.1766}
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:04 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 47
	 loss={'classification': 3.5566, 'neural_augmentation': 0.0, 'total_loss': 3.5566} || top1={'logits': 16.4336} || top5={'logits': 42.1992} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1451, 0.2606, 0.1078, 0.4069, 0.1387, 0.2041, 0.4805, 0.2431, 0.0705, 0.0529, 0.1746, 0.371, 0.1464, 0.2059, 0.1509, 0.1193, 0.0892, 0.1783, 0.0699, 0.09, 0.1939, 0.3967, 0.0997, 0.1356, 0.2538, 0.1683, 0.1082, 0.1058, 0.0539, 0.1535, 0.0636, 0.0862, 0.3441, 0.5473, 0.0669, 0.1713, 0.1706, 0.1775, 0.1146, 0.126, 0.2138, 0.0691, 0.1859, 0.0905, 0.3346, 0.0972, 0.0802, 0.0695, 0.3216, 0.0957, 0.1111, 0.2546, 0.0683, 0.066, 0.0989, 0.1127, 0.0814, 0.1112, 0.104, 0.1518, 0.394, 0.2793, 0.1664, 0.1271, 0.257, 0.5197, 0.1408, 0.0525, 0.2371, 0.444, 0.2207, 0.2484, 0.1141, 0.2169, 0.1408, 0.3296, 0.2881, 0.1402, 0.1034, 0.0944, 0.1064, 0.0701, 0.086, 0.4689, 0.167, 0.0735, 0.2748, 0.1044, 0.466, 0.1453, 0.2737, 0.2739, 0.0902, 0.2186, 0.2649, 0.1407, 0.1138, 0.0766, 0.1547, 0.1509, 0.0842], 'AP': [0.0749, 0.1669, 0.0437, 0.3918, 0.0731, 0.1366, 0.4649, 0.1458, 0.0332, 0.0242, 0.084, 0.2838, 0.0746, 0.1142, 0.0692, 0.0665, 0.0407, 0.0838, 0.0278, 0.0387, 0.1089, 0.3402, 0.0481, 0.0771, 0.1937, 0.0917, 0.047, 0.0531, 0.0304, 0.0821, 0.0319, 0.0346, 0.2574, 0.5302, 0.0317, 0.0933, 0.0825, 0.0969, 0.0497, 0.0653, 0.1259, 0.0303, 0.1046, 0.034, 0.2506, 0.0435, 0.0397, 0.0276, 0.2356, 0.0414, 0.0557, 0.1792, 0.0297, 0.0291, 0.0538, 0.0507, 0.0335, 0.0412, 0.0455, 0.076, 0.3364, 0.1645, 0.0776, 0.0591, 0.1494, 0.5039, 0.0659, 0.0229, 0.1438, 0.4182, 0.1413, 0.1443, 0.0475, 0.1282, 0.0611, 0.2898, 0.2071, 0.0739, 0.0465, 0.0425, 0.0504, 0.032, 0.0381, 0.4474, 0.0793, 0.0307, 0.1936, 0.0406, 0.3476, 0.0765, 0.187, 0.185, 0.0366, 0.1179, 0.1468, 0.0846, 0.053, 0.0355, 0.0841, 0.0686, 0.0348], 'Recall@P=50': [0.0, 0.0116, 0.0, 0.34, 0.004, 0.016, 0.436, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.004, 0.272, 0.0, 0.016, 0.004, 0.008, 0.0, 0.004, 0.004, 0.0, 0.004, 0.0, 0.004, 0.564, 0.0, 0.004, 0.0, 0.0, 0.0, 0.008, 0.004, 0.0, 0.008, 0.0, 0.156, 0.0, 0.008, 0.0, 0.088, 0.0, 0.008, 0.044, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.248, 0.004, 0.0, 0.0, 0.0, 0.508, 0.0, 0.0, 0.004, 0.372, 0.004, 0.008, 0.0, 0.008, 0.0, 0.212, 0.02, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0, 0.0, 0.008, 0.0, 0.024, 0.004, 0.008, 0.028, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0], 'micro': 0.1057, 'macro': 0.1169, 'weighted': 0.1167}
2024-07-17 05:23:10 - [34m[1mLOGS   [0m - Best checkpoint with score 16.43 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:23:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_10.6133.pt
2024-07-17 05:23:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_12.4023.pt', 'checkpoint_score_13.3477.pt', 'checkpoint_score_13.9023.pt', 'checkpoint_score_15.8438.pt', 'checkpoint_score_16.4336.pt']
2024-07-17 05:23:17 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:23:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:23:20 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:23:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 47/iteration 5365 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_47_iter_5365.pt
2024-07-17 05:23:24 - [34m[1mLOGS   [0m - Model state for epoch 47/iteration 5365 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_47_iter_5365.pt
[31m===========================================================================[0m
2024-07-17 05:23:26 - [32m[1mINFO   [0m - Training epoch 48
2024-07-17 05:23:26 - [34m[1mLOGS   [0m - Epoch:  48 [    5366/10000000], loss: {'classification': 3.9346, 'neural_augmentation': 0.2755, 'total_loss': 4.2101}, LR: [2.1e-05, 2.1e-05], Avg. batch load time: 0.412, Elapsed time:  0.68
2024-07-17 05:23:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 48
	 loss={'classification': 3.8519, 'neural_augmentation': 0.2744, 'total_loss': 4.1263}
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:58 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 0.5238095238095238 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 0.5555555555555556 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:23:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 48
	 loss={'classification': 3.4247, 'neural_augmentation': 0.0, 'total_loss': 3.4247} || top1={'logits': 18.9961} || top5={'logits': 46.2812} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.15, 0.2797, 0.1034, 0.4138, 0.1651, 0.2824, 0.5166, 0.3069, 0.0878, 0.0705, 0.2124, 0.3903, 0.1667, 0.2107, 0.2003, 0.1567, 0.1109, 0.1757, 0.0619, 0.088, 0.2271, 0.4104, 0.1065, 0.1585, 0.3037, 0.1508, 0.1255, 0.1755, 0.1308, 0.1629, 0.0717, 0.0971, 0.4589, 0.537, 0.0931, 0.1992, 0.1734, 0.1694, 0.141, 0.148, 0.2632, 0.0822, 0.2154, 0.0892, 0.371, 0.127, 0.0897, 0.0771, 0.3494, 0.1153, 0.1113, 0.279, 0.0782, 0.084, 0.1296, 0.1237, 0.0994, 0.091, 0.1163, 0.1632, 0.4085, 0.2731, 0.1665, 0.1552, 0.2704, 0.5128, 0.1532, 0.0586, 0.2828, 0.4989, 0.202, 0.2806, 0.1296, 0.2161, 0.1982, 0.3617, 0.3705, 0.148, 0.1563, 0.1253, 0.1387, 0.0929, 0.0994, 0.5138, 0.1669, 0.0697, 0.3944, 0.1182, 0.499, 0.1621, 0.272, 0.3225, 0.0979, 0.2252, 0.2997, 0.1919, 0.1281, 0.0868, 0.1781, 0.1445, 0.0799], 'AP': [0.0857, 0.1958, 0.0478, 0.3922, 0.0973, 0.2114, 0.514, 0.2215, 0.0394, 0.0277, 0.1343, 0.3125, 0.0825, 0.1097, 0.1032, 0.0801, 0.0501, 0.0908, 0.0282, 0.0422, 0.1394, 0.3834, 0.054, 0.0968, 0.2069, 0.0669, 0.064, 0.0945, 0.0618, 0.098, 0.0345, 0.0377, 0.4136, 0.4871, 0.0476, 0.1165, 0.0956, 0.1014, 0.0685, 0.0678, 0.1639, 0.0359, 0.1304, 0.0402, 0.2925, 0.0554, 0.0399, 0.0323, 0.2524, 0.0532, 0.0656, 0.2151, 0.0361, 0.0409, 0.0697, 0.0643, 0.0424, 0.0354, 0.0533, 0.0856, 0.3563, 0.16, 0.0927, 0.0798, 0.1633, 0.4728, 0.073, 0.0248, 0.1773, 0.4936, 0.1264, 0.1653, 0.0561, 0.1444, 0.1009, 0.2533, 0.2992, 0.0788, 0.073, 0.0627, 0.0734, 0.0424, 0.0411, 0.5041, 0.0838, 0.0308, 0.3576, 0.06, 0.4709, 0.09, 0.175, 0.2047, 0.0411, 0.1272, 0.211, 0.1167, 0.0597, 0.0367, 0.1083, 0.0793, 0.0368], 'Recall@P=50': [0.0, 0.0058, 0.004, 0.34, 0.02, 0.12, 0.492, 0.088, 0.0, 0.0, 0.036, 0.188, 0.0, 0.0, 0.004, 0.004, 0.0, 0.0, 0.0, 0.0, 0.004, 0.312, 0.0, 0.004, 0.044, 0.0, 0.012, 0.004, 0.0, 0.004, 0.004, 0.0, 0.42, 0.456, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.008, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.004, 0.0, 0.0, 0.012, 0.1, 0.0, 0.004, 0.012, 0.008, 0.0, 0.0, 0.0, 0.004, 0.252, 0.0, 0.008, 0.0, 0.016, 0.492, 0.0, 0.0, 0.0, 0.476, 0.016, 0.008, 0.0, 0.032, 0.004, 0.008, 0.004, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.52, 0.004, 0.0, 0.308, 0.008, 0.496, 0.004, 0.0, 0.02, 0.0, 0.0, 0.016, 0.02, 0.0, 0.0, 0.024, 0.0, 0.0], 'micro': 0.1244, 'macro': 0.1367, 'weighted': 0.1365}
2024-07-17 05:24:05 - [34m[1mLOGS   [0m - Best checkpoint with score 19.00 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:24:07 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_12.4023.pt
2024-07-17 05:24:07 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_13.3477.pt', 'checkpoint_score_13.9023.pt', 'checkpoint_score_15.8438.pt', 'checkpoint_score_16.4336.pt', 'checkpoint_score_18.9961.pt']
2024-07-17 05:24:12 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:24:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:24:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:24:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 48/iteration 5478 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_48_iter_5478.pt
2024-07-17 05:24:19 - [34m[1mLOGS   [0m - Model state for epoch 48/iteration 5478 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_48_iter_5478.pt
[31m===========================================================================[0m
2024-07-17 05:24:21 - [32m[1mINFO   [0m - Training epoch 49
2024-07-17 05:24:22 - [34m[1mLOGS   [0m - Epoch:  49 [    5479/10000000], loss: {'classification': 3.7743, 'neural_augmentation': 0.2788, 'total_loss': 4.0531}, LR: [2e-05, 2e-05], Avg. batch load time: 0.928, Elapsed time:  1.14
2024-07-17 05:24:46 - [34m[1mLOGS   [0m - *** Training summary for epoch 49
	 loss={'classification': 3.7946, 'neural_augmentation': 0.2851, 'total_loss': 4.0796}
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:55 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:24:57 - [34m[1mLOGS   [0m - *** Validation summary for epoch 49
	 loss={'classification': 3.3512, 'neural_augmentation': 0.0, 'total_loss': 3.3512} || top1={'logits': 20.0312} || top5={'logits': 48.1758} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1438, 0.3042, 0.0926, 0.4444, 0.1745, 0.279, 0.5145, 0.3588, 0.0816, 0.0819, 0.2471, 0.416, 0.1693, 0.2202, 0.239, 0.169, 0.0991, 0.1714, 0.0799, 0.109, 0.2536, 0.4297, 0.1054, 0.174, 0.3132, 0.2159, 0.1207, 0.2204, 0.1491, 0.1598, 0.1024, 0.0957, 0.4731, 0.6198, 0.0881, 0.1869, 0.1964, 0.1894, 0.1471, 0.1621, 0.2707, 0.0901, 0.2534, 0.1057, 0.3682, 0.1316, 0.0961, 0.1044, 0.354, 0.12, 0.1169, 0.3209, 0.0821, 0.0832, 0.1577, 0.1327, 0.109, 0.1123, 0.1166, 0.1965, 0.4383, 0.3, 0.1695, 0.1816, 0.2895, 0.5749, 0.1735, 0.0599, 0.2857, 0.5589, 0.2519, 0.2966, 0.1311, 0.2219, 0.2062, 0.3976, 0.3992, 0.1531, 0.1548, 0.1324, 0.1466, 0.1096, 0.1084, 0.5595, 0.1799, 0.0775, 0.4533, 0.1389, 0.5208, 0.2068, 0.2962, 0.3704, 0.1079, 0.2292, 0.3155, 0.2174, 0.1446, 0.0913, 0.168, 0.1698, 0.0882], 'AP': [0.0785, 0.2094, 0.0434, 0.425, 0.1094, 0.219, 0.5186, 0.2798, 0.0371, 0.0312, 0.1677, 0.3148, 0.0839, 0.1157, 0.1224, 0.0954, 0.0448, 0.0927, 0.0372, 0.0498, 0.1527, 0.4091, 0.0549, 0.106, 0.1771, 0.1263, 0.0675, 0.1359, 0.0811, 0.1031, 0.0449, 0.0419, 0.4255, 0.6805, 0.0412, 0.1137, 0.0959, 0.1117, 0.0659, 0.0752, 0.18, 0.0377, 0.1744, 0.0467, 0.2948, 0.0613, 0.0412, 0.0503, 0.2803, 0.0542, 0.066, 0.2587, 0.0364, 0.0385, 0.0782, 0.0654, 0.0472, 0.044, 0.0559, 0.1027, 0.3691, 0.2012, 0.0945, 0.0978, 0.1829, 0.5544, 0.0858, 0.0264, 0.1919, 0.5328, 0.1629, 0.2025, 0.0606, 0.1551, 0.1045, 0.3553, 0.3344, 0.0787, 0.0911, 0.0695, 0.0776, 0.0503, 0.0504, 0.5644, 0.1097, 0.0341, 0.4565, 0.073, 0.4785, 0.1251, 0.2087, 0.2471, 0.0437, 0.1312, 0.2301, 0.1413, 0.0668, 0.0386, 0.1182, 0.0979, 0.0432], 'Recall@P=50': [0.004, 0.0087, 0.0, 0.392, 0.028, 0.14, 0.524, 0.18, 0.0, 0.0, 0.004, 0.004, 0.0, 0.0, 0.016, 0.012, 0.0, 0.0, 0.0, 0.0, 0.012, 0.368, 0.0, 0.012, 0.012, 0.004, 0.012, 0.032, 0.012, 0.008, 0.0, 0.0, 0.424, 0.788, 0.0, 0.008, 0.012, 0.0, 0.0, 0.0, 0.012, 0.0, 0.056, 0.0, 0.224, 0.0, 0.004, 0.004, 0.016, 0.0, 0.028, 0.176, 0.0, 0.004, 0.008, 0.004, 0.0, 0.0, 0.0, 0.004, 0.32, 0.02, 0.004, 0.0, 0.0, 0.612, 0.0, 0.0, 0.016, 0.536, 0.016, 0.016, 0.0, 0.036, 0.004, 0.268, 0.284, 0.008, 0.008, 0.004, 0.0, 0.0, 0.0, 0.576, 0.004, 0.0, 0.404, 0.008, 0.464, 0.004, 0.012, 0.02, 0.0, 0.0, 0.012, 0.06, 0.0, 0.004, 0.012, 0.0, 0.004], 'micro': 0.1416, 'macro': 0.1538, 'weighted': 0.1533}
2024-07-17 05:25:01 - [34m[1mLOGS   [0m - Best checkpoint with score 20.03 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:25:03 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_13.3477.pt
2024-07-17 05:25:03 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_13.9023.pt', 'checkpoint_score_15.8438.pt', 'checkpoint_score_16.4336.pt', 'checkpoint_score_18.9961.pt', 'checkpoint_score_20.0312.pt']
2024-07-17 05:25:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:25:10 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:25:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:25:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 49/iteration 5597 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_49_iter_5597.pt
2024-07-17 05:25:15 - [34m[1mLOGS   [0m - Model state for epoch 49/iteration 5597 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_49_iter_5597.pt
[31m===========================================================================[0m
2024-07-17 05:25:17 - [32m[1mINFO   [0m - Training epoch 50
2024-07-17 05:25:17 - [34m[1mLOGS   [0m - Epoch:  50 [    5598/10000000], loss: {'classification': 3.8577, 'neural_augmentation': 0.2963, 'total_loss': 4.154}, LR: [2e-05, 2e-05], Avg. batch load time: 0.414, Elapsed time:  0.63
2024-07-17 05:25:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 50
	 loss={'classification': 3.7265, 'neural_augmentation': 0.2965, 'total_loss': 4.023}
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.5222222222222223 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.5294117647058824 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.5384615384615384 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.5294117647058824 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:25:50 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:51 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:25:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 50
	 loss={'classification': 3.2432, 'neural_augmentation': 0.0, 'total_loss': 3.2432} || top1={'logits': 22.5781} || top5={'logits': 51.5586} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1553, 0.3323, 0.1184, 0.4425, 0.2097, 0.3182, 0.5528, 0.3592, 0.095, 0.0831, 0.2715, 0.4453, 0.18, 0.2356, 0.266, 0.1941, 0.105, 0.1905, 0.105, 0.1388, 0.2896, 0.4584, 0.1265, 0.2076, 0.3196, 0.2512, 0.1387, 0.2511, 0.1641, 0.1907, 0.1262, 0.1007, 0.5271, 0.7226, 0.1146, 0.2186, 0.2, 0.2087, 0.1661, 0.1722, 0.3398, 0.0912, 0.2784, 0.142, 0.3656, 0.1509, 0.1017, 0.1291, 0.386, 0.1391, 0.1504, 0.364, 0.0918, 0.0992, 0.1929, 0.1481, 0.1196, 0.1176, 0.1238, 0.2039, 0.4453, 0.3273, 0.1815, 0.2248, 0.3251, 0.5698, 0.1947, 0.071, 0.3349, 0.5761, 0.3107, 0.3359, 0.1546, 0.2509, 0.2134, 0.4766, 0.4207, 0.1707, 0.2185, 0.1789, 0.1652, 0.1372, 0.1368, 0.5996, 0.1876, 0.0978, 0.4824, 0.1552, 0.5409, 0.2513, 0.3365, 0.4415, 0.1175, 0.2224, 0.3528, 0.2519, 0.1463, 0.1067, 0.202, 0.1705, 0.0879], 'AP': [0.0818, 0.2316, 0.0561, 0.4287, 0.1402, 0.2664, 0.5545, 0.3024, 0.0426, 0.0314, 0.1935, 0.3532, 0.0867, 0.1331, 0.1618, 0.1184, 0.051, 0.0985, 0.0432, 0.0622, 0.1834, 0.4489, 0.0687, 0.1305, 0.2059, 0.1691, 0.0751, 0.1655, 0.0918, 0.1213, 0.0612, 0.0527, 0.4962, 0.7929, 0.054, 0.1383, 0.1212, 0.1287, 0.0854, 0.0874, 0.2561, 0.0404, 0.2106, 0.0726, 0.2904, 0.0698, 0.043, 0.0628, 0.3131, 0.067, 0.0791, 0.3006, 0.0399, 0.0527, 0.1254, 0.096, 0.0522, 0.0504, 0.0589, 0.1046, 0.4049, 0.2648, 0.1016, 0.1335, 0.2334, 0.5663, 0.097, 0.0298, 0.2347, 0.577, 0.233, 0.2392, 0.0733, 0.1682, 0.1251, 0.4337, 0.3686, 0.0833, 0.1486, 0.1183, 0.0852, 0.0605, 0.067, 0.6047, 0.1212, 0.0447, 0.4932, 0.087, 0.5325, 0.1702, 0.2563, 0.3461, 0.0537, 0.1458, 0.2693, 0.1729, 0.0654, 0.0537, 0.1488, 0.0934, 0.0379], 'Recall@P=50': [0.0, 0.0116, 0.004, 0.376, 0.036, 0.16, 0.524, 0.204, 0.0, 0.0, 0.072, 0.104, 0.0, 0.004, 0.004, 0.012, 0.0, 0.0, 0.0, 0.0, 0.012, 0.408, 0.0, 0.012, 0.008, 0.068, 0.012, 0.004, 0.016, 0.008, 0.004, 0.008, 0.48, 0.868, 0.0, 0.004, 0.048, 0.0, 0.004, 0.0, 0.12, 0.0, 0.004, 0.0, 0.004, 0.0, 0.0, 0.008, 0.008, 0.0, 0.004, 0.212, 0.0, 0.004, 0.028, 0.016, 0.0, 0.0, 0.0, 0.0, 0.384, 0.044, 0.008, 0.02, 0.004, 0.632, 0.0, 0.0, 0.004, 0.604, 0.088, 0.028, 0.008, 0.036, 0.004, 0.432, 0.32, 0.004, 0.016, 0.004, 0.004, 0.0, 0.008, 0.652, 0.012, 0.0, 0.448, 0.016, 0.524, 0.036, 0.008, 0.1, 0.0, 0.012, 0.024, 0.052, 0.0, 0.004, 0.032, 0.0, 0.0], 'micro': 0.1604, 'macro': 0.1787, 'weighted': 0.1779}
2024-07-17 05:25:56 - [34m[1mLOGS   [0m - Best checkpoint with score 22.58 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:25:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_13.9023.pt
2024-07-17 05:25:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_15.8438.pt', 'checkpoint_score_16.4336.pt', 'checkpoint_score_18.9961.pt', 'checkpoint_score_20.0312.pt', 'checkpoint_score_22.5781.pt']
2024-07-17 05:26:03 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:26:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:26:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:26:09 - [34m[1mLOGS   [0m - Training checkpoint for epoch 50/iteration 5711 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_50_iter_5711.pt
2024-07-17 05:26:10 - [34m[1mLOGS   [0m - Model state for epoch 50/iteration 5711 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_50_iter_5711.pt
[31m===========================================================================[0m
2024-07-17 05:26:12 - [32m[1mINFO   [0m - Training epoch 51
2024-07-17 05:26:13 - [34m[1mLOGS   [0m - Epoch:  51 [    5712/10000000], loss: {'classification': 3.6015, 'neural_augmentation': 0.3064, 'total_loss': 3.9078}, LR: [2e-05, 2e-05], Avg. batch load time: 1.372, Elapsed time:  1.59
2024-07-17 05:26:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 51
	 loss={'classification': 3.6542, 'neural_augmentation': 0.308, 'total_loss': 3.9622}
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.5153846153846153 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.5333333333333333 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.5172413793103449 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.5333333333333333 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 0.5263157894736842 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:49 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:49 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:49 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:26:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 51
	 loss={'classification': 3.1423, 'neural_augmentation': 0.0, 'total_loss': 3.1423} || top1={'logits': 25.5352} || top5={'logits': 55.3086} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1774, 0.3358, 0.1378, 0.4602, 0.2219, 0.3426, 0.5815, 0.4092, 0.1135, 0.092, 0.2899, 0.4528, 0.1995, 0.2276, 0.2848, 0.2047, 0.1348, 0.1885, 0.1118, 0.1574, 0.3166, 0.4504, 0.1487, 0.2304, 0.3249, 0.2348, 0.1438, 0.2838, 0.2136, 0.2086, 0.1264, 0.1105, 0.5574, 0.7485, 0.1533, 0.2318, 0.1937, 0.2011, 0.1947, 0.155, 0.3604, 0.1154, 0.3179, 0.1735, 0.3992, 0.1629, 0.1403, 0.1387, 0.4246, 0.1519, 0.1514, 0.3349, 0.1097, 0.1254, 0.2763, 0.1656, 0.1182, 0.1421, 0.1278, 0.2191, 0.4592, 0.3717, 0.2091, 0.2763, 0.3463, 0.5818, 0.208, 0.0817, 0.3629, 0.6333, 0.3488, 0.3353, 0.1565, 0.2468, 0.2418, 0.4822, 0.4441, 0.1759, 0.294, 0.2157, 0.1824, 0.145, 0.1431, 0.6083, 0.2034, 0.1024, 0.4704, 0.1548, 0.5654, 0.2562, 0.3758, 0.468, 0.1391, 0.2565, 0.3417, 0.3111, 0.1525, 0.112, 0.2137, 0.1984, 0.1025], 'AP': [0.0972, 0.2568, 0.0741, 0.4575, 0.1446, 0.3175, 0.5933, 0.349, 0.0538, 0.0386, 0.2022, 0.4065, 0.1015, 0.1287, 0.1762, 0.1195, 0.0684, 0.1034, 0.0494, 0.0936, 0.232, 0.4424, 0.0789, 0.1545, 0.2285, 0.1506, 0.0742, 0.2138, 0.1278, 0.1344, 0.0605, 0.0604, 0.5575, 0.8231, 0.0772, 0.1544, 0.117, 0.126, 0.1003, 0.08, 0.3013, 0.0586, 0.2407, 0.0927, 0.3387, 0.0777, 0.0655, 0.074, 0.3852, 0.0744, 0.0931, 0.2927, 0.0595, 0.0638, 0.2291, 0.0972, 0.0515, 0.0684, 0.0615, 0.1084, 0.4167, 0.317, 0.1292, 0.2132, 0.2901, 0.5653, 0.1088, 0.036, 0.2486, 0.6462, 0.2582, 0.2471, 0.0726, 0.1607, 0.1732, 0.4895, 0.3936, 0.0907, 0.2377, 0.154, 0.107, 0.0652, 0.0776, 0.6214, 0.1314, 0.0489, 0.4844, 0.0951, 0.6093, 0.1796, 0.3274, 0.3959, 0.0666, 0.1549, 0.2809, 0.2172, 0.0747, 0.0561, 0.167, 0.1052, 0.053], 'Recall@P=50': [0.004, 0.0436, 0.004, 0.348, 0.004, 0.22, 0.572, 0.276, 0.0, 0.0, 0.064, 0.336, 0.0, 0.008, 0.004, 0.008, 0.004, 0.0, 0.004, 0.0, 0.004, 0.392, 0.0, 0.016, 0.028, 0.008, 0.008, 0.004, 0.004, 0.024, 0.0, 0.008, 0.536, 0.892, 0.0, 0.004, 0.004, 0.004, 0.008, 0.0, 0.128, 0.0, 0.196, 0.0, 0.24, 0.0, 0.004, 0.008, 0.328, 0.0, 0.032, 0.192, 0.004, 0.004, 0.16, 0.024, 0.0, 0.004, 0.0, 0.0, 0.368, 0.256, 0.008, 0.004, 0.18, 0.62, 0.0, 0.004, 0.008, 0.668, 0.004, 0.004, 0.0, 0.06, 0.064, 0.46, 0.336, 0.0, 0.12, 0.08, 0.016, 0.0, 0.004, 0.68, 0.032, 0.0, 0.42, 0.028, 0.628, 0.02, 0.004, 0.36, 0.0, 0.012, 0.108, 0.004, 0.0, 0.004, 0.044, 0.0, 0.004], 'micro': 0.1852, 'macro': 0.2003, 'weighted': 0.1994}
2024-07-17 05:26:54 - [34m[1mLOGS   [0m - Best checkpoint with score 25.54 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:26:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_15.8438.pt
2024-07-17 05:26:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_16.4336.pt', 'checkpoint_score_18.9961.pt', 'checkpoint_score_20.0312.pt', 'checkpoint_score_22.5781.pt', 'checkpoint_score_25.5352.pt']
2024-07-17 05:27:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:27:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:27:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:27:07 - [34m[1mLOGS   [0m - Training checkpoint for epoch 51/iteration 5835 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_51_iter_5835.pt
2024-07-17 05:27:08 - [34m[1mLOGS   [0m - Model state for epoch 51/iteration 5835 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_51_iter_5835.pt
[31m===========================================================================[0m
2024-07-17 05:27:10 - [32m[1mINFO   [0m - Training epoch 52
2024-07-17 05:27:12 - [34m[1mLOGS   [0m - Epoch:  52 [    5836/10000000], loss: {'classification': 3.6744, 'neural_augmentation': 0.3172, 'total_loss': 3.9915}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 2.004, Elapsed time:  2.22
2024-07-17 05:27:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 52
	 loss={'classification': 3.5768, 'neural_augmentation': 0.3183, 'total_loss': 3.8952}
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5238095238095238 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5172413793103449 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5185185185185185 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5625 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5188679245283019 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5333333333333333 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5277777777777778 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 0.5714285714285714 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:27:46 - [33m[1mWARNING[0m - Found recall at precision 0.5555555555555556 when recall at precision 0.5 was requested.
2024-07-17 05:27:48 - [34m[1mLOGS   [0m - *** Validation summary for epoch 52
	 loss={'classification': 3.032, 'neural_augmentation': 0.0, 'total_loss': 3.032} || top1={'logits': 28.3789} || top5={'logits': 58.0703} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.17, 0.3784, 0.1528, 0.4991, 0.2475, 0.3867, 0.576, 0.4159, 0.1149, 0.1107, 0.291, 0.4897, 0.2011, 0.2561, 0.3259, 0.2377, 0.1476, 0.1982, 0.1357, 0.2355, 0.3492, 0.4689, 0.1612, 0.262, 0.3726, 0.3417, 0.1786, 0.2857, 0.2226, 0.2238, 0.1866, 0.1176, 0.5827, 0.8384, 0.1986, 0.2406, 0.2604, 0.2259, 0.221, 0.1684, 0.4, 0.1223, 0.316, 0.2027, 0.4228, 0.1754, 0.1612, 0.178, 0.4433, 0.1575, 0.1662, 0.3912, 0.1299, 0.123, 0.3699, 0.2121, 0.135, 0.1725, 0.1292, 0.2459, 0.5444, 0.4273, 0.2066, 0.3624, 0.3571, 0.5988, 0.2366, 0.1151, 0.3862, 0.6327, 0.4143, 0.3737, 0.1831, 0.2505, 0.233, 0.5799, 0.495, 0.1738, 0.3299, 0.2923, 0.1893, 0.152, 0.1815, 0.6351, 0.2394, 0.1308, 0.5253, 0.1739, 0.6097, 0.2924, 0.4407, 0.5328, 0.1795, 0.2437, 0.342, 0.3067, 0.1614, 0.1386, 0.2327, 0.2097, 0.0995], 'AP': [0.0929, 0.3012, 0.0787, 0.523, 0.1607, 0.3486, 0.5939, 0.3961, 0.0555, 0.0499, 0.2092, 0.4178, 0.0984, 0.1551, 0.2396, 0.1533, 0.0741, 0.1091, 0.0679, 0.1457, 0.2655, 0.4633, 0.0824, 0.182, 0.2882, 0.2858, 0.0944, 0.2334, 0.157, 0.1528, 0.1009, 0.0602, 0.5837, 0.8829, 0.1076, 0.1855, 0.1802, 0.1388, 0.1217, 0.0886, 0.3348, 0.0691, 0.2498, 0.1354, 0.3904, 0.0874, 0.084, 0.1101, 0.4198, 0.0758, 0.0989, 0.3308, 0.0664, 0.0644, 0.3307, 0.1274, 0.0732, 0.0985, 0.0601, 0.1287, 0.5097, 0.399, 0.1269, 0.2707, 0.3201, 0.5943, 0.1246, 0.0507, 0.2863, 0.63, 0.3495, 0.3071, 0.0785, 0.1816, 0.1323, 0.6064, 0.4846, 0.0825, 0.2844, 0.2528, 0.1075, 0.0813, 0.0965, 0.6731, 0.1667, 0.0663, 0.5393, 0.1112, 0.6668, 0.2182, 0.4069, 0.5184, 0.0881, 0.1387, 0.2752, 0.2281, 0.0838, 0.069, 0.1633, 0.116, 0.0505], 'Recall@P=50': [0.0, 0.0843, 0.0, 0.452, 0.004, 0.264, 0.588, 0.356, 0.0, 0.004, 0.076, 0.328, 0.0, 0.008, 0.12, 0.044, 0.0, 0.0, 0.004, 0.028, 0.112, 0.412, 0.0, 0.036, 0.14, 0.22, 0.004, 0.108, 0.064, 0.008, 0.004, 0.008, 0.58, 0.916, 0.0, 0.012, 0.08, 0.0, 0.004, 0.0, 0.232, 0.008, 0.152, 0.012, 0.316, 0.0, 0.004, 0.016, 0.38, 0.0, 0.004, 0.244, 0.0, 0.0, 0.268, 0.004, 0.008, 0.004, 0.0, 0.0, 0.592, 0.34, 0.004, 0.012, 0.216, 0.648, 0.0, 0.004, 0.072, 0.684, 0.016, 0.2, 0.0, 0.068, 0.004, 0.62, 0.456, 0.004, 0.152, 0.188, 0.016, 0.0, 0.004, 0.724, 0.028, 0.008, 0.528, 0.036, 0.696, 0.008, 0.36, 0.004, 0.012, 0.0, 0.052, 0.076, 0.0, 0.004, 0.02, 0.012, 0.008], 'micro': 0.2174, 'macro': 0.2297, 'weighted': 0.2286}
2024-07-17 05:27:52 - [34m[1mLOGS   [0m - Best checkpoint with score 28.38 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:27:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_16.4336.pt
2024-07-17 05:27:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_18.9961.pt', 'checkpoint_score_20.0312.pt', 'checkpoint_score_22.5781.pt', 'checkpoint_score_25.5352.pt', 'checkpoint_score_28.3789.pt']
2024-07-17 05:27:59 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:28:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:28:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:28:04 - [34m[1mLOGS   [0m - Training checkpoint for epoch 52/iteration 5956 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_52_iter_5956.pt
2024-07-17 05:28:05 - [34m[1mLOGS   [0m - Model state for epoch 52/iteration 5956 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_52_iter_5956.pt
[31m===========================================================================[0m
2024-07-17 05:28:07 - [32m[1mINFO   [0m - Training epoch 53
2024-07-17 05:28:09 - [34m[1mLOGS   [0m - Epoch:  53 [    5957/10000000], loss: {'classification': 3.4759, 'neural_augmentation': 0.3256, 'total_loss': 3.8015}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 1.398, Elapsed time:  1.82
2024-07-17 05:28:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 53
	 loss={'classification': 3.4855, 'neural_augmentation': 0.3303, 'total_loss': 3.8158}
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 0.5206611570247934 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 0.5357142857142857 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 0.5714285714285714 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 0.5154639175257731 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:44 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:45 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:28:45 - [33m[1mWARNING[0m - Found recall at precision 0.5185185185185185 when recall at precision 0.5 was requested.
2024-07-17 05:28:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 53
	 loss={'classification': 2.8822, 'neural_augmentation': 0.0, 'total_loss': 2.8822} || top1={'logits': 31.8086} || top5={'logits': 62.0391} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1976, 0.406, 0.18, 0.5285, 0.2896, 0.43, 0.6202, 0.4688, 0.1315, 0.126, 0.3209, 0.4925, 0.2308, 0.2679, 0.358, 0.2597, 0.1547, 0.2088, 0.1921, 0.3333, 0.4148, 0.4631, 0.1547, 0.2767, 0.3915, 0.3961, 0.2359, 0.3952, 0.2709, 0.2183, 0.2292, 0.1349, 0.6207, 0.8474, 0.2315, 0.2915, 0.2973, 0.2291, 0.2435, 0.1835, 0.4422, 0.1919, 0.3312, 0.2474, 0.4612, 0.2088, 0.2108, 0.18, 0.479, 0.1935, 0.183, 0.4491, 0.1803, 0.1757, 0.4887, 0.2331, 0.1493, 0.1937, 0.1418, 0.24, 0.5182, 0.5207, 0.2833, 0.4482, 0.438, 0.5882, 0.2514, 0.1369, 0.382, 0.6843, 0.5032, 0.4069, 0.1921, 0.2569, 0.295, 0.6483, 0.5318, 0.1823, 0.3884, 0.4, 0.25, 0.187, 0.194, 0.6651, 0.2476, 0.1496, 0.5573, 0.1839, 0.6444, 0.3168, 0.4516, 0.6027, 0.1963, 0.2491, 0.3973, 0.3464, 0.1856, 0.1664, 0.2726, 0.236, 0.1234], 'AP': [0.1067, 0.3457, 0.0981, 0.5548, 0.2076, 0.4091, 0.6461, 0.4566, 0.064, 0.0544, 0.23, 0.4411, 0.1231, 0.1726, 0.2958, 0.1783, 0.0736, 0.1218, 0.0999, 0.2619, 0.3456, 0.4541, 0.0862, 0.2125, 0.3365, 0.343, 0.1285, 0.3364, 0.201, 0.1366, 0.142, 0.0784, 0.637, 0.904, 0.1297, 0.2201, 0.2027, 0.1545, 0.1377, 0.0902, 0.3972, 0.1257, 0.2783, 0.1795, 0.4643, 0.113, 0.1536, 0.1041, 0.4795, 0.1075, 0.1038, 0.4303, 0.1217, 0.0981, 0.4714, 0.1569, 0.0775, 0.1223, 0.0728, 0.1347, 0.5001, 0.5185, 0.1682, 0.4157, 0.4237, 0.6089, 0.1357, 0.0652, 0.2996, 0.6842, 0.4677, 0.3449, 0.0953, 0.1836, 0.2206, 0.7055, 0.5191, 0.0912, 0.3602, 0.355, 0.1712, 0.0953, 0.1038, 0.6971, 0.1715, 0.0775, 0.575, 0.1067, 0.6925, 0.2202, 0.4528, 0.6228, 0.1012, 0.1517, 0.3376, 0.295, 0.099, 0.1015, 0.2174, 0.1414, 0.0684], 'Recall@P=50': [0.0, 0.1831, 0.008, 0.536, 0.04, 0.328, 0.66, 0.436, 0.0, 0.0, 0.128, 0.472, 0.0, 0.008, 0.252, 0.008, 0.0, 0.0, 0.004, 0.212, 0.296, 0.42, 0.0, 0.06, 0.2, 0.328, 0.008, 0.204, 0.056, 0.02, 0.012, 0.016, 0.632, 0.92, 0.0, 0.096, 0.092, 0.004, 0.0, 0.0, 0.312, 0.02, 0.2, 0.008, 0.428, 0.0, 0.008, 0.004, 0.448, 0.004, 0.004, 0.392, 0.044, 0.016, 0.448, 0.04, 0.004, 0.044, 0.0, 0.0, 0.524, 0.508, 0.004, 0.356, 0.372, 0.668, 0.024, 0.004, 0.04, 0.716, 0.484, 0.212, 0.0, 0.052, 0.12, 0.728, 0.568, 0.0, 0.256, 0.3, 0.044, 0.0, 0.02, 0.728, 0.06, 0.0, 0.584, 0.012, 0.76, 0.02, 0.384, 0.664, 0.004, 0.02, 0.232, 0.208, 0.0, 0.02, 0.112, 0.028, 0.008], 'micro': 0.2529, 'macro': 0.268, 'weighted': 0.2667}
2024-07-17 05:28:50 - [34m[1mLOGS   [0m - Best checkpoint with score 31.81 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:28:52 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_18.9961.pt
2024-07-17 05:28:52 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_20.0312.pt', 'checkpoint_score_22.5781.pt', 'checkpoint_score_25.5352.pt', 'checkpoint_score_28.3789.pt', 'checkpoint_score_31.8086.pt']
2024-07-17 05:28:57 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:28:59 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:29:00 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:29:03 - [34m[1mLOGS   [0m - Training checkpoint for epoch 53/iteration 6084 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_53_iter_6084.pt
2024-07-17 05:29:04 - [34m[1mLOGS   [0m - Model state for epoch 53/iteration 6084 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_53_iter_6084.pt
[31m===========================================================================[0m
2024-07-17 05:29:06 - [32m[1mINFO   [0m - Training epoch 54
2024-07-17 05:29:07 - [34m[1mLOGS   [0m - Epoch:  54 [    6085/10000000], loss: {'classification': 3.5478, 'neural_augmentation': 0.3447, 'total_loss': 3.8925}, LR: [1.9e-05, 1.9e-05], Avg. batch load time: 0.824, Elapsed time:  1.04
2024-07-17 05:29:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 54
	 loss={'classification': 3.3936, 'neural_augmentation': 0.3418, 'total_loss': 3.7354}
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.525 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.5178571428571429 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.5454545454545454 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.5196850393700787 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.5172413793103449 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 0.5272727272727272 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:39 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 0.5333333333333333 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 0.5263157894736842 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 0.5306122448979592 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 0.55 when recall at precision 0.5 was requested.
2024-07-17 05:29:40 - [33m[1mWARNING[0m - Found recall at precision 0.5151515151515151 when recall at precision 0.5 was requested.
2024-07-17 05:29:42 - [34m[1mLOGS   [0m - *** Validation summary for epoch 54
	 loss={'classification': 2.7478, 'neural_augmentation': 0.0, 'total_loss': 2.7478} || top1={'logits': 34.7461} || top5={'logits': 65.2656} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.2195, 0.403, 0.2562, 0.5658, 0.3468, 0.4665, 0.6402, 0.5207, 0.1455, 0.1299, 0.318, 0.5451, 0.2373, 0.2751, 0.4074, 0.302, 0.1866, 0.2528, 0.2241, 0.357, 0.4619, 0.5045, 0.1912, 0.297, 0.4449, 0.4279, 0.247, 0.4114, 0.3256, 0.2458, 0.2552, 0.142, 0.6435, 0.8571, 0.3171, 0.297, 0.3168, 0.2312, 0.2444, 0.187, 0.4523, 0.2651, 0.3619, 0.2613, 0.5301, 0.2216, 0.298, 0.2044, 0.4929, 0.1869, 0.1916, 0.4646, 0.2347, 0.2168, 0.5505, 0.2379, 0.1511, 0.2505, 0.1561, 0.2692, 0.5534, 0.5823, 0.3299, 0.558, 0.4389, 0.6177, 0.2707, 0.1683, 0.4153, 0.7342, 0.5683, 0.4, 0.2245, 0.2943, 0.2851, 0.6958, 0.5538, 0.1878, 0.4314, 0.4944, 0.325, 0.2325, 0.196, 0.6783, 0.2938, 0.1766, 0.5631, 0.2045, 0.6784, 0.3485, 0.5474, 0.6469, 0.2139, 0.3004, 0.4173, 0.3811, 0.2222, 0.2233, 0.2805, 0.2415, 0.1659], 'AP': [0.1236, 0.3686, 0.1734, 0.5794, 0.2745, 0.4119, 0.6675, 0.5228, 0.0765, 0.0606, 0.2425, 0.5216, 0.144, 0.176, 0.3463, 0.2253, 0.1047, 0.1794, 0.1241, 0.3, 0.4205, 0.4882, 0.1056, 0.233, 0.3688, 0.3931, 0.1441, 0.3745, 0.2793, 0.1724, 0.1784, 0.0921, 0.6578, 0.9101, 0.2477, 0.2377, 0.2437, 0.1555, 0.1421, 0.0901, 0.4209, 0.1823, 0.3085, 0.2059, 0.5346, 0.1254, 0.2351, 0.1193, 0.5069, 0.1042, 0.1064, 0.4577, 0.1901, 0.1246, 0.5585, 0.1621, 0.0716, 0.1755, 0.0746, 0.1579, 0.553, 0.5975, 0.2276, 0.5313, 0.4387, 0.6273, 0.148, 0.0943, 0.3624, 0.7412, 0.5893, 0.342, 0.1219, 0.2078, 0.2186, 0.749, 0.5334, 0.0927, 0.4282, 0.4608, 0.2324, 0.1297, 0.1051, 0.7133, 0.2195, 0.1032, 0.5958, 0.1184, 0.7232, 0.2831, 0.5694, 0.6894, 0.1347, 0.1824, 0.3637, 0.3331, 0.1205, 0.1485, 0.2558, 0.1836, 0.1028], 'Recall@P=50': [0.0, 0.2587, 0.084, 0.608, 0.116, 0.352, 0.684, 0.528, 0.004, 0.0, 0.132, 0.544, 0.004, 0.004, 0.3, 0.164, 0.0, 0.024, 0.004, 0.264, 0.404, 0.476, 0.0, 0.108, 0.344, 0.36, 0.012, 0.308, 0.2, 0.004, 0.116, 0.012, 0.644, 0.936, 0.164, 0.196, 0.008, 0.004, 0.004, 0.0, 0.004, 0.048, 0.232, 0.116, 0.496, 0.0, 0.172, 0.008, 0.484, 0.0, 0.004, 0.392, 0.092, 0.004, 0.544, 0.032, 0.0, 0.096, 0.0, 0.004, 0.584, 0.608, 0.072, 0.564, 0.372, 0.668, 0.0, 0.004, 0.332, 0.764, 0.62, 0.224, 0.0, 0.076, 0.148, 0.824, 0.588, 0.0, 0.36, 0.448, 0.004, 0.0, 0.016, 0.772, 0.104, 0.02, 0.584, 0.016, 0.752, 0.004, 0.54, 0.732, 0.004, 0.0, 0.288, 0.236, 0.004, 0.044, 0.18, 0.068, 0.008], 'micro': 0.2867, 'macro': 0.3045, 'weighted': 0.3029}
2024-07-17 05:29:46 - [34m[1mLOGS   [0m - Best checkpoint with score 34.75 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:29:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_20.0312.pt
2024-07-17 05:29:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_22.5781.pt', 'checkpoint_score_25.5352.pt', 'checkpoint_score_28.3789.pt', 'checkpoint_score_31.8086.pt', 'checkpoint_score_34.7461.pt']
2024-07-17 05:29:53 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:29:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:29:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:29:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 54/iteration 6198 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_54_iter_6198.pt
2024-07-17 05:30:00 - [34m[1mLOGS   [0m - Model state for epoch 54/iteration 6198 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_54_iter_6198.pt
[31m===========================================================================[0m
2024-07-17 05:30:02 - [32m[1mINFO   [0m - Training epoch 55
2024-07-17 05:30:02 - [34m[1mLOGS   [0m - Epoch:  55 [    6199/10000000], loss: {'classification': 3.2616, 'neural_augmentation': 0.3507, 'total_loss': 3.6123}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 0.556, Elapsed time:  0.77
2024-07-17 05:30:25 - [34m[1mLOGS   [0m - *** Training summary for epoch 55
	 loss={'classification': 3.3053, 'neural_augmentation': 0.3537, 'total_loss': 3.659}
2024-07-17 05:30:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:33 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:33 - [33m[1mWARNING[0m - Found recall at precision 0.5223880597014925 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 0.5161290322580645 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 0.5181818181818182 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 0.5176470588235295 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 0.5185185185185185 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:34 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:30:36 - [34m[1mLOGS   [0m - *** Validation summary for epoch 55
	 loss={'classification': 2.6652, 'neural_augmentation': 0.0, 'total_loss': 2.6652} || top1={'logits': 36.4727} || top5={'logits': 66.6602} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.1976, 0.4473, 0.2364, 0.6079, 0.3799, 0.4606, 0.6511, 0.5022, 0.1522, 0.1445, 0.339, 0.5249, 0.239, 0.2891, 0.4481, 0.3099, 0.1919, 0.2683, 0.2523, 0.4335, 0.4865, 0.4979, 0.1927, 0.3127, 0.4394, 0.4475, 0.3006, 0.4898, 0.3471, 0.2524, 0.3341, 0.1667, 0.6608, 0.8696, 0.3724, 0.3273, 0.3661, 0.2602, 0.2555, 0.2008, 0.4982, 0.2857, 0.3832, 0.341, 0.5835, 0.2528, 0.377, 0.2233, 0.5097, 0.2163, 0.2265, 0.5577, 0.25, 0.213, 0.5544, 0.2609, 0.157, 0.2427, 0.1655, 0.2841, 0.5615, 0.6226, 0.348, 0.5686, 0.457, 0.6627, 0.275, 0.1879, 0.4206, 0.746, 0.61, 0.4482, 0.2346, 0.2862, 0.3821, 0.7398, 0.567, 0.203, 0.4082, 0.5192, 0.3258, 0.2832, 0.2207, 0.7095, 0.3042, 0.1703, 0.5802, 0.23, 0.696, 0.3351, 0.5985, 0.7069, 0.225, 0.2964, 0.4792, 0.4362, 0.2299, 0.2216, 0.315, 0.2685, 0.1835], 'AP': [0.1124, 0.4232, 0.1374, 0.6266, 0.3051, 0.4384, 0.6857, 0.5036, 0.0845, 0.0731, 0.2734, 0.4905, 0.1327, 0.1969, 0.3943, 0.2306, 0.1102, 0.1912, 0.1538, 0.388, 0.4522, 0.4883, 0.1152, 0.2689, 0.3879, 0.4035, 0.1992, 0.4778, 0.2991, 0.1871, 0.2618, 0.0969, 0.6743, 0.9232, 0.3052, 0.2801, 0.2868, 0.1703, 0.144, 0.1146, 0.4194, 0.2009, 0.3313, 0.2807, 0.6183, 0.1673, 0.3289, 0.1368, 0.5161, 0.1233, 0.1376, 0.5688, 0.2028, 0.1352, 0.5709, 0.1721, 0.0805, 0.1809, 0.0838, 0.1786, 0.5719, 0.633, 0.2621, 0.586, 0.4591, 0.6735, 0.1439, 0.1302, 0.3924, 0.7669, 0.6392, 0.3847, 0.128, 0.2001, 0.3223, 0.786, 0.555, 0.1093, 0.3783, 0.5212, 0.2399, 0.1904, 0.1185, 0.7447, 0.2557, 0.0985, 0.6179, 0.1418, 0.7507, 0.2567, 0.635, 0.7348, 0.1328, 0.179, 0.461, 0.3916, 0.1325, 0.1443, 0.29, 0.1717, 0.1068], 'Recall@P=50': [0.0, 0.3372, 0.008, 0.664, 0.18, 0.412, 0.704, 0.48, 0.004, 0.004, 0.14, 0.496, 0.004, 0.012, 0.396, 0.14, 0.012, 0.076, 0.02, 0.364, 0.472, 0.48, 0.0, 0.192, 0.348, 0.4, 0.06, 0.472, 0.212, 0.004, 0.228, 0.008, 0.684, 0.968, 0.276, 0.228, 0.26, 0.004, 0.0, 0.0, 0.432, 0.024, 0.24, 0.176, 0.632, 0.008, 0.292, 0.004, 0.496, 0.0, 0.02, 0.584, 0.112, 0.004, 0.592, 0.068, 0.0, 0.1, 0.0, 0.008, 0.592, 0.664, 0.004, 0.612, 0.388, 0.744, 0.016, 0.056, 0.336, 0.772, 0.684, 0.348, 0.0, 0.02, 0.256, 0.876, 0.624, 0.0, 0.336, 0.512, 0.016, 0.012, 0.004, 0.796, 0.156, 0.012, 0.648, 0.008, 0.76, 0.028, 0.676, 0.744, 0.004, 0.0, 0.416, 0.376, 0.008, 0.028, 0.188, 0.008, 0.028], 'micro': 0.3095, 'macro': 0.3303, 'weighted': 0.3285}
2024-07-17 05:30:40 - [34m[1mLOGS   [0m - Best checkpoint with score 36.47 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:30:41 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_22.5781.pt
2024-07-17 05:30:41 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_25.5352.pt', 'checkpoint_score_28.3789.pt', 'checkpoint_score_31.8086.pt', 'checkpoint_score_34.7461.pt', 'checkpoint_score_36.4727.pt']
2024-07-17 05:30:47 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:30:49 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:30:50 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:30:53 - [34m[1mLOGS   [0m - Training checkpoint for epoch 55/iteration 6304 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_55_iter_6304.pt
2024-07-17 05:30:54 - [34m[1mLOGS   [0m - Model state for epoch 55/iteration 6304 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_55_iter_6304.pt
[31m===========================================================================[0m
2024-07-17 05:30:56 - [32m[1mINFO   [0m - Training epoch 56
2024-07-17 05:30:58 - [34m[1mLOGS   [0m - Epoch:  56 [    6305/10000000], loss: {'classification': 3.3837, 'neural_augmentation': 0.3673, 'total_loss': 3.7511}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 1.762, Elapsed time:  2.04
2024-07-17 05:31:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 56
	 loss={'classification': 3.2251, 'neural_augmentation': 0.3656, 'total_loss': 3.5907}
2024-07-17 05:31:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:28 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 0.5178571428571429 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 0.5185185185185185 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:31:29 - [33m[1mWARNING[0m - Found recall at precision 0.5153846153846153 when recall at precision 0.5 was requested.
2024-07-17 05:31:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 56
	 loss={'classification': 2.5192, 'neural_augmentation': 0.0, 'total_loss': 2.5192} || top1={'logits': 40.5391} || top5={'logits': 70.2539} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.2613, 0.4688, 0.2914, 0.6029, 0.4157, 0.4989, 0.6792, 0.5942, 0.1761, 0.183, 0.3585, 0.5678, 0.2745, 0.3049, 0.4696, 0.3102, 0.2297, 0.3027, 0.2785, 0.4587, 0.5227, 0.5054, 0.2255, 0.3788, 0.49, 0.5022, 0.2857, 0.5112, 0.4165, 0.2551, 0.3531, 0.1773, 0.7159, 0.8857, 0.4039, 0.3503, 0.365, 0.2676, 0.2839, 0.2284, 0.5257, 0.3445, 0.3739, 0.3816, 0.6203, 0.2581, 0.4265, 0.2597, 0.5572, 0.2561, 0.2326, 0.5305, 0.3632, 0.2483, 0.6711, 0.2983, 0.1798, 0.2536, 0.1822, 0.3161, 0.5783, 0.6827, 0.377, 0.6059, 0.4769, 0.6863, 0.2979, 0.1984, 0.4563, 0.7843, 0.6607, 0.4544, 0.2848, 0.3072, 0.4113, 0.7912, 0.576, 0.2209, 0.493, 0.5676, 0.3516, 0.3047, 0.2173, 0.7284, 0.346, 0.1907, 0.6083, 0.2442, 0.7193, 0.364, 0.6492, 0.7338, 0.268, 0.3281, 0.5259, 0.4365, 0.2439, 0.2977, 0.3738, 0.2701, 0.2474], 'AP': [0.1461, 0.4705, 0.208, 0.6324, 0.3586, 0.4805, 0.7132, 0.593, 0.0909, 0.0874, 0.3019, 0.59, 0.1629, 0.2138, 0.4335, 0.2502, 0.1277, 0.219, 0.161, 0.428, 0.5331, 0.5024, 0.1312, 0.3213, 0.4468, 0.4966, 0.1907, 0.4967, 0.3726, 0.2043, 0.2996, 0.1056, 0.7346, 0.9408, 0.3752, 0.2958, 0.2974, 0.1871, 0.1689, 0.1347, 0.5114, 0.2606, 0.3379, 0.317, 0.6608, 0.1786, 0.3839, 0.1434, 0.566, 0.1755, 0.1554, 0.5354, 0.3089, 0.1574, 0.6857, 0.2169, 0.0916, 0.2037, 0.0963, 0.2013, 0.5852, 0.699, 0.3275, 0.6289, 0.4806, 0.7075, 0.1744, 0.128, 0.4178, 0.8071, 0.7119, 0.4348, 0.1916, 0.2287, 0.3521, 0.8355, 0.5688, 0.1178, 0.5219, 0.5463, 0.2729, 0.2148, 0.1239, 0.7489, 0.273, 0.1005, 0.6437, 0.1577, 0.7724, 0.3081, 0.6903, 0.7815, 0.1662, 0.2054, 0.4793, 0.3928, 0.1443, 0.2256, 0.3466, 0.1941, 0.1614], 'Recall@P=50': [0.0, 0.4099, 0.128, 0.664, 0.26, 0.476, 0.74, 0.62, 0.0, 0.0, 0.244, 0.628, 0.008, 0.02, 0.42, 0.008, 0.0, 0.004, 0.008, 0.388, 0.528, 0.496, 0.0, 0.216, 0.472, 0.476, 0.06, 0.492, 0.344, 0.088, 0.216, 0.008, 0.748, 0.964, 0.328, 0.004, 0.016, 0.016, 0.004, 0.004, 0.552, 0.024, 0.276, 0.232, 0.676, 0.004, 0.368, 0.012, 0.58, 0.072, 0.016, 0.552, 0.232, 0.004, 0.744, 0.12, 0.0, 0.128, 0.004, 0.02, 0.62, 0.728, 0.256, 0.64, 0.432, 0.756, 0.0, 0.004, 0.364, 0.812, 0.78, 0.392, 0.068, 0.112, 0.316, 0.904, 0.604, 0.004, 0.464, 0.564, 0.176, 0.064, 0.02, 0.808, 0.168, 0.0, 0.648, 0.044, 0.828, 0.192, 0.712, 0.816, 0.008, 0.02, 0.528, 0.356, 0.004, 0.128, 0.268, 0.012, 0.004], 'micro': 0.3502, 'macro': 0.3659, 'weighted': 0.3641}
2024-07-17 05:31:35 - [34m[1mLOGS   [0m - Best checkpoint with score 40.54 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:31:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_25.5352.pt
2024-07-17 05:31:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_28.3789.pt', 'checkpoint_score_31.8086.pt', 'checkpoint_score_34.7461.pt', 'checkpoint_score_36.4727.pt', 'checkpoint_score_40.5391.pt']
2024-07-17 05:31:41 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:31:44 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:31:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:31:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 56/iteration 6412 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_56_iter_6412.pt
2024-07-17 05:31:48 - [34m[1mLOGS   [0m - Model state for epoch 56/iteration 6412 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_56_iter_6412.pt
[31m===========================================================================[0m
2024-07-17 05:31:50 - [32m[1mINFO   [0m - Training epoch 57
2024-07-17 05:31:51 - [34m[1mLOGS   [0m - Epoch:  57 [    6413/10000000], loss: {'classification': 3.1956, 'neural_augmentation': 0.3723, 'total_loss': 3.5678}, LR: [1.8e-05, 1.8e-05], Avg. batch load time: 0.538, Elapsed time:  0.76
2024-07-17 05:32:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 57
	 loss={'classification': 3.1383, 'neural_augmentation': 0.3777, 'total_loss': 3.516}
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 0.518796992481203 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 0.6666666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 0.5384615384615384 when recall at precision 0.5 was requested.
2024-07-17 05:32:21 - [33m[1mWARNING[0m - Found recall at precision 0.5165562913907285 when recall at precision 0.5 was requested.
2024-07-17 05:32:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 57
	 loss={'classification': 2.3848, 'neural_augmentation': 0.0, 'total_loss': 2.3848} || top1={'logits': 43.4766} || top5={'logits': 73.3242} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.2555, 0.4797, 0.3287, 0.6473, 0.4579, 0.493, 0.6895, 0.6256, 0.1873, 0.2181, 0.3721, 0.5887, 0.2803, 0.3556, 0.5, 0.3133, 0.2368, 0.3156, 0.2908, 0.5122, 0.5376, 0.5126, 0.2208, 0.4146, 0.5179, 0.5219, 0.3493, 0.5734, 0.4202, 0.2757, 0.4358, 0.1733, 0.7299, 0.9068, 0.4427, 0.3889, 0.4303, 0.2737, 0.2943, 0.2117, 0.5306, 0.3978, 0.3946, 0.4396, 0.6814, 0.2813, 0.4777, 0.2727, 0.5556, 0.2922, 0.2653, 0.5784, 0.401, 0.2948, 0.7074, 0.3262, 0.201, 0.283, 0.1818, 0.3302, 0.5817, 0.6913, 0.4267, 0.6413, 0.5324, 0.6998, 0.3101, 0.2217, 0.4501, 0.7927, 0.7304, 0.4872, 0.2947, 0.3155, 0.4156, 0.804, 0.592, 0.2222, 0.5395, 0.5822, 0.3934, 0.3583, 0.2172, 0.7234, 0.36, 0.2191, 0.6437, 0.2766, 0.7069, 0.4, 0.6866, 0.7722, 0.302, 0.3441, 0.5322, 0.4775, 0.2712, 0.3527, 0.3592, 0.2745, 0.2669], 'AP': [0.1589, 0.466, 0.2498, 0.6841, 0.4299, 0.474, 0.7312, 0.632, 0.1004, 0.1103, 0.3082, 0.6048, 0.1624, 0.268, 0.4787, 0.2469, 0.1292, 0.2494, 0.1914, 0.4995, 0.5483, 0.5133, 0.1261, 0.3699, 0.4774, 0.5221, 0.2527, 0.5772, 0.3899, 0.2149, 0.3863, 0.1022, 0.7502, 0.9559, 0.4267, 0.3578, 0.3747, 0.1905, 0.1903, 0.1321, 0.5385, 0.3142, 0.3486, 0.3915, 0.7231, 0.2035, 0.4547, 0.1846, 0.5884, 0.2057, 0.1817, 0.5969, 0.3492, 0.2179, 0.7422, 0.2696, 0.1083, 0.2252, 0.0953, 0.2379, 0.5997, 0.7217, 0.3794, 0.6717, 0.542, 0.722, 0.2025, 0.1746, 0.4494, 0.8272, 0.7787, 0.4638, 0.2197, 0.236, 0.3566, 0.8426, 0.586, 0.1202, 0.5571, 0.5948, 0.3165, 0.2776, 0.1285, 0.7585, 0.3193, 0.1402, 0.6957, 0.1703, 0.7671, 0.3275, 0.7204, 0.8284, 0.2066, 0.2221, 0.5137, 0.456, 0.1819, 0.2615, 0.3331, 0.1979, 0.1891], 'Recall@P=50': [0.0, 0.407, 0.172, 0.748, 0.38, 0.48, 0.776, 0.648, 0.0, 0.008, 0.24, 0.616, 0.004, 0.048, 0.468, 0.132, 0.0, 0.14, 0.004, 0.504, 0.564, 0.492, 0.0, 0.276, 0.508, 0.524, 0.004, 0.548, 0.336, 0.004, 0.376, 0.008, 0.756, 0.968, 0.356, 0.28, 0.372, 0.016, 0.004, 0.0, 0.548, 0.004, 0.252, 0.352, 0.768, 0.004, 0.44, 0.012, 0.604, 0.088, 0.088, 0.6, 0.332, 0.024, 0.784, 0.14, 0.032, 0.132, 0.0, 0.024, 0.664, 0.752, 0.356, 0.692, 0.524, 0.784, 0.024, 0.136, 0.392, 0.848, 0.824, 0.444, 0.004, 0.084, 0.312, 0.92, 0.66, 0.004, 0.508, 0.632, 0.2, 0.148, 0.004, 0.808, 0.224, 0.012, 0.72, 0.008, 0.82, 0.004, 0.74, 0.856, 0.04, 0.016, 0.54, 0.432, 0.008, 0.008, 0.272, 0.008, 0.112], 'micro': 0.3824, 'macro': 0.3967, 'weighted': 0.3946}
2024-07-17 05:32:27 - [34m[1mLOGS   [0m - Best checkpoint with score 43.48 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:32:29 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_28.3789.pt
2024-07-17 05:32:29 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_31.8086.pt', 'checkpoint_score_34.7461.pt', 'checkpoint_score_36.4727.pt', 'checkpoint_score_40.5391.pt', 'checkpoint_score_43.4766.pt']
2024-07-17 05:32:34 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:32:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:32:37 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:32:40 - [34m[1mLOGS   [0m - Training checkpoint for epoch 57/iteration 6511 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_57_iter_6511.pt
2024-07-17 05:32:42 - [34m[1mLOGS   [0m - Model state for epoch 57/iteration 6511 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_57_iter_6511.pt
[31m===========================================================================[0m
2024-07-17 05:32:44 - [32m[1mINFO   [0m - Training epoch 58
2024-07-17 05:32:45 - [34m[1mLOGS   [0m - Epoch:  58 [    6512/10000000], loss: {'classification': 3.0497, 'neural_augmentation': 0.3847, 'total_loss': 3.4344}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 1.271, Elapsed time:  1.48
2024-07-17 05:33:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 58
	 loss={'classification': 3.0437, 'neural_augmentation': 0.3894, 'total_loss': 3.4331}
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5165562913907285 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5416666666666666 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5301204819277109 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5151515151515151 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5833333333333334 when recall at precision 0.5 was requested.
2024-07-17 05:33:16 - [33m[1mWARNING[0m - Found recall at precision 0.5161290322580645 when recall at precision 0.5 was requested.
2024-07-17 05:33:18 - [34m[1mLOGS   [0m - *** Validation summary for epoch 58
	 loss={'classification': 2.2778, 'neural_augmentation': 0.0, 'total_loss': 2.2778} || top1={'logits': 45.8711} || top5={'logits': 75.7031} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.2821, 0.5053, 0.3418, 0.6813, 0.4768, 0.5127, 0.6989, 0.6495, 0.2017, 0.2417, 0.389, 0.5784, 0.2908, 0.3601, 0.5272, 0.3782, 0.2579, 0.3655, 0.3095, 0.5501, 0.6102, 0.5238, 0.2482, 0.4255, 0.5469, 0.5462, 0.381, 0.6161, 0.4701, 0.2876, 0.4482, 0.2065, 0.7395, 0.9215, 0.5011, 0.4408, 0.4578, 0.2745, 0.2851, 0.2439, 0.5382, 0.4266, 0.4337, 0.4626, 0.693, 0.3132, 0.4875, 0.2704, 0.595, 0.3212, 0.2925, 0.6208, 0.4601, 0.3168, 0.7436, 0.3543, 0.2276, 0.287, 0.1947, 0.3455, 0.59, 0.7245, 0.4263, 0.6652, 0.5746, 0.7121, 0.3394, 0.2599, 0.5, 0.8151, 0.714, 0.4828, 0.3305, 0.3287, 0.4636, 0.8, 0.61, 0.2324, 0.5366, 0.6177, 0.4156, 0.4038, 0.2146, 0.7639, 0.3518, 0.2545, 0.6667, 0.279, 0.7434, 0.3972, 0.7159, 0.7682, 0.3026, 0.3535, 0.5495, 0.499, 0.3125, 0.3598, 0.4476, 0.3222, 0.2912], 'AP': [0.174, 0.5131, 0.2833, 0.7132, 0.4896, 0.5046, 0.7465, 0.6861, 0.1123, 0.1248, 0.3383, 0.6053, 0.1902, 0.2821, 0.5141, 0.3181, 0.1567, 0.2942, 0.2101, 0.55, 0.6234, 0.5297, 0.1551, 0.379, 0.5221, 0.5642, 0.2804, 0.6244, 0.4354, 0.2564, 0.4174, 0.1252, 0.7675, 0.9584, 0.497, 0.4185, 0.4171, 0.1904, 0.1674, 0.1564, 0.5301, 0.3533, 0.3925, 0.4204, 0.7386, 0.2368, 0.4682, 0.1894, 0.618, 0.2273, 0.2003, 0.6505, 0.4242, 0.2303, 0.7979, 0.3079, 0.1309, 0.2206, 0.1038, 0.2515, 0.6143, 0.7604, 0.4102, 0.7234, 0.5794, 0.7424, 0.2398, 0.1928, 0.5043, 0.8562, 0.7449, 0.4449, 0.2652, 0.2441, 0.3969, 0.8503, 0.6169, 0.1395, 0.5794, 0.6252, 0.3693, 0.3368, 0.1328, 0.7867, 0.3021, 0.1706, 0.7239, 0.1855, 0.8, 0.3518, 0.7704, 0.8287, 0.1909, 0.2601, 0.538, 0.4915, 0.2167, 0.298, 0.4283, 0.2511, 0.2294], 'Recall@P=50': [0.0119, 0.4884, 0.216, 0.78, 0.448, 0.496, 0.784, 0.724, 0.0, 0.012, 0.312, 0.64, 0.028, 0.052, 0.532, 0.276, 0.0, 0.012, 0.116, 0.548, 0.684, 0.516, 0.0, 0.284, 0.576, 0.576, 0.088, 0.66, 0.44, 0.176, 0.388, 0.02, 0.78, 0.96, 0.488, 0.34, 0.396, 0.004, 0.004, 0.064, 0.572, 0.004, 0.34, 0.008, 0.784, 0.096, 0.468, 0.008, 0.664, 0.1, 0.016, 0.672, 0.412, 0.004, 0.832, 0.248, 0.012, 0.12, 0.0, 0.072, 0.656, 0.776, 0.344, 0.776, 0.568, 0.784, 0.012, 0.128, 0.468, 0.876, 0.82, 0.436, 0.004, 0.04, 0.408, 0.916, 0.676, 0.0, 0.524, 0.652, 0.324, 0.16, 0.008, 0.816, 0.18, 0.016, 0.752, 0.012, 0.864, 0.004, 0.796, 0.864, 0.004, 0.028, 0.576, 0.488, 0.02, 0.008, 0.384, 0.024, 0.168], 'micro': 0.4214, 'macro': 0.4255, 'weighted': 0.4233}
2024-07-17 05:33:22 - [34m[1mLOGS   [0m - Best checkpoint with score 45.87 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:33:23 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_31.8086.pt
2024-07-17 05:33:23 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_34.7461.pt', 'checkpoint_score_36.4727.pt', 'checkpoint_score_40.5391.pt', 'checkpoint_score_43.4766.pt', 'checkpoint_score_45.8711.pt']
2024-07-17 05:33:29 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:33:31 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:33:32 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:33:35 - [34m[1mLOGS   [0m - Training checkpoint for epoch 58/iteration 6621 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_58_iter_6621.pt
2024-07-17 05:33:36 - [34m[1mLOGS   [0m - Model state for epoch 58/iteration 6621 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_58_iter_6621.pt
[31m===========================================================================[0m
2024-07-17 05:33:38 - [32m[1mINFO   [0m - Training epoch 59
2024-07-17 05:33:39 - [34m[1mLOGS   [0m - Epoch:  59 [    6622/10000000], loss: {'classification': 2.9527, 'neural_augmentation': 0.4065, 'total_loss': 3.3592}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 0.874, Elapsed time:  1.09
2024-07-17 05:34:02 - [34m[1mLOGS   [0m - *** Training summary for epoch 59
	 loss={'classification': 2.9679, 'neural_augmentation': 0.4014, 'total_loss': 3.3693}
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 0.5160142348754448 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:34:10 - [33m[1mWARNING[0m - Found recall at precision 0.5428571428571428 when recall at precision 0.5 was requested.
2024-07-17 05:34:11 - [33m[1mWARNING[0m - Found recall at precision 0.5192307692307693 when recall at precision 0.5 was requested.
2024-07-17 05:34:12 - [34m[1mLOGS   [0m - *** Validation summary for epoch 59
	 loss={'classification': 2.166, 'neural_augmentation': 0.0, 'total_loss': 2.166} || top1={'logits': 48.6953} || top5={'logits': 77.8672} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.2822, 0.5253, 0.389, 0.6983, 0.5256, 0.5219, 0.714, 0.6695, 0.2184, 0.2667, 0.3992, 0.5955, 0.3017, 0.3745, 0.5434, 0.3814, 0.259, 0.3876, 0.3706, 0.556, 0.6096, 0.5373, 0.2738, 0.5038, 0.554, 0.6058, 0.3733, 0.6481, 0.5034, 0.3179, 0.4728, 0.2186, 0.7589, 0.9379, 0.5575, 0.486, 0.4756, 0.2912, 0.317, 0.2652, 0.5506, 0.4404, 0.4358, 0.4932, 0.7111, 0.3612, 0.5205, 0.2878, 0.6231, 0.3689, 0.3021, 0.6505, 0.4609, 0.3441, 0.7932, 0.3594, 0.2505, 0.3394, 0.2027, 0.3602, 0.613, 0.7387, 0.4667, 0.7048, 0.5405, 0.7325, 0.3684, 0.2888, 0.4943, 0.8456, 0.7265, 0.5202, 0.4211, 0.3661, 0.4632, 0.8155, 0.6007, 0.2469, 0.591, 0.6137, 0.447, 0.4184, 0.2168, 0.7566, 0.3601, 0.2813, 0.6957, 0.3013, 0.7355, 0.4213, 0.714, 0.7728, 0.356, 0.369, 0.5708, 0.567, 0.3509, 0.4357, 0.4745, 0.3354, 0.3256], 'AP': [0.1749, 0.5418, 0.36, 0.736, 0.5423, 0.5116, 0.7609, 0.6979, 0.1244, 0.1535, 0.3472, 0.6335, 0.1967, 0.3028, 0.5522, 0.3273, 0.159, 0.3319, 0.2709, 0.5655, 0.6341, 0.5456, 0.1793, 0.4846, 0.5563, 0.6414, 0.2889, 0.668, 0.4886, 0.2911, 0.4375, 0.1428, 0.7937, 0.9681, 0.5537, 0.4792, 0.4331, 0.2029, 0.2145, 0.1733, 0.5582, 0.417, 0.3868, 0.4577, 0.7607, 0.2869, 0.5117, 0.2206, 0.6369, 0.2824, 0.2282, 0.6882, 0.4277, 0.2596, 0.8524, 0.3352, 0.1445, 0.2522, 0.1148, 0.2716, 0.6425, 0.7856, 0.4397, 0.7705, 0.5684, 0.7546, 0.2453, 0.2387, 0.5267, 0.8824, 0.7615, 0.4745, 0.3837, 0.2962, 0.4082, 0.8628, 0.609, 0.147, 0.6196, 0.6359, 0.4147, 0.3679, 0.1358, 0.7938, 0.3235, 0.2121, 0.7574, 0.2079, 0.7936, 0.3564, 0.7742, 0.8319, 0.2684, 0.2619, 0.5801, 0.5769, 0.2638, 0.389, 0.4683, 0.2524, 0.2634], 'Recall@P=50': [0.0, 0.5436, 0.312, 0.78, 0.532, 0.528, 0.816, 0.732, 0.0, 0.004, 0.3, 0.652, 0.008, 0.12, 0.568, 0.296, 0.004, 0.276, 0.004, 0.58, 0.7, 0.564, 0.0, 0.48, 0.588, 0.628, 0.14, 0.7, 0.492, 0.2, 0.424, 0.02, 0.82, 0.98, 0.548, 0.444, 0.44, 0.02, 0.008, 0.004, 0.592, 0.376, 0.004, 0.464, 0.812, 0.004, 0.472, 0.004, 0.676, 0.24, 0.016, 0.724, 0.416, 0.016, 0.892, 0.252, 0.032, 0.156, 0.0, 0.016, 0.676, 0.824, 0.424, 0.836, 0.54, 0.792, 0.012, 0.188, 0.48, 0.908, 0.84, 0.528, 0.356, 0.212, 0.428, 0.936, 0.692, 0.0, 0.616, 0.684, 0.38, 0.276, 0.008, 0.832, 0.224, 0.076, 0.768, 0.08, 0.852, 0.308, 0.788, 0.86, 0.008, 0.008, 0.628, 0.612, 0.088, 0.344, 0.432, 0.004, 0.144], 'micro': 0.4491, 'macro': 0.4545, 'weighted': 0.452}
2024-07-17 05:34:16 - [34m[1mLOGS   [0m - Best checkpoint with score 48.70 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:34:18 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_34.7461.pt
2024-07-17 05:34:18 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_36.4727.pt', 'checkpoint_score_40.5391.pt', 'checkpoint_score_43.4766.pt', 'checkpoint_score_45.8711.pt', 'checkpoint_score_48.6953.pt']
2024-07-17 05:34:24 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:34:26 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:34:27 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:34:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 59/iteration 6730 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_59_iter_6730.pt
2024-07-17 05:34:32 - [34m[1mLOGS   [0m - Model state for epoch 59/iteration 6730 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_59_iter_6730.pt
[31m===========================================================================[0m
2024-07-17 05:34:34 - [32m[1mINFO   [0m - Training epoch 60
2024-07-17 05:34:35 - [34m[1mLOGS   [0m - Epoch:  60 [    6731/10000000], loss: {'classification': 3.0045, 'neural_augmentation': 0.4095, 'total_loss': 3.414}, LR: [1.7e-05, 1.7e-05], Avg. batch load time: 1.547, Elapsed time:  1.76
2024-07-17 05:34:57 - [34m[1mLOGS   [0m - *** Training summary for epoch 60
	 loss={'classification': 2.8777, 'neural_augmentation': 0.414, 'total_loss': 3.2917}
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.5165562913907285 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.5161290322580645 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.6 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.55 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.5164835164835165 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.5454545454545454 when recall at precision 0.5 was requested.
2024-07-17 05:35:05 - [33m[1mWARNING[0m - Found recall at precision 0.5188679245283019 when recall at precision 0.5 was requested.
2024-07-17 05:35:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 60
	 loss={'classification': 2.0325, 'neural_augmentation': 0.0, 'total_loss': 2.0325} || top1={'logits': 51.5273} || top5={'logits': 79.8086} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3084, 0.5789, 0.3976, 0.7152, 0.5641, 0.5605, 0.7245, 0.7068, 0.2341, 0.2979, 0.4297, 0.6414, 0.3194, 0.4165, 0.5662, 0.404, 0.2688, 0.3978, 0.372, 0.5969, 0.6388, 0.529, 0.2782, 0.5255, 0.5908, 0.6449, 0.4053, 0.6556, 0.5023, 0.3198, 0.5455, 0.2257, 0.793, 0.9472, 0.5921, 0.5558, 0.5098, 0.3127, 0.334, 0.2946, 0.5576, 0.5, 0.4341, 0.5437, 0.7549, 0.3711, 0.5485, 0.3372, 0.6258, 0.3908, 0.3378, 0.6609, 0.5129, 0.3592, 0.7991, 0.44, 0.2613, 0.3583, 0.2152, 0.4007, 0.6089, 0.749, 0.5011, 0.7066, 0.6032, 0.7592, 0.3641, 0.3095, 0.5385, 0.8452, 0.7991, 0.5695, 0.4591, 0.3584, 0.5306, 0.8346, 0.6512, 0.274, 0.6505, 0.6623, 0.4669, 0.4339, 0.252, 0.7664, 0.4248, 0.2955, 0.7089, 0.3593, 0.7527, 0.4762, 0.7586, 0.7991, 0.3615, 0.3649, 0.5941, 0.5756, 0.3696, 0.4879, 0.5081, 0.369, 0.3991], 'AP': [0.2135, 0.6126, 0.3893, 0.7597, 0.5558, 0.5625, 0.7685, 0.7506, 0.1512, 0.1709, 0.3805, 0.6831, 0.2321, 0.377, 0.5836, 0.3724, 0.1949, 0.349, 0.2787, 0.6061, 0.6827, 0.5468, 0.1854, 0.5285, 0.6199, 0.684, 0.3388, 0.6805, 0.4974, 0.2911, 0.5561, 0.148, 0.8092, 0.9785, 0.6065, 0.5545, 0.4767, 0.2328, 0.2501, 0.2288, 0.5785, 0.4651, 0.3999, 0.532, 0.7904, 0.3139, 0.5392, 0.2796, 0.6505, 0.3194, 0.2883, 0.6873, 0.4797, 0.3036, 0.858, 0.447, 0.1745, 0.2759, 0.1113, 0.3166, 0.6481, 0.799, 0.4914, 0.782, 0.6391, 0.7901, 0.2923, 0.2874, 0.5748, 0.8852, 0.8324, 0.5814, 0.4274, 0.307, 0.5118, 0.884, 0.6665, 0.1705, 0.6771, 0.6826, 0.4514, 0.4187, 0.1705, 0.8017, 0.4069, 0.2281, 0.764, 0.2502, 0.8166, 0.4376, 0.817, 0.8717, 0.2741, 0.2734, 0.5891, 0.5967, 0.2893, 0.4773, 0.5035, 0.3104, 0.3695], 'Recall@P=50': [0.0079, 0.6395, 0.324, 0.8, 0.624, 0.6, 0.812, 0.812, 0.0, 0.004, 0.348, 0.676, 0.004, 0.312, 0.6, 0.332, 0.112, 0.312, 0.012, 0.632, 0.724, 0.52, 0.0, 0.532, 0.672, 0.676, 0.192, 0.7, 0.46, 0.184, 0.548, 0.012, 0.804, 0.988, 0.592, 0.548, 0.484, 0.048, 0.044, 0.128, 0.62, 0.008, 0.004, 0.576, 0.832, 0.136, 0.532, 0.188, 0.696, 0.252, 0.232, 0.716, 0.488, 0.188, 0.904, 0.388, 0.016, 0.236, 0.004, 0.024, 0.708, 0.828, 0.476, 0.828, 0.64, 0.816, 0.004, 0.216, 0.572, 0.892, 0.9, 0.568, 0.412, 0.252, 0.508, 0.932, 0.752, 0.008, 0.668, 0.708, 0.428, 0.332, 0.048, 0.852, 0.344, 0.112, 0.804, 0.148, 0.876, 0.44, 0.832, 0.9, 0.008, 0.044, 0.648, 0.604, 0.16, 0.46, 0.488, 0.004, 0.32], 'micro': 0.4846, 'macro': 0.4925, 'weighted': 0.4902}
2024-07-17 05:35:12 - [34m[1mLOGS   [0m - Best checkpoint with score 51.53 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:35:13 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_36.4727.pt
2024-07-17 05:35:13 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_40.5391.pt', 'checkpoint_score_43.4766.pt', 'checkpoint_score_45.8711.pt', 'checkpoint_score_48.6953.pt', 'checkpoint_score_51.5273.pt']
2024-07-17 05:35:19 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:35:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:35:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:35:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 60/iteration 6833 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_60_iter_6833.pt
2024-07-17 05:35:26 - [34m[1mLOGS   [0m - Model state for epoch 60/iteration 6833 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_60_iter_6833.pt
[31m===========================================================================[0m
2024-07-17 05:35:28 - [32m[1mINFO   [0m - Training epoch 61
2024-07-17 05:35:30 - [34m[1mLOGS   [0m - Epoch:  61 [    6834/10000000], loss: {'classification': 2.9217, 'neural_augmentation': 0.4291, 'total_loss': 3.3508}, LR: [1.6e-05, 1.6e-05], Avg. batch load time: 1.757, Elapsed time:  1.97
2024-07-17 05:35:53 - [34m[1mLOGS   [0m - *** Training summary for epoch 61
	 loss={'classification': 2.776, 'neural_augmentation': 0.427, 'total_loss': 3.203}
2024-07-17 05:36:01 - [33m[1mWARNING[0m - Found recall at precision 0.5211267605633803 when recall at precision 0.5 was requested.
2024-07-17 05:36:01 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:36:01 - [33m[1mWARNING[0m - Found recall at precision 0.5245901639344263 when recall at precision 0.5 was requested.
2024-07-17 05:36:01 - [33m[1mWARNING[0m - Found recall at precision 0.5263157894736842 when recall at precision 0.5 was requested.
2024-07-17 05:36:01 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:36:02 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:36:02 - [33m[1mWARNING[0m - Found recall at precision 0.5151515151515151 when recall at precision 0.5 was requested.
2024-07-17 05:36:02 - [33m[1mWARNING[0m - Found recall at precision 0.5285714285714286 when recall at precision 0.5 was requested.
2024-07-17 05:36:02 - [33m[1mWARNING[0m - Found recall at precision 0.525974025974026 when recall at precision 0.5 was requested.
2024-07-17 05:36:03 - [34m[1mLOGS   [0m - *** Validation summary for epoch 61
	 loss={'classification': 1.9052, 'neural_augmentation': 0.0, 'total_loss': 1.9052} || top1={'logits': 54.5195} || top5={'logits': 82.1875} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.328, 0.5754, 0.469, 0.7413, 0.5765, 0.5605, 0.7432, 0.7521, 0.2624, 0.3043, 0.4488, 0.6418, 0.3323, 0.4299, 0.5996, 0.4444, 0.3274, 0.4202, 0.4195, 0.6132, 0.6711, 0.5485, 0.3088, 0.6004, 0.6348, 0.6727, 0.4111, 0.6866, 0.5374, 0.3588, 0.5891, 0.2741, 0.8009, 0.9588, 0.6123, 0.5728, 0.5564, 0.3359, 0.3677, 0.3129, 0.6089, 0.5444, 0.4693, 0.5739, 0.7611, 0.4449, 0.5714, 0.3446, 0.6492, 0.4276, 0.3407, 0.6788, 0.5602, 0.419, 0.8197, 0.4574, 0.3091, 0.3898, 0.2348, 0.4183, 0.6539, 0.7907, 0.5537, 0.7696, 0.6306, 0.7609, 0.4083, 0.3325, 0.5866, 0.8747, 0.7767, 0.5696, 0.512, 0.3858, 0.5212, 0.8258, 0.6524, 0.269, 0.6545, 0.6638, 0.4765, 0.4706, 0.2629, 0.7791, 0.4337, 0.3406, 0.734, 0.3683, 0.7698, 0.4991, 0.7865, 0.8094, 0.4185, 0.3878, 0.6122, 0.6171, 0.4109, 0.5364, 0.5297, 0.397, 0.4145], 'AP': [0.243, 0.6035, 0.476, 0.7768, 0.5964, 0.5555, 0.783, 0.7868, 0.1769, 0.2017, 0.4084, 0.701, 0.2867, 0.3783, 0.6259, 0.4208, 0.2517, 0.3738, 0.3405, 0.6382, 0.71, 0.569, 0.1894, 0.6132, 0.6633, 0.7323, 0.343, 0.7332, 0.5548, 0.3604, 0.6014, 0.2004, 0.8268, 0.9807, 0.6509, 0.5995, 0.5308, 0.2577, 0.3016, 0.2574, 0.6355, 0.5315, 0.4407, 0.596, 0.8025, 0.3922, 0.577, 0.3012, 0.6855, 0.3827, 0.284, 0.7326, 0.5482, 0.3662, 0.8807, 0.4707, 0.2113, 0.3159, 0.1333, 0.3452, 0.6937, 0.8317, 0.5566, 0.8237, 0.6519, 0.7904, 0.3456, 0.316, 0.6202, 0.9029, 0.8377, 0.5666, 0.5007, 0.326, 0.5007, 0.8896, 0.6917, 0.1686, 0.6982, 0.683, 0.4761, 0.4712, 0.1917, 0.8206, 0.4228, 0.2722, 0.8001, 0.2765, 0.8354, 0.4674, 0.8396, 0.8812, 0.3555, 0.2906, 0.6295, 0.646, 0.3301, 0.5283, 0.5292, 0.3281, 0.3957], 'Recall@P=50': [0.0711, 0.6337, 0.412, 0.82, 0.648, 0.58, 0.832, 0.828, 0.016, 0.016, 0.388, 0.712, 0.16, 0.296, 0.664, 0.376, 0.148, 0.296, 0.348, 0.688, 0.78, 0.576, 0.0, 0.644, 0.728, 0.74, 0.244, 0.776, 0.552, 0.256, 0.64, 0.04, 0.836, 0.988, 0.66, 0.624, 0.536, 0.02, 0.112, 0.14, 0.712, 0.556, 0.412, 0.632, 0.836, 0.324, 0.576, 0.216, 0.724, 0.372, 0.004, 0.76, 0.56, 0.252, 0.916, 0.396, 0.052, 0.288, 0.0, 0.012, 0.752, 0.856, 0.52, 0.868, 0.632, 0.836, 0.284, 0.24, 0.632, 0.908, 0.884, 0.604, 0.504, 0.24, 0.54, 0.952, 0.74, 0.0, 0.716, 0.716, 0.428, 0.44, 0.004, 0.876, 0.34, 0.148, 0.884, 0.016, 0.876, 0.428, 0.864, 0.944, 0.02, 0.052, 0.712, 0.656, 0.256, 0.536, 0.512, 0.268, 0.324], 'micro': 0.5209, 'macro': 0.5259, 'weighted': 0.5234}
2024-07-17 05:36:08 - [34m[1mLOGS   [0m - Best checkpoint with score 54.52 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:36:09 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_40.5391.pt
2024-07-17 05:36:09 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_43.4766.pt', 'checkpoint_score_45.8711.pt', 'checkpoint_score_48.6953.pt', 'checkpoint_score_51.5273.pt', 'checkpoint_score_54.5195.pt']
2024-07-17 05:36:15 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:36:17 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:36:18 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:36:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 61/iteration 6945 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_61_iter_6945.pt
2024-07-17 05:36:22 - [34m[1mLOGS   [0m - Model state for epoch 61/iteration 6945 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_61_iter_6945.pt
[31m===========================================================================[0m
2024-07-17 05:36:24 - [32m[1mINFO   [0m - Training epoch 62
2024-07-17 05:36:25 - [34m[1mLOGS   [0m - Epoch:  62 [    6946/10000000], loss: {'classification': 2.6318, 'neural_augmentation': 0.4439, 'total_loss': 3.0758}, LR: [1.6e-05, 1.6e-05], Avg. batch load time: 0.716, Elapsed time:  0.93
2024-07-17 05:36:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 62
	 loss={'classification': 2.6882, 'neural_augmentation': 0.4396, 'total_loss': 3.1277}
2024-07-17 05:36:59 - [33m[1mWARNING[0m - Found recall at precision 0.5246636771300448 when recall at precision 0.5 was requested.
2024-07-17 05:36:59 - [33m[1mWARNING[0m - Found recall at precision 0.5167785234899329 when recall at precision 0.5 was requested.
2024-07-17 05:36:59 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:36:59 - [33m[1mWARNING[0m - Found recall at precision 0.5153374233128835 when recall at precision 0.5 was requested.
2024-07-17 05:37:00 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:37:01 - [34m[1mLOGS   [0m - *** Validation summary for epoch 62
	 loss={'classification': 1.7913, 'neural_augmentation': 0.0, 'total_loss': 1.7913} || top1={'logits': 57.1328} || top5={'logits': 83.7891} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3485, 0.619, 0.5054, 0.7702, 0.6161, 0.562, 0.7635, 0.7734, 0.2637, 0.3333, 0.4367, 0.6468, 0.3682, 0.4441, 0.6164, 0.4864, 0.3561, 0.4211, 0.4187, 0.6255, 0.721, 0.5458, 0.325, 0.6058, 0.6444, 0.6943, 0.4418, 0.7064, 0.5442, 0.409, 0.6313, 0.3068, 0.8225, 0.961, 0.6418, 0.6259, 0.5683, 0.3316, 0.3841, 0.3236, 0.6094, 0.5732, 0.4933, 0.5977, 0.7663, 0.505, 0.5871, 0.3698, 0.6738, 0.4464, 0.373, 0.7227, 0.5943, 0.4188, 0.83, 0.5079, 0.3286, 0.3807, 0.2669, 0.4259, 0.6818, 0.7905, 0.5821, 0.7869, 0.6325, 0.7609, 0.4342, 0.3419, 0.6269, 0.8767, 0.8033, 0.5885, 0.5714, 0.4019, 0.5324, 0.8431, 0.6818, 0.3037, 0.6778, 0.6792, 0.5221, 0.5371, 0.2704, 0.7842, 0.4204, 0.3858, 0.7354, 0.3626, 0.7966, 0.493, 0.7819, 0.8182, 0.4677, 0.3915, 0.6343, 0.6202, 0.4316, 0.5514, 0.5445, 0.3946, 0.5011], 'AP': [0.2723, 0.6551, 0.508, 0.8157, 0.6387, 0.5644, 0.7971, 0.8167, 0.183, 0.198, 0.408, 0.7055, 0.3537, 0.4095, 0.6497, 0.4651, 0.2793, 0.3734, 0.3514, 0.652, 0.7536, 0.5669, 0.2236, 0.6331, 0.678, 0.7596, 0.3705, 0.7479, 0.579, 0.4013, 0.6491, 0.2433, 0.8384, 0.983, 0.6833, 0.6534, 0.569, 0.2505, 0.3467, 0.2649, 0.6462, 0.5696, 0.4842, 0.624, 0.8112, 0.4944, 0.5881, 0.3084, 0.6922, 0.4041, 0.3125, 0.7873, 0.5856, 0.3723, 0.8895, 0.5252, 0.2362, 0.3021, 0.175, 0.3686, 0.7351, 0.8422, 0.5845, 0.8366, 0.6705, 0.7966, 0.3916, 0.3353, 0.6706, 0.9046, 0.8486, 0.6104, 0.566, 0.3485, 0.5373, 0.8943, 0.7156, 0.1944, 0.7289, 0.7044, 0.5285, 0.53, 0.189, 0.8313, 0.4287, 0.3216, 0.8062, 0.2659, 0.8483, 0.4543, 0.8461, 0.885, 0.3945, 0.2997, 0.644, 0.6646, 0.3785, 0.5573, 0.5599, 0.3292, 0.4884], 'Recall@P=50': [0.004, 0.6599, 0.468, 0.844, 0.672, 0.616, 0.848, 0.836, 0.04, 0.004, 0.38, 0.74, 0.24, 0.34, 0.704, 0.436, 0.168, 0.32, 0.344, 0.712, 0.8, 0.58, 0.0, 0.66, 0.748, 0.804, 0.328, 0.788, 0.58, 0.308, 0.668, 0.084, 0.848, 0.988, 0.688, 0.684, 0.6, 0.04, 0.16, 0.164, 0.724, 0.624, 0.44, 0.664, 0.84, 0.504, 0.588, 0.192, 0.748, 0.004, 0.004, 0.848, 0.596, 0.236, 0.928, 0.46, 0.116, 0.244, 0.016, 0.012, 0.792, 0.844, 0.592, 0.868, 0.664, 0.844, 0.336, 0.256, 0.7, 0.912, 0.876, 0.648, 0.576, 0.224, 0.532, 0.956, 0.792, 0.0, 0.756, 0.744, 0.488, 0.548, 0.044, 0.888, 0.356, 0.224, 0.876, 0.108, 0.888, 0.004, 0.884, 0.908, 0.004, 0.008, 0.72, 0.664, 0.32, 0.524, 0.54, 0.008, 0.468], 'micro': 0.5506, 'macro': 0.5508, 'weighted': 0.5484}
2024-07-17 05:37:05 - [34m[1mLOGS   [0m - Best checkpoint with score 57.13 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:37:06 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_43.4766.pt
2024-07-17 05:37:06 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_45.8711.pt', 'checkpoint_score_48.6953.pt', 'checkpoint_score_51.5273.pt', 'checkpoint_score_54.5195.pt', 'checkpoint_score_57.1328.pt']
2024-07-17 05:37:12 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:37:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:37:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:37:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 62/iteration 7067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_62_iter_7067.pt
2024-07-17 05:37:19 - [34m[1mLOGS   [0m - Model state for epoch 62/iteration 7067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_62_iter_7067.pt
[31m===========================================================================[0m
2024-07-17 05:37:21 - [32m[1mINFO   [0m - Training epoch 63
2024-07-17 05:37:22 - [34m[1mLOGS   [0m - Epoch:  63 [    7068/10000000], loss: {'classification': 2.5237, 'neural_augmentation': 0.4461, 'total_loss': 2.9698}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 0.674, Elapsed time:  0.89
2024-07-17 05:37:44 - [34m[1mLOGS   [0m - *** Training summary for epoch 63
	 loss={'classification': 2.6325, 'neural_augmentation': 0.4513, 'total_loss': 3.0838}
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5157232704402516 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5154639175257731 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5211267605633803 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5182481751824818 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5150375939849624 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5228758169934641 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.5171232876712328 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:37:52 - [33m[1mWARNING[0m - Found recall at precision 0.521978021978022 when recall at precision 0.5 was requested.
2024-07-17 05:37:54 - [34m[1mLOGS   [0m - *** Validation summary for epoch 63
	 loss={'classification': 1.7257, 'neural_augmentation': 0.0, 'total_loss': 1.7257} || top1={'logits': 58.5352} || top5={'logits': 84.9609} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3498, 0.644, 0.5106, 0.7526, 0.6378, 0.5983, 0.7642, 0.7839, 0.2614, 0.346, 0.4637, 0.6615, 0.3511, 0.5242, 0.6316, 0.4691, 0.3845, 0.4314, 0.4595, 0.6478, 0.7046, 0.5667, 0.3226, 0.6651, 0.7009, 0.6855, 0.4378, 0.724, 0.5733, 0.4587, 0.6725, 0.3218, 0.822, 0.9587, 0.6562, 0.6498, 0.6113, 0.3454, 0.4309, 0.3554, 0.6093, 0.6094, 0.5219, 0.5966, 0.7942, 0.5541, 0.5962, 0.365, 0.6794, 0.4532, 0.3919, 0.7195, 0.6018, 0.406, 0.8554, 0.5641, 0.3521, 0.4224, 0.2573, 0.4565, 0.7123, 0.7935, 0.6133, 0.7871, 0.6681, 0.7637, 0.4644, 0.397, 0.6327, 0.887, 0.8277, 0.6166, 0.5929, 0.4028, 0.5618, 0.833, 0.6874, 0.2953, 0.7126, 0.6862, 0.5529, 0.5587, 0.3126, 0.7866, 0.4413, 0.4055, 0.7756, 0.3972, 0.8042, 0.5399, 0.8199, 0.8531, 0.5069, 0.405, 0.6479, 0.6522, 0.4387, 0.5809, 0.5687, 0.427, 0.5206], 'AP': [0.2627, 0.6798, 0.5231, 0.8081, 0.6779, 0.6064, 0.7915, 0.8202, 0.1828, 0.2276, 0.4587, 0.7363, 0.2969, 0.526, 0.6733, 0.4616, 0.3259, 0.4093, 0.4005, 0.6687, 0.7422, 0.5984, 0.225, 0.6713, 0.7394, 0.7638, 0.389, 0.7866, 0.6049, 0.4436, 0.701, 0.2641, 0.8474, 0.9853, 0.6922, 0.6755, 0.6186, 0.2585, 0.4047, 0.3026, 0.6369, 0.6123, 0.4975, 0.616, 0.8258, 0.5401, 0.6005, 0.3392, 0.7152, 0.4089, 0.3473, 0.7938, 0.594, 0.384, 0.9036, 0.5736, 0.2725, 0.3488, 0.1785, 0.4042, 0.7591, 0.8477, 0.5999, 0.8508, 0.7262, 0.8045, 0.4374, 0.3731, 0.6879, 0.9135, 0.8776, 0.6434, 0.5877, 0.358, 0.5695, 0.8955, 0.7418, 0.2022, 0.7468, 0.7215, 0.5634, 0.5791, 0.2335, 0.8328, 0.4624, 0.326, 0.8366, 0.3074, 0.857, 0.5015, 0.8794, 0.9193, 0.455, 0.3091, 0.6704, 0.6991, 0.3954, 0.5765, 0.585, 0.3774, 0.5356], 'Recall@P=50': [0.004, 0.7093, 0.48, 0.84, 0.7, 0.656, 0.848, 0.836, 0.072, 0.024, 0.4, 0.808, 0.132, 0.528, 0.724, 0.424, 0.256, 0.36, 0.42, 0.72, 0.792, 0.636, 0.0, 0.68, 0.804, 0.808, 0.296, 0.824, 0.636, 0.396, 0.74, 0.204, 0.852, 0.996, 0.708, 0.696, 0.648, 0.04, 0.252, 0.212, 0.712, 0.696, 0.524, 0.66, 0.856, 0.56, 0.632, 0.232, 0.748, 0.004, 0.004, 0.844, 0.62, 0.284, 0.932, 0.548, 0.004, 0.296, 0.028, 0.384, 0.808, 0.884, 0.636, 0.896, 0.736, 0.848, 0.416, 0.32, 0.724, 0.92, 0.904, 0.696, 0.604, 0.252, 0.572, 0.952, 0.812, 0.0, 0.8, 0.772, 0.588, 0.58, 0.056, 0.868, 0.38, 0.184, 0.904, 0.192, 0.888, 0.568, 0.916, 0.94, 0.024, 0.008, 0.732, 0.692, 0.312, 0.596, 0.576, 0.316, 0.504], 'micro': 0.5742, 'macro': 0.5751, 'weighted': 0.5724}
2024-07-17 05:37:59 - [34m[1mLOGS   [0m - Best checkpoint with score 58.54 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:38:00 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_45.8711.pt
2024-07-17 05:38:00 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_48.6953.pt', 'checkpoint_score_51.5273.pt', 'checkpoint_score_54.5195.pt', 'checkpoint_score_57.1328.pt', 'checkpoint_score_58.5352.pt']
2024-07-17 05:38:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:38:08 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:38:09 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:38:12 - [34m[1mLOGS   [0m - Training checkpoint for epoch 63/iteration 7169 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_63_iter_7169.pt
2024-07-17 05:38:13 - [34m[1mLOGS   [0m - Model state for epoch 63/iteration 7169 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_63_iter_7169.pt
[31m===========================================================================[0m
2024-07-17 05:38:15 - [32m[1mINFO   [0m - Training epoch 64
2024-07-17 05:38:16 - [34m[1mLOGS   [0m - Epoch:  64 [    7170/10000000], loss: {'classification': 2.4364, 'neural_augmentation': 0.4605, 'total_loss': 2.8968}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 1.102, Elapsed time:  1.32
2024-07-17 05:38:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 64
	 loss={'classification': 2.5431, 'neural_augmentation': 0.4639, 'total_loss': 3.0069}
2024-07-17 05:38:48 - [33m[1mWARNING[0m - Found recall at precision 0.5384615384615384 when recall at precision 0.5 was requested.
2024-07-17 05:38:48 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:38:48 - [33m[1mWARNING[0m - Found recall at precision 0.5204081632653061 when recall at precision 0.5 was requested.
2024-07-17 05:38:48 - [33m[1mWARNING[0m - Found recall at precision 0.515527950310559 when recall at precision 0.5 was requested.
2024-07-17 05:38:49 - [33m[1mWARNING[0m - Found recall at precision 1.0 when recall at precision 0.5 was requested.
2024-07-17 05:38:50 - [34m[1mLOGS   [0m - *** Validation summary for epoch 64
	 loss={'classification': 1.6178, 'neural_augmentation': 0.0, 'total_loss': 1.6178} || top1={'logits': 60.9609} || top5={'logits': 86.4219} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3717, 0.6056, 0.5629, 0.7617, 0.6667, 0.5958, 0.778, 0.8098, 0.316, 0.3567, 0.4978, 0.7258, 0.423, 0.5489, 0.6578, 0.5147, 0.4312, 0.465, 0.4679, 0.6576, 0.728, 0.5832, 0.3414, 0.6681, 0.7299, 0.7306, 0.4576, 0.749, 0.6182, 0.5409, 0.7198, 0.3914, 0.8348, 0.9652, 0.6889, 0.6862, 0.6194, 0.3656, 0.5045, 0.3414, 0.6385, 0.6402, 0.5204, 0.6245, 0.7807, 0.6048, 0.611, 0.3984, 0.6839, 0.506, 0.4009, 0.7411, 0.6225, 0.447, 0.8595, 0.5786, 0.3333, 0.4436, 0.2898, 0.4529, 0.7088, 0.8126, 0.6193, 0.8188, 0.7064, 0.7916, 0.4629, 0.4093, 0.6715, 0.8989, 0.8312, 0.6441, 0.6274, 0.4292, 0.5575, 0.835, 0.7042, 0.3099, 0.7431, 0.7045, 0.5632, 0.5792, 0.3316, 0.816, 0.4874, 0.4401, 0.7839, 0.412, 0.8086, 0.5418, 0.812, 0.8364, 0.5483, 0.4086, 0.6532, 0.676, 0.4725, 0.614, 0.5986, 0.4612, 0.5634], 'AP': [0.2869, 0.6658, 0.6033, 0.8225, 0.6913, 0.6226, 0.8058, 0.8521, 0.2326, 0.2424, 0.4847, 0.7817, 0.4258, 0.5613, 0.7032, 0.5189, 0.3939, 0.4453, 0.4052, 0.6922, 0.7678, 0.5984, 0.2296, 0.7065, 0.7636, 0.8056, 0.4078, 0.8049, 0.6553, 0.5397, 0.7493, 0.3479, 0.8639, 0.9889, 0.7338, 0.7159, 0.6443, 0.2924, 0.5266, 0.2976, 0.6775, 0.6525, 0.5103, 0.669, 0.8272, 0.6159, 0.6333, 0.3806, 0.735, 0.4621, 0.3575, 0.8113, 0.6282, 0.4399, 0.9116, 0.6116, 0.2972, 0.3867, 0.2303, 0.4129, 0.7549, 0.8637, 0.6323, 0.878, 0.748, 0.8146, 0.4657, 0.3966, 0.7398, 0.9243, 0.8983, 0.6801, 0.6509, 0.3861, 0.5726, 0.9042, 0.7464, 0.213, 0.783, 0.7338, 0.5882, 0.6003, 0.2536, 0.8464, 0.4945, 0.3904, 0.8485, 0.3449, 0.8684, 0.5451, 0.8747, 0.9142, 0.4784, 0.314, 0.6796, 0.7322, 0.4554, 0.6335, 0.6116, 0.4134, 0.5859], 'Recall@P=50': [0.1621, 0.6831, 0.592, 0.86, 0.732, 0.704, 0.868, 0.88, 0.1, 0.028, 0.472, 0.832, 0.332, 0.56, 0.752, 0.484, 0.364, 0.424, 0.008, 0.732, 0.844, 0.636, 0.0, 0.716, 0.812, 0.856, 0.34, 0.844, 0.696, 0.564, 0.776, 0.292, 0.88, 0.996, 0.776, 0.736, 0.696, 0.096, 0.496, 0.204, 0.748, 0.7, 0.508, 0.716, 0.848, 0.632, 0.652, 0.288, 0.792, 0.468, 0.252, 0.848, 0.644, 0.364, 0.94, 0.6, 0.208, 0.376, 0.076, 0.392, 0.812, 0.892, 0.628, 0.9, 0.764, 0.856, 0.424, 0.332, 0.82, 0.928, 0.932, 0.728, 0.676, 0.332, 0.572, 0.952, 0.824, 0.0, 0.816, 0.768, 0.604, 0.592, 0.084, 0.892, 0.432, 0.348, 0.908, 0.248, 0.904, 0.536, 0.916, 0.944, 0.004, 0.008, 0.796, 0.728, 0.416, 0.636, 0.588, 0.372, 0.568], 'micro': 0.6039, 'macro': 0.6058, 'weighted': 0.6028}
2024-07-17 05:38:55 - [34m[1mLOGS   [0m - Best checkpoint with score 60.96 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:38:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_48.6953.pt
2024-07-17 05:38:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_51.5273.pt', 'checkpoint_score_54.5195.pt', 'checkpoint_score_57.1328.pt', 'checkpoint_score_58.5352.pt', 'checkpoint_score_60.9609.pt']
2024-07-17 05:39:02 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:39:04 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:39:05 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:39:08 - [34m[1mLOGS   [0m - Training checkpoint for epoch 64/iteration 7285 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_64_iter_7285.pt
2024-07-17 05:39:09 - [34m[1mLOGS   [0m - Model state for epoch 64/iteration 7285 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_64_iter_7285.pt
[31m===========================================================================[0m
2024-07-17 05:39:11 - [32m[1mINFO   [0m - Training epoch 65
2024-07-17 05:39:12 - [34m[1mLOGS   [0m - Epoch:  65 [    7286/10000000], loss: {'classification': 2.4528, 'neural_augmentation': 0.4821, 'total_loss': 2.9349}, LR: [1.5e-05, 1.5e-05], Avg. batch load time: 1.030, Elapsed time:  1.25
2024-07-17 05:39:37 - [34m[1mLOGS   [0m - *** Training summary for epoch 65
	 loss={'classification': 2.4704, 'neural_augmentation': 0.4758, 'total_loss': 2.9462}
2024-07-17 05:39:45 - [33m[1mWARNING[0m - Found recall at precision 0.5163934426229508 when recall at precision 0.5 was requested.
2024-07-17 05:39:47 - [34m[1mLOGS   [0m - *** Validation summary for epoch 65
	 loss={'classification': 1.523, 'neural_augmentation': 0.0, 'total_loss': 1.523} || top1={'logits': 63.582} || top5={'logits': 87.8711} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.3898, 0.6469, 0.5952, 0.7799, 0.6667, 0.6055, 0.7815, 0.8132, 0.3287, 0.3716, 0.5115, 0.6926, 0.4798, 0.5356, 0.6726, 0.5455, 0.4618, 0.4575, 0.5, 0.6793, 0.7876, 0.5726, 0.3633, 0.6728, 0.7403, 0.7489, 0.4566, 0.7633, 0.6256, 0.591, 0.7465, 0.4277, 0.8414, 0.9735, 0.7086, 0.7093, 0.6652, 0.3609, 0.5397, 0.3589, 0.6851, 0.6639, 0.543, 0.6195, 0.8051, 0.6228, 0.638, 0.3988, 0.7061, 0.5, 0.4286, 0.7556, 0.6566, 0.4817, 0.8805, 0.6185, 0.3663, 0.4662, 0.3317, 0.4601, 0.7243, 0.839, 0.6504, 0.8217, 0.7373, 0.7724, 0.5011, 0.4542, 0.7168, 0.9068, 0.8406, 0.6559, 0.6652, 0.414, 0.5986, 0.8429, 0.7186, 0.3295, 0.7409, 0.7245, 0.6043, 0.5783, 0.3434, 0.8206, 0.4588, 0.4415, 0.8049, 0.4276, 0.8255, 0.5638, 0.8323, 0.8637, 0.5607, 0.4131, 0.674, 0.6995, 0.499, 0.6316, 0.6035, 0.4933, 0.6014], 'AP': [0.3294, 0.7107, 0.6218, 0.8402, 0.7069, 0.6265, 0.8174, 0.8646, 0.2559, 0.2693, 0.4993, 0.7629, 0.4977, 0.5575, 0.7245, 0.5586, 0.4234, 0.438, 0.4511, 0.7047, 0.8066, 0.6002, 0.258, 0.7202, 0.7769, 0.8204, 0.413, 0.8255, 0.6733, 0.5917, 0.7717, 0.3842, 0.8714, 0.9928, 0.7655, 0.7401, 0.6798, 0.2909, 0.5721, 0.3241, 0.7455, 0.693, 0.5519, 0.6619, 0.8361, 0.6711, 0.6536, 0.3689, 0.7596, 0.4865, 0.3948, 0.8356, 0.6827, 0.4544, 0.9241, 0.6387, 0.3223, 0.4011, 0.2931, 0.4269, 0.7756, 0.8868, 0.6602, 0.8886, 0.7771, 0.8095, 0.5205, 0.4555, 0.7749, 0.9327, 0.8894, 0.6815, 0.6944, 0.3788, 0.6192, 0.9068, 0.7808, 0.2264, 0.7911, 0.7518, 0.6382, 0.6065, 0.2602, 0.855, 0.47, 0.4008, 0.8659, 0.3456, 0.8767, 0.5665, 0.9033, 0.9276, 0.5147, 0.3269, 0.717, 0.7507, 0.4844, 0.6513, 0.6298, 0.447, 0.6335], 'Recall@P=50': [0.1818, 0.7587, 0.604, 0.876, 0.744, 0.684, 0.86, 0.88, 0.028, 0.124, 0.5, 0.832, 0.452, 0.56, 0.772, 0.588, 0.416, 0.396, 0.488, 0.752, 0.84, 0.628, 0.004, 0.724, 0.816, 0.872, 0.336, 0.868, 0.744, 0.612, 0.772, 0.324, 0.892, 0.996, 0.82, 0.76, 0.712, 0.036, 0.576, 0.224, 0.792, 0.736, 0.004, 0.728, 0.856, 0.708, 0.668, 0.256, 0.804, 0.476, 0.292, 0.872, 0.716, 0.46, 0.944, 0.664, 0.252, 0.428, 0.152, 0.376, 0.84, 0.908, 0.692, 0.904, 0.788, 0.852, 0.472, 0.392, 0.864, 0.936, 0.92, 0.74, 0.7, 0.344, 0.616, 0.956, 0.856, 0.004, 0.8, 0.796, 0.696, 0.576, 0.056, 0.892, 0.42, 0.316, 0.92, 0.008, 0.904, 0.604, 0.944, 0.952, 0.608, 0.1, 0.78, 0.748, 0.48, 0.636, 0.62, 0.472, 0.636], 'micro': 0.631, 'macro': 0.6279, 'weighted': 0.6252}
2024-07-17 05:39:51 - [34m[1mLOGS   [0m - Best checkpoint with score 63.58 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:39:53 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_51.5273.pt
2024-07-17 05:39:53 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_54.5195.pt', 'checkpoint_score_57.1328.pt', 'checkpoint_score_58.5352.pt', 'checkpoint_score_60.9609.pt', 'checkpoint_score_63.5820.pt']
2024-07-17 05:39:58 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:40:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:40:02 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:40:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 65/iteration 7404 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_65_iter_7404.pt
2024-07-17 05:40:06 - [34m[1mLOGS   [0m - Model state for epoch 65/iteration 7404 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_65_iter_7404.pt
[31m===========================================================================[0m
2024-07-17 05:40:08 - [32m[1mINFO   [0m - Training epoch 66
2024-07-17 05:40:09 - [34m[1mLOGS   [0m - Epoch:  66 [    7405/10000000], loss: {'classification': 2.3992, 'neural_augmentation': 0.4792, 'total_loss': 2.8784}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 0.946, Elapsed time:  1.16
2024-07-17 05:40:31 - [34m[1mLOGS   [0m - *** Training summary for epoch 66
	 loss={'classification': 2.4178, 'neural_augmentation': 0.4886, 'total_loss': 2.9064}
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.5238095238095238 when recall at precision 0.5 was requested.
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.5205479452054794 when recall at precision 0.5 was requested.
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.5333333333333333 when recall at precision 0.5 was requested.
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.5171428571428571 when recall at precision 0.5 was requested.
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.515358361774744 when recall at precision 0.5 was requested.
2024-07-17 05:40:39 - [33m[1mWARNING[0m - Found recall at precision 0.5172413793103449 when recall at precision 0.5 was requested.
2024-07-17 05:40:41 - [34m[1mLOGS   [0m - *** Validation summary for epoch 66
	 loss={'classification': 1.4513, 'neural_augmentation': 0.0, 'total_loss': 1.4513} || top1={'logits': 65.4102} || top5={'logits': 88.793} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4204, 0.6595, 0.6313, 0.7852, 0.6926, 0.6358, 0.7919, 0.8319, 0.3249, 0.4262, 0.5389, 0.6883, 0.4551, 0.5703, 0.678, 0.5714, 0.5196, 0.4887, 0.5, 0.6846, 0.7877, 0.5914, 0.3856, 0.6947, 0.759, 0.7689, 0.4806, 0.7735, 0.6503, 0.6022, 0.7819, 0.4484, 0.8491, 0.9736, 0.7361, 0.7366, 0.6695, 0.3777, 0.5543, 0.3881, 0.6979, 0.6838, 0.563, 0.6532, 0.7892, 0.6614, 0.6473, 0.4398, 0.7158, 0.5353, 0.4405, 0.7783, 0.7041, 0.5208, 0.9004, 0.6513, 0.4073, 0.5057, 0.3521, 0.489, 0.7505, 0.8417, 0.6652, 0.8473, 0.7666, 0.8049, 0.5588, 0.5083, 0.7377, 0.9061, 0.843, 0.6585, 0.6904, 0.424, 0.5972, 0.8361, 0.7382, 0.3275, 0.7547, 0.7195, 0.6131, 0.6089, 0.3626, 0.8245, 0.4848, 0.4714, 0.8238, 0.4468, 0.8178, 0.5794, 0.8525, 0.8798, 0.6167, 0.4167, 0.6795, 0.7206, 0.5338, 0.655, 0.6126, 0.5251, 0.6457], 'AP': [0.3608, 0.7156, 0.6664, 0.8428, 0.7224, 0.6671, 0.8212, 0.883, 0.2547, 0.3162, 0.5357, 0.7636, 0.456, 0.6121, 0.7231, 0.5899, 0.5064, 0.4698, 0.4558, 0.7198, 0.8081, 0.6305, 0.2686, 0.7247, 0.7919, 0.8492, 0.4524, 0.8273, 0.7103, 0.6219, 0.815, 0.4263, 0.8775, 0.9933, 0.8039, 0.768, 0.689, 0.3035, 0.5846, 0.3565, 0.7515, 0.7125, 0.5767, 0.702, 0.8343, 0.7125, 0.6685, 0.4253, 0.7634, 0.5067, 0.4124, 0.8677, 0.7085, 0.4948, 0.9328, 0.7014, 0.3681, 0.4602, 0.3087, 0.4608, 0.8042, 0.8966, 0.6871, 0.8999, 0.8089, 0.8355, 0.5826, 0.5018, 0.8056, 0.9326, 0.8988, 0.696, 0.7224, 0.4054, 0.6316, 0.9089, 0.7946, 0.2473, 0.8043, 0.7596, 0.6527, 0.6639, 0.2961, 0.8614, 0.5172, 0.4442, 0.8767, 0.3917, 0.8807, 0.5883, 0.9098, 0.9399, 0.5761, 0.3301, 0.7205, 0.7758, 0.5306, 0.6888, 0.6393, 0.479, 0.6723], 'Recall@P=50': [0.2925, 0.7529, 0.664, 0.884, 0.772, 0.736, 0.888, 0.908, 0.072, 0.004, 0.568, 0.82, 0.396, 0.616, 0.76, 0.628, 0.48, 0.476, 0.456, 0.776, 0.852, 0.648, 0.016, 0.748, 0.84, 0.912, 0.4, 0.86, 0.772, 0.636, 0.824, 0.4, 0.892, 0.996, 0.868, 0.788, 0.748, 0.004, 0.604, 0.256, 0.776, 0.752, 0.592, 0.756, 0.86, 0.736, 0.684, 0.36, 0.82, 0.536, 0.392, 0.924, 0.724, 0.524, 0.952, 0.72, 0.268, 0.484, 0.172, 0.46, 0.856, 0.912, 0.72, 0.912, 0.836, 0.876, 0.604, 0.516, 0.888, 0.94, 0.928, 0.748, 0.744, 0.316, 0.632, 0.956, 0.848, 0.004, 0.836, 0.8, 0.692, 0.644, 0.18, 0.9, 0.436, 0.4, 0.932, 0.392, 0.912, 0.628, 0.94, 0.964, 0.66, 0.004, 0.796, 0.812, 0.512, 0.696, 0.62, 0.544, 0.66], 'micro': 0.6572, 'macro': 0.6516, 'weighted': 0.6489}
2024-07-17 05:40:46 - [34m[1mLOGS   [0m - Best checkpoint with score 65.41 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:40:47 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_54.5195.pt
2024-07-17 05:40:47 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_57.1328.pt', 'checkpoint_score_58.5352.pt', 'checkpoint_score_60.9609.pt', 'checkpoint_score_63.5820.pt', 'checkpoint_score_65.4102.pt']
2024-07-17 05:40:52 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:40:55 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:40:56 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:40:59 - [34m[1mLOGS   [0m - Training checkpoint for epoch 66/iteration 7510 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_66_iter_7510.pt
2024-07-17 05:41:00 - [34m[1mLOGS   [0m - Model state for epoch 66/iteration 7510 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_66_iter_7510.pt
[31m===========================================================================[0m
2024-07-17 05:41:02 - [32m[1mINFO   [0m - Training epoch 67
2024-07-17 05:41:03 - [34m[1mLOGS   [0m - Epoch:  67 [    7511/10000000], loss: {'classification': 2.5023, 'neural_augmentation': 0.5024, 'total_loss': 3.0047}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 0.645, Elapsed time:  0.88
2024-07-17 05:41:26 - [34m[1mLOGS   [0m - *** Training summary for epoch 67
	 loss={'classification': 2.3572, 'neural_augmentation': 0.5011, 'total_loss': 2.8583}
2024-07-17 05:41:35 - [33m[1mWARNING[0m - Found recall at precision 0.516320474777448 when recall at precision 0.5 was requested.
2024-07-17 05:41:35 - [33m[1mWARNING[0m - Found recall at precision 0.5166666666666667 when recall at precision 0.5 was requested.
2024-07-17 05:41:37 - [34m[1mLOGS   [0m - *** Validation summary for epoch 67
	 loss={'classification': 1.3694, 'neural_augmentation': 0.0, 'total_loss': 1.3694} || top1={'logits': 67.2773} || top5={'logits': 89.918} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.442, 0.6748, 0.6575, 0.793, 0.6872, 0.6499, 0.8018, 0.8362, 0.3646, 0.4346, 0.5618, 0.7129, 0.5339, 0.5875, 0.7174, 0.5756, 0.5684, 0.5096, 0.5046, 0.7073, 0.8033, 0.5833, 0.4012, 0.7235, 0.7674, 0.7761, 0.5088, 0.7975, 0.6736, 0.6652, 0.8042, 0.473, 0.8516, 0.9741, 0.7573, 0.7455, 0.6637, 0.3861, 0.6365, 0.4053, 0.738, 0.7196, 0.6232, 0.6858, 0.806, 0.7318, 0.6482, 0.4701, 0.7193, 0.5389, 0.4811, 0.7857, 0.7042, 0.5305, 0.8976, 0.6681, 0.406, 0.5203, 0.3953, 0.513, 0.7578, 0.851, 0.6728, 0.8577, 0.7652, 0.81, 0.5808, 0.5391, 0.7722, 0.9184, 0.8697, 0.6861, 0.7216, 0.4517, 0.6089, 0.8491, 0.7418, 0.3481, 0.7948, 0.7434, 0.6411, 0.6112, 0.3862, 0.825, 0.5368, 0.5214, 0.8288, 0.4856, 0.8182, 0.6112, 0.8787, 0.8994, 0.6285, 0.422, 0.7082, 0.7098, 0.5338, 0.6795, 0.6205, 0.5322, 0.6898], 'AP': [0.3932, 0.7478, 0.6995, 0.8586, 0.7361, 0.6858, 0.8261, 0.8788, 0.292, 0.3346, 0.5593, 0.7807, 0.5587, 0.6503, 0.7586, 0.6009, 0.5836, 0.4977, 0.4814, 0.7222, 0.8327, 0.6246, 0.2834, 0.7641, 0.8089, 0.8496, 0.4845, 0.8507, 0.7247, 0.6826, 0.8332, 0.4636, 0.8858, 0.9937, 0.8186, 0.7896, 0.6935, 0.3226, 0.6833, 0.3767, 0.7928, 0.7492, 0.6454, 0.7389, 0.8425, 0.768, 0.6742, 0.4494, 0.7723, 0.53, 0.4595, 0.8638, 0.7357, 0.5146, 0.9404, 0.7188, 0.3738, 0.4812, 0.3523, 0.493, 0.8106, 0.8998, 0.7093, 0.9039, 0.8126, 0.8347, 0.6035, 0.5217, 0.823, 0.9442, 0.9224, 0.7331, 0.7642, 0.429, 0.6443, 0.9135, 0.8001, 0.2705, 0.8328, 0.7789, 0.6889, 0.6715, 0.3066, 0.8669, 0.5632, 0.4826, 0.8789, 0.412, 0.8803, 0.6289, 0.9239, 0.9469, 0.5945, 0.3411, 0.7413, 0.7775, 0.5529, 0.7067, 0.665, 0.5042, 0.7262], 'Recall@P=50': [0.3241, 0.7703, 0.724, 0.888, 0.796, 0.752, 0.884, 0.9, 0.024, 0.224, 0.6, 0.828, 0.536, 0.652, 0.78, 0.62, 0.612, 0.488, 0.504, 0.788, 0.884, 0.644, 0.008, 0.784, 0.848, 0.912, 0.456, 0.896, 0.772, 0.716, 0.844, 0.424, 0.9, 0.996, 0.88, 0.812, 0.752, 0.004, 0.72, 0.26, 0.824, 0.804, 0.74, 0.752, 0.856, 0.812, 0.696, 0.416, 0.824, 0.56, 0.448, 0.928, 0.768, 0.004, 0.96, 0.74, 0.28, 0.512, 0.24, 0.496, 0.852, 0.924, 0.744, 0.916, 0.844, 0.872, 0.632, 0.004, 0.908, 0.948, 0.944, 0.776, 0.796, 0.36, 0.68, 0.956, 0.876, 0.072, 0.852, 0.808, 0.744, 0.7, 0.124, 0.9, 0.552, 0.544, 0.936, 0.412, 0.912, 0.636, 0.948, 0.968, 0.672, 0.124, 0.808, 0.796, 0.556, 0.684, 0.68, 0.54, 0.724], 'micro': 0.6759, 'macro': 0.6745, 'weighted': 0.6719}
2024-07-17 05:41:41 - [34m[1mLOGS   [0m - Best checkpoint with score 67.28 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:41:42 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_57.1328.pt
2024-07-17 05:41:42 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_58.5352.pt', 'checkpoint_score_60.9609.pt', 'checkpoint_score_63.5820.pt', 'checkpoint_score_65.4102.pt', 'checkpoint_score_67.2773.pt']
2024-07-17 05:41:48 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:41:51 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:41:52 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:41:55 - [34m[1mLOGS   [0m - Training checkpoint for epoch 67/iteration 7624 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_67_iter_7624.pt
2024-07-17 05:41:56 - [34m[1mLOGS   [0m - Model state for epoch 67/iteration 7624 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_67_iter_7624.pt
[31m===========================================================================[0m
2024-07-17 05:41:58 - [32m[1mINFO   [0m - Training epoch 68
2024-07-17 05:41:58 - [34m[1mLOGS   [0m - Epoch:  68 [    7625/10000000], loss: {'classification': 2.2328, 'neural_augmentation': 0.5174, 'total_loss': 2.7502}, LR: [1.4e-05, 1.4e-05], Avg. batch load time: 0.331, Elapsed time:  0.55
2024-07-17 05:42:21 - [34m[1mLOGS   [0m - *** Training summary for epoch 68
	 loss={'classification': 2.3085, 'neural_augmentation': 0.5135, 'total_loss': 2.822}
2024-07-17 05:42:29 - [33m[1mWARNING[0m - Found recall at precision 0.5205479452054794 when recall at precision 0.5 was requested.
2024-07-17 05:42:30 - [33m[1mWARNING[0m - Found recall at precision 0.5208333333333334 when recall at precision 0.5 was requested.
2024-07-17 05:42:32 - [34m[1mLOGS   [0m - *** Validation summary for epoch 68
	 loss={'classification': 1.3126, 'neural_augmentation': 0.0, 'total_loss': 1.3126} || top1={'logits': 68.6992} || top5={'logits': 90.5352} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4374, 0.6917, 0.654, 0.8052, 0.6989, 0.654, 0.8106, 0.8369, 0.3707, 0.4348, 0.5757, 0.7284, 0.5251, 0.6072, 0.7304, 0.6052, 0.5982, 0.5096, 0.5185, 0.7122, 0.8125, 0.5909, 0.4072, 0.7129, 0.7823, 0.7824, 0.5222, 0.8048, 0.6834, 0.6794, 0.8009, 0.4945, 0.8595, 0.9801, 0.7615, 0.7569, 0.6917, 0.3905, 0.6486, 0.4291, 0.7343, 0.7261, 0.6193, 0.6969, 0.7883, 0.7426, 0.6682, 0.4939, 0.7311, 0.5479, 0.5031, 0.7939, 0.7176, 0.5431, 0.8971, 0.709, 0.4069, 0.5265, 0.415, 0.5165, 0.7719, 0.8559, 0.6958, 0.8627, 0.7811, 0.8118, 0.6106, 0.566, 0.7755, 0.9148, 0.8708, 0.6947, 0.7377, 0.4641, 0.6239, 0.845, 0.7719, 0.3544, 0.8051, 0.7489, 0.6475, 0.6244, 0.3954, 0.8337, 0.554, 0.5219, 0.8394, 0.499, 0.8323, 0.6295, 0.8808, 0.898, 0.6477, 0.4298, 0.7202, 0.7294, 0.5445, 0.6915, 0.6455, 0.5357, 0.7206], 'AP': [0.3953, 0.7533, 0.7158, 0.8701, 0.7563, 0.7016, 0.8214, 0.9014, 0.2946, 0.3536, 0.5792, 0.7943, 0.5495, 0.6727, 0.7754, 0.6238, 0.6164, 0.4978, 0.4924, 0.7365, 0.8452, 0.6375, 0.303, 0.7526, 0.8174, 0.8599, 0.5246, 0.8544, 0.751, 0.7135, 0.8421, 0.5095, 0.8877, 0.9949, 0.8245, 0.7999, 0.7259, 0.338, 0.7087, 0.3908, 0.7861, 0.7494, 0.6574, 0.7396, 0.8247, 0.8033, 0.6874, 0.4852, 0.7932, 0.5411, 0.4844, 0.8746, 0.7408, 0.5429, 0.9423, 0.7435, 0.3938, 0.5008, 0.3881, 0.5024, 0.8251, 0.9104, 0.7285, 0.9073, 0.8351, 0.84, 0.639, 0.5614, 0.8323, 0.9437, 0.9181, 0.7216, 0.7793, 0.4427, 0.673, 0.9155, 0.8246, 0.2831, 0.843, 0.7884, 0.6989, 0.6947, 0.3571, 0.8743, 0.5779, 0.491, 0.8906, 0.4384, 0.8884, 0.6478, 0.9322, 0.9467, 0.6125, 0.354, 0.7711, 0.7858, 0.5755, 0.738, 0.6846, 0.5284, 0.7443], 'Recall@P=50': [0.3617, 0.7849, 0.752, 0.888, 0.812, 0.768, 0.88, 0.916, 0.192, 0.324, 0.6, 0.864, 0.528, 0.676, 0.82, 0.648, 0.62, 0.512, 0.484, 0.78, 0.872, 0.68, 0.04, 0.784, 0.86, 0.928, 0.524, 0.892, 0.808, 0.732, 0.864, 0.456, 0.912, 0.996, 0.888, 0.828, 0.788, 0.004, 0.74, 0.296, 0.84, 0.804, 0.748, 0.772, 0.844, 0.844, 0.708, 0.484, 0.852, 0.572, 0.488, 0.936, 0.764, 0.004, 0.96, 0.796, 0.324, 0.52, 0.292, 0.512, 0.864, 0.952, 0.752, 0.92, 0.856, 0.88, 0.692, 0.592, 0.9, 0.956, 0.944, 0.78, 0.82, 0.4, 0.692, 0.96, 0.892, 0.104, 0.872, 0.836, 0.78, 0.744, 0.288, 0.904, 0.544, 0.532, 0.94, 0.456, 0.912, 0.668, 0.948, 0.96, 0.688, 0.096, 0.828, 0.812, 0.58, 0.76, 0.704, 0.568, 0.72], 'micro': 0.6932, 'macro': 0.6892, 'weighted': 0.6865}
2024-07-17 05:42:35 - [34m[1mLOGS   [0m - Best checkpoint with score 68.70 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:42:37 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_58.5352.pt
2024-07-17 05:42:37 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_60.9609.pt', 'checkpoint_score_63.5820.pt', 'checkpoint_score_65.4102.pt', 'checkpoint_score_67.2773.pt', 'checkpoint_score_68.6992.pt']
2024-07-17 05:42:43 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:42:46 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:42:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:42:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 68/iteration 7730 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_68_iter_7730.pt
2024-07-17 05:42:51 - [34m[1mLOGS   [0m - Model state for epoch 68/iteration 7730 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_68_iter_7730.pt
[31m===========================================================================[0m
2024-07-17 05:42:53 - [32m[1mINFO   [0m - Training epoch 69
2024-07-17 05:42:53 - [34m[1mLOGS   [0m - Epoch:  69 [    7731/10000000], loss: {'classification': 2.1653, 'neural_augmentation': 0.5282, 'total_loss': 2.6935}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 0.448, Elapsed time:  0.67
2024-07-17 05:43:16 - [34m[1mLOGS   [0m - *** Training summary for epoch 69
	 loss={'classification': 2.2535, 'neural_augmentation': 0.5256, 'total_loss': 2.7791}
2024-07-17 05:43:24 - [33m[1mWARNING[0m - Found recall at precision 0.52 when recall at precision 0.5 was requested.
2024-07-17 05:43:27 - [34m[1mLOGS   [0m - *** Validation summary for epoch 69
	 loss={'classification': 1.2506, 'neural_augmentation': 0.0, 'total_loss': 1.2506} || top1={'logits': 70.2578} || top5={'logits': 91.1016} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4639, 0.693, 0.6915, 0.818, 0.7205, 0.6724, 0.8137, 0.8491, 0.3972, 0.4606, 0.6069, 0.7459, 0.5776, 0.6355, 0.7364, 0.6124, 0.6414, 0.5269, 0.5434, 0.7089, 0.8312, 0.6063, 0.4281, 0.72, 0.7942, 0.7948, 0.5392, 0.8121, 0.6926, 0.6867, 0.8118, 0.5224, 0.8649, 0.9858, 0.7728, 0.7957, 0.7156, 0.3921, 0.714, 0.4044, 0.7689, 0.7379, 0.6282, 0.6892, 0.8207, 0.7427, 0.6743, 0.4906, 0.7494, 0.5643, 0.5217, 0.8132, 0.7457, 0.5651, 0.9065, 0.7265, 0.45, 0.5405, 0.4312, 0.5283, 0.7778, 0.86, 0.7322, 0.8753, 0.795, 0.8204, 0.6236, 0.5568, 0.7886, 0.9197, 0.8589, 0.7146, 0.7709, 0.4844, 0.6374, 0.8486, 0.7794, 0.3679, 0.8217, 0.7682, 0.6746, 0.6172, 0.4104, 0.8295, 0.5444, 0.5299, 0.8414, 0.4794, 0.8518, 0.6525, 0.8954, 0.8963, 0.654, 0.4293, 0.716, 0.75, 0.5778, 0.7181, 0.6637, 0.5425, 0.7371], 'AP': [0.4374, 0.7615, 0.75, 0.8825, 0.7762, 0.711, 0.8293, 0.9025, 0.3096, 0.3982, 0.6069, 0.804, 0.6089, 0.71, 0.7841, 0.6411, 0.6702, 0.5167, 0.5397, 0.7481, 0.8675, 0.648, 0.3129, 0.7628, 0.8414, 0.8728, 0.5288, 0.8661, 0.764, 0.7317, 0.8548, 0.5434, 0.8971, 0.9959, 0.8274, 0.8242, 0.7419, 0.3392, 0.7644, 0.3834, 0.8154, 0.7755, 0.6706, 0.7548, 0.8419, 0.8039, 0.6985, 0.4863, 0.81, 0.5681, 0.5066, 0.9022, 0.7758, 0.5746, 0.9498, 0.763, 0.4265, 0.5335, 0.4096, 0.5214, 0.8394, 0.9201, 0.7584, 0.9188, 0.8502, 0.8505, 0.6462, 0.5576, 0.8406, 0.9489, 0.9207, 0.7508, 0.8081, 0.4635, 0.6827, 0.9171, 0.8356, 0.2935, 0.859, 0.7988, 0.7281, 0.6841, 0.3387, 0.8758, 0.5661, 0.5267, 0.8966, 0.4499, 0.9019, 0.6839, 0.9414, 0.95, 0.64, 0.3744, 0.7696, 0.8055, 0.5984, 0.7557, 0.6996, 0.5421, 0.7739], 'Recall@P=50': [0.4091, 0.7791, 0.772, 0.912, 0.804, 0.78, 0.884, 0.932, 0.008, 0.412, 0.68, 0.856, 0.612, 0.744, 0.812, 0.652, 0.696, 0.548, 0.528, 0.804, 0.896, 0.708, 0.052, 0.78, 0.864, 0.932, 0.564, 0.904, 0.868, 0.784, 0.864, 0.516, 0.916, 0.996, 0.876, 0.836, 0.792, 0.16, 0.804, 0.296, 0.86, 0.824, 0.756, 0.808, 0.856, 0.844, 0.704, 0.46, 0.868, 0.576, 0.484, 0.948, 0.82, 0.632, 0.96, 0.812, 0.376, 0.564, 0.376, 0.56, 0.872, 0.952, 0.792, 0.936, 0.88, 0.884, 0.724, 0.544, 0.916, 0.956, 0.952, 0.808, 0.828, 0.424, 0.688, 0.956, 0.88, 0.004, 0.876, 0.852, 0.792, 0.74, 0.184, 0.912, 0.56, 0.548, 0.948, 0.432, 0.92, 0.72, 0.948, 0.964, 0.716, 0.24, 0.812, 0.82, 0.612, 0.76, 0.732, 0.556, 0.78], 'micro': 0.7126, 'macro': 0.706, 'weighted': 0.7035}
2024-07-17 05:43:31 - [34m[1mLOGS   [0m - Best checkpoint with score 70.26 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:43:32 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_60.9609.pt
2024-07-17 05:43:32 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_63.5820.pt', 'checkpoint_score_65.4102.pt', 'checkpoint_score_67.2773.pt', 'checkpoint_score_68.6992.pt', 'checkpoint_score_70.2578.pt']
2024-07-17 05:43:37 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:43:40 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:43:41 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:43:44 - [34m[1mLOGS   [0m - Training checkpoint for epoch 69/iteration 7838 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_69_iter_7838.pt
2024-07-17 05:43:45 - [34m[1mLOGS   [0m - Model state for epoch 69/iteration 7838 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_69_iter_7838.pt
[31m===========================================================================[0m
2024-07-17 05:43:47 - [32m[1mINFO   [0m - Training epoch 70
2024-07-17 05:43:48 - [34m[1mLOGS   [0m - Epoch:  70 [    7839/10000000], loss: {'classification': 2.2352, 'neural_augmentation': 0.5362, 'total_loss': 2.7714}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 0.382, Elapsed time:  0.59
2024-07-17 05:44:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 70
	 loss={'classification': 2.2181, 'neural_augmentation': 0.5375, 'total_loss': 2.7556}
2024-07-17 05:44:17 - [33m[1mWARNING[0m - Found recall at precision 0.5154320987654321 when recall at precision 0.5 was requested.
2024-07-17 05:44:18 - [33m[1mWARNING[0m - Found recall at precision 0.5217391304347826 when recall at precision 0.5 was requested.
2024-07-17 05:44:18 - [33m[1mWARNING[0m - Found recall at precision 0.5155709342560554 when recall at precision 0.5 was requested.
2024-07-17 05:44:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 70
	 loss={'classification': 1.1917, 'neural_augmentation': 0.0, 'total_loss': 1.1917} || top1={'logits': 71.8359} || top5={'logits': 91.8125} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4773, 0.7088, 0.7375, 0.8246, 0.7202, 0.6736, 0.8114, 0.8602, 0.4211, 0.501, 0.6161, 0.7545, 0.5991, 0.6446, 0.7534, 0.6314, 0.6636, 0.5241, 0.5511, 0.7173, 0.8341, 0.6186, 0.434, 0.7364, 0.7919, 0.8033, 0.569, 0.8276, 0.7054, 0.7119, 0.8403, 0.5506, 0.8697, 0.9841, 0.7991, 0.7905, 0.7328, 0.4233, 0.7619, 0.4364, 0.7582, 0.7453, 0.6519, 0.6975, 0.8083, 0.7519, 0.6921, 0.5265, 0.752, 0.5726, 0.5431, 0.8069, 0.7534, 0.6025, 0.9155, 0.7485, 0.4741, 0.5649, 0.4615, 0.5672, 0.7908, 0.8677, 0.7257, 0.8822, 0.7908, 0.8282, 0.6281, 0.5917, 0.8102, 0.9281, 0.8842, 0.7368, 0.7983, 0.5059, 0.6824, 0.8641, 0.7866, 0.3924, 0.8351, 0.7604, 0.6864, 0.6608, 0.434, 0.8447, 0.5874, 0.5534, 0.8434, 0.5273, 0.8512, 0.6738, 0.8968, 0.9342, 0.6583, 0.4511, 0.7227, 0.773, 0.5733, 0.7344, 0.6799, 0.5804, 0.7699], 'AP': [0.4623, 0.7718, 0.7796, 0.8836, 0.7799, 0.7046, 0.8432, 0.9176, 0.3531, 0.4395, 0.6322, 0.8199, 0.6448, 0.7208, 0.7964, 0.6584, 0.6932, 0.5317, 0.5507, 0.755, 0.8843, 0.6592, 0.3253, 0.7897, 0.8429, 0.8815, 0.5702, 0.8772, 0.7812, 0.746, 0.8681, 0.5766, 0.8986, 0.9957, 0.8561, 0.8242, 0.7565, 0.3806, 0.803, 0.4158, 0.8121, 0.787, 0.6983, 0.7544, 0.8416, 0.8285, 0.7193, 0.5279, 0.8108, 0.5816, 0.5355, 0.8984, 0.7878, 0.6254, 0.9522, 0.7851, 0.4619, 0.5687, 0.4426, 0.5693, 0.8427, 0.9269, 0.7544, 0.923, 0.853, 0.8588, 0.671, 0.5995, 0.8618, 0.9507, 0.9292, 0.7866, 0.8278, 0.4792, 0.7147, 0.9234, 0.8522, 0.3318, 0.8685, 0.8032, 0.7526, 0.7234, 0.3753, 0.8777, 0.621, 0.5662, 0.9047, 0.5507, 0.9033, 0.7092, 0.9454, 0.9588, 0.6638, 0.3698, 0.7817, 0.8251, 0.6149, 0.7925, 0.7164, 0.5905, 0.7985], 'Recall@P=50': [0.4466, 0.7965, 0.804, 0.912, 0.828, 0.748, 0.916, 0.944, 0.276, 0.448, 0.704, 0.864, 0.636, 0.768, 0.82, 0.668, 0.752, 0.544, 0.604, 0.816, 0.908, 0.708, 0.04, 0.804, 0.868, 0.928, 0.628, 0.908, 0.896, 0.78, 0.876, 0.556, 0.916, 0.996, 0.892, 0.848, 0.8, 0.256, 0.864, 0.344, 0.88, 0.844, 0.788, 0.8, 0.86, 0.868, 0.72, 0.528, 0.872, 0.604, 0.536, 0.944, 0.82, 0.664, 0.96, 0.812, 0.432, 0.572, 0.4, 0.628, 0.876, 0.96, 0.812, 0.948, 0.884, 0.888, 0.7, 0.644, 0.92, 0.96, 0.952, 0.824, 0.848, 0.512, 0.748, 0.956, 0.904, 0.004, 0.872, 0.84, 0.828, 0.8, 0.352, 0.908, 0.596, 0.592, 0.94, 0.548, 0.936, 0.724, 0.964, 0.968, 0.76, 0.016, 0.84, 0.836, 0.652, 0.82, 0.74, 0.656, 0.8], 'micro': 0.7303, 'macro': 0.7253, 'weighted': 0.7229}
2024-07-17 05:44:24 - [34m[1mLOGS   [0m - Best checkpoint with score 71.84 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:44:25 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_63.5820.pt
2024-07-17 05:44:25 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_65.4102.pt', 'checkpoint_score_67.2773.pt', 'checkpoint_score_68.6992.pt', 'checkpoint_score_70.2578.pt', 'checkpoint_score_71.8359.pt']
2024-07-17 05:44:31 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:44:34 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:44:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:44:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 70/iteration 7940 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_70_iter_7940.pt
2024-07-17 05:44:39 - [34m[1mLOGS   [0m - Model state for epoch 70/iteration 7940 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_70_iter_7940.pt
[31m===========================================================================[0m
2024-07-17 05:44:41 - [32m[1mINFO   [0m - Training epoch 71
2024-07-17 05:44:41 - [34m[1mLOGS   [0m - Epoch:  71 [    7941/10000000], loss: {'classification': 2.049, 'neural_augmentation': 0.5474, 'total_loss': 2.5964}, LR: [1.3e-05, 1.3e-05], Avg. batch load time: 0.672, Elapsed time:  0.89
2024-07-17 05:45:08 - [34m[1mLOGS   [0m - *** Training summary for epoch 71
	 loss={'classification': 2.1522, 'neural_augmentation': 0.5503, 'total_loss': 2.7025}
2024-07-17 05:45:19 - [34m[1mLOGS   [0m - *** Validation summary for epoch 71
	 loss={'classification': 1.1445, 'neural_augmentation': 0.0, 'total_loss': 1.1445} || top1={'logits': 72.6445} || top5={'logits': 92.3242} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.481, 0.7276, 0.7273, 0.8482, 0.7381, 0.6753, 0.819, 0.8705, 0.4279, 0.4895, 0.6337, 0.7563, 0.6245, 0.6667, 0.7763, 0.636, 0.7195, 0.5504, 0.5656, 0.7106, 0.838, 0.626, 0.4502, 0.7419, 0.8052, 0.8165, 0.5683, 0.8306, 0.7212, 0.7489, 0.851, 0.5739, 0.8655, 0.986, 0.8131, 0.7946, 0.7313, 0.4226, 0.7712, 0.4547, 0.7667, 0.7571, 0.6721, 0.7051, 0.8238, 0.778, 0.6964, 0.515, 0.7556, 0.5882, 0.5499, 0.8102, 0.7826, 0.6038, 0.9202, 0.7725, 0.4725, 0.5652, 0.5142, 0.5574, 0.7886, 0.8831, 0.7289, 0.8951, 0.8101, 0.826, 0.6396, 0.5846, 0.8313, 0.9256, 0.887, 0.7458, 0.8066, 0.5182, 0.6921, 0.8602, 0.8057, 0.3846, 0.8354, 0.7668, 0.7078, 0.6799, 0.4642, 0.8522, 0.6242, 0.5741, 0.86, 0.5499, 0.8477, 0.6682, 0.9158, 0.925, 0.659, 0.4322, 0.7381, 0.7841, 0.5859, 0.7333, 0.6801, 0.5818, 0.758], 'AP': [0.4788, 0.7931, 0.7846, 0.895, 0.7891, 0.7188, 0.8456, 0.9203, 0.368, 0.4359, 0.6551, 0.8244, 0.6667, 0.7485, 0.8123, 0.6727, 0.7636, 0.5608, 0.5785, 0.7577, 0.8822, 0.6758, 0.3524, 0.7909, 0.8515, 0.8842, 0.5834, 0.8829, 0.8021, 0.7897, 0.8862, 0.6042, 0.8998, 0.9952, 0.8598, 0.8285, 0.7623, 0.3679, 0.823, 0.4355, 0.8246, 0.7989, 0.7251, 0.7721, 0.8522, 0.8642, 0.7229, 0.5207, 0.821, 0.6093, 0.5516, 0.891, 0.8003, 0.6255, 0.9534, 0.8123, 0.4608, 0.5713, 0.518, 0.5622, 0.8535, 0.9303, 0.7647, 0.9295, 0.8637, 0.8585, 0.6809, 0.591, 0.8721, 0.952, 0.9341, 0.7843, 0.8395, 0.5023, 0.7328, 0.9232, 0.8615, 0.3246, 0.8773, 0.8134, 0.7616, 0.7387, 0.4006, 0.8915, 0.6478, 0.5821, 0.905, 0.5618, 0.8977, 0.7275, 0.9517, 0.9584, 0.6839, 0.3748, 0.8018, 0.8186, 0.6291, 0.7978, 0.728, 0.5999, 0.8085], 'Recall@P=50': [0.4565, 0.8169, 0.8, 0.928, 0.828, 0.772, 0.904, 0.952, 0.272, 0.464, 0.716, 0.872, 0.684, 0.78, 0.828, 0.716, 0.796, 0.564, 0.608, 0.824, 0.916, 0.724, 0.072, 0.804, 0.872, 0.928, 0.644, 0.904, 0.892, 0.84, 0.908, 0.592, 0.92, 0.996, 0.904, 0.856, 0.824, 0.244, 0.876, 0.376, 0.88, 0.852, 0.792, 0.832, 0.872, 0.924, 0.712, 0.5, 0.872, 0.596, 0.548, 0.936, 0.824, 0.004, 0.96, 0.848, 0.428, 0.616, 0.512, 0.608, 0.892, 0.956, 0.792, 0.936, 0.88, 0.892, 0.74, 0.612, 0.936, 0.964, 0.96, 0.808, 0.86, 0.516, 0.756, 0.956, 0.912, 0.164, 0.9, 0.872, 0.828, 0.8, 0.372, 0.92, 0.632, 0.632, 0.936, 0.592, 0.916, 0.756, 0.956, 0.976, 0.788, 0.136, 0.848, 0.828, 0.652, 0.812, 0.768, 0.652, 0.82], 'micro': 0.7415, 'macro': 0.737, 'weighted': 0.7347}
2024-07-17 05:45:23 - [34m[1mLOGS   [0m - Best checkpoint with score 72.64 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:45:24 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_65.4102.pt
2024-07-17 05:45:24 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_67.2773.pt', 'checkpoint_score_68.6992.pt', 'checkpoint_score_70.2578.pt', 'checkpoint_score_71.8359.pt', 'checkpoint_score_72.6445.pt']
2024-07-17 05:45:30 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:45:32 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:45:33 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:45:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 71/iteration 8067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_71_iter_8067.pt
2024-07-17 05:45:38 - [34m[1mLOGS   [0m - Model state for epoch 71/iteration 8067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_71_iter_8067.pt
[31m===========================================================================[0m
2024-07-17 05:45:40 - [32m[1mINFO   [0m - Training epoch 72
2024-07-17 05:45:41 - [34m[1mLOGS   [0m - Epoch:  72 [    8068/10000000], loss: {'classification': 2.0737, 'neural_augmentation': 0.5637, 'total_loss': 2.6374}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 1.031, Elapsed time:  1.25
2024-07-17 05:46:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 72
	 loss={'classification': 2.1184, 'neural_augmentation': 0.5622, 'total_loss': 2.6807}
2024-07-17 05:46:15 - [34m[1mLOGS   [0m - *** Validation summary for epoch 72
	 loss={'classification': 1.0952, 'neural_augmentation': 0.0, 'total_loss': 1.0952} || top1={'logits': 73.7852} || top5={'logits': 92.9297} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4893, 0.7187, 0.7445, 0.8437, 0.7444, 0.7, 0.822, 0.8758, 0.4632, 0.501, 0.6508, 0.7505, 0.6697, 0.679, 0.7794, 0.6446, 0.7364, 0.5328, 0.6123, 0.7196, 0.8436, 0.6217, 0.4757, 0.7371, 0.8162, 0.8248, 0.5756, 0.843, 0.7323, 0.754, 0.8536, 0.6141, 0.8635, 0.988, 0.8302, 0.818, 0.7568, 0.4449, 0.8068, 0.4612, 0.7835, 0.7657, 0.7049, 0.7203, 0.8341, 0.7913, 0.7022, 0.5401, 0.7565, 0.6106, 0.5538, 0.8344, 0.788, 0.6242, 0.9272, 0.783, 0.4899, 0.5832, 0.5268, 0.5742, 0.7983, 0.8822, 0.7347, 0.898, 0.8216, 0.8356, 0.64, 0.6472, 0.8254, 0.9339, 0.88, 0.7424, 0.8186, 0.5251, 0.679, 0.8776, 0.8148, 0.3911, 0.843, 0.7766, 0.711, 0.7131, 0.4589, 0.8446, 0.6177, 0.5791, 0.8594, 0.5603, 0.8671, 0.677, 0.9185, 0.9155, 0.6616, 0.4539, 0.743, 0.778, 0.6021, 0.748, 0.7036, 0.5855, 0.7733], 'AP': [0.4987, 0.7916, 0.8075, 0.8943, 0.7951, 0.7504, 0.8489, 0.9277, 0.396, 0.4671, 0.6699, 0.8187, 0.7183, 0.7667, 0.8159, 0.6866, 0.7802, 0.5535, 0.6132, 0.7656, 0.8996, 0.676, 0.3842, 0.7897, 0.8578, 0.8987, 0.5928, 0.8886, 0.8142, 0.7961, 0.8989, 0.6428, 0.904, 0.9963, 0.8664, 0.8466, 0.7767, 0.4141, 0.8389, 0.4394, 0.8355, 0.8137, 0.7469, 0.7804, 0.856, 0.8739, 0.7373, 0.5376, 0.8368, 0.6235, 0.5615, 0.9089, 0.8184, 0.6484, 0.9568, 0.817, 0.4861, 0.5983, 0.5435, 0.5783, 0.8663, 0.9362, 0.7758, 0.9324, 0.8815, 0.8767, 0.6865, 0.6414, 0.87, 0.9588, 0.9304, 0.7749, 0.8613, 0.5201, 0.7172, 0.9301, 0.8741, 0.3483, 0.8888, 0.8126, 0.7756, 0.782, 0.4129, 0.8886, 0.6551, 0.6185, 0.9119, 0.6002, 0.9149, 0.7425, 0.9491, 0.9576, 0.6828, 0.3857, 0.8163, 0.834, 0.6454, 0.8197, 0.7346, 0.6074, 0.8296], 'Recall@P=50': [0.4664, 0.8169, 0.836, 0.912, 0.848, 0.784, 0.92, 0.956, 0.312, 0.488, 0.72, 0.868, 0.772, 0.828, 0.832, 0.736, 0.828, 0.544, 0.636, 0.832, 0.92, 0.736, 0.16, 0.824, 0.888, 0.94, 0.64, 0.916, 0.896, 0.852, 0.9, 0.68, 0.924, 0.996, 0.904, 0.864, 0.816, 0.296, 0.868, 0.396, 0.88, 0.88, 0.82, 0.828, 0.864, 0.928, 0.728, 0.54, 0.884, 0.6, 0.592, 0.948, 0.872, 0.724, 0.968, 0.86, 0.452, 0.652, 0.516, 0.612, 0.904, 0.964, 0.8, 0.936, 0.9, 0.92, 0.712, 0.676, 0.936, 0.972, 0.952, 0.812, 0.88, 0.524, 0.732, 0.96, 0.916, 0.228, 0.912, 0.86, 0.848, 0.84, 0.424, 0.916, 0.632, 0.624, 0.948, 0.608, 0.936, 0.784, 0.964, 0.976, 0.784, 0.016, 0.868, 0.848, 0.656, 0.844, 0.768, 0.684, 0.836], 'micro': 0.7573, 'macro': 0.7504, 'weighted': 0.7481}
2024-07-17 05:46:19 - [34m[1mLOGS   [0m - Best checkpoint with score 73.79 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:46:20 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_67.2773.pt
2024-07-17 05:46:20 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_68.6992.pt', 'checkpoint_score_70.2578.pt', 'checkpoint_score_71.8359.pt', 'checkpoint_score_72.6445.pt', 'checkpoint_score_73.7852.pt']
2024-07-17 05:46:26 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:46:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:46:29 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:46:32 - [34m[1mLOGS   [0m - Training checkpoint for epoch 72/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_72_iter_8178.pt
2024-07-17 05:46:33 - [34m[1mLOGS   [0m - Model state for epoch 72/iteration 8178 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_72_iter_8178.pt
[31m===========================================================================[0m
2024-07-17 05:46:35 - [32m[1mINFO   [0m - Training epoch 73
2024-07-17 05:46:37 - [34m[1mLOGS   [0m - Epoch:  73 [    8179/10000000], loss: {'classification': 2.0106, 'neural_augmentation': 0.5689, 'total_loss': 2.5795}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 1.425, Elapsed time:  1.64
2024-07-17 05:47:03 - [34m[1mLOGS   [0m - *** Training summary for epoch 73
	 loss={'classification': 2.069, 'neural_augmentation': 0.5739, 'total_loss': 2.6429}
2024-07-17 05:47:11 - [33m[1mWARNING[0m - Found recall at precision 0.5155875299760192 when recall at precision 0.5 was requested.
2024-07-17 05:47:13 - [34m[1mLOGS   [0m - *** Validation summary for epoch 73
	 loss={'classification': 1.054, 'neural_augmentation': 0.0, 'total_loss': 1.054} || top1={'logits': 75.0469} || top5={'logits': 93.2422} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.4989, 0.7267, 0.7692, 0.8517, 0.7373, 0.7133, 0.827, 0.8841, 0.4713, 0.5325, 0.6723, 0.7733, 0.6506, 0.7183, 0.7832, 0.6736, 0.7393, 0.562, 0.6015, 0.7193, 0.869, 0.6292, 0.4632, 0.7643, 0.8347, 0.8285, 0.6176, 0.8463, 0.7285, 0.7865, 0.8692, 0.6247, 0.8798, 0.99, 0.8361, 0.8156, 0.7474, 0.4421, 0.8092, 0.4663, 0.8033, 0.778, 0.6918, 0.7265, 0.8186, 0.7967, 0.7172, 0.5745, 0.7689, 0.6045, 0.5688, 0.8447, 0.7879, 0.6455, 0.9266, 0.7932, 0.4875, 0.6429, 0.5068, 0.5973, 0.804, 0.8884, 0.7581, 0.8951, 0.834, 0.845, 0.6653, 0.6449, 0.8351, 0.9339, 0.8957, 0.7574, 0.8243, 0.5413, 0.7059, 0.8616, 0.8167, 0.405, 0.8513, 0.7841, 0.7212, 0.7026, 0.4671, 0.8621, 0.652, 0.613, 0.8777, 0.5934, 0.8717, 0.6866, 0.9187, 0.9212, 0.6846, 0.4542, 0.7446, 0.8083, 0.6231, 0.7745, 0.7116, 0.6222, 0.7895], 'AP': [0.5092, 0.7997, 0.8246, 0.9049, 0.8071, 0.7569, 0.8628, 0.9325, 0.4078, 0.5014, 0.7, 0.832, 0.7185, 0.8032, 0.8197, 0.7123, 0.7775, 0.5774, 0.6222, 0.7731, 0.9048, 0.6812, 0.3788, 0.8085, 0.8644, 0.9006, 0.6458, 0.8918, 0.8171, 0.8254, 0.9108, 0.6648, 0.9112, 0.9974, 0.8728, 0.8579, 0.7736, 0.4138, 0.8493, 0.4518, 0.8607, 0.819, 0.7472, 0.7927, 0.8525, 0.8685, 0.7534, 0.5839, 0.8522, 0.6352, 0.5879, 0.9242, 0.8221, 0.6802, 0.958, 0.8356, 0.4895, 0.6579, 0.5343, 0.6128, 0.8686, 0.9414, 0.7952, 0.9409, 0.8842, 0.8808, 0.7217, 0.6507, 0.8909, 0.9587, 0.9384, 0.8064, 0.8662, 0.5264, 0.7464, 0.9217, 0.8704, 0.3808, 0.8898, 0.8165, 0.7896, 0.778, 0.4304, 0.896, 0.6804, 0.6401, 0.9247, 0.6324, 0.9149, 0.7528, 0.955, 0.9549, 0.6983, 0.396, 0.8222, 0.8528, 0.6683, 0.8433, 0.7413, 0.6582, 0.8393], 'Recall@P=50': [0.4783, 0.8314, 0.864, 0.932, 0.864, 0.792, 0.924, 0.964, 0.26, 0.544, 0.756, 0.88, 0.784, 0.856, 0.824, 0.752, 0.836, 0.6, 0.684, 0.848, 0.924, 0.736, 0.092, 0.836, 0.9, 0.94, 0.684, 0.908, 0.908, 0.86, 0.936, 0.696, 0.924, 0.996, 0.904, 0.872, 0.82, 0.348, 0.872, 0.42, 0.908, 0.856, 0.808, 0.848, 0.872, 0.912, 0.764, 0.608, 0.912, 0.632, 0.612, 0.968, 0.868, 0.752, 0.968, 0.876, 0.468, 0.696, 0.504, 0.668, 0.916, 0.976, 0.828, 0.956, 0.9, 0.916, 0.744, 0.688, 0.948, 0.968, 0.968, 0.84, 0.888, 0.56, 0.776, 0.956, 0.924, 0.304, 0.896, 0.868, 0.864, 0.828, 0.42, 0.928, 0.668, 0.652, 0.96, 0.656, 0.936, 0.8, 0.972, 0.968, 0.816, 0.288, 0.876, 0.856, 0.712, 0.872, 0.772, 0.744, 0.848], 'micro': 0.7694, 'macro': 0.7633, 'weighted': 0.7609}
2024-07-17 05:47:17 - [34m[1mLOGS   [0m - Best checkpoint with score 75.05 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:47:19 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_68.6992.pt
2024-07-17 05:47:19 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_70.2578.pt', 'checkpoint_score_71.8359.pt', 'checkpoint_score_72.6445.pt', 'checkpoint_score_73.7852.pt', 'checkpoint_score_75.0469.pt']
2024-07-17 05:47:24 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:47:27 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:47:28 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:47:31 - [34m[1mLOGS   [0m - Training checkpoint for epoch 73/iteration 8302 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_73_iter_8302.pt
2024-07-17 05:47:32 - [34m[1mLOGS   [0m - Model state for epoch 73/iteration 8302 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_73_iter_8302.pt
[31m===========================================================================[0m
2024-07-17 05:47:34 - [32m[1mINFO   [0m - Training epoch 74
2024-07-17 05:47:35 - [34m[1mLOGS   [0m - Epoch:  74 [    8303/10000000], loss: {'classification': 1.8888, 'neural_augmentation': 0.5904, 'total_loss': 2.4792}, LR: [1.2e-05, 1.2e-05], Avg. batch load time: 0.627, Elapsed time:  0.85
2024-07-17 05:48:00 - [34m[1mLOGS   [0m - *** Training summary for epoch 74
	 loss={'classification': 2.0357, 'neural_augmentation': 0.5856, 'total_loss': 2.6213}
2024-07-17 05:48:08 - [33m[1mWARNING[0m - Found recall at precision 0.5161290322580645 when recall at precision 0.5 was requested.
2024-07-17 05:48:08 - [33m[1mWARNING[0m - Found recall at precision 0.5162790697674419 when recall at precision 0.5 was requested.
2024-07-17 05:48:08 - [33m[1mWARNING[0m - Found recall at precision 0.5234899328859061 when recall at precision 0.5 was requested.
2024-07-17 05:48:10 - [34m[1mLOGS   [0m - *** Validation summary for epoch 74
	 loss={'classification': 1.0163, 'neural_augmentation': 0.0, 'total_loss': 1.0163} || top1={'logits': 75.9258} || top5={'logits': 93.7539} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.498, 0.7282, 0.784, 0.8644, 0.7495, 0.7102, 0.8291, 0.8874, 0.4739, 0.5355, 0.6653, 0.8033, 0.6827, 0.7295, 0.7974, 0.6787, 0.7591, 0.5689, 0.6351, 0.7261, 0.8721, 0.6378, 0.4804, 0.7692, 0.8312, 0.8375, 0.6291, 0.8512, 0.7532, 0.8066, 0.8828, 0.6288, 0.8723, 0.992, 0.8436, 0.8351, 0.7604, 0.4618, 0.8306, 0.4823, 0.7874, 0.7815, 0.7087, 0.7506, 0.837, 0.7937, 0.7181, 0.5972, 0.765, 0.6133, 0.5941, 0.8408, 0.7897, 0.655, 0.9333, 0.7895, 0.524, 0.6409, 0.5423, 0.6061, 0.8018, 0.8916, 0.7696, 0.8985, 0.8484, 0.8524, 0.6814, 0.6874, 0.837, 0.9375, 0.8945, 0.7566, 0.834, 0.5439, 0.713, 0.8663, 0.8415, 0.424, 0.8524, 0.7939, 0.734, 0.7097, 0.4918, 0.8679, 0.6731, 0.6029, 0.8836, 0.6125, 0.8697, 0.6955, 0.9336, 0.9378, 0.6988, 0.4646, 0.7529, 0.8271, 0.6441, 0.7872, 0.7163, 0.6032, 0.7982], 'AP': [0.5102, 0.8117, 0.8413, 0.9022, 0.8073, 0.7569, 0.8701, 0.9423, 0.4146, 0.5207, 0.6968, 0.8587, 0.7451, 0.8108, 0.8264, 0.7204, 0.7951, 0.5905, 0.6722, 0.7815, 0.9103, 0.7003, 0.3867, 0.8186, 0.8665, 0.9098, 0.6604, 0.8968, 0.8385, 0.8406, 0.9183, 0.6807, 0.9113, 0.9974, 0.8811, 0.8615, 0.7884, 0.4428, 0.8718, 0.4756, 0.8466, 0.816, 0.7702, 0.8231, 0.869, 0.8745, 0.7607, 0.6211, 0.8413, 0.657, 0.6273, 0.9205, 0.8336, 0.6927, 0.9605, 0.836, 0.5226, 0.6678, 0.5711, 0.6173, 0.8764, 0.9401, 0.8158, 0.9417, 0.8974, 0.8895, 0.746, 0.6735, 0.8995, 0.9582, 0.9378, 0.8073, 0.8679, 0.5332, 0.7634, 0.9288, 0.8958, 0.4073, 0.8959, 0.8265, 0.8099, 0.7892, 0.4708, 0.8959, 0.703, 0.658, 0.9305, 0.6524, 0.9231, 0.7738, 0.9585, 0.9667, 0.709, 0.4115, 0.8253, 0.8666, 0.6747, 0.859, 0.7474, 0.6303, 0.8448], 'Recall@P=50': [0.4881, 0.8459, 0.876, 0.912, 0.86, 0.78, 0.932, 0.972, 0.356, 0.552, 0.764, 0.892, 0.8, 0.848, 0.84, 0.76, 0.848, 0.576, 0.784, 0.84, 0.932, 0.748, 0.124, 0.844, 0.912, 0.944, 0.692, 0.916, 0.912, 0.872, 0.932, 0.72, 0.928, 1.0, 0.912, 0.868, 0.82, 0.396, 0.908, 0.444, 0.912, 0.868, 0.812, 0.892, 0.888, 0.936, 0.764, 0.628, 0.904, 0.64, 0.676, 0.972, 0.876, 0.796, 0.968, 0.856, 0.54, 0.716, 0.568, 0.66, 0.916, 0.964, 0.856, 0.96, 0.912, 0.928, 0.792, 0.692, 0.96, 0.968, 0.964, 0.836, 0.896, 0.556, 0.8, 0.968, 0.932, 0.304, 0.912, 0.876, 0.872, 0.852, 0.468, 0.924, 0.684, 0.672, 0.972, 0.66, 0.94, 0.86, 0.964, 0.976, 0.812, 0.312, 0.876, 0.88, 0.704, 0.9, 0.788, 0.708, 0.86], 'micro': 0.7812, 'macro': 0.7749, 'weighted': 0.7724}
2024-07-17 05:48:14 - [34m[1mLOGS   [0m - Best checkpoint with score 75.93 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:48:15 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_70.2578.pt
2024-07-17 05:48:15 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_71.8359.pt', 'checkpoint_score_72.6445.pt', 'checkpoint_score_73.7852.pt', 'checkpoint_score_75.0469.pt', 'checkpoint_score_75.9258.pt']
2024-07-17 05:48:21 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:48:24 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:48:24 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:48:28 - [34m[1mLOGS   [0m - Training checkpoint for epoch 74/iteration 8418 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_74_iter_8418.pt
2024-07-17 05:48:29 - [34m[1mLOGS   [0m - Model state for epoch 74/iteration 8418 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_74_iter_8418.pt
[31m===========================================================================[0m
2024-07-17 05:48:31 - [32m[1mINFO   [0m - Training epoch 75
2024-07-17 05:48:33 - [34m[1mLOGS   [0m - Epoch:  75 [    8419/10000000], loss: {'classification': 2.0892, 'neural_augmentation': 0.5943, 'total_loss': 2.6836}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 1.785, Elapsed time:  2.00
2024-07-17 05:48:55 - [34m[1mLOGS   [0m - *** Training summary for epoch 75
	 loss={'classification': 2.0174, 'neural_augmentation': 0.5977, 'total_loss': 2.615}
2024-07-17 05:49:03 - [33m[1mWARNING[0m - Found recall at precision 0.5221238938053098 when recall at precision 0.5 was requested.
2024-07-17 05:49:06 - [34m[1mLOGS   [0m - *** Validation summary for epoch 75
	 loss={'classification': 0.9799, 'neural_augmentation': 0.0, 'total_loss': 0.9799} || top1={'logits': 76.6953} || top5={'logits': 94.1055} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5212, 0.7373, 0.7791, 0.8606, 0.7565, 0.72, 0.8286, 0.8855, 0.4846, 0.5636, 0.6808, 0.78, 0.7206, 0.728, 0.8052, 0.6808, 0.7739, 0.5806, 0.6584, 0.7387, 0.8705, 0.6559, 0.4777, 0.7771, 0.8245, 0.8381, 0.6248, 0.8503, 0.7723, 0.8, 0.8944, 0.6623, 0.8761, 0.988, 0.8434, 0.8401, 0.7633, 0.4588, 0.8267, 0.5, 0.8157, 0.7848, 0.7254, 0.7629, 0.8373, 0.8307, 0.7273, 0.5913, 0.7911, 0.6293, 0.6065, 0.8469, 0.8059, 0.6667, 0.9356, 0.8042, 0.5295, 0.6485, 0.5538, 0.6047, 0.8167, 0.8908, 0.7673, 0.9028, 0.8513, 0.8524, 0.6898, 0.671, 0.8364, 0.9358, 0.8866, 0.7907, 0.8434, 0.5714, 0.7345, 0.8848, 0.8444, 0.4368, 0.8644, 0.7948, 0.7479, 0.7335, 0.4959, 0.8662, 0.6697, 0.6167, 0.8718, 0.616, 0.8844, 0.7053, 0.9317, 0.9317, 0.6903, 0.4618, 0.7527, 0.821, 0.6468, 0.7899, 0.7215, 0.6154, 0.8238], 'AP': [0.5423, 0.8155, 0.8386, 0.9154, 0.8186, 0.7623, 0.8732, 0.9415, 0.4249, 0.5324, 0.716, 0.8483, 0.778, 0.8148, 0.8368, 0.7238, 0.8216, 0.6046, 0.6837, 0.7872, 0.9166, 0.7118, 0.3952, 0.823, 0.8735, 0.9111, 0.6671, 0.8982, 0.8512, 0.8461, 0.9291, 0.7062, 0.9091, 0.9982, 0.8885, 0.8678, 0.7909, 0.4385, 0.8752, 0.4906, 0.8713, 0.8176, 0.7736, 0.8222, 0.8717, 0.8938, 0.7705, 0.6087, 0.8601, 0.6679, 0.6429, 0.9258, 0.8433, 0.7036, 0.9624, 0.8496, 0.5327, 0.679, 0.5894, 0.6276, 0.8891, 0.945, 0.8189, 0.9435, 0.9047, 0.8897, 0.7512, 0.6763, 0.8935, 0.9595, 0.9402, 0.8315, 0.8733, 0.5636, 0.7778, 0.9366, 0.898, 0.4241, 0.9036, 0.838, 0.8177, 0.8067, 0.478, 0.8987, 0.7083, 0.6635, 0.929, 0.6695, 0.9278, 0.7804, 0.963, 0.9639, 0.7235, 0.4223, 0.8399, 0.858, 0.6925, 0.8636, 0.7588, 0.6615, 0.8617], 'Recall@P=50': [0.5415, 0.8488, 0.86, 0.932, 0.88, 0.8, 0.928, 0.976, 0.372, 0.58, 0.792, 0.892, 0.824, 0.864, 0.852, 0.764, 0.864, 0.596, 0.784, 0.836, 0.944, 0.74, 0.288, 0.832, 0.92, 0.94, 0.684, 0.916, 0.916, 0.888, 0.944, 0.712, 0.928, 1.0, 0.912, 0.888, 0.836, 0.36, 0.916, 0.472, 0.908, 0.876, 0.82, 0.868, 0.884, 0.94, 0.78, 0.628, 0.912, 0.68, 0.732, 0.968, 0.888, 0.768, 0.976, 0.876, 0.556, 0.744, 0.568, 0.684, 0.932, 0.964, 0.864, 0.956, 0.928, 0.92, 0.816, 0.712, 0.952, 0.972, 0.964, 0.86, 0.912, 0.604, 0.816, 0.964, 0.94, 0.324, 0.92, 0.884, 0.884, 0.86, 0.488, 0.928, 0.692, 0.704, 0.964, 0.708, 0.932, 0.88, 0.968, 0.976, 0.824, 0.308, 0.9, 0.856, 0.724, 0.916, 0.796, 0.712, 0.868], 'micro': 0.7898, 'macro': 0.7834, 'weighted': 0.7811}
2024-07-17 05:49:10 - [34m[1mLOGS   [0m - Best checkpoint with score 76.70 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:49:11 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_71.8359.pt
2024-07-17 05:49:11 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_72.6445.pt', 'checkpoint_score_73.7852.pt', 'checkpoint_score_75.0469.pt', 'checkpoint_score_75.9258.pt', 'checkpoint_score_76.6953.pt']
2024-07-17 05:49:17 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:49:19 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:49:19 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:49:23 - [34m[1mLOGS   [0m - Training checkpoint for epoch 75/iteration 8527 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_75_iter_8527.pt
2024-07-17 05:49:24 - [34m[1mLOGS   [0m - Model state for epoch 75/iteration 8527 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_75_iter_8527.pt
[31m===========================================================================[0m
2024-07-17 05:49:26 - [32m[1mINFO   [0m - Training epoch 76
2024-07-17 05:49:26 - [34m[1mLOGS   [0m - Epoch:  76 [    8528/10000000], loss: {'classification': 1.9656, 'neural_augmentation': 0.6016, 'total_loss': 2.5673}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 0.444, Elapsed time:  0.70
2024-07-17 05:49:50 - [34m[1mLOGS   [0m - *** Training summary for epoch 76
	 loss={'classification': 1.9871, 'neural_augmentation': 0.6092, 'total_loss': 2.5963}
2024-07-17 05:49:58 - [33m[1mWARNING[0m - Found recall at precision 0.5172413793103449 when recall at precision 0.5 was requested.
2024-07-17 05:49:58 - [33m[1mWARNING[0m - Found recall at precision 0.5192307692307693 when recall at precision 0.5 was requested.
2024-07-17 05:49:59 - [33m[1mWARNING[0m - Found recall at precision 0.5208333333333334 when recall at precision 0.5 was requested.
2024-07-17 05:50:00 - [34m[1mLOGS   [0m - *** Validation summary for epoch 76
	 loss={'classification': 0.9523, 'neural_augmentation': 0.0, 'total_loss': 0.9523} || top1={'logits': 77.6016} || top5={'logits': 94.3477} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5262, 0.7488, 0.7974, 0.8632, 0.7583, 0.7219, 0.8364, 0.8816, 0.4864, 0.5733, 0.6944, 0.8069, 0.7385, 0.7449, 0.808, 0.7042, 0.7918, 0.5893, 0.6653, 0.7459, 0.873, 0.6554, 0.495, 0.7904, 0.8354, 0.8507, 0.6564, 0.8648, 0.7654, 0.8195, 0.8918, 0.6949, 0.8856, 0.986, 0.8476, 0.8384, 0.7625, 0.4781, 0.8415, 0.514, 0.809, 0.7875, 0.7273, 0.7623, 0.8285, 0.8434, 0.7246, 0.6057, 0.7837, 0.6286, 0.6432, 0.8532, 0.8085, 0.6781, 0.932, 0.8255, 0.5594, 0.6726, 0.5801, 0.65, 0.8164, 0.9062, 0.7664, 0.9075, 0.8636, 0.8554, 0.7087, 0.6881, 0.8485, 0.9375, 0.8998, 0.7845, 0.867, 0.58, 0.7387, 0.8816, 0.8471, 0.4399, 0.8753, 0.7991, 0.759, 0.7473, 0.5085, 0.8655, 0.6769, 0.6132, 0.878, 0.6445, 0.8838, 0.723, 0.9388, 0.9353, 0.7092, 0.4745, 0.7775, 0.8248, 0.6752, 0.8106, 0.7357, 0.639, 0.834], 'AP': [0.546, 0.8173, 0.8548, 0.9122, 0.8156, 0.7627, 0.882, 0.9449, 0.4448, 0.5728, 0.7334, 0.871, 0.8074, 0.8278, 0.8386, 0.7502, 0.8371, 0.6204, 0.6981, 0.7996, 0.925, 0.7166, 0.4258, 0.8368, 0.8758, 0.9169, 0.6935, 0.9051, 0.8445, 0.8643, 0.9326, 0.7396, 0.9137, 0.9981, 0.8927, 0.8761, 0.802, 0.4651, 0.8964, 0.5042, 0.8671, 0.8259, 0.7795, 0.8283, 0.8707, 0.9079, 0.7837, 0.6287, 0.8609, 0.68, 0.6742, 0.9274, 0.8429, 0.7127, 0.9614, 0.864, 0.5655, 0.709, 0.6056, 0.6739, 0.8864, 0.9515, 0.8219, 0.9478, 0.9089, 0.8967, 0.7666, 0.6984, 0.9088, 0.9597, 0.9443, 0.8306, 0.8867, 0.5989, 0.7884, 0.9299, 0.8936, 0.4307, 0.909, 0.837, 0.8277, 0.8115, 0.4841, 0.9002, 0.72, 0.6674, 0.9314, 0.6961, 0.9264, 0.7964, 0.9631, 0.9659, 0.7531, 0.4075, 0.8485, 0.8697, 0.7093, 0.8832, 0.7641, 0.6713, 0.8669], 'Recall@P=50': [0.5415, 0.8663, 0.888, 0.928, 0.876, 0.804, 0.928, 0.968, 0.396, 0.592, 0.812, 0.892, 0.852, 0.872, 0.868, 0.792, 0.872, 0.652, 0.82, 0.852, 0.948, 0.768, 0.344, 0.864, 0.92, 0.948, 0.708, 0.92, 0.908, 0.904, 0.948, 0.772, 0.932, 1.0, 0.92, 0.9, 0.84, 0.42, 0.924, 0.488, 0.924, 0.884, 0.804, 0.876, 0.888, 0.968, 0.796, 0.636, 0.916, 0.724, 0.732, 0.972, 0.892, 0.816, 0.976, 0.896, 0.548, 0.776, 0.624, 0.728, 0.924, 0.972, 0.884, 0.948, 0.932, 0.932, 0.836, 0.748, 0.956, 0.972, 0.964, 0.86, 0.904, 0.66, 0.832, 0.968, 0.948, 0.324, 0.94, 0.868, 0.888, 0.884, 0.488, 0.932, 0.728, 0.724, 0.96, 0.74, 0.936, 0.872, 0.968, 0.98, 0.84, 0.3, 0.9, 0.884, 0.764, 0.936, 0.812, 0.756, 0.876], 'micro': 0.7997, 'macro': 0.794, 'weighted': 0.7916}
2024-07-17 05:50:04 - [34m[1mLOGS   [0m - Best checkpoint with score 77.60 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:50:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_72.6445.pt
2024-07-17 05:50:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_73.7852.pt', 'checkpoint_score_75.0469.pt', 'checkpoint_score_75.9258.pt', 'checkpoint_score_76.6953.pt', 'checkpoint_score_77.6016.pt']
2024-07-17 05:50:11 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:50:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:50:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:50:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 76/iteration 8636 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_76_iter_8636.pt
2024-07-17 05:50:19 - [34m[1mLOGS   [0m - Model state for epoch 76/iteration 8636 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_76_iter_8636.pt
[31m===========================================================================[0m
2024-07-17 05:50:21 - [32m[1mINFO   [0m - Training epoch 77
2024-07-17 05:50:23 - [34m[1mLOGS   [0m - Epoch:  77 [    8637/10000000], loss: {'classification': 1.9639, 'neural_augmentation': 0.6208, 'total_loss': 2.5847}, LR: [1.1e-05, 1.1e-05], Avg. batch load time: 1.308, Elapsed time:  1.52
2024-07-17 05:50:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 77
	 loss={'classification': 1.9561, 'neural_augmentation': 0.6211, 'total_loss': 2.5773}
2024-07-17 05:50:53 - [33m[1mWARNING[0m - Found recall at precision 0.5198237885462555 when recall at precision 0.5 was requested.
2024-07-17 05:50:53 - [33m[1mWARNING[0m - Found recall at precision 0.5177664974619289 when recall at precision 0.5 was requested.
2024-07-17 05:50:54 - [33m[1mWARNING[0m - Found recall at precision 0.5153374233128835 when recall at precision 0.5 was requested.
2024-07-17 05:50:55 - [34m[1mLOGS   [0m - *** Validation summary for epoch 77
	 loss={'classification': 0.9232, 'neural_augmentation': 0.0, 'total_loss': 0.9232} || top1={'logits': 78.168} || top5={'logits': 94.4688} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5332, 0.7564, 0.7966, 0.8734, 0.7823, 0.7319, 0.843, 0.8828, 0.5071, 0.5837, 0.7031, 0.8238, 0.739, 0.7702, 0.8112, 0.7244, 0.7819, 0.588, 0.6875, 0.7442, 0.8769, 0.6557, 0.4945, 0.8106, 0.8438, 0.8482, 0.6627, 0.8687, 0.7984, 0.8289, 0.9, 0.7152, 0.8908, 0.988, 0.8583, 0.8412, 0.7637, 0.4837, 0.8426, 0.4989, 0.8037, 0.7879, 0.7356, 0.7627, 0.838, 0.8469, 0.7318, 0.6282, 0.7956, 0.6286, 0.6548, 0.8669, 0.8197, 0.6908, 0.9295, 0.8276, 0.5641, 0.6852, 0.5928, 0.6462, 0.8166, 0.9121, 0.7798, 0.9156, 0.8714, 0.8613, 0.7155, 0.6977, 0.8421, 0.9395, 0.9019, 0.8, 0.8701, 0.5926, 0.7559, 0.875, 0.8519, 0.4391, 0.8747, 0.7931, 0.7784, 0.7794, 0.519, 0.8737, 0.6907, 0.6297, 0.8867, 0.6519, 0.8934, 0.7262, 0.9312, 0.9361, 0.7218, 0.4702, 0.78, 0.8362, 0.6962, 0.8168, 0.7396, 0.6391, 0.833], 'AP': [0.551, 0.8329, 0.8668, 0.9182, 0.8382, 0.7706, 0.8811, 0.9433, 0.4774, 0.5774, 0.7463, 0.876, 0.807, 0.8435, 0.8444, 0.7551, 0.8299, 0.6252, 0.7121, 0.7984, 0.9195, 0.7288, 0.4078, 0.8425, 0.8812, 0.9174, 0.7106, 0.9081, 0.8702, 0.8725, 0.9369, 0.752, 0.9178, 0.999, 0.8959, 0.8778, 0.8032, 0.464, 0.9065, 0.5096, 0.872, 0.8221, 0.7934, 0.8409, 0.8769, 0.9131, 0.787, 0.6619, 0.8744, 0.6839, 0.6935, 0.9389, 0.848, 0.7197, 0.9634, 0.8721, 0.5687, 0.7273, 0.6294, 0.6699, 0.894, 0.9498, 0.8298, 0.9505, 0.9184, 0.8957, 0.7745, 0.7046, 0.9093, 0.9623, 0.9473, 0.8504, 0.8928, 0.5994, 0.7923, 0.9341, 0.9064, 0.4332, 0.9132, 0.8438, 0.84, 0.838, 0.4976, 0.9016, 0.7322, 0.6823, 0.9405, 0.6961, 0.9319, 0.803, 0.9641, 0.9668, 0.7658, 0.4313, 0.8539, 0.8783, 0.7182, 0.8874, 0.7702, 0.6877, 0.8687], 'Recall@P=50': [0.5395, 0.8779, 0.904, 0.932, 0.884, 0.808, 0.932, 0.96, 0.5, 0.612, 0.812, 0.904, 0.86, 0.896, 0.864, 0.808, 0.872, 0.624, 0.808, 0.852, 0.944, 0.776, 0.004, 0.872, 0.924, 0.948, 0.72, 0.92, 0.92, 0.92, 0.944, 0.792, 0.94, 1.0, 0.92, 0.888, 0.848, 0.452, 0.944, 0.496, 0.928, 0.892, 0.844, 0.888, 0.9, 0.972, 0.796, 0.676, 0.92, 0.72, 0.752, 0.98, 0.892, 0.816, 0.976, 0.9, 0.568, 0.792, 0.644, 0.716, 0.936, 0.964, 0.896, 0.956, 0.932, 0.92, 0.836, 0.736, 0.952, 0.972, 0.972, 0.88, 0.912, 0.644, 0.828, 0.968, 0.952, 0.348, 0.932, 0.888, 0.9, 0.888, 0.52, 0.924, 0.72, 0.736, 0.98, 0.752, 0.94, 0.868, 0.964, 0.98, 0.844, 0.336, 0.916, 0.888, 0.74, 0.928, 0.796, 0.768, 0.864], 'micro': 0.8083, 'macro': 0.8013, 'weighted': 0.7989}
2024-07-17 05:51:00 - [34m[1mLOGS   [0m - Best checkpoint with score 78.17 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:51:01 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_73.7852.pt
2024-07-17 05:51:01 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_75.0469.pt', 'checkpoint_score_75.9258.pt', 'checkpoint_score_76.6953.pt', 'checkpoint_score_77.6016.pt', 'checkpoint_score_78.1680.pt']
2024-07-17 05:51:07 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:51:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:51:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:51:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 77/iteration 8744 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_77_iter_8744.pt
2024-07-17 05:51:14 - [34m[1mLOGS   [0m - Model state for epoch 77/iteration 8744 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_77_iter_8744.pt
[31m===========================================================================[0m
2024-07-17 05:51:16 - [32m[1mINFO   [0m - Training epoch 78
2024-07-17 05:51:18 - [34m[1mLOGS   [0m - Epoch:  78 [    8745/10000000], loss: {'classification': 2.0179, 'neural_augmentation': 0.6354, 'total_loss': 2.6534}, LR: [1e-05, 1e-05], Avg. batch load time: 1.860, Elapsed time:  2.07
2024-07-17 05:51:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 78
	 loss={'classification': 1.9365, 'neural_augmentation': 0.6323, 'total_loss': 2.5688}
2024-07-17 05:51:49 - [33m[1mWARNING[0m - Found recall at precision 0.525 when recall at precision 0.5 was requested.
2024-07-17 05:51:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 78
	 loss={'classification': 0.9006, 'neural_augmentation': 0.0, 'total_loss': 0.9006} || top1={'logits': 78.7109} || top5={'logits': 94.75} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5474, 0.7656, 0.7991, 0.8734, 0.7699, 0.7468, 0.8383, 0.8936, 0.5, 0.5963, 0.7117, 0.8218, 0.7445, 0.7642, 0.8161, 0.7207, 0.7957, 0.6096, 0.7075, 0.7424, 0.8817, 0.6623, 0.5018, 0.7849, 0.8423, 0.8454, 0.6693, 0.8737, 0.7968, 0.8302, 0.9038, 0.6992, 0.8817, 0.99, 0.8641, 0.85, 0.7862, 0.4942, 0.8541, 0.518, 0.8034, 0.7967, 0.7442, 0.7739, 0.847, 0.86, 0.7252, 0.6476, 0.7931, 0.638, 0.6581, 0.8737, 0.823, 0.6751, 0.9325, 0.8333, 0.5613, 0.6879, 0.6064, 0.6539, 0.824, 0.9106, 0.7835, 0.9149, 0.8734, 0.8636, 0.7254, 0.7156, 0.8465, 0.9405, 0.9076, 0.8162, 0.8688, 0.5966, 0.7566, 0.8907, 0.8637, 0.4572, 0.8793, 0.8103, 0.7784, 0.75, 0.5419, 0.8708, 0.6957, 0.635, 0.8934, 0.6667, 0.9076, 0.7474, 0.9414, 0.9414, 0.7207, 0.4544, 0.7913, 0.8289, 0.6966, 0.8419, 0.751, 0.6615, 0.8351], 'AP': [0.5734, 0.8321, 0.8702, 0.9163, 0.831, 0.777, 0.881, 0.9468, 0.4537, 0.6002, 0.7524, 0.8738, 0.8175, 0.8451, 0.8536, 0.7628, 0.8457, 0.6385, 0.7362, 0.8052, 0.9275, 0.7315, 0.4414, 0.8284, 0.889, 0.9133, 0.7204, 0.9092, 0.8696, 0.8806, 0.9409, 0.7469, 0.9139, 0.9989, 0.8982, 0.8916, 0.8133, 0.4816, 0.9053, 0.5241, 0.8707, 0.8235, 0.7917, 0.8422, 0.8806, 0.9212, 0.7846, 0.6765, 0.8727, 0.6981, 0.6968, 0.9405, 0.8453, 0.7094, 0.96, 0.8725, 0.5821, 0.7307, 0.6375, 0.6955, 0.8989, 0.9539, 0.8358, 0.947, 0.9205, 0.9063, 0.7852, 0.7217, 0.9145, 0.9621, 0.9516, 0.8605, 0.8986, 0.6141, 0.8029, 0.936, 0.9135, 0.4516, 0.9202, 0.8534, 0.8429, 0.8272, 0.5167, 0.9021, 0.7427, 0.7003, 0.9383, 0.7155, 0.9374, 0.8104, 0.9644, 0.9706, 0.7708, 0.4335, 0.8608, 0.8719, 0.7319, 0.9046, 0.7784, 0.6982, 0.8685], 'Recall@P=50': [0.585, 0.8866, 0.912, 0.928, 0.892, 0.804, 0.94, 0.972, 0.42, 0.628, 0.804, 0.9, 0.844, 0.884, 0.864, 0.8, 0.88, 0.672, 0.828, 0.86, 0.948, 0.764, 0.472, 0.844, 0.928, 0.944, 0.732, 0.928, 0.916, 0.928, 0.948, 0.788, 0.94, 1.0, 0.92, 0.9, 0.852, 0.444, 0.936, 0.512, 0.944, 0.884, 0.832, 0.896, 0.896, 0.972, 0.804, 0.736, 0.916, 0.732, 0.748, 0.968, 0.88, 0.82, 0.968, 0.904, 0.6, 0.772, 0.628, 0.744, 0.94, 0.976, 0.88, 0.956, 0.952, 0.928, 0.844, 0.768, 0.96, 0.972, 0.968, 0.884, 0.912, 0.676, 0.84, 0.968, 0.96, 0.336, 0.936, 0.892, 0.904, 0.892, 0.584, 0.932, 0.752, 0.74, 0.972, 0.772, 0.944, 0.884, 0.976, 0.984, 0.84, 0.344, 0.896, 0.884, 0.764, 0.94, 0.82, 0.772, 0.868], 'micro': 0.814, 'macro': 0.807, 'weighted': 0.8047}
2024-07-17 05:51:55 - [34m[1mLOGS   [0m - Best checkpoint with score 78.71 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:51:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_75.0469.pt
2024-07-17 05:51:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_75.9258.pt', 'checkpoint_score_76.6953.pt', 'checkpoint_score_77.6016.pt', 'checkpoint_score_78.1680.pt', 'checkpoint_score_78.7109.pt']
2024-07-17 05:52:03 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:52:05 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:52:06 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:52:09 - [34m[1mLOGS   [0m - Training checkpoint for epoch 78/iteration 8852 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_78_iter_8852.pt
2024-07-17 05:52:10 - [34m[1mLOGS   [0m - Model state for epoch 78/iteration 8852 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_78_iter_8852.pt
[31m===========================================================================[0m
2024-07-17 05:52:12 - [32m[1mINFO   [0m - Training epoch 79
2024-07-17 05:52:13 - [34m[1mLOGS   [0m - Epoch:  79 [    8853/10000000], loss: {'classification': 1.8464, 'neural_augmentation': 0.6484, 'total_loss': 2.4948}, LR: [1e-05, 1e-05], Avg. batch load time: 0.838, Elapsed time:  1.11
2024-07-17 05:52:36 - [34m[1mLOGS   [0m - *** Training summary for epoch 79
	 loss={'classification': 1.9261, 'neural_augmentation': 0.6442, 'total_loss': 2.5703}
2024-07-17 05:52:46 - [34m[1mLOGS   [0m - *** Validation summary for epoch 79
	 loss={'classification': 0.8774, 'neural_augmentation': 0.0, 'total_loss': 0.8774} || top1={'logits': 79.3164} || top5={'logits': 94.9688} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5513, 0.7685, 0.8107, 0.8767, 0.7724, 0.7436, 0.8383, 0.895, 0.5222, 0.6009, 0.7219, 0.8235, 0.7527, 0.7877, 0.8142, 0.7326, 0.8009, 0.6116, 0.7117, 0.7556, 0.8857, 0.6738, 0.5039, 0.8096, 0.8446, 0.8571, 0.6825, 0.8797, 0.8016, 0.8447, 0.9036, 0.7149, 0.8884, 0.99, 0.866, 0.8491, 0.7802, 0.4969, 0.8626, 0.5278, 0.8092, 0.7923, 0.7414, 0.7974, 0.8491, 0.8605, 0.7285, 0.6483, 0.8042, 0.6475, 0.6776, 0.866, 0.8286, 0.6977, 0.9311, 0.837, 0.5828, 0.7143, 0.6283, 0.6596, 0.8245, 0.9155, 0.7941, 0.9205, 0.8795, 0.8662, 0.7366, 0.7143, 0.8524, 0.9419, 0.9079, 0.8139, 0.879, 0.5957, 0.7686, 0.8802, 0.8641, 0.4554, 0.8785, 0.7949, 0.7769, 0.7654, 0.5325, 0.8805, 0.7026, 0.6614, 0.888, 0.668, 0.9072, 0.7595, 0.9393, 0.9436, 0.7249, 0.488, 0.7892, 0.8373, 0.7038, 0.8307, 0.7572, 0.6639, 0.8448], 'AP': [0.5731, 0.8385, 0.8777, 0.918, 0.8343, 0.7839, 0.8847, 0.9501, 0.4807, 0.6101, 0.7692, 0.879, 0.8166, 0.8544, 0.852, 0.7665, 0.8543, 0.6502, 0.7394, 0.8134, 0.9256, 0.7303, 0.4444, 0.851, 0.8917, 0.9191, 0.7291, 0.9106, 0.8772, 0.8949, 0.9424, 0.7742, 0.9182, 0.9994, 0.9027, 0.8909, 0.8213, 0.481, 0.9101, 0.5262, 0.8809, 0.824, 0.7993, 0.8627, 0.8808, 0.9247, 0.7926, 0.6786, 0.88, 0.7062, 0.7244, 0.9406, 0.8571, 0.7218, 0.9632, 0.8811, 0.5869, 0.7506, 0.6575, 0.7003, 0.8997, 0.956, 0.8489, 0.9548, 0.9205, 0.9079, 0.792, 0.7332, 0.9162, 0.9633, 0.9466, 0.8603, 0.9001, 0.6068, 0.8041, 0.9369, 0.9152, 0.4664, 0.9175, 0.847, 0.8425, 0.8377, 0.5224, 0.9075, 0.7485, 0.7329, 0.9406, 0.7252, 0.9354, 0.8227, 0.966, 0.9709, 0.7739, 0.4492, 0.8663, 0.8843, 0.7381, 0.9061, 0.7823, 0.7013, 0.8732], 'Recall@P=50': [0.5731, 0.8924, 0.916, 0.94, 0.884, 0.824, 0.94, 0.96, 0.472, 0.632, 0.824, 0.9, 0.86, 0.896, 0.86, 0.8, 0.884, 0.692, 0.84, 0.856, 0.948, 0.8, 0.44, 0.88, 0.932, 0.948, 0.768, 0.924, 0.916, 0.94, 0.952, 0.812, 0.94, 1.0, 0.924, 0.896, 0.872, 0.484, 0.944, 0.516, 0.936, 0.9, 0.848, 0.912, 0.904, 0.968, 0.828, 0.716, 0.92, 0.724, 0.776, 0.98, 0.908, 0.816, 0.976, 0.896, 0.62, 0.812, 0.66, 0.748, 0.944, 0.972, 0.888, 0.96, 0.948, 0.932, 0.836, 0.78, 0.96, 0.976, 0.964, 0.9, 0.912, 0.684, 0.828, 0.968, 0.96, 0.376, 0.936, 0.884, 0.9, 0.888, 0.548, 0.936, 0.756, 0.8, 0.972, 0.784, 0.94, 0.896, 0.972, 0.984, 0.844, 0.348, 0.916, 0.892, 0.78, 0.944, 0.812, 0.78, 0.872], 'micro': 0.8204, 'macro': 0.8131, 'weighted': 0.8108}
2024-07-17 05:52:51 - [34m[1mLOGS   [0m - Best checkpoint with score 79.32 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:52:52 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_75.9258.pt
2024-07-17 05:52:52 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_76.6953.pt', 'checkpoint_score_77.6016.pt', 'checkpoint_score_78.1680.pt', 'checkpoint_score_78.7109.pt', 'checkpoint_score_79.3164.pt']
2024-07-17 05:52:58 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:53:01 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:53:01 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:53:05 - [34m[1mLOGS   [0m - Training checkpoint for epoch 79/iteration 8957 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_79_iter_8957.pt
2024-07-17 05:53:06 - [34m[1mLOGS   [0m - Model state for epoch 79/iteration 8957 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_79_iter_8957.pt
[31m===========================================================================[0m
2024-07-17 05:53:08 - [32m[1mINFO   [0m - Training epoch 80
2024-07-17 05:53:09 - [34m[1mLOGS   [0m - Epoch:  80 [    8958/10000000], loss: {'classification': 1.7967, 'neural_augmentation': 0.6572, 'total_loss': 2.4539}, LR: [1e-05, 1e-05], Avg. batch load time: 1.103, Elapsed time:  1.34
2024-07-17 05:53:32 - [34m[1mLOGS   [0m - *** Training summary for epoch 80
	 loss={'classification': 1.8781, 'neural_augmentation': 0.6554, 'total_loss': 2.5335}
2024-07-17 05:53:40 - [33m[1mWARNING[0m - Found recall at precision 0.5150501672240803 when recall at precision 0.5 was requested.
2024-07-17 05:53:41 - [33m[1mWARNING[0m - Found recall at precision 0.5187165775401069 when recall at precision 0.5 was requested.
2024-07-17 05:53:43 - [34m[1mLOGS   [0m - *** Validation summary for epoch 80
	 loss={'classification': 0.8599, 'neural_augmentation': 0.0, 'total_loss': 0.8599} || top1={'logits': 79.9883} || top5={'logits': 95.1797} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5509, 0.7731, 0.8222, 0.8778, 0.7935, 0.7542, 0.8437, 0.9135, 0.5328, 0.614, 0.7235, 0.8313, 0.7887, 0.7787, 0.8273, 0.7291, 0.8105, 0.6062, 0.7191, 0.7676, 0.8828, 0.6834, 0.5154, 0.8301, 0.8408, 0.8571, 0.6711, 0.8835, 0.8143, 0.8473, 0.9087, 0.7321, 0.886, 0.9879, 0.875, 0.8525, 0.7888, 0.5187, 0.8553, 0.5298, 0.7935, 0.7927, 0.7543, 0.8085, 0.8517, 0.8659, 0.7315, 0.6598, 0.8008, 0.6459, 0.6845, 0.8723, 0.8255, 0.714, 0.9325, 0.8491, 0.5946, 0.7244, 0.6144, 0.6812, 0.8289, 0.9167, 0.7872, 0.9165, 0.8871, 0.8737, 0.7343, 0.7185, 0.8641, 0.9421, 0.9128, 0.8225, 0.8766, 0.6109, 0.7651, 0.8815, 0.8607, 0.475, 0.8745, 0.8122, 0.7899, 0.7801, 0.5413, 0.8787, 0.726, 0.6693, 0.8902, 0.6917, 0.911, 0.7654, 0.9443, 0.9414, 0.7385, 0.4984, 0.8057, 0.8398, 0.7062, 0.8475, 0.7396, 0.6796, 0.8394], 'AP': [0.5874, 0.8414, 0.8808, 0.9203, 0.8437, 0.7885, 0.8826, 0.9571, 0.5068, 0.6248, 0.7709, 0.8824, 0.8385, 0.8546, 0.858, 0.7684, 0.8627, 0.6497, 0.7523, 0.8214, 0.9324, 0.7463, 0.4641, 0.8602, 0.8823, 0.924, 0.7305, 0.9146, 0.8844, 0.8949, 0.946, 0.7857, 0.9165, 0.9992, 0.9059, 0.8924, 0.825, 0.5151, 0.9166, 0.5281, 0.8708, 0.8258, 0.8094, 0.8674, 0.8847, 0.9313, 0.7967, 0.6845, 0.8797, 0.7128, 0.7321, 0.9421, 0.8578, 0.7438, 0.9644, 0.8932, 0.5989, 0.7652, 0.6455, 0.7175, 0.9053, 0.9587, 0.8385, 0.9551, 0.9295, 0.9173, 0.7922, 0.7405, 0.9211, 0.9651, 0.9533, 0.8685, 0.903, 0.6294, 0.8075, 0.9376, 0.9114, 0.4846, 0.9194, 0.858, 0.8546, 0.8528, 0.5413, 0.9073, 0.7629, 0.7455, 0.9425, 0.7431, 0.9446, 0.8226, 0.9642, 0.9714, 0.7796, 0.4578, 0.8743, 0.8815, 0.7508, 0.9128, 0.7815, 0.711, 0.8748], 'Recall@P=50': [0.5731, 0.8924, 0.924, 0.932, 0.896, 0.824, 0.928, 0.968, 0.564, 0.672, 0.828, 0.92, 0.88, 0.888, 0.864, 0.804, 0.904, 0.696, 0.852, 0.86, 0.956, 0.804, 0.476, 0.884, 0.944, 0.952, 0.752, 0.928, 0.92, 0.948, 0.952, 0.832, 0.944, 1.0, 0.928, 0.9, 0.876, 0.532, 0.944, 0.528, 0.944, 0.904, 0.864, 0.916, 0.912, 0.976, 0.816, 0.716, 0.92, 0.736, 0.78, 0.98, 0.892, 0.84, 0.976, 0.912, 0.616, 0.82, 0.664, 0.756, 0.952, 0.972, 0.884, 0.964, 0.948, 0.932, 0.848, 0.804, 0.968, 0.98, 0.968, 0.908, 0.916, 0.712, 0.836, 0.976, 0.96, 0.412, 0.932, 0.896, 0.908, 0.904, 0.58, 0.932, 0.768, 0.816, 0.972, 0.8, 0.956, 0.888, 0.98, 0.984, 0.852, 0.364, 0.92, 0.884, 0.776, 0.944, 0.82, 0.78, 0.876], 'micro': 0.8262, 'macro': 0.8193, 'weighted': 0.8171}
2024-07-17 05:53:47 - [34m[1mLOGS   [0m - Best checkpoint with score 79.99 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:53:48 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_76.6953.pt
2024-07-17 05:53:48 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_77.6016.pt', 'checkpoint_score_78.1680.pt', 'checkpoint_score_78.7109.pt', 'checkpoint_score_79.3164.pt', 'checkpoint_score_79.9883.pt']
2024-07-17 05:53:54 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:53:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:53:57 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:54:01 - [34m[1mLOGS   [0m - Training checkpoint for epoch 80/iteration 9067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_80_iter_9067.pt
2024-07-17 05:54:02 - [34m[1mLOGS   [0m - Model state for epoch 80/iteration 9067 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_80_iter_9067.pt
[31m===========================================================================[0m
2024-07-17 05:54:04 - [32m[1mINFO   [0m - Training epoch 81
2024-07-17 05:54:04 - [34m[1mLOGS   [0m - Epoch:  81 [    9068/10000000], loss: {'classification': 1.7649, 'neural_augmentation': 0.6517, 'total_loss': 2.4166}, LR: [9e-06, 9e-06], Avg. batch load time: 0.356, Elapsed time:  0.57
2024-07-17 05:54:27 - [34m[1mLOGS   [0m - *** Training summary for epoch 81
	 loss={'classification': 1.8745, 'neural_augmentation': 0.666, 'total_loss': 2.5405}
2024-07-17 05:54:36 - [33m[1mWARNING[0m - Found recall at precision 0.5153846153846153 when recall at precision 0.5 was requested.
2024-07-17 05:54:38 - [34m[1mLOGS   [0m - *** Validation summary for epoch 81
	 loss={'classification': 0.8459, 'neural_augmentation': 0.0, 'total_loss': 0.8459} || top1={'logits': 80.0586} || top5={'logits': 95.1914} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5699, 0.7759, 0.8359, 0.8769, 0.7937, 0.7548, 0.843, 0.9113, 0.5284, 0.6174, 0.7313, 0.8364, 0.7702, 0.7857, 0.8253, 0.7293, 0.8193, 0.622, 0.732, 0.775, 0.88, 0.6861, 0.5035, 0.8108, 0.8486, 0.8571, 0.6928, 0.888, 0.7977, 0.8608, 0.9143, 0.744, 0.8879, 0.99, 0.881, 0.8438, 0.7874, 0.5331, 0.8643, 0.5431, 0.8129, 0.7918, 0.754, 0.8058, 0.8504, 0.8623, 0.7392, 0.6739, 0.7939, 0.6499, 0.6879, 0.8753, 0.8337, 0.7129, 0.9309, 0.8571, 0.5902, 0.7542, 0.6202, 0.6915, 0.831, 0.9237, 0.8041, 0.9196, 0.8821, 0.8745, 0.7573, 0.7196, 0.8601, 0.9458, 0.9218, 0.8359, 0.8785, 0.6054, 0.7824, 0.8784, 0.8689, 0.4655, 0.8843, 0.807, 0.8008, 0.8017, 0.5602, 0.8755, 0.7202, 0.6833, 0.8898, 0.6998, 0.9144, 0.7698, 0.9379, 0.938, 0.7411, 0.4953, 0.7915, 0.8509, 0.7091, 0.8613, 0.7534, 0.6923, 0.8497], 'AP': [0.5961, 0.8433, 0.8916, 0.9203, 0.84, 0.792, 0.8853, 0.9572, 0.4997, 0.6353, 0.7832, 0.8914, 0.8353, 0.8675, 0.8599, 0.777, 0.8662, 0.6562, 0.7585, 0.8303, 0.9342, 0.7584, 0.4432, 0.856, 0.8823, 0.923, 0.7508, 0.9141, 0.8759, 0.9066, 0.9486, 0.7919, 0.9218, 0.9994, 0.9077, 0.898, 0.8312, 0.5192, 0.9198, 0.5431, 0.8808, 0.8237, 0.8087, 0.864, 0.888, 0.9283, 0.8066, 0.7025, 0.8771, 0.7196, 0.7365, 0.9466, 0.8675, 0.7462, 0.9679, 0.8944, 0.6053, 0.7844, 0.6582, 0.7187, 0.9039, 0.9612, 0.8496, 0.9585, 0.9302, 0.9155, 0.8114, 0.7433, 0.9182, 0.9665, 0.958, 0.8853, 0.9033, 0.6299, 0.8238, 0.9361, 0.9153, 0.4782, 0.9239, 0.8649, 0.8603, 0.8746, 0.5378, 0.9066, 0.7713, 0.7558, 0.9449, 0.7556, 0.9434, 0.8282, 0.9625, 0.9713, 0.7905, 0.4554, 0.8694, 0.8894, 0.7522, 0.9217, 0.7826, 0.7292, 0.8783], 'Recall@P=50': [0.6324, 0.8808, 0.92, 0.94, 0.892, 0.828, 0.932, 0.976, 0.544, 0.664, 0.824, 0.92, 0.888, 0.92, 0.868, 0.816, 0.904, 0.692, 0.852, 0.864, 0.956, 0.82, 0.38, 0.868, 0.94, 0.944, 0.772, 0.932, 0.92, 0.956, 0.952, 0.844, 0.948, 1.0, 0.928, 0.904, 0.88, 0.548, 0.956, 0.528, 0.94, 0.92, 0.864, 0.916, 0.892, 0.98, 0.816, 0.728, 0.916, 0.752, 0.772, 0.988, 0.924, 0.84, 0.984, 0.908, 0.62, 0.824, 0.68, 0.764, 0.948, 0.972, 0.892, 0.964, 0.948, 0.932, 0.86, 0.784, 0.956, 0.98, 0.98, 0.916, 0.912, 0.704, 0.848, 0.976, 0.964, 0.4, 0.94, 0.888, 0.916, 0.924, 0.576, 0.928, 0.796, 0.82, 0.976, 0.804, 0.948, 0.9, 0.984, 0.984, 0.864, 0.356, 0.928, 0.892, 0.804, 0.948, 0.82, 0.8, 0.876], 'micro': 0.8302, 'macro': 0.8237, 'weighted': 0.8215}
2024-07-17 05:54:42 - [34m[1mLOGS   [0m - Best checkpoint with score 80.06 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:54:44 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_77.6016.pt
2024-07-17 05:54:44 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_78.1680.pt', 'checkpoint_score_78.7109.pt', 'checkpoint_score_79.3164.pt', 'checkpoint_score_79.9883.pt', 'checkpoint_score_80.0586.pt']
2024-07-17 05:54:49 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:54:52 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:54:53 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:54:56 - [34m[1mLOGS   [0m - Training checkpoint for epoch 81/iteration 9177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_81_iter_9177.pt
2024-07-17 05:54:57 - [34m[1mLOGS   [0m - Model state for epoch 81/iteration 9177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_81_iter_9177.pt
[31m===========================================================================[0m
2024-07-17 05:54:59 - [32m[1mINFO   [0m - Training epoch 82
2024-07-17 05:55:01 - [34m[1mLOGS   [0m - Epoch:  82 [    9178/10000000], loss: {'classification': 1.8018, 'neural_augmentation': 0.6752, 'total_loss': 2.477}, LR: [9e-06, 9e-06], Avg. batch load time: 1.495, Elapsed time:  1.71
2024-07-17 05:55:23 - [34m[1mLOGS   [0m - *** Training summary for epoch 82
	 loss={'classification': 1.8556, 'neural_augmentation': 0.6773, 'total_loss': 2.5329}
2024-07-17 05:55:34 - [34m[1mLOGS   [0m - *** Validation summary for epoch 82
	 loss={'classification': 0.8259, 'neural_augmentation': 0.0, 'total_loss': 0.8259} || top1={'logits': 80.6953} || top5={'logits': 95.3945} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5629, 0.7745, 0.8274, 0.8755, 0.796, 0.7485, 0.8445, 0.9076, 0.5243, 0.622, 0.7349, 0.8333, 0.7868, 0.7782, 0.8316, 0.7417, 0.824, 0.6266, 0.7515, 0.7738, 0.8852, 0.6985, 0.527, 0.8196, 0.8566, 0.8548, 0.7004, 0.8917, 0.8057, 0.8601, 0.9212, 0.7426, 0.8884, 0.99, 0.8771, 0.8525, 0.7835, 0.5356, 0.8596, 0.5514, 0.825, 0.7967, 0.7676, 0.7949, 0.8554, 0.8743, 0.7315, 0.6735, 0.818, 0.6608, 0.7032, 0.8784, 0.8313, 0.7235, 0.9305, 0.8632, 0.6014, 0.7291, 0.6263, 0.6992, 0.8392, 0.9299, 0.7941, 0.9295, 0.8894, 0.8745, 0.7588, 0.7218, 0.8645, 0.9439, 0.9262, 0.8308, 0.8805, 0.6209, 0.7891, 0.8852, 0.8639, 0.4822, 0.8809, 0.8017, 0.8, 0.7926, 0.5586, 0.8817, 0.7277, 0.6802, 0.8934, 0.7122, 0.917, 0.7842, 0.9514, 0.9461, 0.7578, 0.5018, 0.8008, 0.8516, 0.7325, 0.8758, 0.7596, 0.687, 0.8522], 'AP': [0.6007, 0.8488, 0.8906, 0.9255, 0.8456, 0.7935, 0.8904, 0.9549, 0.4933, 0.6483, 0.789, 0.8928, 0.848, 0.8659, 0.8633, 0.7802, 0.8732, 0.6708, 0.7739, 0.8281, 0.9361, 0.76, 0.4819, 0.8665, 0.8959, 0.9251, 0.75, 0.9196, 0.8763, 0.912, 0.9496, 0.8003, 0.9199, 0.9993, 0.9082, 0.9023, 0.8331, 0.5308, 0.9169, 0.5572, 0.8902, 0.8339, 0.8162, 0.8624, 0.8938, 0.9368, 0.8035, 0.7135, 0.8904, 0.7264, 0.7562, 0.9449, 0.8636, 0.7628, 0.9677, 0.8984, 0.6194, 0.7789, 0.6714, 0.7373, 0.913, 0.9608, 0.8513, 0.9586, 0.9322, 0.9212, 0.8168, 0.7498, 0.9246, 0.9652, 0.9606, 0.8804, 0.9093, 0.644, 0.8311, 0.9392, 0.9187, 0.4936, 0.9255, 0.8678, 0.865, 0.8638, 0.5475, 0.9073, 0.7809, 0.7481, 0.9457, 0.7615, 0.9423, 0.8347, 0.9656, 0.9754, 0.7975, 0.4692, 0.8796, 0.8928, 0.7637, 0.9252, 0.793, 0.7334, 0.8831], 'Recall@P=50': [0.6245, 0.8866, 0.924, 0.944, 0.896, 0.82, 0.936, 0.98, 0.488, 0.708, 0.832, 0.92, 0.876, 0.932, 0.872, 0.812, 0.908, 0.704, 0.84, 0.86, 0.956, 0.844, 0.52, 0.884, 0.948, 0.956, 0.792, 0.932, 0.92, 0.956, 0.956, 0.856, 0.944, 1.0, 0.936, 0.912, 0.88, 0.556, 0.956, 0.548, 0.936, 0.928, 0.864, 0.92, 0.912, 0.976, 0.824, 0.744, 0.928, 0.76, 0.816, 0.98, 0.904, 0.856, 0.984, 0.92, 0.64, 0.832, 0.716, 0.764, 0.952, 0.976, 0.888, 0.964, 0.952, 0.932, 0.872, 0.8, 0.964, 0.976, 0.98, 0.908, 0.92, 0.732, 0.864, 0.976, 0.964, 0.428, 0.944, 0.904, 0.932, 0.904, 0.604, 0.932, 0.804, 0.808, 0.98, 0.832, 0.944, 0.9, 0.976, 0.988, 0.852, 0.416, 0.924, 0.892, 0.804, 0.944, 0.828, 0.796, 0.88], 'micro': 0.8362, 'macro': 0.829, 'weighted': 0.8267}
2024-07-17 05:55:38 - [34m[1mLOGS   [0m - Best checkpoint with score 80.70 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:55:39 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_78.1680.pt
2024-07-17 05:55:39 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_78.7109.pt', 'checkpoint_score_79.3164.pt', 'checkpoint_score_79.9883.pt', 'checkpoint_score_80.0586.pt', 'checkpoint_score_80.6953.pt']
2024-07-17 05:55:45 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:55:48 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:55:48 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:55:52 - [34m[1mLOGS   [0m - Training checkpoint for epoch 82/iteration 9287 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_82_iter_9287.pt
2024-07-17 05:55:53 - [34m[1mLOGS   [0m - Model state for epoch 82/iteration 9287 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_82_iter_9287.pt
[31m===========================================================================[0m
2024-07-17 05:55:55 - [32m[1mINFO   [0m - Training epoch 83
2024-07-17 05:55:57 - [34m[1mLOGS   [0m - Epoch:  83 [    9288/10000000], loss: {'classification': 1.9282, 'neural_augmentation': 0.6875, 'total_loss': 2.6158}, LR: [9e-06, 9e-06], Avg. batch load time: 1.905, Elapsed time:  2.11
2024-07-17 05:56:20 - [34m[1mLOGS   [0m - *** Training summary for epoch 83
	 loss={'classification': 1.8303, 'neural_augmentation': 0.6874, 'total_loss': 2.5177}
2024-07-17 05:56:31 - [34m[1mLOGS   [0m - *** Validation summary for epoch 83
	 loss={'classification': 0.8123, 'neural_augmentation': 0.0, 'total_loss': 0.8123} || top1={'logits': 80.9023} || top5={'logits': 95.4609} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5847, 0.7858, 0.8412, 0.8851, 0.8008, 0.7511, 0.8493, 0.9121, 0.536, 0.6192, 0.7466, 0.8542, 0.7835, 0.7957, 0.8277, 0.75, 0.8233, 0.6407, 0.7406, 0.7743, 0.8932, 0.6993, 0.53, 0.8198, 0.8565, 0.8671, 0.7074, 0.898, 0.8219, 0.8619, 0.9284, 0.7521, 0.8951, 0.992, 0.8819, 0.8629, 0.7889, 0.5403, 0.8724, 0.5561, 0.8359, 0.7954, 0.7603, 0.811, 0.8584, 0.8653, 0.7339, 0.697, 0.8126, 0.6728, 0.7131, 0.8745, 0.8394, 0.7329, 0.9363, 0.8608, 0.6218, 0.7434, 0.6297, 0.6949, 0.8304, 0.9262, 0.8, 0.9311, 0.8857, 0.8755, 0.7609, 0.7265, 0.8674, 0.9508, 0.924, 0.8347, 0.8842, 0.6342, 0.7965, 0.8834, 0.8724, 0.5052, 0.8803, 0.8044, 0.8074, 0.8069, 0.5747, 0.887, 0.7401, 0.698, 0.9034, 0.7164, 0.9151, 0.7853, 0.9426, 0.9482, 0.7633, 0.488, 0.8078, 0.8565, 0.7284, 0.8699, 0.7673, 0.717, 0.8547], 'AP': [0.6124, 0.8478, 0.8968, 0.9269, 0.85, 0.7931, 0.8937, 0.957, 0.5171, 0.6496, 0.7928, 0.898, 0.8463, 0.8771, 0.8615, 0.7917, 0.8777, 0.6774, 0.7824, 0.8306, 0.936, 0.7586, 0.4744, 0.865, 0.8939, 0.9319, 0.7697, 0.9194, 0.8863, 0.9134, 0.9557, 0.8047, 0.9208, 0.9995, 0.9144, 0.9057, 0.835, 0.5441, 0.9261, 0.5719, 0.8971, 0.8277, 0.8204, 0.8764, 0.892, 0.933, 0.8069, 0.7347, 0.892, 0.7372, 0.7642, 0.9465, 0.8717, 0.7667, 0.97, 0.8967, 0.6211, 0.7934, 0.6745, 0.7397, 0.9101, 0.964, 0.8545, 0.9585, 0.9301, 0.9169, 0.8162, 0.7538, 0.9263, 0.9634, 0.9561, 0.8832, 0.9159, 0.6569, 0.8366, 0.9387, 0.9286, 0.5077, 0.9272, 0.8666, 0.8712, 0.8784, 0.5729, 0.9119, 0.789, 0.7608, 0.9502, 0.7688, 0.9462, 0.8478, 0.9645, 0.9745, 0.8065, 0.4572, 0.8844, 0.8981, 0.7642, 0.9235, 0.7972, 0.7531, 0.8852], 'Recall@P=50': [0.6759, 0.8895, 0.932, 0.936, 0.896, 0.824, 0.94, 0.972, 0.564, 0.68, 0.848, 0.924, 0.884, 0.932, 0.872, 0.82, 0.912, 0.696, 0.844, 0.872, 0.944, 0.824, 0.512, 0.876, 0.944, 0.964, 0.812, 0.952, 0.924, 0.952, 0.952, 0.86, 0.948, 1.0, 0.94, 0.916, 0.876, 0.544, 0.964, 0.56, 0.94, 0.924, 0.876, 0.916, 0.912, 0.98, 0.832, 0.772, 0.932, 0.796, 0.824, 0.976, 0.912, 0.856, 0.984, 0.92, 0.004, 0.832, 0.72, 0.788, 0.948, 0.972, 0.888, 0.968, 0.952, 0.932, 0.876, 0.8, 0.96, 0.976, 0.98, 0.916, 0.924, 0.74, 0.86, 0.976, 0.968, 0.492, 0.948, 0.912, 0.924, 0.936, 0.636, 0.94, 0.816, 0.82, 0.98, 0.832, 0.948, 0.908, 0.984, 0.984, 0.86, 0.364, 0.928, 0.896, 0.792, 0.948, 0.84, 0.812, 0.88], 'micro': 0.8398, 'macro': 0.8335, 'weighted': 0.8314}
2024-07-17 05:56:35 - [34m[1mLOGS   [0m - Best checkpoint with score 80.90 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:56:36 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_78.7109.pt
2024-07-17 05:56:36 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_79.3164.pt', 'checkpoint_score_79.9883.pt', 'checkpoint_score_80.0586.pt', 'checkpoint_score_80.6953.pt', 'checkpoint_score_80.9023.pt']
2024-07-17 05:56:42 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:56:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:56:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:56:49 - [34m[1mLOGS   [0m - Training checkpoint for epoch 83/iteration 9401 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_83_iter_9401.pt
2024-07-17 05:56:50 - [34m[1mLOGS   [0m - Model state for epoch 83/iteration 9401 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_83_iter_9401.pt
[31m===========================================================================[0m
2024-07-17 05:56:52 - [32m[1mINFO   [0m - Training epoch 84
2024-07-17 05:56:53 - [34m[1mLOGS   [0m - Epoch:  84 [    9402/10000000], loss: {'classification': 1.6819, 'neural_augmentation': 0.7013, 'total_loss': 2.3832}, LR: [9e-06, 9e-06], Avg. batch load time: 1.158, Elapsed time:  1.38
2024-07-17 05:57:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 84
	 loss={'classification': 1.8126, 'neural_augmentation': 0.6985, 'total_loss': 2.5111}
2024-07-17 05:57:27 - [33m[1mWARNING[0m - Found recall at precision 0.51953125 when recall at precision 0.5 was requested.
2024-07-17 05:57:29 - [34m[1mLOGS   [0m - *** Validation summary for epoch 84
	 loss={'classification': 0.7965, 'neural_augmentation': 0.0, 'total_loss': 0.7965} || top1={'logits': 81.2461} || top5={'logits': 95.5781} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.5913, 0.7917, 0.8465, 0.8889, 0.8167, 0.756, 0.8458, 0.9172, 0.5487, 0.6309, 0.7619, 0.8475, 0.7991, 0.8084, 0.8384, 0.7448, 0.8245, 0.6406, 0.76, 0.7868, 0.897, 0.6986, 0.5261, 0.8274, 0.8613, 0.8732, 0.7085, 0.9012, 0.8316, 0.8632, 0.9286, 0.7759, 0.8941, 0.992, 0.8861, 0.8607, 0.7898, 0.5336, 0.8798, 0.5507, 0.8427, 0.8015, 0.7658, 0.811, 0.8491, 0.863, 0.7511, 0.6923, 0.8245, 0.665, 0.7152, 0.8752, 0.8434, 0.7541, 0.936, 0.8675, 0.6395, 0.7769, 0.6309, 0.7174, 0.841, 0.9284, 0.805, 0.9247, 0.8917, 0.8787, 0.7805, 0.7364, 0.8689, 0.945, 0.9206, 0.8406, 0.8889, 0.6373, 0.8078, 0.8773, 0.8765, 0.5029, 0.888, 0.8008, 0.8126, 0.8134, 0.5704, 0.8866, 0.7368, 0.7052, 0.9087, 0.729, 0.9244, 0.7809, 0.9474, 0.9458, 0.7625, 0.5143, 0.8033, 0.8622, 0.7336, 0.8787, 0.7627, 0.7095, 0.8534], 'AP': [0.6222, 0.8494, 0.9053, 0.9314, 0.8607, 0.7977, 0.8917, 0.9602, 0.5253, 0.6693, 0.8005, 0.9051, 0.8576, 0.8873, 0.8645, 0.7895, 0.8773, 0.6746, 0.798, 0.8445, 0.9433, 0.7604, 0.4796, 0.8699, 0.9008, 0.9335, 0.7695, 0.9195, 0.8943, 0.9164, 0.9536, 0.8182, 0.9237, 0.9996, 0.9151, 0.9081, 0.8432, 0.5412, 0.9287, 0.5577, 0.9021, 0.834, 0.8245, 0.8718, 0.8918, 0.9383, 0.8168, 0.7243, 0.8973, 0.7426, 0.7681, 0.9517, 0.879, 0.7864, 0.9712, 0.9062, 0.6415, 0.812, 0.6798, 0.7534, 0.9179, 0.9641, 0.8568, 0.9587, 0.9381, 0.9203, 0.8269, 0.7604, 0.9314, 0.9654, 0.9591, 0.8909, 0.9145, 0.659, 0.842, 0.937, 0.9298, 0.5178, 0.9343, 0.8715, 0.8768, 0.8819, 0.5772, 0.9016, 0.79, 0.7742, 0.9514, 0.7791, 0.9497, 0.8482, 0.9668, 0.9755, 0.8096, 0.4868, 0.8775, 0.9008, 0.7742, 0.9351, 0.7994, 0.7572, 0.8866], 'Recall@P=50': [0.664, 0.8953, 0.94, 0.948, 0.9, 0.832, 0.932, 0.972, 0.608, 0.708, 0.848, 0.932, 0.9, 0.94, 0.868, 0.812, 0.904, 0.704, 0.856, 0.88, 0.968, 0.828, 0.504, 0.88, 0.952, 0.98, 0.812, 0.94, 0.916, 0.952, 0.952, 0.856, 0.944, 1.0, 0.932, 0.924, 0.892, 0.564, 0.96, 0.532, 0.948, 0.916, 0.88, 0.924, 0.912, 0.984, 0.84, 0.752, 0.932, 0.8, 0.832, 0.984, 0.928, 0.888, 0.988, 0.928, 0.656, 0.848, 0.728, 0.812, 0.952, 0.98, 0.896, 0.964, 0.96, 0.928, 0.868, 0.8, 0.968, 0.98, 0.98, 0.932, 0.924, 0.728, 0.872, 0.976, 0.968, 0.46, 0.952, 0.896, 0.92, 0.936, 0.648, 0.94, 0.812, 0.844, 0.976, 0.836, 0.96, 0.916, 0.98, 0.984, 0.86, 0.46, 0.924, 0.9, 0.804, 0.964, 0.836, 0.812, 0.88], 'micro': 0.8442, 'macro': 0.8384, 'weighted': 0.8363}
2024-07-17 05:57:33 - [34m[1mLOGS   [0m - Best checkpoint with score 81.25 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:57:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_79.3164.pt
2024-07-17 05:57:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_79.9883.pt', 'checkpoint_score_80.0586.pt', 'checkpoint_score_80.6953.pt', 'checkpoint_score_80.9023.pt', 'checkpoint_score_81.2461.pt']
2024-07-17 05:57:40 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:57:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:57:44 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:57:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 84/iteration 9521 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_84_iter_9521.pt
2024-07-17 05:57:48 - [34m[1mLOGS   [0m - Model state for epoch 84/iteration 9521 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_84_iter_9521.pt
[31m===========================================================================[0m
2024-07-17 05:57:50 - [32m[1mINFO   [0m - Training epoch 85
2024-07-17 05:57:52 - [34m[1mLOGS   [0m - Epoch:  85 [    9522/10000000], loss: {'classification': 1.9065, 'neural_augmentation': 0.7096, 'total_loss': 2.6161}, LR: [8e-06, 8e-06], Avg. batch load time: 1.645, Elapsed time:  1.86
2024-07-17 05:58:14 - [34m[1mLOGS   [0m - *** Training summary for epoch 85
	 loss={'classification': 1.8003, 'neural_augmentation': 0.7089, 'total_loss': 2.5091}
2024-07-17 05:58:24 - [34m[1mLOGS   [0m - *** Validation summary for epoch 85
	 loss={'classification': 0.7781, 'neural_augmentation': 0.0, 'total_loss': 0.7781} || top1={'logits': 81.5391} || top5={'logits': 95.7617} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6026, 0.7859, 0.8393, 0.8865, 0.8157, 0.7571, 0.8504, 0.9153, 0.5246, 0.6444, 0.7474, 0.8566, 0.8117, 0.7949, 0.8455, 0.7601, 0.8452, 0.6457, 0.7632, 0.7826, 0.8979, 0.7099, 0.5367, 0.839, 0.8676, 0.8708, 0.7195, 0.9012, 0.832, 0.8727, 0.9328, 0.7666, 0.8874, 0.992, 0.8795, 0.863, 0.7841, 0.5429, 0.8704, 0.5628, 0.8354, 0.8102, 0.7754, 0.8118, 0.8589, 0.8782, 0.7446, 0.7045, 0.8215, 0.6682, 0.7273, 0.8785, 0.8375, 0.7368, 0.9342, 0.8689, 0.6445, 0.7646, 0.6427, 0.7291, 0.8463, 0.9312, 0.8094, 0.9361, 0.8936, 0.8803, 0.7802, 0.7458, 0.8636, 0.9472, 0.9212, 0.8308, 0.8879, 0.6542, 0.8061, 0.8921, 0.8798, 0.5089, 0.8907, 0.815, 0.8076, 0.8194, 0.5989, 0.8941, 0.7446, 0.7218, 0.8961, 0.7229, 0.9144, 0.7936, 0.9572, 0.9482, 0.7677, 0.5078, 0.8106, 0.8378, 0.7393, 0.8839, 0.7763, 0.701, 0.8541], 'AP': [0.6331, 0.8553, 0.8997, 0.9307, 0.8566, 0.7986, 0.8986, 0.9558, 0.5158, 0.6761, 0.801, 0.9039, 0.8659, 0.8812, 0.8719, 0.7978, 0.8895, 0.684, 0.7991, 0.8415, 0.9446, 0.7718, 0.5048, 0.8815, 0.9078, 0.9361, 0.7739, 0.9235, 0.8982, 0.9238, 0.9568, 0.8183, 0.9215, 0.9995, 0.9129, 0.9135, 0.8436, 0.5515, 0.9249, 0.576, 0.901, 0.843, 0.8267, 0.8733, 0.8935, 0.9409, 0.8118, 0.7397, 0.9007, 0.7488, 0.781, 0.9478, 0.8761, 0.7757, 0.9669, 0.9066, 0.6581, 0.8052, 0.6991, 0.7708, 0.9171, 0.9643, 0.8687, 0.9627, 0.9383, 0.9255, 0.8278, 0.7716, 0.9298, 0.9639, 0.961, 0.8838, 0.9133, 0.6763, 0.8452, 0.9424, 0.9326, 0.5296, 0.9332, 0.8773, 0.8766, 0.8832, 0.6028, 0.9122, 0.7926, 0.7789, 0.9488, 0.7798, 0.9468, 0.8585, 0.9667, 0.9765, 0.8063, 0.486, 0.8872, 0.887, 0.7768, 0.9382, 0.8028, 0.7518, 0.8887], 'Recall@P=50': [0.7115, 0.8924, 0.936, 0.936, 0.904, 0.832, 0.94, 0.968, 0.528, 0.72, 0.852, 0.928, 0.896, 0.932, 0.872, 0.82, 0.908, 0.716, 0.852, 0.876, 0.968, 0.84, 0.524, 0.888, 0.956, 0.972, 0.816, 0.944, 0.928, 0.956, 0.96, 0.864, 0.948, 1.0, 0.936, 0.928, 0.892, 0.588, 0.956, 0.584, 0.944, 0.912, 0.884, 0.92, 0.904, 0.984, 0.844, 0.78, 0.932, 0.804, 0.86, 0.98, 0.92, 0.904, 0.984, 0.92, 0.66, 0.848, 0.768, 0.84, 0.956, 0.976, 0.904, 0.968, 0.956, 0.944, 0.876, 0.82, 0.968, 0.976, 0.984, 0.916, 0.924, 0.76, 0.88, 0.976, 0.972, 0.512, 0.944, 0.9, 0.92, 0.944, 0.672, 0.94, 0.824, 0.836, 0.984, 0.844, 0.956, 0.928, 0.984, 0.984, 0.852, 0.488, 0.936, 0.892, 0.812, 0.952, 0.868, 0.8, 0.888], 'micro': 0.8481, 'macro': 0.8418, 'weighted': 0.8397}
2024-07-17 05:58:28 - [34m[1mLOGS   [0m - Best checkpoint with score 81.54 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:58:30 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_79.9883.pt
2024-07-17 05:58:30 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_80.0586.pt', 'checkpoint_score_80.6953.pt', 'checkpoint_score_80.9023.pt', 'checkpoint_score_81.2461.pt', 'checkpoint_score_81.5391.pt']
2024-07-17 05:58:35 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:58:38 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:58:39 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:58:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 85/iteration 9628 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_85_iter_9628.pt
2024-07-17 05:58:43 - [34m[1mLOGS   [0m - Model state for epoch 85/iteration 9628 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_85_iter_9628.pt
[31m===========================================================================[0m
2024-07-17 05:58:45 - [32m[1mINFO   [0m - Training epoch 86
2024-07-17 05:58:46 - [34m[1mLOGS   [0m - Epoch:  86 [    9629/10000000], loss: {'classification': 1.7052, 'neural_augmentation': 0.7142, 'total_loss': 2.4194}, LR: [8e-06, 8e-06], Avg. batch load time: 0.875, Elapsed time:  1.22
2024-07-17 05:59:09 - [34m[1mLOGS   [0m - *** Training summary for epoch 86
	 loss={'classification': 1.7812, 'neural_augmentation': 0.7184, 'total_loss': 2.4996}
2024-07-17 05:59:20 - [34m[1mLOGS   [0m - *** Validation summary for epoch 86
	 loss={'classification': 0.7656, 'neural_augmentation': 0.0, 'total_loss': 0.7656} || top1={'logits': 82.0742} || top5={'logits': 95.8008} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6106, 0.7943, 0.8455, 0.8884, 0.8191, 0.7647, 0.8485, 0.9212, 0.5431, 0.6372, 0.7526, 0.8654, 0.8164, 0.8127, 0.8379, 0.7732, 0.8337, 0.6457, 0.7658, 0.7788, 0.9012, 0.7126, 0.5559, 0.8428, 0.8663, 0.874, 0.722, 0.9027, 0.8337, 0.8805, 0.9339, 0.7686, 0.8927, 0.992, 0.8809, 0.8594, 0.7924, 0.5646, 0.8884, 0.5602, 0.8327, 0.8039, 0.7692, 0.8419, 0.8607, 0.8803, 0.75, 0.7105, 0.8088, 0.6821, 0.7269, 0.8852, 0.8519, 0.748, 0.9344, 0.8722, 0.6488, 0.7871, 0.6465, 0.7202, 0.8456, 0.9374, 0.8108, 0.9366, 0.8944, 0.8908, 0.7899, 0.7455, 0.8784, 0.9512, 0.932, 0.847, 0.8837, 0.6571, 0.8086, 0.8907, 0.883, 0.5196, 0.893, 0.8139, 0.8211, 0.834, 0.5996, 0.8917, 0.7442, 0.7251, 0.9012, 0.742, 0.9244, 0.7935, 0.9508, 0.9504, 0.7718, 0.5092, 0.815, 0.8559, 0.7403, 0.8852, 0.7727, 0.7303, 0.8638], 'AP': [0.642, 0.861, 0.9062, 0.9313, 0.8585, 0.8087, 0.8987, 0.9639, 0.5253, 0.6744, 0.8069, 0.9092, 0.8691, 0.8954, 0.87, 0.8028, 0.8886, 0.6904, 0.8023, 0.8412, 0.9453, 0.7753, 0.5158, 0.8843, 0.8948, 0.9353, 0.7877, 0.9232, 0.8995, 0.9296, 0.9569, 0.8258, 0.9222, 0.9996, 0.9176, 0.9151, 0.8474, 0.5697, 0.9303, 0.5887, 0.8992, 0.8405, 0.8283, 0.8876, 0.898, 0.9416, 0.8189, 0.7449, 0.8939, 0.7525, 0.7825, 0.9513, 0.8821, 0.7928, 0.968, 0.9147, 0.6589, 0.8176, 0.7104, 0.7707, 0.9175, 0.969, 0.8669, 0.9637, 0.9391, 0.9294, 0.8358, 0.7699, 0.9328, 0.9666, 0.9602, 0.901, 0.9141, 0.6777, 0.8523, 0.943, 0.9341, 0.5349, 0.9341, 0.8744, 0.8803, 0.8957, 0.615, 0.9098, 0.8036, 0.7923, 0.9536, 0.7922, 0.9526, 0.8568, 0.9682, 0.9775, 0.8133, 0.4866, 0.8883, 0.897, 0.7795, 0.9413, 0.8032, 0.7648, 0.888], 'Recall@P=50': [0.7233, 0.9157, 0.94, 0.948, 0.904, 0.852, 0.948, 0.98, 0.592, 0.72, 0.86, 0.932, 0.9, 0.944, 0.872, 0.82, 0.908, 0.72, 0.848, 0.892, 0.976, 0.84, 0.532, 0.896, 0.948, 0.964, 0.824, 0.948, 0.92, 0.956, 0.956, 0.872, 0.952, 1.0, 0.936, 0.936, 0.888, 0.612, 0.956, 0.592, 0.948, 0.916, 0.884, 0.924, 0.916, 0.984, 0.836, 0.772, 0.936, 0.824, 0.848, 0.984, 0.916, 0.892, 0.984, 0.924, 0.668, 0.856, 0.78, 0.832, 0.948, 0.98, 0.908, 0.964, 0.948, 0.936, 0.872, 0.804, 0.96, 0.98, 0.98, 0.936, 0.928, 0.744, 0.868, 0.976, 0.98, 0.52, 0.944, 0.896, 0.924, 0.936, 0.676, 0.94, 0.836, 0.856, 0.98, 0.86, 0.96, 0.924, 0.98, 0.988, 0.876, 0.472, 0.936, 0.896, 0.808, 0.964, 0.86, 0.82, 0.884], 'micro': 0.8518, 'macro': 0.8459, 'weighted': 0.844}
2024-07-17 05:59:24 - [34m[1mLOGS   [0m - Best checkpoint with score 82.07 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 05:59:25 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_80.0586.pt
2024-07-17 05:59:25 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_80.6953.pt', 'checkpoint_score_80.9023.pt', 'checkpoint_score_81.2461.pt', 'checkpoint_score_81.5391.pt', 'checkpoint_score_82.0742.pt']
2024-07-17 05:59:31 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 05:59:33 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 05:59:34 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 05:59:37 - [34m[1mLOGS   [0m - Training checkpoint for epoch 86/iteration 9737 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_86_iter_9737.pt
2024-07-17 05:59:38 - [34m[1mLOGS   [0m - Model state for epoch 86/iteration 9737 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_86_iter_9737.pt
[31m===========================================================================[0m
2024-07-17 05:59:40 - [32m[1mINFO   [0m - Training epoch 87
2024-07-17 05:59:41 - [34m[1mLOGS   [0m - Epoch:  87 [    9738/10000000], loss: {'classification': 1.6871, 'neural_augmentation': 0.7373, 'total_loss': 2.4244}, LR: [8e-06, 8e-06], Avg. batch load time: 0.431, Elapsed time:  0.69
2024-07-17 06:00:04 - [34m[1mLOGS   [0m - *** Training summary for epoch 87
	 loss={'classification': 1.774, 'neural_augmentation': 0.7292, 'total_loss': 2.5032}
2024-07-17 06:00:12 - [33m[1mWARNING[0m - Found recall at precision 0.516245487364621 when recall at precision 0.5 was requested.
2024-07-17 06:00:14 - [34m[1mLOGS   [0m - *** Validation summary for epoch 87
	 loss={'classification': 0.7579, 'neural_augmentation': 0.0, 'total_loss': 0.7579} || top1={'logits': 82.2969} || top5={'logits': 95.8516} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6165, 0.7929, 0.8488, 0.8925, 0.8207, 0.7676, 0.8486, 0.9228, 0.5438, 0.6466, 0.7649, 0.8624, 0.8166, 0.8102, 0.8426, 0.7734, 0.8512, 0.6467, 0.7646, 0.7883, 0.9012, 0.7221, 0.5559, 0.8379, 0.8697, 0.8735, 0.7224, 0.9042, 0.8441, 0.879, 0.9358, 0.7742, 0.896, 0.992, 0.8814, 0.8659, 0.7992, 0.569, 0.8843, 0.5727, 0.8374, 0.8116, 0.7796, 0.8124, 0.8624, 0.8782, 0.7627, 0.7069, 0.8147, 0.6834, 0.7458, 0.8879, 0.8419, 0.742, 0.9356, 0.872, 0.6595, 0.7795, 0.6479, 0.7158, 0.8399, 0.9384, 0.8091, 0.94, 0.9015, 0.8903, 0.7951, 0.755, 0.8839, 0.9482, 0.9309, 0.8541, 0.8866, 0.6638, 0.8107, 0.8907, 0.8848, 0.5247, 0.8973, 0.8264, 0.8058, 0.8252, 0.6076, 0.8898, 0.7559, 0.728, 0.9034, 0.7437, 0.9206, 0.8129, 0.9593, 0.948, 0.7835, 0.5181, 0.8156, 0.8547, 0.7595, 0.8903, 0.7689, 0.7179, 0.8608], 'AP': [0.6474, 0.8648, 0.9083, 0.9311, 0.8633, 0.809, 0.8963, 0.9648, 0.5356, 0.6937, 0.8115, 0.912, 0.8751, 0.8962, 0.8723, 0.8041, 0.8935, 0.6954, 0.8115, 0.8494, 0.9474, 0.7786, 0.5141, 0.8795, 0.9012, 0.9353, 0.7917, 0.9259, 0.9058, 0.9301, 0.9596, 0.8345, 0.9241, 0.9997, 0.9188, 0.9189, 0.8544, 0.5685, 0.9275, 0.5941, 0.8984, 0.8463, 0.8411, 0.8734, 0.8992, 0.9479, 0.8238, 0.7511, 0.8975, 0.7566, 0.7989, 0.9507, 0.881, 0.7815, 0.9686, 0.9176, 0.6808, 0.8244, 0.7159, 0.7727, 0.9185, 0.9659, 0.8677, 0.9626, 0.9394, 0.9305, 0.8444, 0.7853, 0.9334, 0.9639, 0.9616, 0.9044, 0.9171, 0.689, 0.8537, 0.9394, 0.9398, 0.5462, 0.9387, 0.8812, 0.8788, 0.8931, 0.6195, 0.9139, 0.803, 0.7947, 0.9543, 0.796, 0.9522, 0.8676, 0.9691, 0.976, 0.8258, 0.4948, 0.8897, 0.9021, 0.7883, 0.9449, 0.8047, 0.7617, 0.8868], 'Recall@P=50': [0.7391, 0.9215, 0.94, 0.94, 0.904, 0.848, 0.944, 0.984, 0.568, 0.736, 0.864, 0.94, 0.9, 0.944, 0.868, 0.82, 0.912, 0.732, 0.852, 0.888, 0.964, 0.848, 0.532, 0.88, 0.952, 0.956, 0.828, 0.948, 0.924, 0.956, 0.96, 0.876, 0.944, 1.0, 0.94, 0.936, 0.9, 0.612, 0.952, 0.572, 0.952, 0.928, 0.884, 0.928, 0.916, 0.984, 0.836, 0.784, 0.944, 0.784, 0.864, 0.984, 0.92, 0.892, 0.984, 0.94, 0.724, 0.856, 0.776, 0.836, 0.952, 0.976, 0.9, 0.964, 0.948, 0.94, 0.884, 0.824, 0.964, 0.98, 0.984, 0.94, 0.928, 0.796, 0.884, 0.976, 0.98, 0.544, 0.952, 0.904, 0.928, 0.936, 0.684, 0.94, 0.832, 0.852, 0.984, 0.86, 0.964, 0.924, 0.984, 0.976, 0.864, 0.528, 0.944, 0.904, 0.82, 0.964, 0.876, 0.82, 0.88], 'micro': 0.8547, 'macro': 0.8492, 'weighted': 0.8473}
2024-07-17 06:00:19 - [34m[1mLOGS   [0m - Best checkpoint with score 82.30 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:00:20 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_80.6953.pt
2024-07-17 06:00:20 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_80.9023.pt', 'checkpoint_score_81.2461.pt', 'checkpoint_score_81.5391.pt', 'checkpoint_score_82.0742.pt', 'checkpoint_score_82.2969.pt']
2024-07-17 06:00:26 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:00:29 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:00:30 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:00:33 - [34m[1mLOGS   [0m - Training checkpoint for epoch 87/iteration 9846 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_87_iter_9846.pt
2024-07-17 06:00:34 - [34m[1mLOGS   [0m - Model state for epoch 87/iteration 9846 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_87_iter_9846.pt
[31m===========================================================================[0m
2024-07-17 06:00:36 - [32m[1mINFO   [0m - Training epoch 88
2024-07-17 06:00:37 - [34m[1mLOGS   [0m - Epoch:  88 [    9847/10000000], loss: {'classification': 1.6187, 'neural_augmentation': 0.7387, 'total_loss': 2.3574}, LR: [7e-06, 7e-06], Avg. batch load time: 0.883, Elapsed time:  1.10
2024-07-17 06:00:58 - [34m[1mLOGS   [0m - *** Training summary for epoch 88
	 loss={'classification': 1.7622, 'neural_augmentation': 0.7382, 'total_loss': 2.5003}
2024-07-17 06:01:09 - [34m[1mLOGS   [0m - *** Validation summary for epoch 88
	 loss={'classification': 0.7486, 'neural_augmentation': 0.0, 'total_loss': 0.7486} || top1={'logits': 82.3672} || top5={'logits': 95.8672} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6202, 0.7965, 0.8552, 0.8943, 0.8264, 0.7686, 0.8548, 0.9249, 0.5428, 0.6462, 0.756, 0.8689, 0.8193, 0.8165, 0.8414, 0.7768, 0.8602, 0.6495, 0.7766, 0.7822, 0.8981, 0.729, 0.5566, 0.834, 0.8725, 0.8833, 0.7228, 0.9012, 0.8513, 0.8814, 0.9405, 0.7808, 0.8998, 0.992, 0.8861, 0.8732, 0.7992, 0.5675, 0.8826, 0.5667, 0.8489, 0.8113, 0.7789, 0.8258, 0.8642, 0.8813, 0.7626, 0.71, 0.8214, 0.6881, 0.7427, 0.8846, 0.8434, 0.7579, 0.9412, 0.8708, 0.6638, 0.7894, 0.6604, 0.7245, 0.8495, 0.9376, 0.8133, 0.9414, 0.8973, 0.8921, 0.7952, 0.7559, 0.883, 0.9508, 0.9231, 0.841, 0.8875, 0.6694, 0.8075, 0.8902, 0.8902, 0.524, 0.8951, 0.8222, 0.813, 0.844, 0.5923, 0.8954, 0.7627, 0.7249, 0.9008, 0.75, 0.9224, 0.8039, 0.9512, 0.9469, 0.7826, 0.5085, 0.8203, 0.8619, 0.7636, 0.8952, 0.7719, 0.722, 0.8621], 'AP': [0.6549, 0.8654, 0.9116, 0.935, 0.8645, 0.8123, 0.9008, 0.9642, 0.5387, 0.7008, 0.8138, 0.9206, 0.8736, 0.8987, 0.873, 0.8058, 0.8982, 0.7007, 0.816, 0.8478, 0.9434, 0.786, 0.5105, 0.8797, 0.9002, 0.938, 0.7895, 0.9267, 0.9052, 0.9317, 0.9612, 0.8389, 0.9249, 0.9997, 0.9205, 0.919, 0.8546, 0.5726, 0.9319, 0.6052, 0.9102, 0.8407, 0.8406, 0.8831, 0.8974, 0.9485, 0.8253, 0.7549, 0.8987, 0.7584, 0.8, 0.9569, 0.8872, 0.7944, 0.969, 0.9157, 0.6772, 0.8277, 0.7265, 0.7703, 0.9212, 0.9671, 0.8729, 0.9644, 0.942, 0.9318, 0.8468, 0.7826, 0.938, 0.9626, 0.9609, 0.9005, 0.9202, 0.6966, 0.8593, 0.9435, 0.945, 0.5482, 0.9388, 0.883, 0.8861, 0.9003, 0.6173, 0.913, 0.8088, 0.7902, 0.9552, 0.794, 0.9542, 0.8613, 0.9681, 0.9754, 0.828, 0.4878, 0.8923, 0.9055, 0.7935, 0.9467, 0.8108, 0.759, 0.8944], 'Recall@P=50': [0.7312, 0.9041, 0.936, 0.952, 0.908, 0.844, 0.948, 0.984, 0.564, 0.752, 0.86, 0.94, 0.9, 0.952, 0.876, 0.82, 0.912, 0.736, 0.856, 0.896, 0.972, 0.84, 0.516, 0.88, 0.96, 0.96, 0.824, 0.948, 0.928, 0.96, 0.964, 0.896, 0.948, 1.0, 0.944, 0.936, 0.904, 0.612, 0.96, 0.596, 0.948, 0.92, 0.892, 0.924, 0.908, 0.988, 0.848, 0.78, 0.944, 0.788, 0.86, 0.988, 0.932, 0.896, 0.984, 0.928, 0.688, 0.856, 0.776, 0.832, 0.952, 0.976, 0.912, 0.972, 0.956, 0.944, 0.876, 0.824, 0.968, 0.98, 0.98, 0.936, 0.936, 0.784, 0.892, 0.976, 0.98, 0.536, 0.952, 0.912, 0.928, 0.94, 0.684, 0.94, 0.844, 0.848, 0.984, 0.856, 0.964, 0.928, 0.98, 0.98, 0.856, 0.484, 0.936, 0.908, 0.816, 0.964, 0.872, 0.824, 0.9], 'micro': 0.8577, 'macro': 0.8513, 'weighted': 0.8494}
2024-07-17 06:01:13 - [34m[1mLOGS   [0m - Best checkpoint with score 82.37 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:01:14 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_80.9023.pt
2024-07-17 06:01:14 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_81.2461.pt', 'checkpoint_score_81.5391.pt', 'checkpoint_score_82.0742.pt', 'checkpoint_score_82.2969.pt', 'checkpoint_score_82.3672.pt']
2024-07-17 06:01:20 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:01:23 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:01:24 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:01:27 - [34m[1mLOGS   [0m - Training checkpoint for epoch 88/iteration 9950 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_88_iter_9950.pt
2024-07-17 06:01:28 - [34m[1mLOGS   [0m - Model state for epoch 88/iteration 9950 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_88_iter_9950.pt
[31m===========================================================================[0m
2024-07-17 06:01:30 - [32m[1mINFO   [0m - Training epoch 89
2024-07-17 06:01:31 - [34m[1mLOGS   [0m - Epoch:  89 [    9951/10000000], loss: {'classification': 1.6414, 'neural_augmentation': 0.7382, 'total_loss': 2.3795}, LR: [7e-06, 7e-06], Avg. batch load time: 0.548, Elapsed time:  0.77
2024-07-17 06:01:56 - [34m[1mLOGS   [0m - *** Training summary for epoch 89
	 loss={'classification': 1.7415, 'neural_augmentation': 0.7477, 'total_loss': 2.4892}
2024-07-17 06:02:07 - [34m[1mLOGS   [0m - *** Validation summary for epoch 89
	 loss={'classification': 0.7451, 'neural_augmentation': 0.0, 'total_loss': 0.7451} || top1={'logits': 82.6641} || top5={'logits': 96.0} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6159, 0.7976, 0.8565, 0.8934, 0.8242, 0.7702, 0.8583, 0.9234, 0.5564, 0.657, 0.7574, 0.8689, 0.8114, 0.8326, 0.8455, 0.7768, 0.8519, 0.6535, 0.778, 0.7899, 0.9019, 0.7178, 0.5615, 0.8504, 0.8685, 0.8803, 0.735, 0.9053, 0.8425, 0.8838, 0.9431, 0.7817, 0.896, 0.992, 0.8861, 0.866, 0.7957, 0.5656, 0.8834, 0.5761, 0.856, 0.8155, 0.7866, 0.8233, 0.8571, 0.8875, 0.7608, 0.7162, 0.8299, 0.6833, 0.7335, 0.8841, 0.8473, 0.7611, 0.9398, 0.8789, 0.6567, 0.7863, 0.6654, 0.7261, 0.8427, 0.9355, 0.8103, 0.9438, 0.9064, 0.8916, 0.7959, 0.7632, 0.882, 0.9528, 0.929, 0.8537, 0.8926, 0.6641, 0.8195, 0.8907, 0.8857, 0.5247, 0.8964, 0.8223, 0.8189, 0.8376, 0.6016, 0.8894, 0.7619, 0.753, 0.9028, 0.7526, 0.9314, 0.8247, 0.9506, 0.9528, 0.7815, 0.5174, 0.8287, 0.869, 0.7672, 0.9034, 0.7743, 0.7353, 0.8608], 'AP': [0.6499, 0.8672, 0.9133, 0.9299, 0.8638, 0.8201, 0.9023, 0.9654, 0.5526, 0.6987, 0.8227, 0.9182, 0.8681, 0.9102, 0.8726, 0.8082, 0.8988, 0.7046, 0.8186, 0.8517, 0.942, 0.7775, 0.5154, 0.8872, 0.9045, 0.9375, 0.7972, 0.9258, 0.9013, 0.9283, 0.9639, 0.8342, 0.9226, 0.9997, 0.9218, 0.9193, 0.8518, 0.5788, 0.9301, 0.5999, 0.9105, 0.8266, 0.8426, 0.891, 0.8991, 0.951, 0.8275, 0.7597, 0.8994, 0.7618, 0.8006, 0.9551, 0.8846, 0.7904, 0.9695, 0.9167, 0.6784, 0.8327, 0.7215, 0.7737, 0.9187, 0.9671, 0.8685, 0.9667, 0.9446, 0.9332, 0.8527, 0.7884, 0.9381, 0.966, 0.9612, 0.9039, 0.9237, 0.6925, 0.8585, 0.9449, 0.941, 0.5572, 0.9397, 0.8823, 0.8908, 0.9064, 0.6182, 0.9132, 0.8099, 0.8057, 0.9555, 0.7985, 0.954, 0.8664, 0.9694, 0.9777, 0.8265, 0.4944, 0.8945, 0.9099, 0.7961, 0.9492, 0.8086, 0.7735, 0.8896], 'Recall@P=50': [0.7352, 0.9128, 0.94, 0.944, 0.908, 0.844, 0.948, 0.98, 0.592, 0.756, 0.86, 0.94, 0.896, 0.968, 0.868, 0.828, 0.916, 0.728, 0.86, 0.884, 0.968, 0.84, 0.536, 0.892, 0.972, 0.968, 0.82, 0.952, 0.92, 0.964, 0.964, 0.868, 0.944, 1.0, 0.944, 0.932, 0.896, 0.624, 0.96, 0.588, 0.952, 0.008, 0.892, 0.932, 0.924, 0.988, 0.864, 0.8, 0.952, 0.812, 0.86, 0.984, 0.924, 0.892, 0.984, 0.928, 0.72, 0.856, 0.78, 0.832, 0.952, 0.976, 0.916, 0.972, 0.956, 0.944, 0.896, 0.828, 0.968, 0.98, 0.98, 0.932, 0.928, 0.784, 0.888, 0.984, 0.976, 0.536, 0.956, 0.908, 0.928, 0.944, 0.664, 0.94, 0.836, 0.856, 0.984, 0.852, 0.96, 0.904, 0.984, 0.98, 0.868, 0.5, 0.936, 0.916, 0.816, 0.968, 0.868, 0.828, 0.892], 'micro': 0.8596, 'macro': 0.8527, 'weighted': 0.8507}
2024-07-17 06:02:11 - [34m[1mLOGS   [0m - Best checkpoint with score 82.66 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:02:12 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_81.2461.pt
2024-07-17 06:02:12 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_81.5391.pt', 'checkpoint_score_82.0742.pt', 'checkpoint_score_82.2969.pt', 'checkpoint_score_82.3672.pt', 'checkpoint_score_82.6641.pt']
2024-07-17 06:02:18 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:02:21 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:02:22 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:02:25 - [34m[1mLOGS   [0m - Training checkpoint for epoch 89/iteration 10069 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_89_iter_10069.pt
2024-07-17 06:02:26 - [34m[1mLOGS   [0m - Model state for epoch 89/iteration 10069 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_89_iter_10069.pt
[31m===========================================================================[0m
2024-07-17 06:02:28 - [32m[1mINFO   [0m - Training epoch 90
2024-07-17 06:02:29 - [34m[1mLOGS   [0m - Epoch:  90 [   10070/10000000], loss: {'classification': 1.6519, 'neural_augmentation': 0.7484, 'total_loss': 2.4003}, LR: [7e-06, 7e-06], Avg. batch load time: 0.791, Elapsed time:  1.00
2024-07-17 06:02:51 - [34m[1mLOGS   [0m - *** Training summary for epoch 90
	 loss={'classification': 1.7405, 'neural_augmentation': 0.7573, 'total_loss': 2.4979}
2024-07-17 06:03:00 - [33m[1mWARNING[0m - Found recall at precision 0.5220588235294118 when recall at precision 0.5 was requested.
2024-07-17 06:03:02 - [34m[1mLOGS   [0m - *** Validation summary for epoch 90
	 loss={'classification': 0.7303, 'neural_augmentation': 0.0, 'total_loss': 0.7303} || top1={'logits': 82.8711} || top5={'logits': 96.2148} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6363, 0.8035, 0.8571, 0.8938, 0.8216, 0.7811, 0.8522, 0.9339, 0.5598, 0.6566, 0.7683, 0.8683, 0.8333, 0.8132, 0.8559, 0.7845, 0.8537, 0.6637, 0.7837, 0.7884, 0.8998, 0.7303, 0.569, 0.8529, 0.8795, 0.8765, 0.7353, 0.9012, 0.8462, 0.8821, 0.9472, 0.791, 0.8983, 0.994, 0.8842, 0.868, 0.8052, 0.5621, 0.8898, 0.5747, 0.852, 0.8169, 0.7771, 0.8417, 0.863, 0.888, 0.7682, 0.7284, 0.8309, 0.6932, 0.7536, 0.8912, 0.8476, 0.7485, 0.939, 0.8766, 0.6667, 0.7948, 0.6578, 0.7348, 0.8498, 0.9435, 0.8206, 0.94, 0.9068, 0.8992, 0.8071, 0.7597, 0.8943, 0.9535, 0.9259, 0.8495, 0.8946, 0.668, 0.817, 0.8876, 0.8893, 0.5311, 0.8984, 0.821, 0.816, 0.8408, 0.6107, 0.8936, 0.7627, 0.7574, 0.9084, 0.7598, 0.9244, 0.8097, 0.9571, 0.9524, 0.7992, 0.5122, 0.8294, 0.8728, 0.7611, 0.897, 0.7819, 0.7281, 0.8638], 'AP': [0.6707, 0.8676, 0.9176, 0.9356, 0.8675, 0.8179, 0.9037, 0.9662, 0.5514, 0.6951, 0.8321, 0.9225, 0.8844, 0.9004, 0.8766, 0.8125, 0.9018, 0.7055, 0.824, 0.8507, 0.9457, 0.7885, 0.5335, 0.8919, 0.9097, 0.9375, 0.8022, 0.9257, 0.9029, 0.9304, 0.9651, 0.8493, 0.9269, 0.9997, 0.9206, 0.9243, 0.8602, 0.578, 0.9379, 0.6065, 0.9102, 0.8489, 0.8418, 0.9021, 0.9044, 0.9493, 0.8323, 0.7715, 0.9056, 0.7713, 0.8109, 0.9584, 0.8805, 0.787, 0.9693, 0.9212, 0.6865, 0.836, 0.7203, 0.7837, 0.9206, 0.9682, 0.8791, 0.9662, 0.9447, 0.9366, 0.8541, 0.7874, 0.9383, 0.9655, 0.9633, 0.9034, 0.9248, 0.7017, 0.8659, 0.9407, 0.942, 0.5516, 0.9429, 0.8889, 0.8915, 0.903, 0.631, 0.9159, 0.8132, 0.808, 0.9605, 0.8074, 0.9562, 0.8722, 0.9709, 0.9777, 0.8385, 0.4999, 0.8968, 0.9102, 0.7998, 0.9508, 0.8162, 0.7746, 0.8896], 'Recall@P=50': [0.7628, 0.9041, 0.94, 0.952, 0.908, 0.852, 0.948, 0.98, 0.6, 0.752, 0.868, 0.94, 0.904, 0.948, 0.876, 0.828, 0.92, 0.728, 0.872, 0.884, 0.968, 0.856, 0.568, 0.896, 0.964, 0.972, 0.832, 0.952, 0.928, 0.96, 0.968, 0.888, 0.944, 1.0, 0.944, 0.936, 0.9, 0.624, 0.972, 0.58, 0.952, 0.932, 0.896, 0.94, 0.924, 0.984, 0.864, 0.8, 0.94, 0.844, 0.876, 0.988, 0.932, 0.892, 0.984, 0.952, 0.732, 0.868, 0.784, 0.848, 0.956, 0.976, 0.92, 0.98, 0.956, 0.944, 0.888, 0.832, 0.964, 0.98, 0.984, 0.936, 0.928, 0.78, 0.876, 0.976, 0.976, 0.548, 0.952, 0.916, 0.924, 0.94, 0.688, 0.94, 0.84, 0.86, 0.988, 0.868, 0.964, 0.916, 0.988, 0.984, 0.868, 0.512, 0.94, 0.912, 0.824, 0.972, 0.864, 0.836, 0.888], 'micro': 0.8629, 'macro': 0.8565, 'weighted': 0.8546}
2024-07-17 06:03:06 - [34m[1mLOGS   [0m - Best checkpoint with score 82.87 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:03:08 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_81.5391.pt
2024-07-17 06:03:08 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_82.0742.pt', 'checkpoint_score_82.2969.pt', 'checkpoint_score_82.3672.pt', 'checkpoint_score_82.6641.pt', 'checkpoint_score_82.8711.pt']
2024-07-17 06:03:13 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:03:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:03:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:03:20 - [34m[1mLOGS   [0m - Training checkpoint for epoch 90/iteration 10177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_90_iter_10177.pt
2024-07-17 06:03:21 - [34m[1mLOGS   [0m - Model state for epoch 90/iteration 10177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_90_iter_10177.pt
[31m===========================================================================[0m
2024-07-17 06:03:23 - [32m[1mINFO   [0m - Training epoch 91
2024-07-17 06:03:24 - [34m[1mLOGS   [0m - Epoch:  91 [   10178/10000000], loss: {'classification': 1.6572, 'neural_augmentation': 0.7647, 'total_loss': 2.4218}, LR: [7e-06, 7e-06], Avg. batch load time: 0.781, Elapsed time:  0.99
2024-07-17 06:03:49 - [34m[1mLOGS   [0m - *** Training summary for epoch 91
	 loss={'classification': 1.7216, 'neural_augmentation': 0.7662, 'total_loss': 2.4878}
2024-07-17 06:03:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 91
	 loss={'classification': 0.7229, 'neural_augmentation': 0.0, 'total_loss': 0.7229} || top1={'logits': 83.0859} || top5={'logits': 96.2148} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6338, 0.8098, 0.8766, 0.8908, 0.8299, 0.7734, 0.8537, 0.9303, 0.5628, 0.6613, 0.7689, 0.8699, 0.8208, 0.828, 0.8571, 0.7722, 0.8619, 0.6601, 0.7864, 0.7974, 0.9069, 0.7211, 0.578, 0.8453, 0.8794, 0.8826, 0.7371, 0.9021, 0.8541, 0.8893, 0.9489, 0.7992, 0.8996, 0.992, 0.8875, 0.8764, 0.8034, 0.5745, 0.8948, 0.5794, 0.8566, 0.8189, 0.7967, 0.8238, 0.8641, 0.8816, 0.764, 0.7303, 0.8388, 0.694, 0.75, 0.8902, 0.8446, 0.7735, 0.9506, 0.8853, 0.6623, 0.8068, 0.6667, 0.7429, 0.8537, 0.9405, 0.8268, 0.9429, 0.9053, 0.8964, 0.8043, 0.7604, 0.8866, 0.9533, 0.9293, 0.8583, 0.8974, 0.6793, 0.8277, 0.8845, 0.882, 0.5378, 0.9038, 0.8202, 0.8214, 0.8462, 0.6115, 0.8932, 0.777, 0.751, 0.9073, 0.7696, 0.9289, 0.8261, 0.9556, 0.9551, 0.8077, 0.522, 0.8207, 0.8658, 0.7627, 0.9064, 0.7803, 0.7314, 0.8608], 'AP': [0.6726, 0.8727, 0.9228, 0.9292, 0.8727, 0.8169, 0.903, 0.9655, 0.56, 0.7078, 0.832, 0.9243, 0.8794, 0.9071, 0.8767, 0.813, 0.9089, 0.7092, 0.827, 0.8572, 0.9467, 0.7802, 0.5331, 0.8867, 0.9122, 0.9387, 0.8005, 0.9283, 0.9049, 0.9322, 0.966, 0.8528, 0.9275, 0.9997, 0.9246, 0.9273, 0.856, 0.5859, 0.9362, 0.6123, 0.9148, 0.8496, 0.8479, 0.8952, 0.906, 0.9468, 0.8382, 0.7741, 0.9056, 0.7657, 0.8137, 0.9597, 0.8839, 0.8108, 0.9701, 0.9243, 0.6912, 0.8476, 0.7165, 0.7917, 0.9249, 0.9698, 0.8877, 0.9695, 0.9438, 0.9392, 0.8566, 0.7904, 0.9403, 0.9658, 0.9662, 0.9103, 0.9276, 0.7153, 0.8726, 0.9411, 0.9426, 0.5625, 0.9447, 0.888, 0.8945, 0.9097, 0.6465, 0.9153, 0.8209, 0.8052, 0.9593, 0.8121, 0.9548, 0.8796, 0.9692, 0.9804, 0.8434, 0.4973, 0.8968, 0.909, 0.8046, 0.9548, 0.8126, 0.7743, 0.8895], 'Recall@P=50': [0.7747, 0.9273, 0.94, 0.94, 0.904, 0.836, 0.952, 0.98, 0.604, 0.776, 0.868, 0.952, 0.912, 0.96, 0.872, 0.836, 0.944, 0.708, 0.864, 0.892, 0.96, 0.84, 0.676, 0.888, 0.968, 0.968, 0.832, 0.952, 0.928, 0.964, 0.972, 0.876, 0.944, 1.0, 0.944, 0.944, 0.896, 0.624, 0.96, 0.612, 0.952, 0.94, 0.896, 0.94, 0.924, 0.984, 0.864, 0.82, 0.944, 0.832, 0.864, 0.988, 0.924, 0.912, 0.984, 0.952, 0.752, 0.88, 0.784, 0.852, 0.952, 0.976, 0.924, 0.98, 0.952, 0.948, 0.892, 0.84, 0.972, 0.98, 0.984, 0.944, 0.932, 0.772, 0.888, 0.984, 0.984, 0.548, 0.96, 0.916, 0.928, 0.94, 0.708, 0.944, 0.848, 0.864, 0.98, 0.872, 0.96, 0.936, 0.988, 0.984, 0.868, 0.468, 0.944, 0.912, 0.816, 0.972, 0.868, 0.844, 0.912], 'micro': 0.8649, 'macro': 0.8589, 'weighted': 0.8571}
2024-07-17 06:04:04 - [34m[1mLOGS   [0m - Best checkpoint with score 83.09 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:04:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_82.0742.pt
2024-07-17 06:04:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_82.2969.pt', 'checkpoint_score_82.3672.pt', 'checkpoint_score_82.6641.pt', 'checkpoint_score_82.8711.pt', 'checkpoint_score_83.0859.pt']
2024-07-17 06:04:11 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:04:14 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:04:15 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:04:18 - [34m[1mLOGS   [0m - Training checkpoint for epoch 91/iteration 10293 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_91_iter_10293.pt
2024-07-17 06:04:19 - [34m[1mLOGS   [0m - Model state for epoch 91/iteration 10293 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_91_iter_10293.pt
[31m===========================================================================[0m
2024-07-17 06:04:21 - [32m[1mINFO   [0m - Training epoch 92
2024-07-17 06:04:22 - [34m[1mLOGS   [0m - Epoch:  92 [   10294/10000000], loss: {'classification': 1.6202, 'neural_augmentation': 0.7722, 'total_loss': 2.3924}, LR: [6e-06, 6e-06], Avg. batch load time: 0.598, Elapsed time:  0.81
2024-07-17 06:04:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 92
	 loss={'classification': 1.7288, 'neural_augmentation': 0.7753, 'total_loss': 2.5041}
2024-07-17 06:04:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 92
	 loss={'classification': 0.7129, 'neural_augmentation': 0.0, 'total_loss': 0.7129} || top1={'logits': 83.1719} || top5={'logits': 96.2305} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6321, 0.8062, 0.8681, 0.8952, 0.8398, 0.7788, 0.8537, 0.9322, 0.5693, 0.66, 0.7725, 0.8771, 0.8337, 0.8277, 0.8578, 0.7696, 0.8637, 0.6706, 0.7942, 0.7974, 0.914, 0.7232, 0.5646, 0.8559, 0.8821, 0.884, 0.7361, 0.9072, 0.8547, 0.8857, 0.9493, 0.796, 0.8968, 0.994, 0.887, 0.8712, 0.8059, 0.5816, 0.8921, 0.5821, 0.8664, 0.8281, 0.8017, 0.8381, 0.8645, 0.888, 0.7824, 0.7341, 0.8414, 0.6993, 0.7495, 0.8944, 0.8493, 0.7759, 0.9508, 0.8848, 0.6667, 0.7952, 0.677, 0.7443, 0.856, 0.9353, 0.8249, 0.9452, 0.9057, 0.8998, 0.812, 0.7719, 0.8879, 0.9532, 0.9298, 0.8577, 0.8989, 0.6892, 0.8207, 0.8915, 0.895, 0.5304, 0.9012, 0.8326, 0.8296, 0.848, 0.6298, 0.896, 0.7749, 0.7541, 0.9109, 0.7578, 0.9286, 0.8356, 0.9576, 0.9533, 0.7991, 0.5211, 0.8245, 0.8698, 0.775, 0.9069, 0.787, 0.7269, 0.8655], 'AP': [0.6759, 0.8718, 0.9232, 0.9342, 0.8783, 0.8246, 0.9048, 0.9664, 0.5706, 0.707, 0.8338, 0.927, 0.8862, 0.9114, 0.8795, 0.8152, 0.9096, 0.7143, 0.832, 0.8568, 0.9481, 0.7867, 0.5381, 0.8935, 0.9179, 0.9422, 0.8037, 0.9292, 0.9079, 0.934, 0.9682, 0.8523, 0.9267, 0.9997, 0.9246, 0.9251, 0.863, 0.5924, 0.9374, 0.607, 0.9199, 0.8537, 0.8544, 0.9005, 0.9034, 0.9532, 0.8394, 0.7753, 0.9109, 0.7766, 0.8093, 0.9586, 0.8888, 0.8164, 0.9717, 0.924, 0.6934, 0.8452, 0.7424, 0.7976, 0.9266, 0.9685, 0.8828, 0.9689, 0.9483, 0.9361, 0.8626, 0.8054, 0.9414, 0.9657, 0.9631, 0.9099, 0.9291, 0.7242, 0.8671, 0.9429, 0.9481, 0.571, 0.946, 0.8886, 0.8969, 0.9097, 0.6554, 0.9172, 0.8259, 0.8141, 0.9616, 0.8068, 0.9542, 0.8811, 0.9699, 0.9808, 0.8433, 0.4946, 0.9, 0.9119, 0.8155, 0.9524, 0.8192, 0.7771, 0.8938], 'Recall@P=50': [0.7668, 0.9215, 0.96, 0.948, 0.912, 0.856, 0.952, 0.98, 0.624, 0.764, 0.872, 0.944, 0.912, 0.968, 0.876, 0.84, 0.932, 0.756, 0.872, 0.896, 0.968, 0.848, 0.64, 0.9, 0.968, 0.98, 0.832, 0.96, 0.928, 0.968, 0.972, 0.884, 0.944, 1.0, 0.944, 0.944, 0.896, 0.632, 0.972, 0.608, 0.956, 0.936, 0.904, 0.932, 0.924, 0.984, 0.86, 0.812, 0.952, 0.828, 0.864, 0.984, 0.936, 0.908, 0.984, 0.948, 0.756, 0.88, 0.792, 0.852, 0.96, 0.976, 0.912, 0.98, 0.956, 0.948, 0.892, 0.836, 0.972, 0.98, 0.984, 0.94, 0.936, 0.808, 0.888, 0.98, 0.984, 0.548, 0.964, 0.916, 0.94, 0.94, 0.728, 0.952, 0.852, 0.86, 0.988, 0.86, 0.964, 0.928, 0.988, 0.984, 0.876, 0.528, 0.944, 0.912, 0.832, 0.972, 0.872, 0.836, 0.9], 'micro': 0.8682, 'macro': 0.8617, 'weighted': 0.8599}
2024-07-17 06:05:01 - [34m[1mLOGS   [0m - Best checkpoint with score 83.17 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:05:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_82.2969.pt
2024-07-17 06:05:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_82.3672.pt', 'checkpoint_score_82.6641.pt', 'checkpoint_score_82.8711.pt', 'checkpoint_score_83.0859.pt', 'checkpoint_score_83.1719.pt']
2024-07-17 06:05:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:05:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:05:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:05:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 92/iteration 10403 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_92_iter_10403.pt
2024-07-17 06:05:17 - [34m[1mLOGS   [0m - Model state for epoch 92/iteration 10403 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_92_iter_10403.pt
[31m===========================================================================[0m
2024-07-17 06:05:19 - [32m[1mINFO   [0m - Training epoch 93
2024-07-17 06:05:20 - [34m[1mLOGS   [0m - Epoch:  93 [   10404/10000000], loss: {'classification': 1.5674, 'neural_augmentation': 0.7813, 'total_loss': 2.3488}, LR: [6e-06, 6e-06], Avg. batch load time: 0.859, Elapsed time:  1.07
2024-07-17 06:05:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 93
	 loss={'classification': 1.7029, 'neural_augmentation': 0.7837, 'total_loss': 2.4865}
2024-07-17 06:05:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 93
	 loss={'classification': 0.7017, 'neural_augmentation': 0.0, 'total_loss': 0.7017} || top1={'logits': 83.457} || top5={'logits': 96.3711} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6421, 0.8056, 0.867, 0.9038, 0.8306, 0.7762, 0.8559, 0.9306, 0.565, 0.661, 0.7815, 0.8687, 0.8394, 0.818, 0.859, 0.7834, 0.8637, 0.6761, 0.7939, 0.7948, 0.9177, 0.7299, 0.5821, 0.8491, 0.8889, 0.8822, 0.7484, 0.9091, 0.8527, 0.8921, 0.9412, 0.8057, 0.8974, 0.996, 0.887, 0.8848, 0.8086, 0.585, 0.8963, 0.5941, 0.8624, 0.8279, 0.7942, 0.8485, 0.8643, 0.888, 0.7815, 0.743, 0.8491, 0.7046, 0.7607, 0.8866, 0.851, 0.7754, 0.9448, 0.8821, 0.6711, 0.8026, 0.677, 0.7538, 0.856, 0.9414, 0.8303, 0.9467, 0.9117, 0.8996, 0.808, 0.7651, 0.8833, 0.9553, 0.9309, 0.8548, 0.8955, 0.6739, 0.823, 0.8939, 0.8972, 0.5542, 0.9032, 0.8274, 0.8283, 0.8538, 0.6217, 0.895, 0.7785, 0.7642, 0.9058, 0.7785, 0.9269, 0.8279, 0.9613, 0.9555, 0.8034, 0.5292, 0.8297, 0.8692, 0.7761, 0.9051, 0.788, 0.7432, 0.8674], 'AP': [0.6892, 0.875, 0.9237, 0.9399, 0.8766, 0.8224, 0.91, 0.9679, 0.5579, 0.7041, 0.8356, 0.9268, 0.8933, 0.9025, 0.8796, 0.8181, 0.9062, 0.714, 0.8328, 0.8567, 0.9523, 0.7915, 0.5564, 0.8972, 0.9166, 0.9418, 0.8133, 0.9282, 0.9103, 0.9393, 0.9665, 0.8631, 0.9286, 0.9997, 0.9277, 0.9307, 0.8634, 0.5955, 0.9404, 0.6187, 0.9213, 0.8578, 0.8534, 0.9083, 0.9041, 0.9512, 0.8416, 0.7798, 0.9144, 0.7861, 0.8253, 0.956, 0.8913, 0.8108, 0.9713, 0.9283, 0.6981, 0.8434, 0.7385, 0.8028, 0.9214, 0.971, 0.8905, 0.9703, 0.9473, 0.9389, 0.8619, 0.7975, 0.9417, 0.9637, 0.9653, 0.907, 0.9261, 0.7139, 0.8737, 0.9442, 0.9514, 0.5883, 0.9457, 0.8935, 0.8987, 0.9161, 0.6547, 0.9174, 0.8292, 0.8178, 0.9618, 0.8179, 0.9585, 0.8858, 0.969, 0.9796, 0.845, 0.4979, 0.9003, 0.9109, 0.8158, 0.9542, 0.8202, 0.7828, 0.8952], 'Recall@P=50': [0.7945, 0.9302, 0.952, 0.948, 0.916, 0.864, 0.956, 0.98, 0.616, 0.764, 0.872, 0.948, 0.912, 0.96, 0.884, 0.832, 0.916, 0.728, 0.864, 0.888, 0.972, 0.856, 0.684, 0.9, 0.968, 0.972, 0.844, 0.952, 0.932, 0.968, 0.972, 0.888, 0.948, 1.0, 0.948, 0.948, 0.9, 0.632, 0.976, 0.624, 0.956, 0.936, 0.896, 0.944, 0.92, 0.984, 0.88, 0.816, 0.952, 0.848, 0.876, 0.98, 0.94, 0.908, 0.984, 0.952, 0.744, 0.868, 0.792, 0.856, 0.952, 0.976, 0.92, 0.984, 0.952, 0.952, 0.896, 0.836, 0.968, 0.98, 0.984, 0.94, 0.928, 0.792, 0.888, 0.98, 0.984, 0.576, 0.96, 0.92, 0.94, 0.944, 0.724, 0.952, 0.852, 0.864, 0.984, 0.864, 0.968, 0.932, 0.984, 0.984, 0.868, 0.5, 0.94, 0.912, 0.84, 0.976, 0.876, 0.836, 0.904], 'micro': 0.8692, 'macro': 0.8638, 'weighted': 0.8621}
2024-07-17 06:06:00 - [34m[1mLOGS   [0m - Best checkpoint with score 83.46 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:06:02 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_82.3672.pt
2024-07-17 06:06:02 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_82.6641.pt', 'checkpoint_score_82.8711.pt', 'checkpoint_score_83.0859.pt', 'checkpoint_score_83.1719.pt', 'checkpoint_score_83.4570.pt']
2024-07-17 06:06:08 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:06:11 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:06:12 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:06:17 - [34m[1mLOGS   [0m - Training checkpoint for epoch 93/iteration 10525 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_93_iter_10525.pt
2024-07-17 06:06:19 - [34m[1mLOGS   [0m - Model state for epoch 93/iteration 10525 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_93_iter_10525.pt
[31m===========================================================================[0m
2024-07-17 06:06:21 - [32m[1mINFO   [0m - Training epoch 94
2024-07-17 06:06:23 - [34m[1mLOGS   [0m - Epoch:  94 [   10526/10000000], loss: {'classification': 1.846, 'neural_augmentation': 0.7942, 'total_loss': 2.6402}, LR: [6e-06, 6e-06], Avg. batch load time: 1.704, Elapsed time:  1.92
2024-07-17 06:06:45 - [34m[1mLOGS   [0m - *** Training summary for epoch 94
	 loss={'classification': 1.6992, 'neural_augmentation': 0.792, 'total_loss': 2.4912}
2024-07-17 06:06:56 - [34m[1mLOGS   [0m - *** Validation summary for epoch 94
	 loss={'classification': 0.6982, 'neural_augmentation': 0.0, 'total_loss': 0.6982} || top1={'logits': 83.5547} || top5={'logits': 96.3672} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6485, 0.8072, 0.8739, 0.8974, 0.8233, 0.7742, 0.8615, 0.9363, 0.5683, 0.6705, 0.7828, 0.8701, 0.835, 0.822, 0.8577, 0.7877, 0.8619, 0.6726, 0.8008, 0.8071, 0.916, 0.7304, 0.588, 0.8596, 0.8867, 0.8844, 0.749, 0.9129, 0.8601, 0.8852, 0.9431, 0.81, 0.8987, 0.994, 0.8861, 0.8831, 0.8114, 0.5714, 0.8912, 0.588, 0.8671, 0.8327, 0.8084, 0.8304, 0.8655, 0.8911, 0.7836, 0.7328, 0.8496, 0.7161, 0.7649, 0.8916, 0.849, 0.7778, 0.9448, 0.8875, 0.6735, 0.8009, 0.6798, 0.7394, 0.856, 0.9461, 0.8228, 0.953, 0.908, 0.8983, 0.8154, 0.7651, 0.8853, 0.9553, 0.9342, 0.8606, 0.8988, 0.6766, 0.8277, 0.8889, 0.8964, 0.545, 0.9019, 0.8212, 0.8423, 0.8542, 0.6218, 0.8954, 0.7773, 0.7775, 0.908, 0.7778, 0.9244, 0.8317, 0.959, 0.9574, 0.8093, 0.5287, 0.8257, 0.8821, 0.7804, 0.9072, 0.7876, 0.7343, 0.8692], 'AP': [0.6916, 0.873, 0.925, 0.9389, 0.8741, 0.8266, 0.9093, 0.9688, 0.5691, 0.7141, 0.8411, 0.9283, 0.8902, 0.9092, 0.8802, 0.818, 0.9128, 0.7214, 0.8372, 0.8654, 0.9522, 0.7935, 0.5537, 0.9021, 0.9078, 0.9445, 0.8121, 0.9314, 0.9126, 0.9368, 0.9662, 0.8616, 0.9278, 0.9997, 0.9287, 0.9296, 0.8677, 0.5973, 0.9405, 0.6192, 0.9178, 0.8627, 0.8558, 0.9017, 0.9051, 0.9534, 0.8456, 0.7781, 0.9124, 0.7934, 0.8256, 0.9582, 0.89, 0.8145, 0.9717, 0.93, 0.7008, 0.8508, 0.7462, 0.8024, 0.9257, 0.9717, 0.8875, 0.971, 0.9483, 0.9386, 0.8637, 0.8019, 0.9412, 0.9661, 0.9671, 0.9141, 0.9302, 0.7214, 0.8771, 0.9472, 0.9462, 0.5803, 0.9462, 0.8891, 0.9036, 0.9154, 0.6409, 0.9192, 0.8258, 0.8235, 0.9623, 0.8143, 0.9563, 0.8825, 0.968, 0.9784, 0.8554, 0.5072, 0.904, 0.9192, 0.8176, 0.9579, 0.8237, 0.7847, 0.8957], 'Recall@P=50': [0.7905, 0.9244, 0.956, 0.948, 0.908, 0.852, 0.952, 0.98, 0.624, 0.768, 0.876, 0.952, 0.908, 0.968, 0.884, 0.82, 0.936, 0.752, 0.868, 0.9, 0.964, 0.852, 0.696, 0.908, 0.968, 0.976, 0.848, 0.956, 0.944, 0.968, 0.972, 0.888, 0.948, 1.0, 0.948, 0.948, 0.904, 0.64, 0.98, 0.632, 0.956, 0.94, 0.896, 0.936, 0.92, 0.988, 0.88, 0.816, 0.956, 0.868, 0.884, 0.988, 0.936, 0.912, 0.988, 0.952, 0.744, 0.872, 0.792, 0.852, 0.956, 0.976, 0.916, 0.984, 0.96, 0.956, 0.896, 0.84, 0.964, 0.98, 0.984, 0.948, 0.932, 0.808, 0.892, 0.988, 0.98, 0.544, 0.96, 0.916, 0.94, 0.94, 0.676, 0.956, 0.852, 0.872, 0.984, 0.872, 0.968, 0.932, 0.98, 0.984, 0.88, 0.556, 0.94, 0.92, 0.84, 0.976, 0.884, 0.844, 0.896], 'micro': 0.8717, 'macro': 0.8652, 'weighted': 0.8635}
2024-07-17 06:07:01 - [34m[1mLOGS   [0m - Best checkpoint with score 83.55 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:07:03 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_82.6641.pt
2024-07-17 06:07:03 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_82.8711.pt', 'checkpoint_score_83.0859.pt', 'checkpoint_score_83.1719.pt', 'checkpoint_score_83.4570.pt', 'checkpoint_score_83.5547.pt']
2024-07-17 06:07:09 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:07:13 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:07:14 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:07:19 - [34m[1mLOGS   [0m - Training checkpoint for epoch 94/iteration 10634 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_94_iter_10634.pt
2024-07-17 06:07:20 - [34m[1mLOGS   [0m - Model state for epoch 94/iteration 10634 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_94_iter_10634.pt
[31m===========================================================================[0m
2024-07-17 06:07:22 - [32m[1mINFO   [0m - Training epoch 95
2024-07-17 06:07:24 - [34m[1mLOGS   [0m - Epoch:  95 [   10635/10000000], loss: {'classification': 1.7243, 'neural_augmentation': 0.7993, 'total_loss': 2.5236}, LR: [6e-06, 6e-06], Avg. batch load time: 1.483, Elapsed time:  1.69
2024-07-17 06:07:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 95
	 loss={'classification': 1.6809, 'neural_augmentation': 0.801, 'total_loss': 2.4819}
2024-07-17 06:07:59 - [34m[1mLOGS   [0m - *** Validation summary for epoch 95
	 loss={'classification': 0.6906, 'neural_augmentation': 0.0, 'total_loss': 0.6906} || top1={'logits': 83.7656} || top5={'logits': 96.3789} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6535, 0.8099, 0.8674, 0.898, 0.837, 0.7822, 0.8584, 0.9378, 0.5825, 0.6733, 0.7773, 0.876, 0.8467, 0.8307, 0.8608, 0.7837, 0.8627, 0.6816, 0.8, 0.8, 0.9106, 0.7303, 0.59, 0.8603, 0.8872, 0.8858, 0.7485, 0.9155, 0.859, 0.8917, 0.9489, 0.8271, 0.9002, 0.994, 0.8843, 0.8848, 0.8128, 0.5732, 0.8957, 0.5983, 0.8653, 0.8289, 0.7926, 0.8467, 0.8668, 0.9006, 0.78, 0.74, 0.8458, 0.7114, 0.7553, 0.8852, 0.8594, 0.7826, 0.9421, 0.8889, 0.6694, 0.8071, 0.6845, 0.7371, 0.8606, 0.9457, 0.8243, 0.9469, 0.9136, 0.9038, 0.8176, 0.7672, 0.8916, 0.9576, 0.9374, 0.8629, 0.9011, 0.6851, 0.8297, 0.8907, 0.904, 0.5509, 0.9061, 0.8292, 0.8397, 0.8515, 0.6273, 0.8968, 0.7748, 0.7853, 0.9069, 0.7766, 0.9237, 0.8313, 0.9551, 0.9514, 0.811, 0.5297, 0.8392, 0.8791, 0.778, 0.911, 0.7864, 0.7361, 0.8692], 'AP': [0.6947, 0.8795, 0.9265, 0.9361, 0.8792, 0.8259, 0.908, 0.9697, 0.5816, 0.7187, 0.8401, 0.9319, 0.8953, 0.9093, 0.8826, 0.8187, 0.9148, 0.7255, 0.8362, 0.8633, 0.9524, 0.7965, 0.5588, 0.9047, 0.9143, 0.9424, 0.813, 0.9316, 0.9109, 0.9442, 0.9675, 0.8768, 0.9298, 0.9998, 0.9263, 0.9332, 0.8665, 0.5946, 0.9459, 0.6222, 0.9222, 0.8592, 0.8592, 0.9094, 0.9096, 0.9574, 0.8435, 0.7804, 0.9117, 0.7898, 0.8222, 0.9585, 0.8949, 0.8179, 0.9703, 0.93, 0.7005, 0.8579, 0.7465, 0.7989, 0.9261, 0.9713, 0.8898, 0.9702, 0.951, 0.943, 0.8658, 0.8001, 0.9432, 0.9673, 0.9698, 0.9182, 0.9336, 0.7297, 0.8803, 0.9469, 0.9525, 0.5854, 0.945, 0.8921, 0.9075, 0.9147, 0.652, 0.9201, 0.8268, 0.826, 0.9638, 0.8237, 0.9592, 0.8855, 0.9688, 0.9771, 0.8556, 0.5131, 0.9067, 0.9191, 0.8165, 0.9587, 0.8226, 0.7848, 0.8991], 'Recall@P=50': [0.8221, 0.9186, 0.956, 0.948, 0.916, 0.86, 0.956, 0.98, 0.644, 0.776, 0.88, 0.952, 0.916, 0.956, 0.888, 0.836, 0.936, 0.752, 0.872, 0.888, 0.98, 0.856, 0.68, 0.92, 0.972, 0.976, 0.832, 0.956, 0.932, 0.968, 0.968, 0.9, 0.956, 1.0, 0.948, 0.956, 0.904, 0.632, 0.976, 0.624, 0.956, 0.94, 0.9, 0.952, 0.932, 0.988, 0.88, 0.828, 0.96, 0.868, 0.864, 0.988, 0.948, 0.912, 0.988, 0.952, 0.756, 0.876, 0.792, 0.844, 0.956, 0.976, 0.928, 0.984, 0.96, 0.956, 0.896, 0.844, 0.968, 0.98, 0.984, 0.952, 0.932, 0.812, 0.896, 0.988, 0.984, 0.588, 0.952, 0.916, 0.944, 0.944, 0.684, 0.956, 0.86, 0.872, 0.984, 0.88, 0.972, 0.936, 0.988, 0.984, 0.876, 0.524, 0.94, 0.916, 0.848, 0.976, 0.876, 0.84, 0.896], 'micro': 0.8743, 'macro': 0.8672, 'weighted': 0.8656}
2024-07-17 06:08:03 - [34m[1mLOGS   [0m - Best checkpoint with score 83.77 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:08:05 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_82.8711.pt
2024-07-17 06:08:05 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.0859.pt', 'checkpoint_score_83.1719.pt', 'checkpoint_score_83.4570.pt', 'checkpoint_score_83.5547.pt', 'checkpoint_score_83.7656.pt']
2024-07-17 06:08:12 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:08:16 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:08:17 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:08:21 - [34m[1mLOGS   [0m - Training checkpoint for epoch 95/iteration 10752 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_95_iter_10752.pt
2024-07-17 06:08:22 - [34m[1mLOGS   [0m - Model state for epoch 95/iteration 10752 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_95_iter_10752.pt
[31m===========================================================================[0m
2024-07-17 06:08:24 - [32m[1mINFO   [0m - Training epoch 96
2024-07-17 06:08:24 - [34m[1mLOGS   [0m - Epoch:  96 [   10753/10000000], loss: {'classification': 1.6389, 'neural_augmentation': 0.8052, 'total_loss': 2.4441}, LR: [6e-06, 6e-06], Avg. batch load time: 0.361, Elapsed time:  0.57
2024-07-17 06:08:48 - [34m[1mLOGS   [0m - *** Training summary for epoch 96
	 loss={'classification': 1.6933, 'neural_augmentation': 0.8085, 'total_loss': 2.5019}
2024-07-17 06:08:58 - [34m[1mLOGS   [0m - *** Validation summary for epoch 96
	 loss={'classification': 0.6892, 'neural_augmentation': 0.0, 'total_loss': 0.6892} || top1={'logits': 83.7656} || top5={'logits': 96.5039} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6632, 0.8158, 0.8837, 0.8921, 0.8428, 0.7854, 0.8617, 0.9366, 0.5692, 0.686, 0.7845, 0.8789, 0.8471, 0.8322, 0.8577, 0.7868, 0.869, 0.6832, 0.806, 0.8, 0.9079, 0.7344, 0.5904, 0.8627, 0.8919, 0.8858, 0.758, 0.9163, 0.8642, 0.895, 0.9493, 0.8098, 0.8998, 0.994, 0.8866, 0.8898, 0.8147, 0.5795, 0.8957, 0.6018, 0.8619, 0.8352, 0.8008, 0.8373, 0.8657, 0.9028, 0.7889, 0.7539, 0.8399, 0.7135, 0.7656, 0.8916, 0.8629, 0.7758, 0.9463, 0.8861, 0.671, 0.8161, 0.6765, 0.7467, 0.8589, 0.9461, 0.8354, 0.9508, 0.9196, 0.9036, 0.8233, 0.7669, 0.8907, 0.9576, 0.9336, 0.8642, 0.8981, 0.6977, 0.8312, 0.8929, 0.9034, 0.5483, 0.9083, 0.8333, 0.8369, 0.8548, 0.6318, 0.8955, 0.7844, 0.7856, 0.9046, 0.7872, 0.9302, 0.834, 0.956, 0.9576, 0.8094, 0.5333, 0.8351, 0.8742, 0.7785, 0.9128, 0.7919, 0.7354, 0.8716], 'AP': [0.6958, 0.8813, 0.9299, 0.9358, 0.8787, 0.8286, 0.9118, 0.9675, 0.5777, 0.7289, 0.8424, 0.9324, 0.8946, 0.9135, 0.8821, 0.8253, 0.917, 0.7234, 0.84, 0.8668, 0.9515, 0.7955, 0.5644, 0.9049, 0.9202, 0.9448, 0.8164, 0.9325, 0.913, 0.9432, 0.9705, 0.8699, 0.93, 0.9998, 0.9291, 0.9332, 0.8719, 0.5992, 0.9417, 0.6269, 0.9217, 0.8562, 0.8596, 0.907, 0.908, 0.9538, 0.8494, 0.7947, 0.9114, 0.7966, 0.8322, 0.9603, 0.8962, 0.8139, 0.9715, 0.9305, 0.7094, 0.8613, 0.7453, 0.806, 0.9236, 0.9719, 0.8961, 0.9708, 0.9504, 0.9437, 0.8701, 0.8051, 0.9436, 0.9648, 0.9681, 0.9181, 0.9331, 0.7362, 0.8777, 0.9472, 0.9503, 0.5896, 0.9487, 0.8938, 0.9071, 0.9192, 0.6693, 0.9177, 0.8374, 0.8268, 0.9628, 0.8313, 0.9586, 0.8869, 0.9669, 0.9789, 0.8614, 0.512, 0.907, 0.9177, 0.8235, 0.9603, 0.823, 0.7843, 0.8995], 'Recall@P=50': [0.8103, 0.936, 0.956, 0.944, 0.912, 0.856, 0.952, 0.976, 0.628, 0.788, 0.88, 0.952, 0.912, 0.96, 0.884, 0.852, 0.944, 0.736, 0.876, 0.9, 0.98, 0.852, 0.716, 0.916, 0.976, 0.98, 0.84, 0.956, 0.94, 0.968, 0.98, 0.904, 0.952, 1.0, 0.948, 0.952, 0.9, 0.636, 0.964, 0.628, 0.956, 0.932, 0.896, 0.94, 0.928, 0.988, 0.876, 0.832, 0.948, 0.888, 0.892, 0.988, 0.944, 0.916, 0.984, 0.952, 0.792, 0.888, 0.8, 0.856, 0.952, 0.976, 0.94, 0.98, 0.96, 0.96, 0.892, 0.836, 0.972, 0.98, 0.984, 0.952, 0.936, 0.808, 0.892, 0.988, 0.984, 0.572, 0.968, 0.916, 0.94, 0.944, 0.704, 0.952, 0.868, 0.872, 0.984, 0.88, 0.964, 0.932, 0.984, 0.98, 0.888, 0.492, 0.948, 0.916, 0.844, 0.972, 0.876, 0.836, 0.904], 'micro': 0.8744, 'macro': 0.869, 'weighted': 0.8673}
2024-07-17 06:09:03 - [34m[1mLOGS   [0m - Best checkpoint with score 83.77 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:09:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:09:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:09:15 - [34m[1mLOGS   [0m - Training checkpoint for epoch 96/iteration 10859 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_96_iter_10859.pt
2024-07-17 06:09:16 - [34m[1mLOGS   [0m - Model state for epoch 96/iteration 10859 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_96_iter_10859.pt
[31m===========================================================================[0m
2024-07-17 06:09:18 - [32m[1mINFO   [0m - Training epoch 97
2024-07-17 06:09:19 - [34m[1mLOGS   [0m - Epoch:  97 [   10860/10000000], loss: {'classification': 1.5836, 'neural_augmentation': 0.827, 'total_loss': 2.4106}, LR: [5e-06, 5e-06], Avg. batch load time: 0.630, Elapsed time:  0.85
2024-07-17 06:09:42 - [34m[1mLOGS   [0m - *** Training summary for epoch 97
	 loss={'classification': 1.6809, 'neural_augmentation': 0.816, 'total_loss': 2.4969}
2024-07-17 06:09:53 - [34m[1mLOGS   [0m - *** Validation summary for epoch 97
	 loss={'classification': 0.6879, 'neural_augmentation': 0.0, 'total_loss': 0.6879} || top1={'logits': 83.8047} || top5={'logits': 96.4766} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6557, 0.8259, 0.8761, 0.9049, 0.8361, 0.7932, 0.8648, 0.94, 0.5672, 0.6871, 0.7835, 0.8654, 0.8481, 0.8313, 0.8577, 0.7846, 0.8721, 0.686, 0.8178, 0.8053, 0.9095, 0.7373, 0.5943, 0.8531, 0.8884, 0.8858, 0.7595, 0.9148, 0.8578, 0.8871, 0.9487, 0.8207, 0.8979, 0.994, 0.8821, 0.8907, 0.8128, 0.5943, 0.9027, 0.607, 0.8548, 0.8333, 0.8033, 0.8478, 0.8697, 0.9016, 0.7824, 0.7588, 0.844, 0.7198, 0.7696, 0.8866, 0.8607, 0.7683, 0.9465, 0.8884, 0.6722, 0.8122, 0.6788, 0.7452, 0.8669, 0.9441, 0.83, 0.9532, 0.9177, 0.9053, 0.833, 0.7741, 0.8884, 0.9613, 0.9295, 0.8637, 0.9036, 0.6983, 0.8294, 0.8934, 0.9026, 0.5447, 0.9079, 0.8403, 0.8348, 0.8565, 0.6336, 0.8998, 0.7828, 0.7874, 0.908, 0.7815, 0.9308, 0.8444, 0.9571, 0.9535, 0.805, 0.5317, 0.8362, 0.8742, 0.781, 0.9128, 0.7904, 0.7406, 0.8685], 'AP': [0.7004, 0.8837, 0.9277, 0.9391, 0.8849, 0.8322, 0.9088, 0.9697, 0.5805, 0.7336, 0.8449, 0.9284, 0.8956, 0.9136, 0.8844, 0.8225, 0.9203, 0.7293, 0.8442, 0.8687, 0.9497, 0.801, 0.567, 0.9022, 0.9196, 0.9438, 0.814, 0.9321, 0.9138, 0.9405, 0.9726, 0.8728, 0.9281, 0.9998, 0.9287, 0.9365, 0.866, 0.6066, 0.9419, 0.6346, 0.9168, 0.8477, 0.8645, 0.9138, 0.9054, 0.9565, 0.849, 0.798, 0.9126, 0.7974, 0.8397, 0.9579, 0.8967, 0.812, 0.9711, 0.9333, 0.7026, 0.8641, 0.7383, 0.7995, 0.9287, 0.9719, 0.8925, 0.9698, 0.9487, 0.9451, 0.8725, 0.8096, 0.944, 0.9642, 0.9662, 0.9151, 0.9331, 0.7387, 0.8803, 0.9471, 0.9522, 0.5948, 0.9479, 0.8981, 0.9053, 0.9164, 0.6662, 0.9219, 0.8376, 0.8265, 0.9613, 0.8303, 0.9614, 0.8861, 0.9689, 0.9791, 0.8565, 0.5101, 0.9063, 0.9162, 0.8224, 0.9597, 0.8269, 0.7906, 0.8998], 'Recall@P=50': [0.7945, 0.9331, 0.952, 0.952, 0.912, 0.86, 0.96, 0.98, 0.62, 0.78, 0.896, 0.952, 0.916, 0.96, 0.888, 0.84, 0.948, 0.74, 0.872, 0.908, 0.96, 0.856, 0.712, 0.912, 0.972, 0.98, 0.844, 0.96, 0.94, 0.968, 0.984, 0.9, 0.948, 1.0, 0.948, 0.964, 0.904, 0.636, 0.98, 0.648, 0.96, 0.94, 0.9, 0.952, 0.92, 0.988, 0.868, 0.828, 0.948, 0.876, 0.896, 0.988, 0.948, 0.912, 0.984, 0.956, 0.756, 0.892, 0.804, 0.86, 0.968, 0.976, 0.924, 0.988, 0.956, 0.96, 0.896, 0.836, 0.968, 0.98, 0.984, 0.952, 0.936, 0.804, 0.896, 0.98, 0.984, 0.58, 0.96, 0.928, 0.94, 0.944, 0.712, 0.952, 0.868, 0.888, 0.98, 0.888, 0.968, 0.932, 0.984, 0.984, 0.888, 0.5, 0.944, 0.92, 0.852, 0.976, 0.876, 0.848, 0.908], 'micro': 0.875, 'macro': 0.8696, 'weighted': 0.868}
2024-07-17 06:09:57 - [34m[1mLOGS   [0m - Best checkpoint with score 83.80 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:09:59 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.0859.pt
2024-07-17 06:09:59 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.1719.pt', 'checkpoint_score_83.4570.pt', 'checkpoint_score_83.5547.pt', 'checkpoint_score_83.7656.pt', 'checkpoint_score_83.8047.pt']
2024-07-17 06:10:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:10:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:10:11 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:10:16 - [34m[1mLOGS   [0m - Training checkpoint for epoch 97/iteration 10969 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_97_iter_10969.pt
2024-07-17 06:10:17 - [34m[1mLOGS   [0m - Model state for epoch 97/iteration 10969 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_97_iter_10969.pt
[31m===========================================================================[0m
2024-07-17 06:10:19 - [32m[1mINFO   [0m - Training epoch 98
2024-07-17 06:10:20 - [34m[1mLOGS   [0m - Epoch:  98 [   10970/10000000], loss: {'classification': 1.6832, 'neural_augmentation': 0.8168, 'total_loss': 2.5}, LR: [5e-06, 5e-06], Avg. batch load time: 0.419, Elapsed time:  0.64
2024-07-17 06:10:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 98
	 loss={'classification': 1.684, 'neural_augmentation': 0.8227, 'total_loss': 2.5067}
2024-07-17 06:10:52 - [34m[1mLOGS   [0m - *** Validation summary for epoch 98
	 loss={'classification': 0.6777, 'neural_augmentation': 0.0, 'total_loss': 0.6777} || top1={'logits': 84.0117} || top5={'logits': 96.4727} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6583, 0.8185, 0.8809, 0.8975, 0.8444, 0.7759, 0.8612, 0.9366, 0.5731, 0.6899, 0.7866, 0.8862, 0.839, 0.8333, 0.859, 0.7857, 0.8727, 0.6787, 0.8062, 0.8079, 0.9125, 0.7385, 0.5876, 0.86, 0.8924, 0.884, 0.7554, 0.9125, 0.8671, 0.8986, 0.9514, 0.8199, 0.8998, 0.996, 0.8884, 0.8917, 0.8191, 0.5912, 0.8975, 0.5978, 0.8768, 0.8336, 0.8067, 0.8534, 0.8714, 0.9002, 0.7882, 0.7475, 0.8589, 0.7205, 0.7791, 0.893, 0.8566, 0.785, 0.9465, 0.8876, 0.6748, 0.8162, 0.6808, 0.7633, 0.8656, 0.9499, 0.8285, 0.9485, 0.9146, 0.9072, 0.8235, 0.781, 0.8943, 0.9572, 0.9306, 0.8649, 0.902, 0.6987, 0.8312, 0.896, 0.9091, 0.5566, 0.9042, 0.833, 0.8399, 0.8683, 0.639, 0.8945, 0.7863, 0.7879, 0.9109, 0.7841, 0.9286, 0.8326, 0.9597, 0.9572, 0.8117, 0.5366, 0.8333, 0.8805, 0.7797, 0.9102, 0.7929, 0.7432, 0.8703], 'AP': [0.7009, 0.8807, 0.9301, 0.9394, 0.8864, 0.8316, 0.9106, 0.9702, 0.5794, 0.7326, 0.8494, 0.9343, 0.8934, 0.9153, 0.8834, 0.8295, 0.9208, 0.7233, 0.8456, 0.8694, 0.9527, 0.7963, 0.5661, 0.9077, 0.9265, 0.9458, 0.8183, 0.9341, 0.916, 0.9436, 0.9712, 0.8752, 0.9267, 0.9998, 0.9323, 0.9368, 0.8745, 0.6102, 0.9402, 0.6289, 0.9293, 0.8532, 0.8641, 0.9137, 0.9104, 0.9551, 0.8523, 0.7971, 0.9179, 0.7988, 0.8394, 0.9591, 0.8979, 0.8267, 0.971, 0.932, 0.715, 0.8654, 0.7477, 0.815, 0.9316, 0.9735, 0.8946, 0.9718, 0.952, 0.9448, 0.8749, 0.8162, 0.9474, 0.9644, 0.9678, 0.9207, 0.9347, 0.7389, 0.879, 0.9485, 0.9562, 0.6044, 0.9484, 0.8941, 0.9069, 0.9248, 0.6743, 0.9197, 0.8445, 0.8326, 0.9632, 0.8296, 0.9634, 0.8892, 0.9695, 0.9797, 0.8592, 0.5136, 0.9078, 0.9203, 0.8236, 0.9627, 0.8261, 0.7935, 0.9025], 'Recall@P=50': [0.8103, 0.936, 0.96, 0.956, 0.916, 0.868, 0.952, 0.98, 0.632, 0.78, 0.896, 0.952, 0.92, 0.968, 0.888, 0.84, 0.948, 0.728, 0.876, 0.904, 0.98, 0.852, 0.704, 0.916, 0.976, 0.976, 0.848, 0.956, 0.944, 0.968, 0.976, 0.908, 0.94, 1.0, 0.948, 0.952, 0.912, 0.644, 0.976, 0.656, 0.956, 0.944, 0.904, 0.94, 0.924, 0.988, 0.872, 0.836, 0.952, 0.872, 0.896, 0.988, 0.944, 0.916, 0.98, 0.952, 0.796, 0.888, 0.808, 0.868, 0.956, 0.976, 0.932, 0.984, 0.96, 0.96, 0.896, 0.848, 0.972, 0.98, 0.984, 0.952, 0.944, 0.808, 0.9, 0.988, 0.984, 0.576, 0.968, 0.916, 0.94, 0.948, 0.724, 0.956, 0.872, 0.872, 0.984, 0.884, 0.972, 0.944, 0.988, 0.984, 0.904, 0.528, 0.944, 0.916, 0.848, 0.98, 0.872, 0.852, 0.904], 'micro': 0.8777, 'macro': 0.8719, 'weighted': 0.8702}
2024-07-17 06:10:56 - [34m[1mLOGS   [0m - Best checkpoint with score 84.01 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:10:58 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.1719.pt
2024-07-17 06:10:58 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.4570.pt', 'checkpoint_score_83.5547.pt', 'checkpoint_score_83.7656.pt', 'checkpoint_score_83.8047.pt', 'checkpoint_score_84.0117.pt']
2024-07-17 06:11:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:11:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:11:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:11:14 - [34m[1mLOGS   [0m - Training checkpoint for epoch 98/iteration 11068 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_98_iter_11068.pt
2024-07-17 06:11:15 - [34m[1mLOGS   [0m - Model state for epoch 98/iteration 11068 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_98_iter_11068.pt
[31m===========================================================================[0m
2024-07-17 06:11:17 - [32m[1mINFO   [0m - Training epoch 99
2024-07-17 06:11:18 - [34m[1mLOGS   [0m - Epoch:  99 [   11069/10000000], loss: {'classification': 1.5373, 'neural_augmentation': 0.8359, 'total_loss': 2.3732}, LR: [5e-06, 5e-06], Avg. batch load time: 0.865, Elapsed time:  1.08
2024-07-17 06:11:41 - [34m[1mLOGS   [0m - *** Training summary for epoch 99
	 loss={'classification': 1.6601, 'neural_augmentation': 0.8303, 'total_loss': 2.4904}
2024-07-17 06:11:49 - [33m[1mWARNING[0m - Found recall at precision 0.51875 when recall at precision 0.5 was requested.
2024-07-17 06:11:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 99
	 loss={'classification': 0.6707, 'neural_augmentation': 0.0, 'total_loss': 0.6707} || top1={'logits': 84.0898} || top5={'logits': 96.625} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.661, 0.8228, 0.879, 0.9035, 0.8441, 0.7913, 0.8623, 0.9378, 0.5862, 0.6953, 0.7888, 0.8785, 0.8477, 0.8401, 0.8577, 0.7832, 0.8696, 0.6871, 0.8114, 0.8097, 0.9187, 0.7397, 0.591, 0.8571, 0.8958, 0.8853, 0.7655, 0.9121, 0.8615, 0.894, 0.9551, 0.8333, 0.9021, 0.996, 0.8921, 0.8902, 0.817, 0.5904, 0.8994, 0.6046, 0.8641, 0.8308, 0.8049, 0.8697, 0.8662, 0.8957, 0.7873, 0.7667, 0.8542, 0.7254, 0.7733, 0.8911, 0.8653, 0.7848, 0.9487, 0.9008, 0.7066, 0.8214, 0.6761, 0.7619, 0.8651, 0.948, 0.834, 0.9487, 0.9132, 0.9034, 0.8327, 0.7789, 0.8866, 0.9597, 0.9325, 0.8665, 0.9045, 0.7031, 0.8309, 0.8952, 0.9066, 0.5605, 0.9073, 0.8344, 0.8448, 0.8607, 0.6348, 0.8954, 0.7867, 0.7941, 0.9087, 0.7796, 0.9325, 0.8276, 0.9577, 0.959, 0.8186, 0.5451, 0.843, 0.8845, 0.789, 0.9165, 0.7921, 0.7516, 0.8661], 'AP': [0.7077, 0.8825, 0.9325, 0.9425, 0.8878, 0.834, 0.9113, 0.9707, 0.5914, 0.7343, 0.854, 0.9367, 0.8964, 0.9165, 0.8853, 0.8289, 0.9207, 0.729, 0.8493, 0.8689, 0.9532, 0.7994, 0.5748, 0.9071, 0.9245, 0.9449, 0.8269, 0.935, 0.914, 0.9419, 0.973, 0.8761, 0.9297, 0.9999, 0.9313, 0.9392, 0.8761, 0.6038, 0.9436, 0.6297, 0.9256, 0.8503, 0.8663, 0.9165, 0.9061, 0.954, 0.8556, 0.8029, 0.9198, 0.8046, 0.837, 0.9621, 0.901, 0.8277, 0.9715, 0.9352, 0.7302, 0.8678, 0.7418, 0.8135, 0.9302, 0.973, 0.9011, 0.9719, 0.9513, 0.9463, 0.8754, 0.8164, 0.9451, 0.9681, 0.9677, 0.9197, 0.9341, 0.7414, 0.8823, 0.9478, 0.9529, 0.6038, 0.9507, 0.8966, 0.909, 0.9204, 0.6679, 0.9203, 0.8387, 0.8368, 0.9662, 0.8318, 0.9639, 0.8875, 0.9696, 0.9799, 0.8645, 0.524, 0.9092, 0.9229, 0.8308, 0.9624, 0.8298, 0.794, 0.9025], 'Recall@P=50': [0.8221, 0.9302, 0.96, 0.952, 0.916, 0.876, 0.956, 0.984, 0.656, 0.8, 0.888, 0.952, 0.916, 0.964, 0.884, 0.852, 0.948, 0.752, 0.884, 0.912, 0.972, 0.856, 0.716, 0.928, 0.972, 0.98, 0.856, 0.956, 0.944, 0.968, 0.976, 0.904, 0.944, 1.0, 0.948, 0.968, 0.904, 0.656, 0.98, 0.664, 0.96, 0.008, 0.908, 0.948, 0.92, 0.988, 0.88, 0.836, 0.956, 0.876, 0.88, 0.988, 0.952, 0.932, 0.98, 0.952, 0.796, 0.9, 0.8, 0.856, 0.96, 0.976, 0.936, 0.98, 0.96, 0.96, 0.904, 0.844, 0.972, 0.98, 0.984, 0.952, 0.936, 0.804, 0.892, 0.988, 0.984, 0.612, 0.972, 0.916, 0.944, 0.952, 0.712, 0.96, 0.872, 0.888, 0.984, 0.888, 0.976, 0.94, 0.988, 0.984, 0.892, 0.588, 0.948, 0.924, 0.86, 0.976, 0.884, 0.86, 0.912], 'micro': 0.8793, 'macro': 0.8733, 'weighted': 0.8717}
2024-07-17 06:11:56 - [34m[1mLOGS   [0m - Best checkpoint with score 84.09 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:11:57 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.4570.pt
2024-07-17 06:11:57 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.5547.pt', 'checkpoint_score_83.7656.pt', 'checkpoint_score_83.8047.pt', 'checkpoint_score_84.0117.pt', 'checkpoint_score_84.0898.pt']
2024-07-17 06:12:05 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:12:09 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:12:10 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:12:13 - [34m[1mLOGS   [0m - Training checkpoint for epoch 99/iteration 11177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_99_iter_11177.pt
2024-07-17 06:12:14 - [34m[1mLOGS   [0m - Model state for epoch 99/iteration 11177 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_99_iter_11177.pt
[31m===========================================================================[0m
2024-07-17 06:12:16 - [32m[1mINFO   [0m - Training epoch 100
2024-07-17 06:12:17 - [34m[1mLOGS   [0m - Epoch: 100 [   11178/10000000], loss: {'classification': 1.5229, 'neural_augmentation': 0.8377, 'total_loss': 2.3606}, LR: [5e-06, 5e-06], Avg. batch load time: 1.285, Elapsed time:  1.50
2024-07-17 06:12:40 - [34m[1mLOGS   [0m - *** Training summary for epoch 100
	 loss={'classification': 1.6507, 'neural_augmentation': 0.8367, 'total_loss': 2.4874}
2024-07-17 06:12:51 - [34m[1mLOGS   [0m - *** Validation summary for epoch 100
	 loss={'classification': 0.6683, 'neural_augmentation': 0.0, 'total_loss': 0.6683} || top1={'logits': 84.2891} || top5={'logits': 96.6016} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6646, 0.8178, 0.8731, 0.9031, 0.8412, 0.7789, 0.8634, 0.94, 0.582, 0.6899, 0.7951, 0.8808, 0.8482, 0.833, 0.8584, 0.8009, 0.8731, 0.6883, 0.8069, 0.8079, 0.9133, 0.7322, 0.6031, 0.8655, 0.8928, 0.8853, 0.7667, 0.9118, 0.8699, 0.8982, 0.951, 0.829, 0.8987, 0.994, 0.8889, 0.8862, 0.8228, 0.5789, 0.8961, 0.6078, 0.8696, 0.834, 0.8083, 0.8584, 0.8685, 0.9069, 0.7773, 0.7561, 0.8583, 0.7291, 0.7904, 0.8917, 0.8605, 0.7815, 0.9487, 0.899, 0.6962, 0.8191, 0.6859, 0.765, 0.8612, 0.9501, 0.8323, 0.9551, 0.9118, 0.9057, 0.8286, 0.7884, 0.8975, 0.9569, 0.9292, 0.8667, 0.9073, 0.7071, 0.8211, 0.8961, 0.9037, 0.5642, 0.9061, 0.8421, 0.8443, 0.8595, 0.6463, 0.8983, 0.7816, 0.7948, 0.9113, 0.7802, 0.9283, 0.836, 0.9576, 0.9577, 0.8243, 0.5353, 0.8447, 0.8758, 0.7892, 0.9134, 0.7927, 0.7449, 0.8703], 'AP': [0.7127, 0.8796, 0.9306, 0.9409, 0.8892, 0.827, 0.913, 0.9705, 0.5913, 0.7384, 0.8552, 0.9349, 0.9036, 0.9171, 0.8866, 0.8298, 0.9228, 0.7317, 0.8483, 0.8709, 0.954, 0.798, 0.5928, 0.9129, 0.9216, 0.9478, 0.8261, 0.9372, 0.9184, 0.9448, 0.9732, 0.8833, 0.9289, 0.9998, 0.9341, 0.9347, 0.8778, 0.601, 0.9448, 0.6344, 0.9273, 0.8642, 0.8694, 0.9168, 0.9068, 0.9605, 0.8507, 0.7975, 0.922, 0.8113, 0.845, 0.9591, 0.8971, 0.8259, 0.9703, 0.9363, 0.7298, 0.8693, 0.7568, 0.8175, 0.9302, 0.9742, 0.8976, 0.9729, 0.9509, 0.9454, 0.8719, 0.8226, 0.9494, 0.9666, 0.9667, 0.9183, 0.9328, 0.7547, 0.8819, 0.9505, 0.9544, 0.6051, 0.95, 0.8992, 0.9091, 0.919, 0.6761, 0.9232, 0.8341, 0.8371, 0.9658, 0.8314, 0.9624, 0.8931, 0.9691, 0.98, 0.8657, 0.5248, 0.9132, 0.9221, 0.8312, 0.9635, 0.8318, 0.7883, 0.9012], 'Recall@P=50': [0.8261, 0.939, 0.96, 0.948, 0.932, 0.86, 0.96, 0.98, 0.648, 0.788, 0.892, 0.952, 0.92, 0.964, 0.892, 0.836, 0.948, 0.76, 0.876, 0.908, 0.98, 0.86, 0.728, 0.916, 0.98, 0.976, 0.852, 0.956, 0.952, 0.968, 0.98, 0.912, 0.94, 1.0, 0.948, 0.952, 0.904, 0.648, 0.98, 0.676, 0.956, 0.936, 0.904, 0.952, 0.924, 0.988, 0.88, 0.832, 0.952, 0.884, 0.896, 0.988, 0.94, 0.924, 0.984, 0.96, 0.796, 0.892, 0.8, 0.872, 0.964, 0.98, 0.928, 0.984, 0.96, 0.964, 0.9, 0.848, 0.968, 0.98, 0.984, 0.952, 0.944, 0.82, 0.9, 0.984, 0.984, 0.592, 0.972, 0.924, 0.944, 0.948, 0.712, 0.956, 0.852, 0.888, 0.984, 0.888, 0.972, 0.944, 0.984, 0.984, 0.904, 0.54, 0.952, 0.92, 0.856, 0.98, 0.88, 0.836, 0.912], 'micro': 0.8803, 'macro': 0.8746, 'weighted': 0.873}
2024-07-17 06:12:54 - [34m[1mLOGS   [0m - Best checkpoint with score 84.29 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:12:56 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.5547.pt
2024-07-17 06:12:56 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.7656.pt', 'checkpoint_score_83.8047.pt', 'checkpoint_score_84.0117.pt', 'checkpoint_score_84.0898.pt', 'checkpoint_score_84.2891.pt']
2024-07-17 06:13:01 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:13:03 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:13:04 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:13:06 - [34m[1mLOGS   [0m - Training checkpoint for epoch 100/iteration 11291 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_100_iter_11291.pt
2024-07-17 06:13:07 - [34m[1mLOGS   [0m - Model state for epoch 100/iteration 11291 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_100_iter_11291.pt
[31m===========================================================================[0m
2024-07-17 06:13:09 - [32m[1mINFO   [0m - Training epoch 101
2024-07-17 06:13:11 - [34m[1mLOGS   [0m - Epoch: 101 [   11292/10000000], loss: {'classification': 1.6728, 'neural_augmentation': 0.843, 'total_loss': 2.5158}, LR: [5e-06, 5e-06], Avg. batch load time: 1.593, Elapsed time:  1.80
2024-07-17 06:13:34 - [34m[1mLOGS   [0m - *** Training summary for epoch 101
	 loss={'classification': 1.6427, 'neural_augmentation': 0.8443, 'total_loss': 2.487}
2024-07-17 06:13:45 - [34m[1mLOGS   [0m - *** Validation summary for epoch 101
	 loss={'classification': 0.6634, 'neural_augmentation': 0.0, 'total_loss': 0.6634} || top1={'logits': 84.3047} || top5={'logits': 96.6602} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6685, 0.8246, 0.8831, 0.9036, 0.841, 0.783, 0.8619, 0.9402, 0.5779, 0.692, 0.7854, 0.8803, 0.8505, 0.8379, 0.8595, 0.7895, 0.8701, 0.6889, 0.8158, 0.8061, 0.9208, 0.7371, 0.6, 0.8661, 0.8963, 0.8853, 0.7692, 0.9132, 0.8641, 0.8929, 0.9512, 0.8316, 0.9006, 0.994, 0.8856, 0.8925, 0.8178, 0.581, 0.9002, 0.6128, 0.8735, 0.833, 0.8139, 0.8584, 0.871, 0.9012, 0.7821, 0.7629, 0.8543, 0.7358, 0.7816, 0.888, 0.8634, 0.7819, 0.9506, 0.9024, 0.7023, 0.818, 0.6872, 0.7696, 0.8694, 0.9514, 0.8316, 0.9551, 0.9174, 0.9034, 0.8316, 0.7807, 0.8952, 0.9593, 0.9287, 0.8724, 0.9128, 0.7111, 0.8392, 0.897, 0.908, 0.5647, 0.9084, 0.8481, 0.8449, 0.863, 0.6496, 0.8992, 0.7879, 0.7915, 0.908, 0.7808, 0.9314, 0.835, 0.9613, 0.9577, 0.8207, 0.5458, 0.8482, 0.875, 0.7956, 0.9152, 0.796, 0.751, 0.871], 'AP': [0.7167, 0.8837, 0.9322, 0.9411, 0.8888, 0.8324, 0.9127, 0.9708, 0.5883, 0.7403, 0.8552, 0.9357, 0.9027, 0.9188, 0.8883, 0.8289, 0.9231, 0.737, 0.8495, 0.8758, 0.955, 0.8007, 0.5917, 0.9076, 0.9243, 0.9479, 0.8274, 0.9377, 0.9172, 0.9437, 0.973, 0.8806, 0.9285, 0.9998, 0.933, 0.9398, 0.8791, 0.6019, 0.9469, 0.6395, 0.9271, 0.8561, 0.8698, 0.9162, 0.9084, 0.9582, 0.8545, 0.8019, 0.9188, 0.8152, 0.8485, 0.9573, 0.8998, 0.8213, 0.9706, 0.9398, 0.7323, 0.8691, 0.7496, 0.8199, 0.933, 0.9738, 0.895, 0.974, 0.9535, 0.9457, 0.876, 0.821, 0.9467, 0.9645, 0.9673, 0.9197, 0.936, 0.7507, 0.8888, 0.9483, 0.9544, 0.6078, 0.9528, 0.9023, 0.9132, 0.923, 0.6851, 0.9206, 0.8392, 0.8334, 0.9626, 0.8326, 0.9632, 0.8887, 0.9698, 0.9807, 0.8695, 0.5303, 0.9147, 0.9214, 0.8325, 0.964, 0.8347, 0.7968, 0.9035], 'Recall@P=50': [0.8182, 0.936, 0.956, 0.944, 0.928, 0.872, 0.956, 0.984, 0.652, 0.788, 0.9, 0.952, 0.924, 0.968, 0.892, 0.84, 0.952, 0.768, 0.876, 0.916, 0.976, 0.86, 0.744, 0.908, 0.968, 0.984, 0.852, 0.956, 0.944, 0.968, 0.98, 0.912, 0.948, 1.0, 0.948, 0.964, 0.912, 0.64, 0.988, 0.668, 0.964, 0.94, 0.9, 0.948, 0.924, 0.992, 0.888, 0.836, 0.948, 0.888, 0.904, 0.984, 0.948, 0.928, 0.984, 0.96, 0.788, 0.892, 0.8, 0.876, 0.964, 0.98, 0.924, 0.988, 0.96, 0.964, 0.904, 0.848, 0.972, 0.98, 0.984, 0.952, 0.936, 0.828, 0.904, 0.98, 0.984, 0.604, 0.972, 0.92, 0.948, 0.952, 0.732, 0.956, 0.864, 0.872, 0.984, 0.892, 0.968, 0.94, 0.988, 0.984, 0.9, 0.584, 0.952, 0.92, 0.856, 0.98, 0.88, 0.844, 0.912], 'micro': 0.881, 'macro': 0.8755, 'weighted': 0.8739}
2024-07-17 06:13:49 - [34m[1mLOGS   [0m - Best checkpoint with score 84.30 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:13:50 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.7656.pt
2024-07-17 06:13:50 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_83.8047.pt', 'checkpoint_score_84.0117.pt', 'checkpoint_score_84.0898.pt', 'checkpoint_score_84.2891.pt', 'checkpoint_score_84.3047.pt']
2024-07-17 06:13:55 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:13:57 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:13:58 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:14:00 - [34m[1mLOGS   [0m - Training checkpoint for epoch 101/iteration 11406 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_101_iter_11406.pt
2024-07-17 06:14:01 - [34m[1mLOGS   [0m - Model state for epoch 101/iteration 11406 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_101_iter_11406.pt
[31m===========================================================================[0m
2024-07-17 06:14:03 - [32m[1mINFO   [0m - Training epoch 102
2024-07-17 06:14:05 - [34m[1mLOGS   [0m - Epoch: 102 [   11407/10000000], loss: {'classification': 1.6087, 'neural_augmentation': 0.8488, 'total_loss': 2.4575}, LR: [4e-06, 4e-06], Avg. batch load time: 1.439, Elapsed time:  1.65
2024-07-17 06:14:29 - [34m[1mLOGS   [0m - *** Training summary for epoch 102
	 loss={'classification': 1.637, 'neural_augmentation': 0.8508, 'total_loss': 2.4877}
2024-07-17 06:14:38 - [33m[1mWARNING[0m - Found recall at precision 0.5169082125603864 when recall at precision 0.5 was requested.
2024-07-17 06:14:40 - [34m[1mLOGS   [0m - *** Validation summary for epoch 102
	 loss={'classification': 0.6628, 'neural_augmentation': 0.0, 'total_loss': 0.6628} || top1={'logits': 84.3008} || top5={'logits': 96.6055} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6735, 0.8173, 0.887, 0.914, 0.849, 0.7852, 0.8601, 0.9424, 0.592, 0.6916, 0.7975, 0.8875, 0.8524, 0.8452, 0.8601, 0.7868, 0.8769, 0.6911, 0.8101, 0.8044, 0.9198, 0.7458, 0.5964, 0.8584, 0.8959, 0.8862, 0.7666, 0.9102, 0.8627, 0.8898, 0.9516, 0.8355, 0.9011, 0.994, 0.8843, 0.8912, 0.8277, 0.5828, 0.8994, 0.6066, 0.8755, 0.8327, 0.8143, 0.865, 0.8703, 0.8957, 0.7872, 0.7667, 0.8655, 0.7417, 0.7842, 0.8898, 0.8627, 0.7867, 0.9506, 0.8898, 0.6912, 0.825, 0.6928, 0.7635, 0.872, 0.951, 0.833, 0.951, 0.9196, 0.9053, 0.8347, 0.7808, 0.8903, 0.9618, 0.9287, 0.8664, 0.908, 0.6987, 0.8261, 0.8955, 0.9163, 0.5702, 0.9087, 0.847, 0.8529, 0.871, 0.6444, 0.8971, 0.787, 0.8017, 0.913, 0.7804, 0.9308, 0.8307, 0.9615, 0.9574, 0.8202, 0.5458, 0.853, 0.887, 0.795, 0.9084, 0.7992, 0.7465, 0.8753], 'AP': [0.7176, 0.8791, 0.936, 0.9459, 0.8947, 0.839, 0.9133, 0.9701, 0.6016, 0.7375, 0.8609, 0.9391, 0.9037, 0.9207, 0.8881, 0.8303, 0.9223, 0.7362, 0.8492, 0.8724, 0.9539, 0.8041, 0.5881, 0.9105, 0.9278, 0.95, 0.8273, 0.9362, 0.9175, 0.9433, 0.9756, 0.8804, 0.9312, 0.9998, 0.9341, 0.9371, 0.8784, 0.6009, 0.9467, 0.6331, 0.9304, 0.8532, 0.8708, 0.919, 0.9063, 0.9564, 0.8577, 0.8068, 0.9253, 0.8164, 0.8404, 0.9625, 0.9026, 0.8259, 0.9717, 0.9358, 0.7265, 0.8744, 0.7578, 0.8139, 0.9343, 0.9747, 0.8996, 0.9742, 0.9529, 0.9465, 0.8748, 0.818, 0.9516, 0.9669, 0.9666, 0.9182, 0.9359, 0.7441, 0.8826, 0.951, 0.9563, 0.6134, 0.9475, 0.9003, 0.9109, 0.9256, 0.6734, 0.9214, 0.8437, 0.8408, 0.9664, 0.8292, 0.9635, 0.8911, 0.9724, 0.9803, 0.8702, 0.5295, 0.9165, 0.9243, 0.8356, 0.9609, 0.8367, 0.7983, 0.9036], 'Recall@P=50': [0.8142, 0.9302, 0.96, 0.956, 0.924, 0.876, 0.956, 0.976, 0.648, 0.788, 0.896, 0.956, 0.924, 0.964, 0.892, 0.852, 0.948, 0.772, 0.88, 0.908, 0.968, 0.856, 0.724, 0.912, 0.972, 0.988, 0.86, 0.956, 0.952, 0.968, 0.984, 0.908, 0.948, 1.0, 0.952, 0.956, 0.912, 0.64, 0.98, 0.656, 0.956, 0.944, 0.908, 0.948, 0.92, 0.988, 0.888, 0.828, 0.96, 0.884, 0.88, 0.992, 0.952, 0.924, 0.98, 0.96, 0.8, 0.896, 0.8, 0.864, 0.964, 0.98, 0.928, 0.98, 0.96, 0.964, 0.896, 0.84, 0.976, 0.98, 0.984, 0.944, 0.94, 0.816, 0.892, 0.988, 0.984, 0.608, 0.964, 0.924, 0.94, 0.948, 0.736, 0.952, 0.856, 0.884, 0.984, 0.888, 0.968, 0.944, 0.988, 0.984, 0.892, 0.588, 0.956, 0.924, 0.856, 0.976, 0.884, 0.844, 0.916], 'micro': 0.8824, 'macro': 0.8762, 'weighted': 0.8746}
2024-07-17 06:14:45 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:14:46 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:14:50 - [34m[1mLOGS   [0m - Training checkpoint for epoch 102/iteration 11523 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_102_iter_11523.pt
2024-07-17 06:14:51 - [34m[1mLOGS   [0m - Model state for epoch 102/iteration 11523 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_102_iter_11523.pt
[31m===========================================================================[0m
2024-07-17 06:14:54 - [32m[1mINFO   [0m - Training epoch 103
2024-07-17 06:14:54 - [34m[1mLOGS   [0m - Epoch: 103 [   11524/10000000], loss: {'classification': 1.6498, 'neural_augmentation': 0.8465, 'total_loss': 2.4962}, LR: [4e-06, 4e-06], Avg. batch load time: 0.389, Elapsed time:  0.61
2024-07-17 06:15:18 - [34m[1mLOGS   [0m - *** Training summary for epoch 103
	 loss={'classification': 1.6281, 'neural_augmentation': 0.8557, 'total_loss': 2.4838}
2024-07-17 06:15:28 - [34m[1mLOGS   [0m - *** Validation summary for epoch 103
	 loss={'classification': 0.6543, 'neural_augmentation': 0.0, 'total_loss': 0.6543} || top1={'logits': 84.5781} || top5={'logits': 96.7852} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6785, 0.826, 0.887, 0.9036, 0.843, 0.7862, 0.8635, 0.9378, 0.587, 0.7027, 0.7933, 0.8884, 0.856, 0.8386, 0.8664, 0.7919, 0.8782, 0.6883, 0.8085, 0.8078, 0.924, 0.7431, 0.6028, 0.8644, 0.8998, 0.8893, 0.7635, 0.9167, 0.8686, 0.8948, 0.9532, 0.8344, 0.8983, 0.994, 0.8858, 0.9042, 0.8245, 0.5932, 0.9024, 0.622, 0.874, 0.8477, 0.8162, 0.8589, 0.8753, 0.9032, 0.795, 0.7715, 0.8602, 0.7381, 0.7879, 0.8926, 0.861, 0.7792, 0.9506, 0.8988, 0.6923, 0.8211, 0.6916, 0.7662, 0.8717, 0.9518, 0.8371, 0.9526, 0.9148, 0.9049, 0.8306, 0.7862, 0.8934, 0.9618, 0.9306, 0.8625, 0.9128, 0.7073, 0.8273, 0.8946, 0.9127, 0.5725, 0.908, 0.8553, 0.8481, 0.8682, 0.6443, 0.8977, 0.7903, 0.7983, 0.9087, 0.7865, 0.9308, 0.8369, 0.9634, 0.9533, 0.8182, 0.5475, 0.853, 0.8777, 0.8, 0.9162, 0.7967, 0.7484, 0.8716], 'AP': [0.7282, 0.8872, 0.9329, 0.9425, 0.8926, 0.8362, 0.9131, 0.9696, 0.5999, 0.7415, 0.8597, 0.9359, 0.9072, 0.9187, 0.8906, 0.8308, 0.9255, 0.7395, 0.8511, 0.876, 0.957, 0.8089, 0.5948, 0.9117, 0.9271, 0.9494, 0.8291, 0.9396, 0.9202, 0.9451, 0.9754, 0.8855, 0.9282, 0.9998, 0.9329, 0.9419, 0.8763, 0.6212, 0.9472, 0.6571, 0.9316, 0.8657, 0.8748, 0.9183, 0.9092, 0.9601, 0.8582, 0.8106, 0.924, 0.8166, 0.8519, 0.961, 0.904, 0.823, 0.9711, 0.9372, 0.7296, 0.8755, 0.7539, 0.8238, 0.9325, 0.9735, 0.9033, 0.9751, 0.9537, 0.9486, 0.874, 0.827, 0.9483, 0.9645, 0.9689, 0.9175, 0.9378, 0.754, 0.8884, 0.9477, 0.9561, 0.6065, 0.9529, 0.9048, 0.9144, 0.9245, 0.6866, 0.9241, 0.8438, 0.8422, 0.9654, 0.8393, 0.9614, 0.895, 0.9704, 0.98, 0.8699, 0.5276, 0.9168, 0.9228, 0.8391, 0.966, 0.8332, 0.8027, 0.9054], 'Recall@P=50': [0.834, 0.936, 0.96, 0.948, 0.928, 0.872, 0.956, 0.976, 0.672, 0.796, 0.9, 0.952, 0.928, 0.964, 0.888, 0.856, 0.952, 0.768, 0.88, 0.904, 0.976, 0.872, 0.74, 0.928, 0.976, 0.984, 0.864, 0.956, 0.948, 0.968, 0.984, 0.912, 0.952, 1.0, 0.948, 0.964, 0.912, 0.664, 0.98, 0.692, 0.96, 0.944, 0.9, 0.952, 0.924, 0.996, 0.88, 0.836, 0.952, 0.892, 0.904, 0.988, 0.948, 0.932, 0.98, 0.96, 0.796, 0.908, 0.796, 0.876, 0.968, 0.98, 0.94, 0.984, 0.96, 0.964, 0.9, 0.852, 0.972, 0.98, 0.984, 0.948, 0.948, 0.828, 0.9, 0.988, 0.984, 0.604, 0.976, 0.928, 0.94, 0.948, 0.736, 0.96, 0.872, 0.884, 0.98, 0.896, 0.968, 0.952, 0.988, 0.984, 0.9, 0.584, 0.96, 0.928, 0.86, 0.98, 0.884, 0.856, 0.92], 'micro': 0.8837, 'macro': 0.8781, 'weighted': 0.8767}
2024-07-17 06:15:32 - [34m[1mLOGS   [0m - Best checkpoint with score 84.58 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:15:34 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_83.8047.pt
2024-07-17 06:15:34 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_84.0117.pt', 'checkpoint_score_84.0898.pt', 'checkpoint_score_84.2891.pt', 'checkpoint_score_84.3047.pt', 'checkpoint_score_84.5781.pt']
2024-07-17 06:15:40 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:15:43 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:15:43 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:15:47 - [34m[1mLOGS   [0m - Training checkpoint for epoch 103/iteration 11635 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_103_iter_11635.pt
2024-07-17 06:15:49 - [34m[1mLOGS   [0m - Model state for epoch 103/iteration 11635 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_103_iter_11635.pt
[31m===========================================================================[0m
2024-07-17 06:15:51 - [32m[1mINFO   [0m - Training epoch 104
2024-07-17 06:15:51 - [34m[1mLOGS   [0m - Epoch: 104 [   11636/10000000], loss: {'classification': 1.4921, 'neural_augmentation': 0.8596, 'total_loss': 2.3517}, LR: [4e-06, 4e-06], Avg. batch load time: 0.389, Elapsed time:  0.61
2024-07-17 06:16:13 - [34m[1mLOGS   [0m - *** Training summary for epoch 104
	 loss={'classification': 1.6479, 'neural_augmentation': 0.861, 'total_loss': 2.509}
2024-07-17 06:16:21 - [33m[1mWARNING[0m - Found recall at precision 0.5157657657657657 when recall at precision 0.5 was requested.
2024-07-17 06:16:23 - [34m[1mLOGS   [0m - *** Validation summary for epoch 104
	 loss={'classification': 0.6533, 'neural_augmentation': 0.0, 'total_loss': 0.6533} || top1={'logits': 84.6641} || top5={'logits': 96.7188} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6733, 0.8207, 0.8879, 0.9, 0.8402, 0.7804, 0.8654, 0.9429, 0.592, 0.6998, 0.7942, 0.8761, 0.8501, 0.8423, 0.8608, 0.7902, 0.8755, 0.6917, 0.8151, 0.8126, 0.9231, 0.7383, 0.612, 0.8714, 0.896, 0.8916, 0.766, 0.9143, 0.8675, 0.8974, 0.9532, 0.8366, 0.9023, 0.996, 0.8903, 0.8971, 0.8188, 0.5957, 0.9014, 0.6263, 0.8696, 0.8413, 0.8136, 0.8584, 0.8721, 0.9091, 0.7881, 0.7732, 0.8503, 0.738, 0.7865, 0.8853, 0.865, 0.7865, 0.9489, 0.908, 0.7011, 0.8248, 0.6948, 0.7702, 0.8704, 0.9516, 0.8399, 0.9532, 0.9157, 0.9079, 0.8347, 0.7913, 0.9024, 0.9618, 0.9333, 0.8737, 0.9095, 0.7137, 0.8277, 0.8992, 0.9109, 0.5725, 0.9095, 0.8505, 0.8553, 0.8745, 0.6557, 0.9015, 0.793, 0.8087, 0.9146, 0.7884, 0.9305, 0.8431, 0.9598, 0.9555, 0.8188, 0.5515, 0.8494, 0.8845, 0.7991, 0.9155, 0.8008, 0.7557, 0.8703], 'AP': [0.7269, 0.8826, 0.9325, 0.9414, 0.8873, 0.8341, 0.9123, 0.9736, 0.6091, 0.7459, 0.8598, 0.9334, 0.9064, 0.9229, 0.8897, 0.8302, 0.9247, 0.7418, 0.8515, 0.8791, 0.9557, 0.808, 0.5971, 0.9141, 0.9266, 0.951, 0.832, 0.9403, 0.9226, 0.9448, 0.9758, 0.8877, 0.9314, 0.9998, 0.9358, 0.943, 0.8809, 0.6164, 0.9489, 0.6512, 0.9287, 0.8712, 0.873, 0.9197, 0.9138, 0.9604, 0.8555, 0.8073, 0.9198, 0.8186, 0.8514, 0.9592, 0.9061, 0.8303, 0.9713, 0.9409, 0.7333, 0.8794, 0.7605, 0.8275, 0.9309, 0.9732, 0.9063, 0.9741, 0.9532, 0.9497, 0.8788, 0.8293, 0.9495, 0.9658, 0.9701, 0.9261, 0.9386, 0.7601, 0.8901, 0.9516, 0.9578, 0.6163, 0.9555, 0.9007, 0.9141, 0.9267, 0.6987, 0.9259, 0.8429, 0.8435, 0.9669, 0.843, 0.9672, 0.8954, 0.9702, 0.9807, 0.8723, 0.5354, 0.9176, 0.923, 0.8396, 0.9663, 0.8324, 0.7987, 0.9055], 'Recall@P=50': [0.8379, 0.9419, 0.952, 0.948, 0.92, 0.872, 0.956, 0.98, 0.672, 0.796, 0.904, 0.952, 0.928, 0.976, 0.892, 0.856, 0.952, 0.772, 0.864, 0.908, 0.98, 0.868, 0.736, 0.924, 0.976, 0.988, 0.864, 0.96, 0.956, 0.972, 0.984, 0.92, 0.956, 1.0, 0.948, 0.964, 0.912, 0.656, 0.98, 0.688, 0.96, 0.94, 0.904, 0.952, 0.932, 0.996, 0.88, 0.832, 0.952, 0.892, 0.904, 0.984, 0.952, 0.944, 0.984, 0.96, 0.812, 0.916, 0.816, 0.876, 0.964, 0.976, 0.94, 0.984, 0.96, 0.96, 0.904, 0.848, 0.972, 0.98, 0.984, 0.96, 0.948, 0.832, 0.904, 0.988, 0.984, 0.632, 0.976, 0.92, 0.944, 0.948, 0.736, 0.96, 0.868, 0.892, 0.988, 0.896, 0.972, 0.94, 0.988, 0.984, 0.896, 0.612, 0.96, 0.924, 0.868, 0.984, 0.88, 0.848, 0.916], 'micro': 0.8844, 'macro': 0.8794, 'weighted': 0.8779}
2024-07-17 06:16:27 - [34m[1mLOGS   [0m - Best checkpoint with score 84.66 saved at /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_best.pt
2024-07-17 06:16:29 - [34m[1mLOGS   [0m - Deleting checkpoint: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_score_84.0117.pt
2024-07-17 06:16:29 - [34m[1mLOGS   [0m - Averaging checkpoints: ['checkpoint_score_84.0898.pt', 'checkpoint_score_84.2891.pt', 'checkpoint_score_84.3047.pt', 'checkpoint_score_84.5781.pt', 'checkpoint_score_84.6641.pt']
2024-07-17 06:16:34 - [34m[1mLOGS   [0m - Averaged checkpoint saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_avg.pt
2024-07-17 06:16:37 - [34m[1mLOGS   [0m - Last training checkpoint is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_last.pt
2024-07-17 06:16:38 - [34m[1mLOGS   [0m - Last checkpoint's model state is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_last.pt
2024-07-17 06:16:42 - [34m[1mLOGS   [0m - Training checkpoint for epoch 104/iteration 11737 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/training_checkpoint_epoch_104_iter_11737.pt
2024-07-17 06:16:43 - [34m[1mLOGS   [0m - Model state for epoch 104/iteration 11737 is saved at: /ML-A100/team/mm/models/catlip_data/single_base_500/train/checkpoint_epoch_104_iter_11737.pt
[31m===========================================================================[0m
2024-07-17 06:16:45 - [32m[1mINFO   [0m - Training epoch 105
2024-07-17 06:16:47 - [34m[1mLOGS   [0m - Epoch: 105 [   11738/10000000], loss: {'classification': 1.7937, 'neural_augmentation': 0.8663, 'total_loss': 2.66}, LR: [4e-06, 4e-06], Avg. batch load time: 1.985, Elapsed time:  2.20
2024-07-17 06:17:12 - [34m[1mLOGS   [0m - *** Training summary for epoch 105
	 loss={'classification': 1.6157, 'neural_augmentation': 0.8668, 'total_loss': 2.4825}
2024-07-17 06:17:22 - [34m[1mLOGS   [0m - *** Validation summary for epoch 105
	 loss={'classification': 0.6473, 'neural_augmentation': 0.0, 'total_loss': 0.6473} || top1={'logits': 84.7891} || top5={'logits': 96.8203} || multiclass_classification_pr(pred=logits)={'ODS-F1': [0.6721, 0.8289, 0.8865, 0.9034, 0.843, 0.7851, 0.8671, 0.9426, 0.5904, 0.7, 0.8034, 0.888, 0.8476, 0.8507, 0.8596, 0.7852, 0.8785, 0.6892, 0.8188, 0.8107, 0.925, 0.7461, 0.6069, 0.8632, 0.9006, 0.8924, 0.7634, 0.9162, 0.8694, 0.9018, 0.9556, 0.8388, 0.9002, 0.996, 0.8884, 0.8939, 0.8228, 0.6016, 0.9039, 0.621, 0.8727, 0.8454, 0.8115, 0.8675, 0.8773, 0.902, 0.7906, 0.7746, 0.8628, 0.7383, 0.7845, 0.891, 0.866, 0.7856, 0.9489, 0.8986, 0.6969, 0.8326, 0.7061, 0.7702, 0.8673, 0.9495, 0.8361, 0.9533, 0.9165, 0.9125, 0.8484, 0.7826, 0.8902, 0.9598, 0.9295, 0.8689, 0.9098, 0.7122, 0.8292, 0.8946, 0.9152, 0.5802, 0.9124, 0.8541, 0.8541, 0.8655, 0.6514, 0.8975, 0.8009, 0.806, 0.9135, 0.7891, 0.9314, 0.8417, 0.9655, 0.9576, 0.8194, 0.5511, 0.8547, 0.8879, 0.8018, 0.9125, 0.8067, 0.7432, 0.8661], 'AP': [0.7243, 0.8876, 0.9354, 0.9427, 0.8924, 0.8374, 0.913, 0.9718, 0.6117, 0.7418, 0.8611, 0.9385, 0.9031, 0.9225, 0.8897, 0.827, 0.9267, 0.7417, 0.8588, 0.8777, 0.9557, 0.8076, 0.6003, 0.9129, 0.9257, 0.9488, 0.8341, 0.9379, 0.9203, 0.9492, 0.9751, 0.8864, 0.9336, 0.9998, 0.9346, 0.9429, 0.8814, 0.6194, 0.9499, 0.6483, 0.9308, 0.8689, 0.8712, 0.9215, 0.913, 0.9594, 0.8604, 0.8107, 0.9242, 0.8159, 0.8524, 0.9609, 0.9052, 0.8331, 0.9719, 0.9375, 0.7381, 0.8817, 0.7624, 0.8254, 0.933, 0.9731, 0.9069, 0.9745, 0.9554, 0.9493, 0.8812, 0.8254, 0.9492, 0.9661, 0.9681, 0.9243, 0.9385, 0.7618, 0.8897, 0.9493, 0.9594, 0.6216, 0.9551, 0.9028, 0.9148, 0.9247, 0.6978, 0.9214, 0.8434, 0.8496, 0.966, 0.8444, 0.9667, 0.8934, 0.9705, 0.9805, 0.8751, 0.5363, 0.9166, 0.9261, 0.8411, 0.9653, 0.8373, 0.7988, 0.9086], 'Recall@P=50': [0.8379, 0.9448, 0.956, 0.948, 0.916, 0.876, 0.956, 0.984, 0.684, 0.804, 0.9, 0.952, 0.928, 0.968, 0.892, 0.852, 0.948, 0.78, 0.884, 0.912, 0.972, 0.872, 0.732, 0.924, 0.976, 0.984, 0.876, 0.96, 0.952, 0.976, 0.984, 0.912, 0.952, 1.0, 0.948, 0.964, 0.912, 0.652, 0.988, 0.684, 0.968, 0.94, 0.9, 0.948, 0.928, 0.996, 0.888, 0.84, 0.952, 0.884, 0.904, 0.984, 0.952, 0.932, 0.984, 0.96, 0.8, 0.916, 0.812, 0.876, 0.976, 0.976, 0.948, 0.988, 0.96, 0.964, 0.9, 0.848, 0.972, 0.98, 0.984, 0.96, 0.952, 0.828, 0.904, 0.988, 0.984, 0.648, 0.972, 0.92, 0.944, 0.956, 0.736, 0.96, 0.872, 0.888, 0.984, 0.896, 0.984, 0.944, 0.988, 0.984, 0.9, 0.604, 0.952, 0.928, 0.856, 0.984, 0.888, 0.852, 0.936], 'micro': 0.8863, 'macro': 0.88, 'weighted': 0.8784}
